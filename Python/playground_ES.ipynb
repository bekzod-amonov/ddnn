{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c374a9b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/ddnn/lib/python3.11/site-packages/keras/src/export/tf2onnx_lib.py:8: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n",
      "  if not hasattr(np, \"object\"):\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.compat.v2 as tf\n",
    "tf.enable_v2_behavior()\n",
    "import tensorflow_probability as tfp  \n",
    "from tensorflow_probability import distributions as tfd\n",
    "import tf_keras as keras\n",
    "from multiprocessing import Pool\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "import logging\n",
    "import sys\n",
    "import os, getpass\n",
    "import glob\n",
    "import optuna\n",
    "from optuna.trial import TrialState\n",
    "import time\n",
    "import math\n",
    "import json\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d6b702c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ES Normal\n"
     ]
    }
   ],
   "source": [
    "distribution = 'Normal'\n",
    "paramcount = {'Normal': 2,\n",
    "              'StudentT': 3,\n",
    "              'JSU': 4,\n",
    "              'SinhArcsinh': 4,\n",
    "              'NormalInverseGaussian': 4,\n",
    "              'Point': None}\n",
    "val_multi = 3 # int for # of re-trains - 1 corresponds to old approach\n",
    "val_window = 364 // val_multi\n",
    "\n",
    "if not os.path.exists(f'../trialfiles'):\n",
    "    os.mkdir(f'../trialfiles')\n",
    "\n",
    "INP_SIZE = 221\n",
    "activations = ['sigmoid', 'relu', 'elu', 'tanh', 'softplus', 'softmax']\n",
    "\n",
    "binopt = [True, False]\n",
    "\n",
    "cty = 'ES'\n",
    "repo_root = Path.cwd()\n",
    "storeDBintmp = False\n",
    "\n",
    "print(cty, distribution)\n",
    "\n",
    "if cty != 'ES':\n",
    "    raise ValueError('Incorrect country')\n",
    "if distribution not in paramcount:\n",
    "    raise ValueError('Incorrect distribution')\n",
    "\n",
    "# read data file\n",
    "data       = pd.read_csv(repo_root / \"Datasets\" / f\"{cty}.csv\", index_col=0) \n",
    "data.index = [datetime.strptime(e, '%Y-%m-%d %H:%M:%S') for e in data.index]\n",
    "data = data.iloc[:4*364*24] # take the first 4 years - 1456 days\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "e918f1be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1092"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_retrain = 3\n",
    "INP_SIZE    = 221\n",
    "activation  = ['sigmoid', 'relu', 'elu', 'leaky_relu', 'tanh', 'softplus', 'softmax']\n",
    "binopt      = [True, False]\n",
    "\n",
    "INIT_DATE_EXP   = date.fromisoformat('2020-01-01') # hyper-parameter tuning: training\n",
    "VAL_INIT_DATE   = date.fromisoformat('2022-12-28') # hyper-parameter tuning: validation\n",
    "TRAIN_END_DATE  = date.fromisoformat('2023-12-27') # hyper-parameter tuning: training\n",
    "FINAL_DATE_EXP  = date.fromisoformat(\"2025-12-31\")\n",
    "\n",
    "train_val_days = (TRAIN_END_DATE - INIT_DATE_EXP).days\n",
    "train_days  = (VAL_INIT_DATE - INIT_DATE_EXP).days\n",
    "val_days   = (TRAIN_END_DATE - VAL_INIT_DATE).days\n",
    "val_window = val_days // num_retrain\n",
    "\n",
    "# eval_days\n",
    "# calib_days\n",
    "train_days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "34a0d796",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'elu'"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activations = ['sigmoid', 'relu', 'elu', 'tanh', 'softplus', 'softmax']\n",
    "activation[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a1afda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting optuna\n",
      "  Downloading optuna-4.7.0-py3-none-any.whl.metadata (17 kB)\n",
      "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from optuna) (1.17.2)\n",
      "Collecting colorlog (from optuna)\n",
      "  Downloading colorlog-6.10.1-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from optuna) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from optuna) (25.0)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.12/dist-packages (from optuna) (2.0.45)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from optuna) (4.67.1)\n",
      "Requirement already satisfied: PyYAML in /usr/local/lib/python3.12/dist-packages (from optuna) (6.0.3)\n",
      "Requirement already satisfied: Mako in /usr/local/lib/python3.12/dist-packages (from alembic>=1.5.0->optuna) (1.3.10)\n",
      "Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.12/dist-packages (from alembic>=1.5.0->optuna) (4.15.0)\n",
      "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.12/dist-packages (from Mako->alembic>=1.5.0->optuna) (3.0.3)\n",
      "Downloading optuna-4.7.0-py3-none-any.whl (413 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m413.9/413.9 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading colorlog-6.10.1-py3-none-any.whl (11 kB)\n",
      "Installing collected packages: colorlog, optuna\n",
      "Successfully installed colorlog-6.10.1 optuna-4.7.0\n",
      "Cloning into 'ddnn-execute-once'...\n",
      "remote: Enumerating objects: 33, done.\u001b[K\n",
      "remote: Counting objects: 100% (33/33), done.\u001b[K\n",
      "remote: Compressing objects: 100% (24/24), done.\u001b[K\n",
      "remote: Total 33 (delta 9), reused 30 (delta 6), pack-reused 0 (from 0)\u001b[K\n",
      "Receiving objects: 100% (33/33), 2.40 MiB | 8.38 MiB/s, done.\n",
      "Resolving deltas: 100% (9/9), done.\n",
      "/content/ddnn-execute-once\n",
      "commands.sh  Datasets  LICENSE\tPython\tREADME.md  trialfiles\n",
      "==================== Obtaining Hyperparameters ====================\n",
      "ES Normal\n",
      "Epoch 1/300\n",
      "5/5 - 2s - loss: 1068.4888 - mae: 69.5578 - val_loss: 1492.5305 - val_mae: 215.4227 - 2s/epoch - 303ms/step\n",
      "Epoch 2/300\n",
      "5/5 - 0s - loss: 325.3448 - mae: 69.2147 - val_loss: 665.4649 - val_mae: 215.2248 - 94ms/epoch - 19ms/step\n",
      "Epoch 3/300\n",
      "5/5 - 0s - loss: 167.9954 - mae: 68.8824 - val_loss: 468.0118 - val_mae: 214.9801 - 89ms/epoch - 18ms/step\n",
      "Epoch 4/300\n",
      "5/5 - 0s - loss: 112.3605 - mae: 68.6202 - val_loss: 372.8315 - val_mae: 214.6589 - 108ms/epoch - 22ms/step\n",
      "Epoch 5/300\n",
      "5/5 - 0s - loss: 86.1566 - mae: 68.4156 - val_loss: 319.6145 - val_mae: 214.0696 - 93ms/epoch - 19ms/step\n",
      "Epoch 6/300\n",
      "5/5 - 0s - loss: 71.9435 - mae: 68.2431 - val_loss: 285.9437 - val_mae: 214.1778 - 88ms/epoch - 18ms/step\n",
      "Epoch 7/300\n",
      "5/5 - 0s - loss: 63.2530 - mae: 68.1049 - val_loss: 262.6508 - val_mae: 214.2266 - 88ms/epoch - 18ms/step\n",
      "Epoch 8/300\n",
      "5/5 - 0s - loss: 57.3800 - mae: 67.9124 - val_loss: 245.4334 - val_mae: 213.5650 - 88ms/epoch - 18ms/step\n",
      "Epoch 9/300\n",
      "5/5 - 0s - loss: 53.2442 - mae: 67.7559 - val_loss: 232.2177 - val_mae: 214.0065 - 96ms/epoch - 19ms/step\n",
      "Epoch 10/300\n",
      "5/5 - 0s - loss: 49.8847 - mae: 67.5618 - val_loss: 221.5574 - val_mae: 213.3491 - 90ms/epoch - 18ms/step\n",
      "Epoch 11/300\n",
      "5/5 - 0s - loss: 47.4152 - mae: 67.5078 - val_loss: 212.7098 - val_mae: 213.3487 - 88ms/epoch - 18ms/step\n",
      "Epoch 12/300\n",
      "5/5 - 0s - loss: 45.2043 - mae: 67.3488 - val_loss: 205.2010 - val_mae: 213.1728 - 112ms/epoch - 22ms/step\n",
      "Epoch 13/300\n",
      "5/5 - 0s - loss: 43.3976 - mae: 67.2590 - val_loss: 198.4482 - val_mae: 213.2401 - 94ms/epoch - 19ms/step\n",
      "Epoch 14/300\n",
      "5/5 - 0s - loss: 41.7627 - mae: 67.1562 - val_loss: 192.4640 - val_mae: 213.1073 - 92ms/epoch - 18ms/step\n",
      "Epoch 15/300\n",
      "5/5 - 0s - loss: 40.3599 - mae: 66.9920 - val_loss: 186.9719 - val_mae: 213.2343 - 95ms/epoch - 19ms/step\n",
      "Epoch 16/300\n",
      "5/5 - 0s - loss: 39.0319 - mae: 66.8085 - val_loss: 181.9311 - val_mae: 212.8506 - 90ms/epoch - 18ms/step\n",
      "Epoch 17/300\n",
      "5/5 - 0s - loss: 37.8199 - mae: 66.7454 - val_loss: 177.2856 - val_mae: 212.4450 - 93ms/epoch - 19ms/step\n",
      "Epoch 18/300\n",
      "5/5 - 0s - loss: 36.6793 - mae: 66.7698 - val_loss: 172.9920 - val_mae: 212.3766 - 89ms/epoch - 18ms/step\n",
      "Epoch 19/300\n",
      "5/5 - 0s - loss: 35.6343 - mae: 66.6044 - val_loss: 168.9664 - val_mae: 212.1991 - 92ms/epoch - 18ms/step\n",
      "Epoch 20/300\n",
      "5/5 - 0s - loss: 34.7968 - mae: 66.5414 - val_loss: 165.1347 - val_mae: 212.5419 - 95ms/epoch - 19ms/step\n",
      "Epoch 21/300\n",
      "5/5 - 0s - loss: 33.8672 - mae: 66.3771 - val_loss: 161.3476 - val_mae: 212.2136 - 96ms/epoch - 19ms/step\n",
      "Epoch 22/300\n",
      "5/5 - 0s - loss: 32.9811 - mae: 66.1944 - val_loss: 157.6347 - val_mae: 211.9641 - 90ms/epoch - 18ms/step\n",
      "Epoch 23/300\n",
      "5/5 - 0s - loss: 32.1796 - mae: 66.1313 - val_loss: 154.0736 - val_mae: 212.0236 - 110ms/epoch - 22ms/step\n",
      "Epoch 24/300\n",
      "5/5 - 0s - loss: 31.4071 - mae: 66.0358 - val_loss: 150.7965 - val_mae: 211.7935 - 88ms/epoch - 18ms/step\n",
      "Epoch 25/300\n",
      "5/5 - 0s - loss: 30.7072 - mae: 65.9335 - val_loss: 147.6741 - val_mae: 211.7913 - 90ms/epoch - 18ms/step\n",
      "Epoch 26/300\n",
      "5/5 - 0s - loss: 30.0184 - mae: 65.9075 - val_loss: 144.7137 - val_mae: 211.7861 - 89ms/epoch - 18ms/step\n",
      "Epoch 27/300\n",
      "5/5 - 0s - loss: 29.3772 - mae: 65.6865 - val_loss: 141.8703 - val_mae: 211.6385 - 87ms/epoch - 17ms/step\n",
      "Epoch 28/300\n",
      "5/5 - 0s - loss: 28.7839 - mae: 65.5695 - val_loss: 139.1832 - val_mae: 210.8501 - 86ms/epoch - 17ms/step\n",
      "Epoch 29/300\n",
      "5/5 - 0s - loss: 28.2106 - mae: 65.5242 - val_loss: 136.6486 - val_mae: 211.1677 - 93ms/epoch - 19ms/step\n",
      "Epoch 30/300\n",
      "5/5 - 0s - loss: 27.7160 - mae: 65.3577 - val_loss: 134.1265 - val_mae: 210.9422 - 93ms/epoch - 19ms/step\n",
      "Epoch 31/300\n",
      "5/5 - 0s - loss: 27.1488 - mae: 65.3710 - val_loss: 131.6348 - val_mae: 211.5222 - 96ms/epoch - 19ms/step\n",
      "Epoch 32/300\n",
      "5/5 - 0s - loss: 26.6571 - mae: 65.1952 - val_loss: 129.2821 - val_mae: 210.6961 - 90ms/epoch - 18ms/step\n",
      "Epoch 33/300\n",
      "5/5 - 0s - loss: 26.1547 - mae: 65.2439 - val_loss: 127.0540 - val_mae: 210.1501 - 91ms/epoch - 18ms/step\n",
      "Epoch 34/300\n",
      "5/5 - 0s - loss: 25.7151 - mae: 64.9500 - val_loss: 124.9519 - val_mae: 209.9796 - 105ms/epoch - 21ms/step\n",
      "Epoch 35/300\n",
      "5/5 - 0s - loss: 25.2832 - mae: 65.1229 - val_loss: 122.9588 - val_mae: 210.6675 - 89ms/epoch - 18ms/step\n",
      "Epoch 36/300\n",
      "5/5 - 0s - loss: 24.8852 - mae: 64.9025 - val_loss: 120.9874 - val_mae: 210.8625 - 89ms/epoch - 18ms/step\n",
      "Epoch 37/300\n",
      "5/5 - 0s - loss: 24.4797 - mae: 64.8298 - val_loss: 119.1211 - val_mae: 209.7634 - 88ms/epoch - 18ms/step\n",
      "Epoch 38/300\n",
      "5/5 - 0s - loss: 24.1368 - mae: 64.6782 - val_loss: 117.3247 - val_mae: 209.9625 - 88ms/epoch - 18ms/step\n",
      "Epoch 39/300\n",
      "5/5 - 0s - loss: 23.7251 - mae: 64.6107 - val_loss: 115.6059 - val_mae: 209.5968 - 88ms/epoch - 18ms/step\n",
      "Epoch 40/300\n",
      "5/5 - 0s - loss: 23.3971 - mae: 64.5745 - val_loss: 113.9669 - val_mae: 209.3492 - 89ms/epoch - 18ms/step\n",
      "Epoch 41/300\n",
      "5/5 - 0s - loss: 23.0688 - mae: 64.4766 - val_loss: 112.3340 - val_mae: 209.6631 - 90ms/epoch - 18ms/step\n",
      "Epoch 42/300\n",
      "5/5 - 0s - loss: 22.7390 - mae: 64.2790 - val_loss: 110.7879 - val_mae: 209.3979 - 86ms/epoch - 17ms/step\n",
      "Epoch 43/300\n",
      "5/5 - 0s - loss: 22.4273 - mae: 64.1463 - val_loss: 109.2772 - val_mae: 209.6204 - 89ms/epoch - 18ms/step\n",
      "Epoch 44/300\n",
      "5/5 - 0s - loss: 22.1355 - mae: 64.0891 - val_loss: 107.8497 - val_mae: 209.2217 - 92ms/epoch - 18ms/step\n",
      "Epoch 45/300\n",
      "5/5 - 0s - loss: 21.8475 - mae: 63.9940 - val_loss: 106.4533 - val_mae: 209.4352 - 111ms/epoch - 22ms/step\n",
      "Epoch 46/300\n",
      "5/5 - 0s - loss: 21.5750 - mae: 63.8008 - val_loss: 105.0880 - val_mae: 209.3013 - 91ms/epoch - 18ms/step\n",
      "Epoch 47/300\n",
      "5/5 - 0s - loss: 21.3088 - mae: 63.7145 - val_loss: 103.7896 - val_mae: 208.9806 - 90ms/epoch - 18ms/step\n",
      "Epoch 48/300\n",
      "5/5 - 0s - loss: 21.0675 - mae: 63.7498 - val_loss: 102.5035 - val_mae: 208.9920 - 91ms/epoch - 18ms/step\n",
      "Epoch 49/300\n",
      "5/5 - 0s - loss: 20.8202 - mae: 63.7583 - val_loss: 101.2666 - val_mae: 209.0083 - 84ms/epoch - 17ms/step\n",
      "Epoch 50/300\n",
      "5/5 - 0s - loss: 20.5479 - mae: 63.5496 - val_loss: 100.0784 - val_mae: 209.1097 - 86ms/epoch - 17ms/step\n",
      "Epoch 51/300\n",
      "5/5 - 0s - loss: 20.3311 - mae: 63.3903 - val_loss: 98.8875 - val_mae: 208.3260 - 90ms/epoch - 18ms/step\n",
      "Epoch 52/300\n",
      "5/5 - 0s - loss: 20.1180 - mae: 63.4687 - val_loss: 97.7311 - val_mae: 208.6418 - 90ms/epoch - 18ms/step\n",
      "Epoch 53/300\n",
      "5/5 - 0s - loss: 19.8848 - mae: 63.2664 - val_loss: 96.6313 - val_mae: 208.3929 - 88ms/epoch - 18ms/step\n",
      "Epoch 54/300\n",
      "5/5 - 0s - loss: 19.6826 - mae: 63.1007 - val_loss: 95.5474 - val_mae: 208.2366 - 88ms/epoch - 18ms/step\n",
      "Epoch 55/300\n",
      "5/5 - 0s - loss: 19.4625 - mae: 63.1062 - val_loss: 94.4967 - val_mae: 208.1426 - 90ms/epoch - 18ms/step\n",
      "Epoch 56/300\n",
      "5/5 - 0s - loss: 19.2689 - mae: 62.9346 - val_loss: 93.4457 - val_mae: 208.6943 - 111ms/epoch - 22ms/step\n",
      "Epoch 57/300\n",
      "5/5 - 0s - loss: 19.0955 - mae: 63.0196 - val_loss: 92.4021 - val_mae: 207.9235 - 90ms/epoch - 18ms/step\n",
      "Epoch 58/300\n",
      "5/5 - 0s - loss: 18.8892 - mae: 62.9085 - val_loss: 91.3563 - val_mae: 207.4395 - 90ms/epoch - 18ms/step\n",
      "Epoch 59/300\n",
      "5/5 - 0s - loss: 18.6923 - mae: 62.8196 - val_loss: 90.3484 - val_mae: 208.0153 - 89ms/epoch - 18ms/step\n",
      "Epoch 60/300\n",
      "5/5 - 0s - loss: 18.5115 - mae: 62.6671 - val_loss: 89.3964 - val_mae: 207.6732 - 91ms/epoch - 18ms/step\n",
      "Epoch 61/300\n",
      "5/5 - 0s - loss: 18.3395 - mae: 62.6205 - val_loss: 88.4673 - val_mae: 207.6072 - 85ms/epoch - 17ms/step\n",
      "Epoch 62/300\n",
      "5/5 - 0s - loss: 18.1634 - mae: 62.5073 - val_loss: 87.5479 - val_mae: 206.7853 - 95ms/epoch - 19ms/step\n",
      "Epoch 63/300\n",
      "5/5 - 0s - loss: 18.0055 - mae: 62.4769 - val_loss: 86.6536 - val_mae: 206.4769 - 88ms/epoch - 18ms/step\n",
      "Epoch 64/300\n",
      "5/5 - 0s - loss: 17.8389 - mae: 62.3071 - val_loss: 85.8167 - val_mae: 207.1291 - 87ms/epoch - 17ms/step\n",
      "Epoch 65/300\n",
      "5/5 - 0s - loss: 17.6867 - mae: 62.5306 - val_loss: 84.9871 - val_mae: 206.9507 - 91ms/epoch - 18ms/step\n",
      "Epoch 66/300\n",
      "5/5 - 0s - loss: 17.5457 - mae: 62.2358 - val_loss: 84.1650 - val_mae: 206.2400 - 98ms/epoch - 20ms/step\n",
      "Epoch 67/300\n",
      "5/5 - 0s - loss: 17.3981 - mae: 62.0896 - val_loss: 83.3624 - val_mae: 207.2210 - 111ms/epoch - 22ms/step\n",
      "Epoch 68/300\n",
      "5/5 - 0s - loss: 17.2479 - mae: 62.1458 - val_loss: 82.5765 - val_mae: 206.9459 - 94ms/epoch - 19ms/step\n",
      "Epoch 69/300\n",
      "5/5 - 0s - loss: 17.1153 - mae: 62.0376 - val_loss: 81.8119 - val_mae: 206.4360 - 90ms/epoch - 18ms/step\n",
      "Epoch 70/300\n",
      "5/5 - 0s - loss: 16.9679 - mae: 61.9492 - val_loss: 81.0674 - val_mae: 206.7636 - 87ms/epoch - 17ms/step\n",
      "Epoch 71/300\n",
      "5/5 - 0s - loss: 16.8369 - mae: 61.9762 - val_loss: 80.3243 - val_mae: 206.1640 - 89ms/epoch - 18ms/step\n",
      "Epoch 72/300\n",
      "5/5 - 0s - loss: 16.6961 - mae: 61.7315 - val_loss: 79.6061 - val_mae: 206.8149 - 92ms/epoch - 18ms/step\n",
      "Epoch 73/300\n",
      "5/5 - 0s - loss: 16.5654 - mae: 61.7871 - val_loss: 78.9009 - val_mae: 205.9464 - 94ms/epoch - 19ms/step\n",
      "Epoch 74/300\n",
      "5/5 - 0s - loss: 16.4425 - mae: 61.6264 - val_loss: 78.2167 - val_mae: 205.8862 - 101ms/epoch - 20ms/step\n",
      "Epoch 75/300\n",
      "5/5 - 0s - loss: 16.3182 - mae: 61.6124 - val_loss: 77.5515 - val_mae: 205.5199 - 85ms/epoch - 17ms/step\n",
      "Epoch 76/300\n",
      "5/5 - 0s - loss: 16.2040 - mae: 61.5019 - val_loss: 76.8701 - val_mae: 205.9440 - 87ms/epoch - 17ms/step\n",
      "Epoch 77/300\n",
      "5/5 - 0s - loss: 16.0822 - mae: 61.6107 - val_loss: 76.2164 - val_mae: 206.0709 - 92ms/epoch - 18ms/step\n",
      "Epoch 78/300\n",
      "5/5 - 0s - loss: 15.9634 - mae: 61.2837 - val_loss: 75.5699 - val_mae: 205.6246 - 110ms/epoch - 22ms/step\n",
      "Epoch 79/300\n",
      "5/5 - 0s - loss: 15.8538 - mae: 61.1804 - val_loss: 74.9358 - val_mae: 204.7435 - 86ms/epoch - 17ms/step\n",
      "Epoch 80/300\n",
      "5/5 - 0s - loss: 15.7371 - mae: 61.0989 - val_loss: 74.3239 - val_mae: 205.7039 - 88ms/epoch - 18ms/step\n",
      "Epoch 81/300\n",
      "5/5 - 0s - loss: 15.6388 - mae: 61.1393 - val_loss: 73.7209 - val_mae: 204.9762 - 87ms/epoch - 17ms/step\n",
      "Epoch 82/300\n",
      "5/5 - 0s - loss: 15.5317 - mae: 61.3054 - val_loss: 73.1289 - val_mae: 205.1095 - 103ms/epoch - 21ms/step\n",
      "Epoch 83/300\n",
      "5/5 - 0s - loss: 15.4198 - mae: 60.9032 - val_loss: 72.5516 - val_mae: 205.2632 - 151ms/epoch - 30ms/step\n",
      "Epoch 84/300\n",
      "5/5 - 0s - loss: 15.3177 - mae: 60.9590 - val_loss: 71.9844 - val_mae: 205.2136 - 158ms/epoch - 32ms/step\n",
      "Epoch 85/300\n",
      "5/5 - 0s - loss: 15.2238 - mae: 60.9446 - val_loss: 71.4153 - val_mae: 205.2543 - 158ms/epoch - 32ms/step\n",
      "Epoch 86/300\n",
      "5/5 - 0s - loss: 15.1293 - mae: 60.8329 - val_loss: 70.8638 - val_mae: 204.4745 - 170ms/epoch - 34ms/step\n",
      "Epoch 87/300\n",
      "5/5 - 0s - loss: 15.0252 - mae: 60.7989 - val_loss: 70.3333 - val_mae: 205.0650 - 157ms/epoch - 31ms/step\n",
      "Epoch 88/300\n",
      "5/5 - 0s - loss: 14.9362 - mae: 60.8022 - val_loss: 69.8083 - val_mae: 203.7700 - 140ms/epoch - 28ms/step\n",
      "Epoch 89/300\n",
      "5/5 - 0s - loss: 14.8422 - mae: 60.8442 - val_loss: 69.2987 - val_mae: 204.2656 - 168ms/epoch - 34ms/step\n",
      "Epoch 90/300\n",
      "5/5 - 0s - loss: 14.7503 - mae: 60.6827 - val_loss: 68.7897 - val_mae: 204.8194 - 150ms/epoch - 30ms/step\n",
      "Epoch 91/300\n",
      "5/5 - 0s - loss: 14.6641 - mae: 60.3742 - val_loss: 68.2817 - val_mae: 204.9865 - 163ms/epoch - 33ms/step\n",
      "Epoch 92/300\n",
      "5/5 - 0s - loss: 14.5736 - mae: 60.6889 - val_loss: 67.7898 - val_mae: 203.5660 - 154ms/epoch - 31ms/step\n",
      "Epoch 93/300\n",
      "5/5 - 0s - loss: 14.4855 - mae: 60.3793 - val_loss: 67.2924 - val_mae: 204.4320 - 143ms/epoch - 29ms/step\n",
      "Epoch 94/300\n",
      "5/5 - 0s - loss: 14.4062 - mae: 60.2843 - val_loss: 66.8047 - val_mae: 204.6783 - 158ms/epoch - 32ms/step\n",
      "Epoch 95/300\n",
      "5/5 - 0s - loss: 14.3197 - mae: 60.2188 - val_loss: 66.3178 - val_mae: 204.0363 - 159ms/epoch - 32ms/step\n",
      "Epoch 96/300\n",
      "5/5 - 0s - loss: 14.2337 - mae: 60.1774 - val_loss: 65.8424 - val_mae: 203.4399 - 168ms/epoch - 34ms/step\n",
      "Epoch 97/300\n",
      "5/5 - 0s - loss: 14.1552 - mae: 60.0517 - val_loss: 65.3817 - val_mae: 203.9137 - 146ms/epoch - 29ms/step\n",
      "Epoch 98/300\n",
      "5/5 - 0s - loss: 14.0728 - mae: 60.2429 - val_loss: 64.9270 - val_mae: 203.9918 - 92ms/epoch - 18ms/step\n",
      "Epoch 99/300\n",
      "5/5 - 0s - loss: 13.9947 - mae: 59.9102 - val_loss: 64.4804 - val_mae: 203.5381 - 89ms/epoch - 18ms/step\n",
      "Epoch 100/300\n",
      "5/5 - 0s - loss: 13.9145 - mae: 59.9325 - val_loss: 64.0492 - val_mae: 203.8896 - 91ms/epoch - 18ms/step\n",
      "Epoch 101/300\n",
      "5/5 - 0s - loss: 13.8456 - mae: 60.0513 - val_loss: 63.6229 - val_mae: 202.6842 - 103ms/epoch - 21ms/step\n",
      "Epoch 102/300\n",
      "5/5 - 0s - loss: 13.7656 - mae: 59.4949 - val_loss: 63.1955 - val_mae: 203.4153 - 110ms/epoch - 22ms/step\n",
      "Epoch 103/300\n",
      "5/5 - 0s - loss: 13.6980 - mae: 59.6286 - val_loss: 62.7695 - val_mae: 203.7232 - 92ms/epoch - 18ms/step\n",
      "Epoch 104/300\n",
      "5/5 - 0s - loss: 13.6190 - mae: 59.7142 - val_loss: 62.3454 - val_mae: 202.8734 - 92ms/epoch - 18ms/step\n",
      "Epoch 105/300\n",
      "5/5 - 0s - loss: 13.5524 - mae: 59.4343 - val_loss: 61.9238 - val_mae: 203.0646 - 91ms/epoch - 18ms/step\n",
      "Epoch 106/300\n",
      "5/5 - 0s - loss: 13.4809 - mae: 59.6387 - val_loss: 61.5260 - val_mae: 202.9426 - 87ms/epoch - 17ms/step\n",
      "Epoch 107/300\n",
      "5/5 - 0s - loss: 13.4136 - mae: 59.6927 - val_loss: 61.1360 - val_mae: 203.1894 - 88ms/epoch - 18ms/step\n",
      "Epoch 108/300\n",
      "5/5 - 0s - loss: 13.3450 - mae: 59.5787 - val_loss: 60.7474 - val_mae: 203.3829 - 91ms/epoch - 18ms/step\n",
      "Epoch 109/300\n",
      "5/5 - 0s - loss: 13.2800 - mae: 59.5245 - val_loss: 60.3669 - val_mae: 202.5118 - 96ms/epoch - 19ms/step\n",
      "Epoch 110/300\n",
      "5/5 - 0s - loss: 13.2212 - mae: 59.3807 - val_loss: 59.9857 - val_mae: 203.1656 - 86ms/epoch - 17ms/step\n",
      "Epoch 111/300\n",
      "5/5 - 0s - loss: 13.1505 - mae: 59.2924 - val_loss: 59.6136 - val_mae: 201.9765 - 87ms/epoch - 17ms/step\n",
      "Epoch 112/300\n",
      "5/5 - 0s - loss: 13.0892 - mae: 59.2843 - val_loss: 59.2439 - val_mae: 202.4875 - 87ms/epoch - 17ms/step\n",
      "Epoch 113/300\n",
      "5/5 - 0s - loss: 13.0269 - mae: 59.1329 - val_loss: 58.8890 - val_mae: 201.4066 - 113ms/epoch - 23ms/step\n",
      "Epoch 114/300\n",
      "5/5 - 0s - loss: 12.9660 - mae: 59.1863 - val_loss: 58.5406 - val_mae: 202.3683 - 93ms/epoch - 19ms/step\n",
      "Epoch 115/300\n",
      "5/5 - 0s - loss: 12.9092 - mae: 59.1165 - val_loss: 58.1921 - val_mae: 201.5752 - 93ms/epoch - 19ms/step\n",
      "Epoch 116/300\n",
      "5/5 - 0s - loss: 12.8509 - mae: 58.8837 - val_loss: 57.8422 - val_mae: 201.8072 - 91ms/epoch - 18ms/step\n",
      "Epoch 117/300\n",
      "5/5 - 0s - loss: 12.7892 - mae: 58.8781 - val_loss: 57.4978 - val_mae: 201.6409 - 89ms/epoch - 18ms/step\n",
      "Epoch 118/300\n",
      "5/5 - 0s - loss: 12.7370 - mae: 58.9249 - val_loss: 57.1580 - val_mae: 201.5634 - 92ms/epoch - 18ms/step\n",
      "Epoch 119/300\n",
      "5/5 - 0s - loss: 12.6780 - mae: 58.9811 - val_loss: 56.8127 - val_mae: 201.1258 - 87ms/epoch - 17ms/step\n",
      "Epoch 120/300\n",
      "5/5 - 0s - loss: 12.6212 - mae: 59.0026 - val_loss: 56.4772 - val_mae: 201.5246 - 87ms/epoch - 17ms/step\n",
      "Epoch 121/300\n",
      "5/5 - 0s - loss: 12.5642 - mae: 58.8022 - val_loss: 56.1587 - val_mae: 201.7354 - 90ms/epoch - 18ms/step\n",
      "Epoch 122/300\n",
      "5/5 - 0s - loss: 12.5102 - mae: 58.5233 - val_loss: 55.8377 - val_mae: 202.1591 - 86ms/epoch - 17ms/step\n",
      "Epoch 123/300\n",
      "5/5 - 0s - loss: 12.4547 - mae: 58.6607 - val_loss: 55.5201 - val_mae: 202.1869 - 86ms/epoch - 17ms/step\n",
      "Epoch 124/300\n",
      "5/5 - 0s - loss: 12.4057 - mae: 58.6501 - val_loss: 55.2103 - val_mae: 200.5380 - 121ms/epoch - 24ms/step\n",
      "Epoch 125/300\n",
      "5/5 - 0s - loss: 12.3508 - mae: 58.4629 - val_loss: 54.8997 - val_mae: 201.3722 - 94ms/epoch - 19ms/step\n",
      "Epoch 126/300\n",
      "5/5 - 0s - loss: 12.2990 - mae: 58.3289 - val_loss: 54.5911 - val_mae: 200.7468 - 90ms/epoch - 18ms/step\n",
      "Epoch 127/300\n",
      "5/5 - 0s - loss: 12.2478 - mae: 58.2898 - val_loss: 54.2836 - val_mae: 201.2000 - 87ms/epoch - 17ms/step\n",
      "Epoch 128/300\n",
      "5/5 - 0s - loss: 12.1964 - mae: 58.4181 - val_loss: 53.9791 - val_mae: 200.2945 - 86ms/epoch - 17ms/step\n",
      "Epoch 129/300\n",
      "5/5 - 0s - loss: 12.1473 - mae: 58.2072 - val_loss: 53.6728 - val_mae: 199.5825 - 90ms/epoch - 18ms/step\n",
      "Epoch 130/300\n",
      "5/5 - 0s - loss: 12.0960 - mae: 58.1866 - val_loss: 53.3816 - val_mae: 201.2254 - 91ms/epoch - 18ms/step\n",
      "Epoch 131/300\n",
      "5/5 - 0s - loss: 12.0526 - mae: 58.1585 - val_loss: 53.0964 - val_mae: 200.3536 - 87ms/epoch - 17ms/step\n",
      "Epoch 132/300\n",
      "5/5 - 0s - loss: 12.0029 - mae: 58.2159 - val_loss: 52.8140 - val_mae: 199.9579 - 86ms/epoch - 17ms/step\n",
      "Epoch 133/300\n",
      "5/5 - 0s - loss: 11.9582 - mae: 58.2208 - val_loss: 52.5332 - val_mae: 200.6001 - 88ms/epoch - 18ms/step\n",
      "Epoch 134/300\n",
      "5/5 - 0s - loss: 11.9102 - mae: 58.0720 - val_loss: 52.2580 - val_mae: 199.6042 - 90ms/epoch - 18ms/step\n",
      "Epoch 135/300\n",
      "5/5 - 0s - loss: 11.8629 - mae: 58.0850 - val_loss: 51.9837 - val_mae: 199.8672 - 113ms/epoch - 23ms/step\n",
      "Epoch 136/300\n",
      "5/5 - 0s - loss: 11.8233 - mae: 58.0247 - val_loss: 51.7076 - val_mae: 199.1437 - 94ms/epoch - 19ms/step\n",
      "Epoch 137/300\n",
      "5/5 - 0s - loss: 11.7744 - mae: 57.9698 - val_loss: 51.4292 - val_mae: 199.9965 - 90ms/epoch - 18ms/step\n",
      "Epoch 138/300\n",
      "5/5 - 0s - loss: 11.7322 - mae: 57.8967 - val_loss: 51.1489 - val_mae: 200.0937 - 86ms/epoch - 17ms/step\n",
      "Epoch 139/300\n",
      "5/5 - 0s - loss: 11.6863 - mae: 57.6216 - val_loss: 50.8761 - val_mae: 200.0547 - 87ms/epoch - 17ms/step\n",
      "Epoch 140/300\n",
      "5/5 - 0s - loss: 11.6405 - mae: 57.8179 - val_loss: 50.6108 - val_mae: 200.0213 - 89ms/epoch - 18ms/step\n",
      "Epoch 141/300\n",
      "5/5 - 0s - loss: 11.5988 - mae: 57.7303 - val_loss: 50.3554 - val_mae: 198.8257 - 87ms/epoch - 17ms/step\n",
      "Epoch 142/300\n",
      "5/5 - 0s - loss: 11.5572 - mae: 57.9477 - val_loss: 50.1094 - val_mae: 200.0408 - 86ms/epoch - 17ms/step\n",
      "Epoch 143/300\n",
      "5/5 - 0s - loss: 11.5169 - mae: 57.5928 - val_loss: 49.8589 - val_mae: 199.1887 - 88ms/epoch - 18ms/step\n",
      "Epoch 144/300\n",
      "5/5 - 0s - loss: 11.4755 - mae: 57.5862 - val_loss: 49.6088 - val_mae: 199.3470 - 86ms/epoch - 17ms/step\n",
      "Epoch 145/300\n",
      "5/5 - 0s - loss: 11.4362 - mae: 57.5493 - val_loss: 49.3681 - val_mae: 199.4756 - 88ms/epoch - 18ms/step\n",
      "Epoch 146/300\n",
      "5/5 - 0s - loss: 11.3952 - mae: 57.3335 - val_loss: 49.1326 - val_mae: 199.4439 - 109ms/epoch - 22ms/step\n",
      "Epoch 147/300\n",
      "5/5 - 0s - loss: 11.3564 - mae: 57.4962 - val_loss: 48.9032 - val_mae: 199.1142 - 118ms/epoch - 24ms/step\n",
      "Epoch 148/300\n",
      "5/5 - 0s - loss: 11.3185 - mae: 57.2761 - val_loss: 48.6706 - val_mae: 198.5574 - 86ms/epoch - 17ms/step\n",
      "Epoch 149/300\n",
      "5/5 - 0s - loss: 11.2816 - mae: 57.4725 - val_loss: 48.4441 - val_mae: 198.5156 - 88ms/epoch - 18ms/step\n",
      "Epoch 150/300\n",
      "5/5 - 0s - loss: 11.2455 - mae: 57.3187 - val_loss: 48.2190 - val_mae: 199.0546 - 91ms/epoch - 18ms/step\n",
      "Epoch 151/300\n",
      "5/5 - 0s - loss: 11.2062 - mae: 57.1903 - val_loss: 47.9930 - val_mae: 197.7756 - 90ms/epoch - 18ms/step\n",
      "Epoch 152/300\n",
      "5/5 - 0s - loss: 11.1715 - mae: 57.1599 - val_loss: 47.7693 - val_mae: 199.0592 - 88ms/epoch - 18ms/step\n",
      "Epoch 153/300\n",
      "5/5 - 0s - loss: 11.1342 - mae: 57.4930 - val_loss: 47.5503 - val_mae: 198.3639 - 92ms/epoch - 18ms/step\n",
      "Epoch 154/300\n",
      "5/5 - 0s - loss: 11.1004 - mae: 56.8895 - val_loss: 47.3338 - val_mae: 198.1512 - 86ms/epoch - 17ms/step\n",
      "Epoch 155/300\n",
      "5/5 - 0s - loss: 11.0658 - mae: 57.1631 - val_loss: 47.1237 - val_mae: 198.2844 - 89ms/epoch - 18ms/step\n",
      "Epoch 156/300\n",
      "5/5 - 0s - loss: 11.0270 - mae: 56.9412 - val_loss: 46.9163 - val_mae: 198.8171 - 94ms/epoch - 19ms/step\n",
      "Epoch 157/300\n",
      "5/5 - 0s - loss: 10.9946 - mae: 56.9362 - val_loss: 46.7098 - val_mae: 198.5992 - 112ms/epoch - 22ms/step\n",
      "Epoch 158/300\n",
      "5/5 - 0s - loss: 10.9625 - mae: 56.9761 - val_loss: 46.5057 - val_mae: 197.7872 - 87ms/epoch - 17ms/step\n",
      "Epoch 159/300\n",
      "5/5 - 0s - loss: 10.9282 - mae: 57.0086 - val_loss: 46.2985 - val_mae: 198.4136 - 87ms/epoch - 17ms/step\n",
      "Epoch 160/300\n",
      "5/5 - 0s - loss: 10.8954 - mae: 56.7397 - val_loss: 46.0938 - val_mae: 198.2325 - 85ms/epoch - 17ms/step\n",
      "Epoch 161/300\n",
      "5/5 - 0s - loss: 10.8614 - mae: 56.9762 - val_loss: 45.8927 - val_mae: 197.5520 - 96ms/epoch - 19ms/step\n",
      "Epoch 162/300\n",
      "5/5 - 0s - loss: 10.8294 - mae: 56.6913 - val_loss: 45.6946 - val_mae: 197.8275 - 88ms/epoch - 18ms/step\n",
      "Epoch 163/300\n",
      "5/5 - 0s - loss: 10.7966 - mae: 56.8728 - val_loss: 45.4967 - val_mae: 196.8538 - 90ms/epoch - 18ms/step\n",
      "Epoch 164/300\n",
      "5/5 - 0s - loss: 10.7635 - mae: 56.4681 - val_loss: 45.3057 - val_mae: 198.3612 - 86ms/epoch - 17ms/step\n",
      "Epoch 165/300\n",
      "5/5 - 0s - loss: 10.7325 - mae: 56.4872 - val_loss: 45.1168 - val_mae: 197.3942 - 88ms/epoch - 18ms/step\n",
      "Epoch 166/300\n",
      "5/5 - 0s - loss: 10.7025 - mae: 56.5688 - val_loss: 44.9264 - val_mae: 197.1627 - 87ms/epoch - 17ms/step\n",
      "Epoch 167/300\n",
      "5/5 - 0s - loss: 10.6728 - mae: 56.5370 - val_loss: 44.7340 - val_mae: 197.7735 - 99ms/epoch - 20ms/step\n",
      "Epoch 168/300\n",
      "5/5 - 0s - loss: 10.6420 - mae: 56.5829 - val_loss: 44.5461 - val_mae: 196.6195 - 106ms/epoch - 21ms/step\n",
      "Epoch 169/300\n",
      "5/5 - 0s - loss: 10.6127 - mae: 56.5180 - val_loss: 44.3579 - val_mae: 196.5341 - 100ms/epoch - 20ms/step\n",
      "Epoch 170/300\n",
      "5/5 - 0s - loss: 10.5809 - mae: 56.3295 - val_loss: 44.1669 - val_mae: 197.6011 - 88ms/epoch - 18ms/step\n",
      "Epoch 171/300\n",
      "5/5 - 0s - loss: 10.5507 - mae: 56.3773 - val_loss: 43.9829 - val_mae: 196.4409 - 91ms/epoch - 18ms/step\n",
      "Epoch 172/300\n",
      "5/5 - 0s - loss: 10.5214 - mae: 56.2617 - val_loss: 43.8035 - val_mae: 197.4560 - 86ms/epoch - 17ms/step\n",
      "Epoch 173/300\n",
      "5/5 - 0s - loss: 10.4921 - mae: 56.2672 - val_loss: 43.6248 - val_mae: 197.7014 - 85ms/epoch - 17ms/step\n",
      "Epoch 174/300\n",
      "5/5 - 0s - loss: 10.4632 - mae: 56.3930 - val_loss: 43.4440 - val_mae: 197.1855 - 94ms/epoch - 19ms/step\n",
      "Epoch 175/300\n",
      "5/5 - 0s - loss: 10.4330 - mae: 56.2505 - val_loss: 43.2679 - val_mae: 196.3584 - 85ms/epoch - 17ms/step\n",
      "Epoch 176/300\n",
      "5/5 - 0s - loss: 10.4065 - mae: 56.2121 - val_loss: 43.0911 - val_mae: 196.1246 - 86ms/epoch - 17ms/step\n",
      "Epoch 177/300\n",
      "5/5 - 0s - loss: 10.3779 - mae: 56.1110 - val_loss: 42.9141 - val_mae: 196.5910 - 95ms/epoch - 19ms/step\n",
      "Epoch 178/300\n",
      "5/5 - 0s - loss: 10.3505 - mae: 56.0187 - val_loss: 42.7427 - val_mae: 196.4658 - 91ms/epoch - 18ms/step\n",
      "Epoch 179/300\n",
      "5/5 - 0s - loss: 10.3218 - mae: 56.0886 - val_loss: 42.5703 - val_mae: 196.5726 - 113ms/epoch - 23ms/step\n",
      "Epoch 180/300\n",
      "5/5 - 0s - loss: 10.2949 - mae: 56.1229 - val_loss: 42.3974 - val_mae: 196.6590 - 90ms/epoch - 18ms/step\n",
      "Epoch 181/300\n",
      "5/5 - 0s - loss: 10.2682 - mae: 55.8965 - val_loss: 42.2301 - val_mae: 195.9736 - 86ms/epoch - 17ms/step\n",
      "Epoch 182/300\n",
      "5/5 - 0s - loss: 10.2412 - mae: 56.2952 - val_loss: 42.0672 - val_mae: 196.0702 - 93ms/epoch - 19ms/step\n",
      "Epoch 183/300\n",
      "5/5 - 0s - loss: 10.2185 - mae: 56.1650 - val_loss: 41.9038 - val_mae: 196.1904 - 92ms/epoch - 18ms/step\n",
      "Epoch 184/300\n",
      "5/5 - 0s - loss: 10.1887 - mae: 55.8613 - val_loss: 41.7401 - val_mae: 196.2930 - 93ms/epoch - 19ms/step\n",
      "Epoch 185/300\n",
      "5/5 - 0s - loss: 10.1608 - mae: 55.7602 - val_loss: 41.5733 - val_mae: 195.6487 - 88ms/epoch - 18ms/step\n",
      "Epoch 186/300\n",
      "5/5 - 0s - loss: 10.1356 - mae: 55.6945 - val_loss: 41.4113 - val_mae: 195.2483 - 92ms/epoch - 18ms/step\n",
      "Epoch 187/300\n",
      "5/5 - 0s - loss: 10.1099 - mae: 55.6680 - val_loss: 41.2536 - val_mae: 195.2243 - 88ms/epoch - 18ms/step\n",
      "Epoch 188/300\n",
      "5/5 - 0s - loss: 10.0859 - mae: 55.9918 - val_loss: 41.0966 - val_mae: 195.8371 - 95ms/epoch - 19ms/step\n",
      "Epoch 189/300\n",
      "5/5 - 0s - loss: 10.0599 - mae: 55.8956 - val_loss: 40.9413 - val_mae: 195.8475 - 90ms/epoch - 18ms/step\n",
      "Epoch 190/300\n",
      "5/5 - 0s - loss: 10.0350 - mae: 55.6455 - val_loss: 40.7871 - val_mae: 195.9900 - 110ms/epoch - 22ms/step\n",
      "Epoch 191/300\n",
      "5/5 - 0s - loss: 10.0117 - mae: 55.6799 - val_loss: 40.6352 - val_mae: 195.7451 - 87ms/epoch - 17ms/step\n",
      "Epoch 192/300\n",
      "5/5 - 0s - loss: 9.9877 - mae: 55.5073 - val_loss: 40.4818 - val_mae: 195.9075 - 90ms/epoch - 18ms/step\n",
      "Epoch 193/300\n",
      "5/5 - 0s - loss: 9.9640 - mae: 55.5701 - val_loss: 40.3283 - val_mae: 195.3907 - 90ms/epoch - 18ms/step\n",
      "Epoch 194/300\n",
      "5/5 - 0s - loss: 9.9384 - mae: 55.3754 - val_loss: 40.1712 - val_mae: 194.8386 - 91ms/epoch - 18ms/step\n",
      "Epoch 195/300\n",
      "5/5 - 0s - loss: 9.9163 - mae: 55.4017 - val_loss: 40.0111 - val_mae: 194.7693 - 90ms/epoch - 18ms/step\n",
      "Epoch 196/300\n",
      "5/5 - 0s - loss: 9.8900 - mae: 55.4293 - val_loss: 39.8621 - val_mae: 194.7422 - 86ms/epoch - 17ms/step\n",
      "Epoch 197/300\n",
      "5/5 - 0s - loss: 9.8658 - mae: 55.6416 - val_loss: 39.7130 - val_mae: 194.6581 - 85ms/epoch - 17ms/step\n",
      "Epoch 198/300\n",
      "5/5 - 0s - loss: 9.8416 - mae: 55.5247 - val_loss: 39.5611 - val_mae: 195.6232 - 96ms/epoch - 19ms/step\n",
      "Epoch 199/300\n",
      "5/5 - 0s - loss: 9.8184 - mae: 55.2910 - val_loss: 39.4121 - val_mae: 194.2933 - 92ms/epoch - 18ms/step\n",
      "Epoch 200/300\n",
      "5/5 - 0s - loss: 9.7955 - mae: 55.0926 - val_loss: 39.2667 - val_mae: 194.1750 - 88ms/epoch - 18ms/step\n",
      "Epoch 201/300\n",
      "5/5 - 0s - loss: 9.7721 - mae: 55.3849 - val_loss: 39.1280 - val_mae: 195.1360 - 109ms/epoch - 22ms/step\n",
      "Epoch 202/300\n",
      "5/5 - 0s - loss: 9.7499 - mae: 55.3076 - val_loss: 38.9944 - val_mae: 195.2507 - 98ms/epoch - 20ms/step\n",
      "Epoch 203/300\n",
      "5/5 - 0s - loss: 9.7279 - mae: 54.8581 - val_loss: 38.8597 - val_mae: 194.1861 - 145ms/epoch - 29ms/step\n",
      "Epoch 204/300\n",
      "5/5 - 0s - loss: 9.7063 - mae: 55.1166 - val_loss: 38.7235 - val_mae: 194.3348 - 143ms/epoch - 29ms/step\n",
      "Epoch 205/300\n",
      "5/5 - 0s - loss: 9.6844 - mae: 55.1432 - val_loss: 38.5871 - val_mae: 194.2457 - 150ms/epoch - 30ms/step\n",
      "Epoch 206/300\n",
      "5/5 - 0s - loss: 9.6642 - mae: 54.9717 - val_loss: 38.4492 - val_mae: 193.4259 - 154ms/epoch - 31ms/step\n",
      "Epoch 207/300\n",
      "5/5 - 0s - loss: 9.6429 - mae: 54.9982 - val_loss: 38.3139 - val_mae: 193.8605 - 142ms/epoch - 28ms/step\n",
      "Epoch 208/300\n",
      "5/5 - 0s - loss: 9.6218 - mae: 54.9235 - val_loss: 38.1777 - val_mae: 193.7818 - 162ms/epoch - 32ms/step\n",
      "Epoch 209/300\n",
      "5/5 - 0s - loss: 9.5996 - mae: 55.1938 - val_loss: 38.0434 - val_mae: 193.4606 - 144ms/epoch - 29ms/step\n",
      "Epoch 210/300\n",
      "5/5 - 0s - loss: 9.5796 - mae: 54.7387 - val_loss: 37.9088 - val_mae: 192.9862 - 146ms/epoch - 29ms/step\n",
      "Epoch 211/300\n",
      "5/5 - 0s - loss: 9.5588 - mae: 54.9544 - val_loss: 37.7783 - val_mae: 193.8124 - 157ms/epoch - 31ms/step\n",
      "Epoch 212/300\n",
      "5/5 - 0s - loss: 9.5372 - mae: 55.0434 - val_loss: 37.6499 - val_mae: 193.9411 - 163ms/epoch - 33ms/step\n",
      "Epoch 213/300\n",
      "5/5 - 0s - loss: 9.5171 - mae: 55.0242 - val_loss: 37.5206 - val_mae: 193.1595 - 146ms/epoch - 29ms/step\n",
      "Epoch 214/300\n",
      "5/5 - 0s - loss: 9.4992 - mae: 54.9183 - val_loss: 37.3931 - val_mae: 192.6161 - 151ms/epoch - 30ms/step\n",
      "Epoch 215/300\n",
      "5/5 - 0s - loss: 9.4776 - mae: 54.7734 - val_loss: 37.2673 - val_mae: 193.4796 - 157ms/epoch - 31ms/step\n",
      "Epoch 216/300\n",
      "5/5 - 0s - loss: 9.4570 - mae: 54.9086 - val_loss: 37.1409 - val_mae: 193.0296 - 156ms/epoch - 31ms/step\n",
      "Epoch 217/300\n",
      "5/5 - 0s - loss: 9.4387 - mae: 54.6822 - val_loss: 37.0193 - val_mae: 192.5217 - 163ms/epoch - 33ms/step\n",
      "Epoch 218/300\n",
      "5/5 - 0s - loss: 9.4215 - mae: 54.6269 - val_loss: 36.8989 - val_mae: 193.2573 - 93ms/epoch - 19ms/step\n",
      "Epoch 219/300\n",
      "5/5 - 0s - loss: 9.3993 - mae: 54.7408 - val_loss: 36.7783 - val_mae: 192.6331 - 85ms/epoch - 17ms/step\n",
      "Epoch 220/300\n",
      "5/5 - 0s - loss: 9.3826 - mae: 54.5163 - val_loss: 36.6598 - val_mae: 192.0817 - 94ms/epoch - 19ms/step\n",
      "Epoch 221/300\n",
      "5/5 - 0s - loss: 9.3621 - mae: 54.4457 - val_loss: 36.5402 - val_mae: 193.0120 - 85ms/epoch - 17ms/step\n",
      "Epoch 222/300\n",
      "5/5 - 0s - loss: 9.3429 - mae: 54.4534 - val_loss: 36.4211 - val_mae: 192.7473 - 88ms/epoch - 18ms/step\n",
      "Epoch 223/300\n",
      "5/5 - 0s - loss: 9.3253 - mae: 54.6585 - val_loss: 36.3031 - val_mae: 193.4764 - 89ms/epoch - 18ms/step\n",
      "Epoch 224/300\n",
      "5/5 - 0s - loss: 9.3067 - mae: 54.5682 - val_loss: 36.1846 - val_mae: 192.5880 - 89ms/epoch - 18ms/step\n",
      "Epoch 225/300\n",
      "5/5 - 0s - loss: 9.2886 - mae: 54.6232 - val_loss: 36.0655 - val_mae: 192.5227 - 111ms/epoch - 22ms/step\n",
      "Epoch 226/300\n",
      "5/5 - 0s - loss: 9.2703 - mae: 54.4848 - val_loss: 35.9483 - val_mae: 191.8796 - 89ms/epoch - 18ms/step\n",
      "Epoch 227/300\n",
      "5/5 - 0s - loss: 9.2518 - mae: 54.4952 - val_loss: 35.8334 - val_mae: 192.4874 - 89ms/epoch - 18ms/step\n",
      "Epoch 228/300\n",
      "5/5 - 0s - loss: 9.2334 - mae: 54.2825 - val_loss: 35.7163 - val_mae: 192.0934 - 89ms/epoch - 18ms/step\n",
      "Epoch 229/300\n",
      "5/5 - 0s - loss: 9.2169 - mae: 54.4128 - val_loss: 35.6011 - val_mae: 192.8506 - 91ms/epoch - 18ms/step\n",
      "Epoch 230/300\n",
      "5/5 - 0s - loss: 9.1969 - mae: 54.2803 - val_loss: 35.4867 - val_mae: 192.6652 - 88ms/epoch - 18ms/step\n",
      "Epoch 231/300\n",
      "5/5 - 0s - loss: 9.1804 - mae: 54.5287 - val_loss: 35.3743 - val_mae: 191.7891 - 93ms/epoch - 19ms/step\n",
      "Epoch 232/300\n",
      "5/5 - 0s - loss: 9.1623 - mae: 54.2063 - val_loss: 35.2621 - val_mae: 191.7395 - 87ms/epoch - 17ms/step\n",
      "Epoch 233/300\n",
      "5/5 - 0s - loss: 9.1455 - mae: 54.2706 - val_loss: 35.1518 - val_mae: 192.2327 - 87ms/epoch - 17ms/step\n",
      "Epoch 234/300\n",
      "5/5 - 0s - loss: 9.1290 - mae: 53.9124 - val_loss: 35.0430 - val_mae: 191.4280 - 86ms/epoch - 17ms/step\n",
      "Epoch 235/300\n",
      "5/5 - 0s - loss: 9.1116 - mae: 54.0889 - val_loss: 34.9360 - val_mae: 191.5365 - 86ms/epoch - 17ms/step\n",
      "Epoch 236/300\n",
      "5/5 - 0s - loss: 9.0960 - mae: 54.0814 - val_loss: 34.8277 - val_mae: 191.2192 - 111ms/epoch - 22ms/step\n",
      "Epoch 237/300\n",
      "5/5 - 0s - loss: 9.0776 - mae: 53.9807 - val_loss: 34.7210 - val_mae: 193.0191 - 89ms/epoch - 18ms/step\n",
      "Epoch 238/300\n",
      "5/5 - 0s - loss: 9.0612 - mae: 54.0906 - val_loss: 34.6142 - val_mae: 190.7919 - 87ms/epoch - 17ms/step\n",
      "Epoch 239/300\n",
      "5/5 - 0s - loss: 9.0450 - mae: 53.8604 - val_loss: 34.5101 - val_mae: 190.8885 - 86ms/epoch - 17ms/step\n",
      "Epoch 240/300\n",
      "5/5 - 0s - loss: 9.0287 - mae: 53.9623 - val_loss: 34.4069 - val_mae: 190.7578 - 86ms/epoch - 17ms/step\n",
      "Epoch 241/300\n",
      "5/5 - 0s - loss: 9.0126 - mae: 54.1475 - val_loss: 34.3044 - val_mae: 191.5404 - 95ms/epoch - 19ms/step\n",
      "Epoch 242/300\n",
      "5/5 - 0s - loss: 8.9956 - mae: 53.8759 - val_loss: 34.2027 - val_mae: 190.6331 - 90ms/epoch - 18ms/step\n",
      "Epoch 243/300\n",
      "5/5 - 0s - loss: 8.9804 - mae: 54.3526 - val_loss: 34.0987 - val_mae: 190.6541 - 87ms/epoch - 17ms/step\n",
      "Epoch 244/300\n",
      "5/5 - 0s - loss: 8.9631 - mae: 53.7228 - val_loss: 33.9979 - val_mae: 189.9764 - 85ms/epoch - 17ms/step\n",
      "Epoch 245/300\n",
      "5/5 - 0s - loss: 8.9505 - mae: 53.8379 - val_loss: 33.9003 - val_mae: 191.0134 - 85ms/epoch - 17ms/step\n",
      "Epoch 246/300\n",
      "5/5 - 0s - loss: 8.9337 - mae: 53.8588 - val_loss: 33.8012 - val_mae: 190.6364 - 89ms/epoch - 18ms/step\n",
      "Epoch 247/300\n",
      "5/5 - 0s - loss: 8.9196 - mae: 53.7999 - val_loss: 33.7017 - val_mae: 190.2341 - 103ms/epoch - 21ms/step\n",
      "Epoch 248/300\n",
      "5/5 - 0s - loss: 8.9038 - mae: 53.6553 - val_loss: 33.6053 - val_mae: 191.6719 - 88ms/epoch - 18ms/step\n",
      "Epoch 249/300\n",
      "5/5 - 0s - loss: 8.8891 - mae: 53.7719 - val_loss: 33.5079 - val_mae: 190.3532 - 89ms/epoch - 18ms/step\n",
      "Epoch 250/300\n",
      "5/5 - 0s - loss: 8.8729 - mae: 53.5821 - val_loss: 33.4116 - val_mae: 190.5740 - 86ms/epoch - 17ms/step\n",
      "Epoch 251/300\n",
      "5/5 - 0s - loss: 8.8588 - mae: 53.6610 - val_loss: 33.3159 - val_mae: 189.9853 - 93ms/epoch - 19ms/step\n",
      "Epoch 252/300\n",
      "5/5 - 0s - loss: 8.8432 - mae: 53.4977 - val_loss: 33.2204 - val_mae: 190.0540 - 96ms/epoch - 19ms/step\n",
      "Epoch 253/300\n",
      "5/5 - 0s - loss: 8.8291 - mae: 53.6891 - val_loss: 33.1254 - val_mae: 190.8840 - 91ms/epoch - 18ms/step\n",
      "Epoch 254/300\n",
      "5/5 - 0s - loss: 8.8134 - mae: 53.6931 - val_loss: 33.0298 - val_mae: 190.7044 - 87ms/epoch - 17ms/step\n",
      "Epoch 255/300\n",
      "5/5 - 0s - loss: 8.7991 - mae: 53.3840 - val_loss: 32.9340 - val_mae: 189.9528 - 90ms/epoch - 18ms/step\n",
      "Epoch 256/300\n",
      "5/5 - 0s - loss: 8.7857 - mae: 53.6764 - val_loss: 32.8411 - val_mae: 191.0508 - 92ms/epoch - 18ms/step\n",
      "Epoch 257/300\n",
      "5/5 - 0s - loss: 8.7712 - mae: 53.3147 - val_loss: 32.7509 - val_mae: 189.7311 - 96ms/epoch - 19ms/step\n",
      "Epoch 258/300\n",
      "5/5 - 0s - loss: 8.7568 - mae: 53.6224 - val_loss: 32.6606 - val_mae: 189.8282 - 110ms/epoch - 22ms/step\n",
      "Epoch 259/300\n",
      "5/5 - 0s - loss: 8.7427 - mae: 53.6022 - val_loss: 32.5700 - val_mae: 190.1111 - 91ms/epoch - 18ms/step\n",
      "Epoch 260/300\n",
      "5/5 - 0s - loss: 8.7299 - mae: 53.1740 - val_loss: 32.4776 - val_mae: 189.3052 - 91ms/epoch - 18ms/step\n",
      "Epoch 261/300\n",
      "5/5 - 0s - loss: 8.7149 - mae: 53.5232 - val_loss: 32.3852 - val_mae: 189.6719 - 89ms/epoch - 18ms/step\n",
      "Epoch 262/300\n",
      "5/5 - 0s - loss: 8.7008 - mae: 53.3367 - val_loss: 32.2967 - val_mae: 189.4977 - 88ms/epoch - 18ms/step\n",
      "Epoch 263/300\n",
      "5/5 - 0s - loss: 8.6867 - mae: 53.5955 - val_loss: 32.2094 - val_mae: 189.5921 - 99ms/epoch - 20ms/step\n",
      "Epoch 264/300\n",
      "5/5 - 0s - loss: 8.6727 - mae: 53.2392 - val_loss: 32.1206 - val_mae: 189.5103 - 86ms/epoch - 17ms/step\n",
      "Epoch 265/300\n",
      "5/5 - 0s - loss: 8.6601 - mae: 53.4058 - val_loss: 32.0292 - val_mae: 189.8351 - 99ms/epoch - 20ms/step\n",
      "Epoch 266/300\n",
      "5/5 - 0s - loss: 8.6459 - mae: 53.1561 - val_loss: 31.9374 - val_mae: 189.3948 - 90ms/epoch - 18ms/step\n",
      "Epoch 267/300\n",
      "5/5 - 0s - loss: 8.6320 - mae: 53.4024 - val_loss: 31.8468 - val_mae: 189.4914 - 89ms/epoch - 18ms/step\n",
      "Epoch 268/300\n",
      "5/5 - 0s - loss: 8.6182 - mae: 53.2755 - val_loss: 31.7559 - val_mae: 188.3512 - 87ms/epoch - 17ms/step\n",
      "Epoch 269/300\n",
      "5/5 - 0s - loss: 8.6039 - mae: 53.2306 - val_loss: 31.6677 - val_mae: 188.9489 - 115ms/epoch - 23ms/step\n",
      "Epoch 270/300\n",
      "5/5 - 0s - loss: 8.5910 - mae: 53.1671 - val_loss: 31.5805 - val_mae: 189.6799 - 91ms/epoch - 18ms/step\n",
      "Epoch 271/300\n",
      "5/5 - 0s - loss: 8.5782 - mae: 53.2836 - val_loss: 31.4936 - val_mae: 188.3706 - 85ms/epoch - 17ms/step\n",
      "Epoch 272/300\n",
      "5/5 - 0s - loss: 8.5642 - mae: 53.4065 - val_loss: 31.4085 - val_mae: 189.1954 - 93ms/epoch - 19ms/step\n",
      "Epoch 273/300\n",
      "5/5 - 0s - loss: 8.5522 - mae: 53.1900 - val_loss: 31.3227 - val_mae: 189.0720 - 93ms/epoch - 19ms/step\n",
      "Epoch 274/300\n",
      "5/5 - 0s - loss: 8.5392 - mae: 53.2283 - val_loss: 31.2375 - val_mae: 189.2499 - 88ms/epoch - 18ms/step\n",
      "Epoch 275/300\n",
      "5/5 - 0s - loss: 8.5260 - mae: 53.1989 - val_loss: 31.1541 - val_mae: 189.3244 - 92ms/epoch - 18ms/step\n",
      "Epoch 276/300\n",
      "5/5 - 0s - loss: 8.5132 - mae: 53.1632 - val_loss: 31.0726 - val_mae: 188.2124 - 91ms/epoch - 18ms/step\n",
      "Epoch 277/300\n",
      "5/5 - 0s - loss: 8.5001 - mae: 52.9942 - val_loss: 30.9907 - val_mae: 188.4526 - 91ms/epoch - 18ms/step\n",
      "Epoch 278/300\n",
      "5/5 - 0s - loss: 8.4885 - mae: 52.7883 - val_loss: 30.9085 - val_mae: 187.8356 - 90ms/epoch - 18ms/step\n",
      "Epoch 279/300\n",
      "5/5 - 0s - loss: 8.4760 - mae: 53.0034 - val_loss: 30.8269 - val_mae: 188.6221 - 93ms/epoch - 19ms/step\n",
      "Epoch 280/300\n",
      "5/5 - 0s - loss: 8.4627 - mae: 53.0198 - val_loss: 30.7485 - val_mae: 188.6833 - 108ms/epoch - 22ms/step\n",
      "Epoch 281/300\n",
      "5/5 - 0s - loss: 8.4518 - mae: 52.7869 - val_loss: 30.6695 - val_mae: 188.1742 - 91ms/epoch - 18ms/step\n",
      "Epoch 282/300\n",
      "5/5 - 0s - loss: 8.4400 - mae: 52.5521 - val_loss: 30.5887 - val_mae: 187.4000 - 90ms/epoch - 18ms/step\n",
      "Epoch 283/300\n",
      "5/5 - 0s - loss: 8.4275 - mae: 52.9815 - val_loss: 30.5087 - val_mae: 188.3495 - 90ms/epoch - 18ms/step\n",
      "Epoch 284/300\n",
      "5/5 - 0s - loss: 8.4150 - mae: 52.8948 - val_loss: 30.4307 - val_mae: 187.9306 - 94ms/epoch - 19ms/step\n",
      "Epoch 285/300\n",
      "5/5 - 0s - loss: 8.4041 - mae: 53.0094 - val_loss: 30.3521 - val_mae: 187.5320 - 88ms/epoch - 18ms/step\n",
      "Epoch 286/300\n",
      "5/5 - 0s - loss: 8.3907 - mae: 52.8063 - val_loss: 30.2720 - val_mae: 188.3194 - 88ms/epoch - 18ms/step\n",
      "Epoch 287/300\n",
      "5/5 - 0s - loss: 8.3794 - mae: 52.6944 - val_loss: 30.1929 - val_mae: 186.9326 - 88ms/epoch - 18ms/step\n",
      "Epoch 288/300\n",
      "5/5 - 0s - loss: 8.3669 - mae: 52.8002 - val_loss: 30.1174 - val_mae: 187.7259 - 88ms/epoch - 18ms/step\n",
      "Epoch 289/300\n",
      "5/5 - 0s - loss: 8.3550 - mae: 52.9366 - val_loss: 30.0430 - val_mae: 186.6749 - 90ms/epoch - 18ms/step\n",
      "Epoch 290/300\n",
      "5/5 - 0s - loss: 8.3446 - mae: 52.8633 - val_loss: 29.9685 - val_mae: 187.7909 - 94ms/epoch - 19ms/step\n",
      "Epoch 291/300\n",
      "5/5 - 0s - loss: 8.3322 - mae: 52.4638 - val_loss: 29.8931 - val_mae: 186.9155 - 119ms/epoch - 24ms/step\n",
      "Epoch 292/300\n",
      "5/5 - 0s - loss: 8.3215 - mae: 52.7447 - val_loss: 29.8175 - val_mae: 186.7205 - 94ms/epoch - 19ms/step\n",
      "Epoch 293/300\n",
      "5/5 - 0s - loss: 8.3100 - mae: 52.4632 - val_loss: 29.7427 - val_mae: 187.1136 - 94ms/epoch - 19ms/step\n",
      "Epoch 294/300\n",
      "5/5 - 0s - loss: 8.2980 - mae: 52.7401 - val_loss: 29.6691 - val_mae: 186.8874 - 98ms/epoch - 20ms/step\n",
      "Epoch 295/300\n",
      "5/5 - 0s - loss: 8.2861 - mae: 52.7071 - val_loss: 29.5957 - val_mae: 186.9735 - 93ms/epoch - 19ms/step\n",
      "Epoch 296/300\n",
      "5/5 - 0s - loss: 8.2762 - mae: 52.4255 - val_loss: 29.5227 - val_mae: 186.7269 - 86ms/epoch - 17ms/step\n",
      "Epoch 297/300\n",
      "5/5 - 0s - loss: 8.2665 - mae: 52.5719 - val_loss: 29.4514 - val_mae: 186.8999 - 86ms/epoch - 17ms/step\n",
      "Epoch 298/300\n",
      "5/5 - 0s - loss: 8.2545 - mae: 52.6155 - val_loss: 29.3806 - val_mae: 186.5105 - 103ms/epoch - 21ms/step\n",
      "Epoch 299/300\n",
      "5/5 - 0s - loss: 8.2436 - mae: 52.4028 - val_loss: 29.3099 - val_mae: 188.0952 - 90ms/epoch - 18ms/step\n",
      "Epoch 300/300\n",
      "5/5 - 0s - loss: 8.2323 - mae: 52.3685 - val_loss: 29.2389 - val_mae: 187.1575 - 86ms/epoch - 17ms/step\n",
      "Epoch 1/300\n",
      "5/5 - 1s - loss: 1775.2838 - mae: 87.5788 - val_loss: 754.1769 - val_mae: 145.9470 - 1s/epoch - 237ms/step\n",
      "Epoch 2/300\n",
      "5/5 - 0s - loss: 566.6362 - mae: 87.2045 - val_loss: 407.0048 - val_mae: 145.6954 - 89ms/epoch - 18ms/step\n",
      "Epoch 3/300\n",
      "5/5 - 0s - loss: 302.3740 - mae: 86.8833 - val_loss: 268.6273 - val_mae: 145.4718 - 87ms/epoch - 17ms/step\n",
      "Epoch 4/300\n",
      "5/5 - 0s - loss: 204.0327 - mae: 86.6394 - val_loss: 199.0376 - val_mae: 145.1110 - 86ms/epoch - 17ms/step\n",
      "Epoch 5/300\n",
      "5/5 - 0s - loss: 152.9704 - mae: 86.3852 - val_loss: 163.4809 - val_mae: 144.4857 - 93ms/epoch - 19ms/step\n",
      "Epoch 6/300\n",
      "5/5 - 0s - loss: 125.7502 - mae: 86.1750 - val_loss: 142.0629 - val_mae: 144.6462 - 90ms/epoch - 18ms/step\n",
      "Epoch 7/300\n",
      "5/5 - 0s - loss: 109.1182 - mae: 85.9809 - val_loss: 127.5945 - val_mae: 144.5594 - 89ms/epoch - 18ms/step\n",
      "Epoch 8/300\n",
      "5/5 - 0s - loss: 97.7662 - mae: 85.8366 - val_loss: 116.7692 - val_mae: 144.1366 - 94ms/epoch - 19ms/step\n",
      "Epoch 9/300\n",
      "5/5 - 0s - loss: 89.4559 - mae: 85.6253 - val_loss: 108.4004 - val_mae: 144.3219 - 173ms/epoch - 35ms/step\n",
      "Epoch 10/300\n",
      "5/5 - 0s - loss: 82.8852 - mae: 85.5435 - val_loss: 101.8858 - val_mae: 144.0081 - 144ms/epoch - 29ms/step\n",
      "Epoch 11/300\n",
      "5/5 - 0s - loss: 77.9751 - mae: 85.4018 - val_loss: 96.6604 - val_mae: 143.6972 - 141ms/epoch - 28ms/step\n",
      "Epoch 12/300\n",
      "5/5 - 0s - loss: 73.6859 - mae: 85.3048 - val_loss: 92.3082 - val_mae: 143.3718 - 142ms/epoch - 28ms/step\n",
      "Epoch 13/300\n",
      "5/5 - 0s - loss: 70.0026 - mae: 85.2124 - val_loss: 88.6229 - val_mae: 143.6420 - 144ms/epoch - 29ms/step\n",
      "Epoch 14/300\n",
      "5/5 - 0s - loss: 67.0668 - mae: 84.9377 - val_loss: 85.3911 - val_mae: 143.4470 - 162ms/epoch - 32ms/step\n",
      "Epoch 15/300\n",
      "5/5 - 0s - loss: 64.3913 - mae: 84.9400 - val_loss: 82.5507 - val_mae: 143.2551 - 147ms/epoch - 29ms/step\n",
      "Epoch 16/300\n",
      "5/5 - 0s - loss: 61.5584 - mae: 84.7335 - val_loss: 79.9814 - val_mae: 143.0272 - 158ms/epoch - 32ms/step\n",
      "Epoch 17/300\n",
      "5/5 - 0s - loss: 59.6511 - mae: 84.6435 - val_loss: 77.5896 - val_mae: 142.8748 - 149ms/epoch - 30ms/step\n",
      "Epoch 18/300\n",
      "5/5 - 0s - loss: 57.7906 - mae: 84.6409 - val_loss: 75.3742 - val_mae: 142.8368 - 143ms/epoch - 29ms/step\n",
      "Epoch 19/300\n",
      "5/5 - 0s - loss: 55.7407 - mae: 84.4133 - val_loss: 73.3744 - val_mae: 142.6016 - 146ms/epoch - 29ms/step\n",
      "Epoch 20/300\n",
      "5/5 - 0s - loss: 54.1116 - mae: 84.4417 - val_loss: 71.5143 - val_mae: 142.5207 - 146ms/epoch - 29ms/step\n",
      "Epoch 21/300\n",
      "5/5 - 0s - loss: 52.3789 - mae: 84.3348 - val_loss: 69.7247 - val_mae: 142.3318 - 161ms/epoch - 32ms/step\n",
      "Epoch 22/300\n",
      "5/5 - 0s - loss: 50.7129 - mae: 84.0482 - val_loss: 68.0779 - val_mae: 142.2944 - 149ms/epoch - 30ms/step\n",
      "Epoch 23/300\n",
      "5/5 - 0s - loss: 49.5098 - mae: 84.0364 - val_loss: 66.5188 - val_mae: 142.3830 - 179ms/epoch - 36ms/step\n",
      "Epoch 24/300\n",
      "5/5 - 0s - loss: 48.0270 - mae: 83.9059 - val_loss: 65.0320 - val_mae: 141.9208 - 112ms/epoch - 22ms/step\n",
      "Epoch 25/300\n",
      "5/5 - 0s - loss: 46.7522 - mae: 83.7445 - val_loss: 63.6172 - val_mae: 142.0211 - 84ms/epoch - 17ms/step\n",
      "Epoch 26/300\n",
      "5/5 - 0s - loss: 45.5827 - mae: 83.6700 - val_loss: 62.2732 - val_mae: 141.4694 - 87ms/epoch - 17ms/step\n",
      "Epoch 27/300\n",
      "5/5 - 0s - loss: 44.4294 - mae: 83.6070 - val_loss: 60.9796 - val_mae: 141.3691 - 87ms/epoch - 17ms/step\n",
      "Epoch 28/300\n",
      "5/5 - 0s - loss: 43.3714 - mae: 83.4518 - val_loss: 59.7902 - val_mae: 141.4403 - 89ms/epoch - 18ms/step\n",
      "Epoch 29/300\n",
      "5/5 - 0s - loss: 42.5219 - mae: 83.3177 - val_loss: 58.6620 - val_mae: 141.6702 - 88ms/epoch - 18ms/step\n",
      "Epoch 30/300\n",
      "5/5 - 0s - loss: 41.5847 - mae: 83.3786 - val_loss: 57.6045 - val_mae: 141.5128 - 89ms/epoch - 18ms/step\n",
      "Epoch 31/300\n",
      "5/5 - 0s - loss: 40.5787 - mae: 83.1202 - val_loss: 56.6030 - val_mae: 140.9361 - 92ms/epoch - 18ms/step\n",
      "Epoch 32/300\n",
      "5/5 - 0s - loss: 39.7226 - mae: 82.8998 - val_loss: 55.6355 - val_mae: 140.8015 - 85ms/epoch - 17ms/step\n",
      "Epoch 33/300\n",
      "5/5 - 0s - loss: 39.0513 - mae: 82.7572 - val_loss: 54.6891 - val_mae: 140.2845 - 88ms/epoch - 18ms/step\n",
      "Epoch 34/300\n",
      "5/5 - 0s - loss: 38.3419 - mae: 82.8829 - val_loss: 53.7637 - val_mae: 140.8100 - 108ms/epoch - 22ms/step\n",
      "Epoch 35/300\n",
      "5/5 - 0s - loss: 37.5220 - mae: 82.6157 - val_loss: 52.8919 - val_mae: 140.0954 - 85ms/epoch - 17ms/step\n",
      "Epoch 36/300\n",
      "5/5 - 0s - loss: 36.8987 - mae: 82.5549 - val_loss: 52.0426 - val_mae: 140.7239 - 88ms/epoch - 18ms/step\n",
      "Epoch 37/300\n",
      "5/5 - 0s - loss: 36.2179 - mae: 82.4631 - val_loss: 51.2144 - val_mae: 139.6641 - 87ms/epoch - 17ms/step\n",
      "Epoch 38/300\n",
      "5/5 - 0s - loss: 35.5457 - mae: 82.3840 - val_loss: 50.4114 - val_mae: 140.5022 - 89ms/epoch - 18ms/step\n",
      "Epoch 39/300\n",
      "5/5 - 0s - loss: 34.9316 - mae: 82.1929 - val_loss: 49.6362 - val_mae: 140.3889 - 90ms/epoch - 18ms/step\n",
      "Epoch 40/300\n",
      "5/5 - 0s - loss: 34.3944 - mae: 82.0907 - val_loss: 48.8762 - val_mae: 139.9802 - 87ms/epoch - 17ms/step\n",
      "Epoch 41/300\n",
      "5/5 - 0s - loss: 33.8026 - mae: 81.9700 - val_loss: 48.1280 - val_mae: 139.5308 - 86ms/epoch - 17ms/step\n",
      "Epoch 42/300\n",
      "5/5 - 0s - loss: 33.2580 - mae: 81.9610 - val_loss: 47.4186 - val_mae: 139.5365 - 93ms/epoch - 19ms/step\n",
      "Epoch 43/300\n",
      "5/5 - 0s - loss: 32.7135 - mae: 81.8839 - val_loss: 46.7417 - val_mae: 138.8826 - 88ms/epoch - 18ms/step\n",
      "Epoch 44/300\n",
      "5/5 - 0s - loss: 32.2636 - mae: 81.9173 - val_loss: 46.1030 - val_mae: 139.6030 - 92ms/epoch - 18ms/step\n",
      "Epoch 45/300\n",
      "5/5 - 0s - loss: 31.8222 - mae: 81.6935 - val_loss: 45.4749 - val_mae: 139.3799 - 109ms/epoch - 22ms/step\n",
      "Epoch 46/300\n",
      "5/5 - 0s - loss: 31.3599 - mae: 81.5843 - val_loss: 44.8644 - val_mae: 139.3206 - 99ms/epoch - 20ms/step\n",
      "Epoch 47/300\n",
      "5/5 - 0s - loss: 30.7927 - mae: 81.6251 - val_loss: 44.2805 - val_mae: 138.6473 - 87ms/epoch - 17ms/step\n",
      "Epoch 48/300\n",
      "5/5 - 0s - loss: 30.4954 - mae: 81.3953 - val_loss: 43.7124 - val_mae: 139.0703 - 91ms/epoch - 18ms/step\n",
      "Epoch 49/300\n",
      "5/5 - 0s - loss: 30.1080 - mae: 81.3424 - val_loss: 43.1622 - val_mae: 138.7776 - 92ms/epoch - 18ms/step\n",
      "Epoch 50/300\n",
      "5/5 - 0s - loss: 29.7030 - mae: 81.1024 - val_loss: 42.6312 - val_mae: 138.3938 - 90ms/epoch - 18ms/step\n",
      "Epoch 51/300\n",
      "5/5 - 0s - loss: 29.3044 - mae: 80.9522 - val_loss: 42.1187 - val_mae: 138.9099 - 87ms/epoch - 17ms/step\n",
      "Epoch 52/300\n",
      "5/5 - 0s - loss: 29.0515 - mae: 81.0420 - val_loss: 41.6239 - val_mae: 138.4496 - 90ms/epoch - 18ms/step\n",
      "Epoch 53/300\n",
      "5/5 - 0s - loss: 28.6310 - mae: 81.0074 - val_loss: 41.1497 - val_mae: 138.1741 - 92ms/epoch - 18ms/step\n",
      "Epoch 54/300\n",
      "5/5 - 0s - loss: 28.2143 - mae: 80.8205 - val_loss: 40.6914 - val_mae: 138.5387 - 97ms/epoch - 19ms/step\n",
      "Epoch 55/300\n",
      "5/5 - 0s - loss: 27.9176 - mae: 80.8313 - val_loss: 40.2534 - val_mae: 138.0005 - 92ms/epoch - 18ms/step\n",
      "Epoch 56/300\n",
      "5/5 - 0s - loss: 27.6054 - mae: 80.5618 - val_loss: 39.8151 - val_mae: 138.0386 - 111ms/epoch - 22ms/step\n",
      "Epoch 57/300\n",
      "5/5 - 0s - loss: 27.3251 - mae: 80.6579 - val_loss: 39.3793 - val_mae: 137.7621 - 87ms/epoch - 17ms/step\n",
      "Epoch 58/300\n",
      "5/5 - 0s - loss: 27.0096 - mae: 80.5119 - val_loss: 38.9622 - val_mae: 137.3897 - 89ms/epoch - 18ms/step\n",
      "Epoch 59/300\n",
      "5/5 - 0s - loss: 26.7115 - mae: 80.5793 - val_loss: 38.5561 - val_mae: 137.6608 - 89ms/epoch - 18ms/step\n",
      "Epoch 60/300\n",
      "5/5 - 0s - loss: 26.4390 - mae: 80.2883 - val_loss: 38.1573 - val_mae: 137.4868 - 90ms/epoch - 18ms/step\n",
      "Epoch 61/300\n",
      "5/5 - 0s - loss: 26.1443 - mae: 80.2022 - val_loss: 37.7656 - val_mae: 137.3825 - 88ms/epoch - 18ms/step\n",
      "Epoch 62/300\n",
      "5/5 - 0s - loss: 25.8233 - mae: 79.9918 - val_loss: 37.3905 - val_mae: 136.6693 - 88ms/epoch - 18ms/step\n",
      "Epoch 63/300\n",
      "5/5 - 0s - loss: 25.6268 - mae: 79.9210 - val_loss: 37.0284 - val_mae: 137.0641 - 94ms/epoch - 19ms/step\n",
      "Epoch 64/300\n",
      "5/5 - 0s - loss: 25.3509 - mae: 80.0120 - val_loss: 36.6766 - val_mae: 136.4193 - 89ms/epoch - 18ms/step\n",
      "Epoch 65/300\n",
      "5/5 - 0s - loss: 25.0464 - mae: 79.8888 - val_loss: 36.3268 - val_mae: 136.8722 - 95ms/epoch - 19ms/step\n",
      "Epoch 66/300\n",
      "5/5 - 0s - loss: 24.8620 - mae: 79.9412 - val_loss: 35.9757 - val_mae: 136.4383 - 91ms/epoch - 18ms/step\n",
      "Epoch 67/300\n",
      "5/5 - 0s - loss: 24.5998 - mae: 79.8362 - val_loss: 35.6370 - val_mae: 137.5125 - 108ms/epoch - 22ms/step\n",
      "Epoch 68/300\n",
      "5/5 - 0s - loss: 24.4045 - mae: 79.6474 - val_loss: 35.3020 - val_mae: 136.5860 - 89ms/epoch - 18ms/step\n",
      "Epoch 69/300\n",
      "5/5 - 0s - loss: 24.1764 - mae: 79.4596 - val_loss: 34.9724 - val_mae: 135.7778 - 89ms/epoch - 18ms/step\n",
      "Epoch 70/300\n",
      "5/5 - 0s - loss: 23.9228 - mae: 79.6204 - val_loss: 34.6511 - val_mae: 136.4120 - 96ms/epoch - 19ms/step\n",
      "Epoch 71/300\n",
      "5/5 - 0s - loss: 23.6564 - mae: 79.4363 - val_loss: 34.3294 - val_mae: 136.0808 - 90ms/epoch - 18ms/step\n",
      "Epoch 72/300\n",
      "5/5 - 0s - loss: 23.4933 - mae: 79.2001 - val_loss: 34.0202 - val_mae: 135.9753 - 91ms/epoch - 18ms/step\n",
      "Epoch 73/300\n",
      "5/5 - 0s - loss: 23.2835 - mae: 79.2330 - val_loss: 33.7110 - val_mae: 136.4691 - 91ms/epoch - 18ms/step\n",
      "Epoch 74/300\n",
      "5/5 - 0s - loss: 23.0649 - mae: 79.0768 - val_loss: 33.4188 - val_mae: 135.2724 - 89ms/epoch - 18ms/step\n",
      "Epoch 75/300\n",
      "5/5 - 0s - loss: 22.8862 - mae: 79.0116 - val_loss: 33.1310 - val_mae: 136.2893 - 99ms/epoch - 20ms/step\n",
      "Epoch 76/300\n",
      "5/5 - 0s - loss: 22.6821 - mae: 78.9737 - val_loss: 32.8495 - val_mae: 135.7283 - 90ms/epoch - 18ms/step\n",
      "Epoch 77/300\n",
      "5/5 - 0s - loss: 22.4849 - mae: 78.8603 - val_loss: 32.5733 - val_mae: 134.6537 - 90ms/epoch - 18ms/step\n",
      "Epoch 78/300\n",
      "5/5 - 0s - loss: 22.3214 - mae: 78.8046 - val_loss: 32.3067 - val_mae: 135.1681 - 111ms/epoch - 22ms/step\n",
      "Epoch 79/300\n",
      "5/5 - 0s - loss: 22.1407 - mae: 78.9773 - val_loss: 32.0414 - val_mae: 135.0702 - 89ms/epoch - 18ms/step\n",
      "Epoch 80/300\n",
      "5/5 - 0s - loss: 21.9746 - mae: 78.4979 - val_loss: 31.7856 - val_mae: 134.5850 - 92ms/epoch - 18ms/step\n",
      "Epoch 81/300\n",
      "5/5 - 0s - loss: 21.7666 - mae: 78.3896 - val_loss: 31.5383 - val_mae: 133.9490 - 93ms/epoch - 19ms/step\n",
      "Epoch 82/300\n",
      "5/5 - 0s - loss: 21.5819 - mae: 78.5402 - val_loss: 31.2945 - val_mae: 135.0480 - 88ms/epoch - 18ms/step\n",
      "Epoch 83/300\n",
      "5/5 - 0s - loss: 21.4492 - mae: 78.4963 - val_loss: 31.0535 - val_mae: 135.0293 - 89ms/epoch - 18ms/step\n",
      "Epoch 84/300\n",
      "5/5 - 0s - loss: 21.2934 - mae: 78.4263 - val_loss: 30.8168 - val_mae: 134.5242 - 96ms/epoch - 19ms/step\n",
      "Epoch 85/300\n",
      "5/5 - 0s - loss: 21.1265 - mae: 78.4410 - val_loss: 30.5806 - val_mae: 134.0054 - 95ms/epoch - 19ms/step\n",
      "Epoch 86/300\n",
      "5/5 - 0s - loss: 20.9904 - mae: 78.4172 - val_loss: 30.3485 - val_mae: 134.9100 - 93ms/epoch - 19ms/step\n",
      "Epoch 87/300\n",
      "5/5 - 0s - loss: 20.8490 - mae: 78.3564 - val_loss: 30.1219 - val_mae: 134.2210 - 90ms/epoch - 18ms/step\n",
      "Epoch 88/300\n",
      "5/5 - 0s - loss: 20.6817 - mae: 78.1011 - val_loss: 29.8934 - val_mae: 133.4326 - 109ms/epoch - 22ms/step\n",
      "Epoch 89/300\n",
      "5/5 - 0s - loss: 20.5346 - mae: 78.0994 - val_loss: 29.6725 - val_mae: 133.8526 - 97ms/epoch - 19ms/step\n",
      "Epoch 90/300\n",
      "5/5 - 0s - loss: 20.4062 - mae: 77.9306 - val_loss: 29.4602 - val_mae: 133.9775 - 87ms/epoch - 17ms/step\n",
      "Epoch 91/300\n",
      "5/5 - 0s - loss: 20.2462 - mae: 77.9545 - val_loss: 29.2482 - val_mae: 133.6438 - 88ms/epoch - 18ms/step\n",
      "Epoch 92/300\n",
      "5/5 - 0s - loss: 20.0924 - mae: 78.0223 - val_loss: 29.0427 - val_mae: 133.6162 - 96ms/epoch - 19ms/step\n",
      "Epoch 93/300\n",
      "5/5 - 0s - loss: 19.9710 - mae: 77.7420 - val_loss: 28.8422 - val_mae: 134.0564 - 92ms/epoch - 18ms/step\n",
      "Epoch 94/300\n",
      "5/5 - 0s - loss: 19.8328 - mae: 77.6796 - val_loss: 28.6468 - val_mae: 134.0032 - 92ms/epoch - 18ms/step\n",
      "Epoch 95/300\n",
      "5/5 - 0s - loss: 19.7243 - mae: 77.8844 - val_loss: 28.4560 - val_mae: 133.5014 - 92ms/epoch - 18ms/step\n",
      "Epoch 96/300\n",
      "5/5 - 0s - loss: 19.5823 - mae: 77.4017 - val_loss: 28.2663 - val_mae: 133.0289 - 93ms/epoch - 19ms/step\n",
      "Epoch 97/300\n",
      "5/5 - 0s - loss: 19.4705 - mae: 77.6532 - val_loss: 28.0768 - val_mae: 133.2965 - 94ms/epoch - 19ms/step\n",
      "Epoch 98/300\n",
      "5/5 - 0s - loss: 19.3610 - mae: 77.4806 - val_loss: 27.8952 - val_mae: 133.4301 - 91ms/epoch - 18ms/step\n",
      "Epoch 99/300\n",
      "5/5 - 0s - loss: 19.2228 - mae: 77.4887 - val_loss: 27.7141 - val_mae: 132.8351 - 110ms/epoch - 22ms/step\n",
      "Epoch 100/300\n",
      "5/5 - 0s - loss: 19.0888 - mae: 77.4399 - val_loss: 27.5305 - val_mae: 132.8895 - 91ms/epoch - 18ms/step\n",
      "Epoch 101/300\n",
      "5/5 - 0s - loss: 18.9235 - mae: 77.2284 - val_loss: 27.3510 - val_mae: 132.7915 - 93ms/epoch - 19ms/step\n",
      "Epoch 102/300\n",
      "5/5 - 0s - loss: 18.8873 - mae: 77.1423 - val_loss: 27.1782 - val_mae: 133.0999 - 86ms/epoch - 17ms/step\n",
      "Epoch 103/300\n",
      "5/5 - 0s - loss: 18.7549 - mae: 77.0609 - val_loss: 27.0077 - val_mae: 132.9281 - 85ms/epoch - 17ms/step\n",
      "Epoch 104/300\n",
      "5/5 - 0s - loss: 18.6605 - mae: 76.9914 - val_loss: 26.8347 - val_mae: 132.4983 - 90ms/epoch - 18ms/step\n",
      "Epoch 105/300\n",
      "5/5 - 0s - loss: 18.5670 - mae: 77.2132 - val_loss: 26.6687 - val_mae: 132.6588 - 88ms/epoch - 18ms/step\n",
      "Epoch 106/300\n",
      "5/5 - 0s - loss: 18.4508 - mae: 76.9906 - val_loss: 26.5043 - val_mae: 132.2927 - 93ms/epoch - 19ms/step\n",
      "Epoch 107/300\n",
      "5/5 - 0s - loss: 18.3252 - mae: 77.0189 - val_loss: 26.3442 - val_mae: 132.4826 - 95ms/epoch - 19ms/step\n",
      "Epoch 108/300\n",
      "5/5 - 0s - loss: 18.2094 - mae: 76.9627 - val_loss: 26.1822 - val_mae: 132.1220 - 88ms/epoch - 18ms/step\n",
      "Epoch 109/300\n",
      "5/5 - 0s - loss: 18.1151 - mae: 76.7196 - val_loss: 26.0273 - val_mae: 132.8280 - 91ms/epoch - 18ms/step\n",
      "Epoch 110/300\n",
      "5/5 - 0s - loss: 18.0159 - mae: 76.8663 - val_loss: 25.8748 - val_mae: 131.6711 - 109ms/epoch - 22ms/step\n",
      "Epoch 111/300\n",
      "5/5 - 0s - loss: 17.9307 - mae: 76.6648 - val_loss: 25.7234 - val_mae: 131.3800 - 91ms/epoch - 18ms/step\n",
      "Epoch 112/300\n",
      "5/5 - 0s - loss: 17.7544 - mae: 76.4049 - val_loss: 25.5696 - val_mae: 132.3068 - 90ms/epoch - 18ms/step\n",
      "Epoch 113/300\n",
      "5/5 - 0s - loss: 17.6923 - mae: 76.5910 - val_loss: 25.4228 - val_mae: 131.1796 - 86ms/epoch - 17ms/step\n",
      "Epoch 114/300\n",
      "5/5 - 0s - loss: 17.6009 - mae: 76.4645 - val_loss: 25.2777 - val_mae: 131.3391 - 90ms/epoch - 18ms/step\n",
      "Epoch 115/300\n",
      "5/5 - 0s - loss: 17.5262 - mae: 76.3703 - val_loss: 25.1336 - val_mae: 131.9536 - 91ms/epoch - 18ms/step\n",
      "Epoch 116/300\n",
      "5/5 - 0s - loss: 17.4081 - mae: 76.3581 - val_loss: 24.9950 - val_mae: 131.3927 - 91ms/epoch - 18ms/step\n",
      "Epoch 117/300\n",
      "5/5 - 0s - loss: 17.3528 - mae: 76.0615 - val_loss: 24.8538 - val_mae: 131.3107 - 91ms/epoch - 18ms/step\n",
      "Epoch 118/300\n",
      "5/5 - 0s - loss: 17.2568 - mae: 76.2624 - val_loss: 24.7172 - val_mae: 131.0645 - 89ms/epoch - 18ms/step\n",
      "Epoch 119/300\n",
      "5/5 - 0s - loss: 17.1689 - mae: 76.1715 - val_loss: 24.5859 - val_mae: 130.3179 - 86ms/epoch - 17ms/step\n",
      "Epoch 120/300\n",
      "5/5 - 0s - loss: 17.0803 - mae: 75.9607 - val_loss: 24.4519 - val_mae: 130.9789 - 90ms/epoch - 18ms/step\n",
      "Epoch 121/300\n",
      "5/5 - 0s - loss: 17.0014 - mae: 75.9510 - val_loss: 24.3229 - val_mae: 130.6375 - 103ms/epoch - 21ms/step\n",
      "Epoch 122/300\n",
      "5/5 - 0s - loss: 16.9216 - mae: 76.0300 - val_loss: 24.1957 - val_mae: 130.1421 - 91ms/epoch - 18ms/step\n",
      "Epoch 123/300\n",
      "5/5 - 0s - loss: 16.8263 - mae: 75.8699 - val_loss: 24.0727 - val_mae: 131.0607 - 86ms/epoch - 17ms/step\n",
      "Epoch 124/300\n",
      "5/5 - 0s - loss: 16.7431 - mae: 76.0748 - val_loss: 23.9475 - val_mae: 130.9628 - 88ms/epoch - 18ms/step\n",
      "Epoch 125/300\n",
      "5/5 - 0s - loss: 16.6862 - mae: 76.0412 - val_loss: 23.8226 - val_mae: 129.5118 - 85ms/epoch - 17ms/step\n",
      "Epoch 126/300\n",
      "5/5 - 0s - loss: 16.5823 - mae: 75.7238 - val_loss: 23.7006 - val_mae: 130.1442 - 91ms/epoch - 18ms/step\n",
      "Epoch 127/300\n",
      "5/5 - 0s - loss: 16.5134 - mae: 75.5770 - val_loss: 23.5830 - val_mae: 129.3960 - 98ms/epoch - 20ms/step\n",
      "Epoch 128/300\n",
      "5/5 - 0s - loss: 16.4351 - mae: 75.5689 - val_loss: 23.4670 - val_mae: 129.9582 - 84ms/epoch - 17ms/step\n",
      "Epoch 129/300\n",
      "5/5 - 0s - loss: 16.3688 - mae: 75.6887 - val_loss: 23.3509 - val_mae: 130.6842 - 125ms/epoch - 25ms/step\n",
      "Epoch 130/300\n",
      "5/5 - 0s - loss: 16.2922 - mae: 75.5795 - val_loss: 23.2328 - val_mae: 130.0045 - 156ms/epoch - 31ms/step\n",
      "Epoch 131/300\n",
      "5/5 - 0s - loss: 16.2070 - mae: 75.6049 - val_loss: 23.1206 - val_mae: 130.0145 - 159ms/epoch - 32ms/step\n",
      "Epoch 132/300\n",
      "5/5 - 0s - loss: 16.1462 - mae: 75.2853 - val_loss: 23.0081 - val_mae: 129.5087 - 138ms/epoch - 28ms/step\n",
      "Epoch 133/300\n",
      "5/5 - 0s - loss: 16.0741 - mae: 75.5530 - val_loss: 22.8957 - val_mae: 129.1362 - 161ms/epoch - 32ms/step\n",
      "Epoch 134/300\n",
      "5/5 - 0s - loss: 15.9944 - mae: 75.2407 - val_loss: 22.7853 - val_mae: 129.4034 - 142ms/epoch - 28ms/step\n",
      "Epoch 135/300\n",
      "5/5 - 0s - loss: 15.9558 - mae: 75.4062 - val_loss: 22.6724 - val_mae: 130.7237 - 150ms/epoch - 30ms/step\n",
      "Epoch 136/300\n",
      "5/5 - 0s - loss: 15.8685 - mae: 75.2346 - val_loss: 22.5616 - val_mae: 128.8155 - 144ms/epoch - 29ms/step\n",
      "Epoch 137/300\n",
      "5/5 - 0s - loss: 15.7788 - mae: 75.1699 - val_loss: 22.4524 - val_mae: 129.9377 - 158ms/epoch - 32ms/step\n",
      "Epoch 138/300\n",
      "5/5 - 0s - loss: 15.7143 - mae: 75.1535 - val_loss: 22.3436 - val_mae: 129.4855 - 166ms/epoch - 33ms/step\n",
      "Epoch 139/300\n",
      "5/5 - 0s - loss: 15.6577 - mae: 74.7716 - val_loss: 22.2391 - val_mae: 129.2181 - 159ms/epoch - 32ms/step\n",
      "Epoch 140/300\n",
      "5/5 - 0s - loss: 15.5850 - mae: 75.1045 - val_loss: 22.1377 - val_mae: 129.0472 - 146ms/epoch - 29ms/step\n",
      "Epoch 141/300\n",
      "5/5 - 0s - loss: 15.5169 - mae: 75.0291 - val_loss: 22.0330 - val_mae: 128.5823 - 157ms/epoch - 31ms/step\n",
      "Epoch 142/300\n",
      "5/5 - 0s - loss: 15.4588 - mae: 74.9852 - val_loss: 21.9300 - val_mae: 128.1425 - 168ms/epoch - 34ms/step\n",
      "Epoch 143/300\n",
      "5/5 - 0s - loss: 15.4047 - mae: 74.8842 - val_loss: 21.8297 - val_mae: 128.9148 - 150ms/epoch - 30ms/step\n",
      "Epoch 144/300\n",
      "5/5 - 0s - loss: 15.3270 - mae: 74.8181 - val_loss: 21.7268 - val_mae: 128.8399 - 125ms/epoch - 25ms/step\n",
      "Epoch 145/300\n",
      "5/5 - 0s - loss: 15.2688 - mae: 74.6810 - val_loss: 21.6278 - val_mae: 128.6687 - 111ms/epoch - 22ms/step\n",
      "Epoch 146/300\n",
      "5/5 - 0s - loss: 15.2001 - mae: 74.6236 - val_loss: 21.5274 - val_mae: 128.4338 - 90ms/epoch - 18ms/step\n",
      "Epoch 147/300\n",
      "5/5 - 0s - loss: 15.1430 - mae: 74.6493 - val_loss: 21.4278 - val_mae: 128.0566 - 91ms/epoch - 18ms/step\n",
      "Epoch 148/300\n",
      "5/5 - 0s - loss: 15.0684 - mae: 74.5527 - val_loss: 21.3310 - val_mae: 127.8747 - 90ms/epoch - 18ms/step\n",
      "Epoch 149/300\n",
      "5/5 - 0s - loss: 15.0147 - mae: 74.5048 - val_loss: 21.2378 - val_mae: 127.6191 - 93ms/epoch - 19ms/step\n",
      "Epoch 150/300\n",
      "5/5 - 0s - loss: 14.9575 - mae: 74.5642 - val_loss: 21.1435 - val_mae: 128.0812 - 88ms/epoch - 18ms/step\n",
      "Epoch 151/300\n",
      "5/5 - 0s - loss: 14.8975 - mae: 74.6160 - val_loss: 21.0516 - val_mae: 127.9511 - 100ms/epoch - 20ms/step\n",
      "Epoch 152/300\n",
      "5/5 - 0s - loss: 14.8612 - mae: 74.5028 - val_loss: 20.9609 - val_mae: 127.8287 - 88ms/epoch - 18ms/step\n",
      "Epoch 153/300\n",
      "5/5 - 0s - loss: 14.7802 - mae: 74.1037 - val_loss: 20.8683 - val_mae: 126.9619 - 87ms/epoch - 17ms/step\n",
      "Epoch 154/300\n",
      "5/5 - 0s - loss: 14.7400 - mae: 74.0727 - val_loss: 20.7746 - val_mae: 127.2472 - 88ms/epoch - 18ms/step\n",
      "Epoch 155/300\n",
      "5/5 - 0s - loss: 14.6629 - mae: 74.0889 - val_loss: 20.6801 - val_mae: 126.5463 - 93ms/epoch - 19ms/step\n",
      "Epoch 156/300\n",
      "5/5 - 0s - loss: 14.6227 - mae: 74.0539 - val_loss: 20.5898 - val_mae: 128.1036 - 114ms/epoch - 23ms/step\n",
      "Epoch 157/300\n",
      "5/5 - 0s - loss: 14.5902 - mae: 74.2306 - val_loss: 20.5036 - val_mae: 126.8684 - 92ms/epoch - 18ms/step\n",
      "Epoch 158/300\n",
      "5/5 - 0s - loss: 14.5220 - mae: 74.0363 - val_loss: 20.4195 - val_mae: 126.9709 - 93ms/epoch - 19ms/step\n",
      "Epoch 159/300\n",
      "5/5 - 0s - loss: 14.4648 - mae: 74.2467 - val_loss: 20.3366 - val_mae: 127.7884 - 94ms/epoch - 19ms/step\n",
      "Epoch 160/300\n",
      "5/5 - 0s - loss: 14.4038 - mae: 73.9339 - val_loss: 20.2549 - val_mae: 127.1422 - 89ms/epoch - 18ms/step\n",
      "Epoch 161/300\n",
      "5/5 - 0s - loss: 14.3661 - mae: 73.8496 - val_loss: 20.1677 - val_mae: 126.8512 - 89ms/epoch - 18ms/step\n",
      "Epoch 162/300\n",
      "5/5 - 0s - loss: 14.3079 - mae: 74.0977 - val_loss: 20.0861 - val_mae: 125.9562 - 85ms/epoch - 17ms/step\n",
      "Epoch 163/300\n",
      "5/5 - 0s - loss: 14.2521 - mae: 73.9676 - val_loss: 20.0024 - val_mae: 126.4264 - 89ms/epoch - 18ms/step\n",
      "Epoch 164/300\n",
      "5/5 - 0s - loss: 14.2017 - mae: 73.9367 - val_loss: 19.9215 - val_mae: 126.8956 - 86ms/epoch - 17ms/step\n",
      "Epoch 165/300\n",
      "5/5 - 0s - loss: 14.1556 - mae: 73.7336 - val_loss: 19.8410 - val_mae: 126.6156 - 91ms/epoch - 18ms/step\n",
      "Epoch 166/300\n",
      "5/5 - 0s - loss: 14.1103 - mae: 73.5563 - val_loss: 19.7560 - val_mae: 126.5107 - 91ms/epoch - 18ms/step\n",
      "Epoch 167/300\n",
      "5/5 - 0s - loss: 14.0720 - mae: 73.5765 - val_loss: 19.6745 - val_mae: 126.1027 - 102ms/epoch - 20ms/step\n",
      "Epoch 168/300\n",
      "5/5 - 0s - loss: 14.0107 - mae: 73.4880 - val_loss: 19.5940 - val_mae: 125.2725 - 87ms/epoch - 17ms/step\n",
      "Epoch 169/300\n",
      "5/5 - 0s - loss: 13.9572 - mae: 73.4324 - val_loss: 19.5157 - val_mae: 126.0597 - 92ms/epoch - 18ms/step\n",
      "Epoch 170/300\n",
      "5/5 - 0s - loss: 13.9210 - mae: 73.3642 - val_loss: 19.4407 - val_mae: 126.3216 - 90ms/epoch - 18ms/step\n",
      "Epoch 171/300\n",
      "5/5 - 0s - loss: 13.8726 - mae: 73.5712 - val_loss: 19.3636 - val_mae: 126.1632 - 86ms/epoch - 17ms/step\n",
      "Epoch 172/300\n",
      "5/5 - 0s - loss: 13.8098 - mae: 73.4969 - val_loss: 19.2905 - val_mae: 125.3396 - 89ms/epoch - 18ms/step\n",
      "Epoch 173/300\n",
      "5/5 - 0s - loss: 13.7656 - mae: 73.3877 - val_loss: 19.2127 - val_mae: 126.3178 - 103ms/epoch - 21ms/step\n",
      "Epoch 174/300\n",
      "5/5 - 0s - loss: 13.7276 - mae: 73.4571 - val_loss: 19.1388 - val_mae: 124.9886 - 86ms/epoch - 17ms/step\n",
      "Epoch 175/300\n",
      "5/5 - 0s - loss: 13.6761 - mae: 73.3469 - val_loss: 19.0673 - val_mae: 125.2517 - 88ms/epoch - 18ms/step\n",
      "Epoch 176/300\n",
      "5/5 - 0s - loss: 13.6375 - mae: 73.3182 - val_loss: 18.9932 - val_mae: 126.6657 - 93ms/epoch - 19ms/step\n",
      "Epoch 177/300\n",
      "5/5 - 0s - loss: 13.5962 - mae: 73.5389 - val_loss: 18.9208 - val_mae: 125.1305 - 84ms/epoch - 17ms/step\n",
      "Epoch 178/300\n",
      "5/5 - 0s - loss: 13.5433 - mae: 73.6313 - val_loss: 18.8501 - val_mae: 124.8602 - 104ms/epoch - 21ms/step\n",
      "Epoch 179/300\n",
      "5/5 - 0s - loss: 13.5119 - mae: 73.4633 - val_loss: 18.7795 - val_mae: 125.4400 - 90ms/epoch - 18ms/step\n",
      "Epoch 180/300\n",
      "5/5 - 0s - loss: 13.4607 - mae: 72.9848 - val_loss: 18.7095 - val_mae: 124.4235 - 92ms/epoch - 18ms/step\n",
      "Epoch 181/300\n",
      "5/5 - 0s - loss: 13.4160 - mae: 73.2276 - val_loss: 18.6428 - val_mae: 123.2384 - 87ms/epoch - 17ms/step\n",
      "Epoch 182/300\n",
      "5/5 - 0s - loss: 13.3728 - mae: 72.9506 - val_loss: 18.5762 - val_mae: 125.8547 - 88ms/epoch - 18ms/step\n",
      "Epoch 183/300\n",
      "5/5 - 0s - loss: 13.3382 - mae: 72.9497 - val_loss: 18.5080 - val_mae: 124.5121 - 87ms/epoch - 17ms/step\n",
      "Epoch 184/300\n",
      "5/5 - 0s - loss: 13.2984 - mae: 73.0727 - val_loss: 18.4404 - val_mae: 124.6463 - 88ms/epoch - 18ms/step\n",
      "Epoch 185/300\n",
      "5/5 - 0s - loss: 13.2521 - mae: 72.9190 - val_loss: 18.3739 - val_mae: 123.8748 - 88ms/epoch - 18ms/step\n",
      "Epoch 186/300\n",
      "5/5 - 0s - loss: 13.2102 - mae: 72.7067 - val_loss: 18.3079 - val_mae: 124.0250 - 93ms/epoch - 19ms/step\n",
      "Epoch 187/300\n",
      "5/5 - 0s - loss: 13.1619 - mae: 72.9976 - val_loss: 18.2428 - val_mae: 124.3744 - 87ms/epoch - 17ms/step\n",
      "Epoch 188/300\n",
      "5/5 - 0s - loss: 13.1305 - mae: 72.4582 - val_loss: 18.1777 - val_mae: 124.1979 - 84ms/epoch - 17ms/step\n",
      "Epoch 189/300\n",
      "5/5 - 0s - loss: 13.0964 - mae: 72.8863 - val_loss: 18.1172 - val_mae: 125.1681 - 107ms/epoch - 21ms/step\n",
      "Epoch 190/300\n",
      "5/5 - 0s - loss: 13.0457 - mae: 72.5527 - val_loss: 18.0527 - val_mae: 123.6817 - 94ms/epoch - 19ms/step\n",
      "Epoch 191/300\n",
      "5/5 - 0s - loss: 13.0171 - mae: 72.7147 - val_loss: 17.9890 - val_mae: 123.8545 - 93ms/epoch - 19ms/step\n",
      "Epoch 192/300\n",
      "5/5 - 0s - loss: 12.9711 - mae: 72.5772 - val_loss: 17.9283 - val_mae: 123.9097 - 92ms/epoch - 18ms/step\n",
      "Epoch 193/300\n",
      "5/5 - 0s - loss: 12.9484 - mae: 72.6767 - val_loss: 17.8683 - val_mae: 122.7138 - 92ms/epoch - 18ms/step\n",
      "Epoch 194/300\n",
      "5/5 - 0s - loss: 12.9034 - mae: 72.4495 - val_loss: 17.8100 - val_mae: 123.7468 - 91ms/epoch - 18ms/step\n",
      "Epoch 195/300\n",
      "5/5 - 0s - loss: 12.8610 - mae: 72.5612 - val_loss: 17.7532 - val_mae: 123.2416 - 87ms/epoch - 17ms/step\n",
      "Epoch 196/300\n",
      "5/5 - 0s - loss: 12.8384 - mae: 72.5058 - val_loss: 17.6919 - val_mae: 123.8655 - 92ms/epoch - 18ms/step\n",
      "Epoch 197/300\n",
      "5/5 - 0s - loss: 12.7940 - mae: 72.4491 - val_loss: 17.6357 - val_mae: 122.8655 - 89ms/epoch - 18ms/step\n",
      "Epoch 198/300\n",
      "5/5 - 0s - loss: 12.7578 - mae: 72.4316 - val_loss: 17.5804 - val_mae: 122.9210 - 89ms/epoch - 18ms/step\n",
      "Epoch 199/300\n",
      "5/5 - 0s - loss: 12.7318 - mae: 72.3608 - val_loss: 17.5250 - val_mae: 123.7244 - 89ms/epoch - 18ms/step\n",
      "Epoch 200/300\n",
      "5/5 - 0s - loss: 12.6890 - mae: 72.5804 - val_loss: 17.4696 - val_mae: 123.2441 - 112ms/epoch - 22ms/step\n",
      "Epoch 201/300\n",
      "5/5 - 0s - loss: 12.6631 - mae: 72.2643 - val_loss: 17.4143 - val_mae: 122.6752 - 91ms/epoch - 18ms/step\n",
      "Epoch 202/300\n",
      "5/5 - 0s - loss: 12.6178 - mae: 72.2886 - val_loss: 17.3621 - val_mae: 123.6480 - 91ms/epoch - 18ms/step\n",
      "Epoch 203/300\n",
      "5/5 - 0s - loss: 12.5930 - mae: 72.1721 - val_loss: 17.3086 - val_mae: 123.1241 - 87ms/epoch - 17ms/step\n",
      "Epoch 204/300\n",
      "5/5 - 0s - loss: 12.5535 - mae: 72.2513 - val_loss: 17.2547 - val_mae: 122.5536 - 88ms/epoch - 18ms/step\n",
      "Epoch 205/300\n",
      "5/5 - 0s - loss: 12.5240 - mae: 72.1616 - val_loss: 17.2019 - val_mae: 122.1960 - 88ms/epoch - 18ms/step\n",
      "Epoch 206/300\n",
      "5/5 - 0s - loss: 12.4928 - mae: 71.9965 - val_loss: 17.1487 - val_mae: 121.8118 - 103ms/epoch - 21ms/step\n",
      "Epoch 207/300\n",
      "5/5 - 0s - loss: 12.4551 - mae: 72.2015 - val_loss: 17.0953 - val_mae: 122.6228 - 90ms/epoch - 18ms/step\n",
      "Epoch 208/300\n",
      "5/5 - 0s - loss: 12.4189 - mae: 72.0515 - val_loss: 17.0395 - val_mae: 122.6391 - 90ms/epoch - 18ms/step\n",
      "Epoch 209/300\n",
      "5/5 - 0s - loss: 12.3926 - mae: 72.0015 - val_loss: 16.9821 - val_mae: 123.5923 - 88ms/epoch - 18ms/step\n",
      "Epoch 210/300\n",
      "5/5 - 0s - loss: 12.3664 - mae: 71.9315 - val_loss: 16.9277 - val_mae: 122.1513 - 83ms/epoch - 17ms/step\n",
      "Epoch 211/300\n",
      "5/5 - 0s - loss: 12.3236 - mae: 71.7322 - val_loss: 16.8712 - val_mae: 122.7927 - 113ms/epoch - 23ms/step\n",
      "Epoch 212/300\n",
      "5/5 - 0s - loss: 12.2890 - mae: 72.0708 - val_loss: 16.8145 - val_mae: 122.4731 - 94ms/epoch - 19ms/step\n",
      "Epoch 213/300\n",
      "5/5 - 0s - loss: 12.2578 - mae: 72.0969 - val_loss: 16.7624 - val_mae: 122.6673 - 90ms/epoch - 18ms/step\n",
      "Epoch 214/300\n",
      "5/5 - 0s - loss: 12.2264 - mae: 71.8167 - val_loss: 16.7113 - val_mae: 121.4063 - 88ms/epoch - 18ms/step\n",
      "Epoch 215/300\n",
      "5/5 - 0s - loss: 12.2028 - mae: 71.8534 - val_loss: 16.6624 - val_mae: 122.0804 - 86ms/epoch - 17ms/step\n",
      "Epoch 216/300\n",
      "5/5 - 0s - loss: 12.1642 - mae: 71.6544 - val_loss: 16.6144 - val_mae: 122.0476 - 86ms/epoch - 17ms/step\n",
      "Epoch 217/300\n",
      "5/5 - 0s - loss: 12.1383 - mae: 71.9656 - val_loss: 16.5652 - val_mae: 120.8513 - 86ms/epoch - 17ms/step\n",
      "Epoch 218/300\n",
      "5/5 - 0s - loss: 12.1079 - mae: 71.7780 - val_loss: 16.5138 - val_mae: 121.6104 - 85ms/epoch - 17ms/step\n",
      "Epoch 219/300\n",
      "5/5 - 0s - loss: 12.0715 - mae: 71.6271 - val_loss: 16.4626 - val_mae: 121.2034 - 88ms/epoch - 18ms/step\n",
      "Epoch 220/300\n",
      "5/5 - 0s - loss: 12.0480 - mae: 71.7129 - val_loss: 16.4140 - val_mae: 121.5116 - 89ms/epoch - 18ms/step\n",
      "Epoch 221/300\n",
      "5/5 - 0s - loss: 12.0191 - mae: 71.5821 - val_loss: 16.3665 - val_mae: 121.0664 - 87ms/epoch - 17ms/step\n",
      "Epoch 222/300\n",
      "5/5 - 0s - loss: 11.9867 - mae: 71.5947 - val_loss: 16.3170 - val_mae: 120.5318 - 115ms/epoch - 23ms/step\n",
      "Epoch 223/300\n",
      "5/5 - 0s - loss: 11.9565 - mae: 71.4763 - val_loss: 16.2686 - val_mae: 120.7152 - 91ms/epoch - 18ms/step\n",
      "Epoch 224/300\n",
      "5/5 - 0s - loss: 11.9294 - mae: 71.4216 - val_loss: 16.2229 - val_mae: 120.8952 - 86ms/epoch - 17ms/step\n",
      "Epoch 225/300\n",
      "5/5 - 0s - loss: 11.8961 - mae: 71.2703 - val_loss: 16.1731 - val_mae: 121.6748 - 85ms/epoch - 17ms/step\n",
      "Epoch 226/300\n",
      "5/5 - 0s - loss: 11.8664 - mae: 71.3889 - val_loss: 16.1289 - val_mae: 121.1080 - 89ms/epoch - 18ms/step\n",
      "Epoch 227/300\n",
      "5/5 - 0s - loss: 11.8464 - mae: 71.2336 - val_loss: 16.0824 - val_mae: 120.8538 - 85ms/epoch - 17ms/step\n",
      "Epoch 228/300\n",
      "5/5 - 0s - loss: 11.8208 - mae: 71.4479 - val_loss: 16.0364 - val_mae: 120.8657 - 86ms/epoch - 17ms/step\n",
      "Epoch 229/300\n",
      "5/5 - 0s - loss: 11.7986 - mae: 71.2094 - val_loss: 15.9920 - val_mae: 121.4476 - 93ms/epoch - 19ms/step\n",
      "Epoch 230/300\n",
      "5/5 - 0s - loss: 11.7699 - mae: 71.4838 - val_loss: 15.9462 - val_mae: 121.1617 - 87ms/epoch - 17ms/step\n",
      "Epoch 231/300\n",
      "5/5 - 0s - loss: 11.7293 - mae: 71.0351 - val_loss: 15.9026 - val_mae: 119.6855 - 89ms/epoch - 18ms/step\n",
      "Epoch 232/300\n",
      "5/5 - 0s - loss: 11.7144 - mae: 71.2207 - val_loss: 15.8600 - val_mae: 120.4947 - 89ms/epoch - 18ms/step\n",
      "Epoch 233/300\n",
      "5/5 - 0s - loss: 11.6837 - mae: 71.3912 - val_loss: 15.8159 - val_mae: 119.7106 - 115ms/epoch - 23ms/step\n",
      "Epoch 234/300\n",
      "5/5 - 0s - loss: 11.6570 - mae: 71.2319 - val_loss: 15.7718 - val_mae: 119.5240 - 95ms/epoch - 19ms/step\n",
      "Epoch 235/300\n",
      "5/5 - 0s - loss: 11.6257 - mae: 71.1532 - val_loss: 15.7279 - val_mae: 119.9297 - 92ms/epoch - 18ms/step\n",
      "Epoch 236/300\n",
      "5/5 - 0s - loss: 11.6064 - mae: 70.8331 - val_loss: 15.6845 - val_mae: 119.8522 - 86ms/epoch - 17ms/step\n",
      "Epoch 237/300\n",
      "5/5 - 0s - loss: 11.5777 - mae: 71.3494 - val_loss: 15.6429 - val_mae: 121.1296 - 90ms/epoch - 18ms/step\n",
      "Epoch 238/300\n",
      "5/5 - 0s - loss: 11.5565 - mae: 71.1306 - val_loss: 15.6001 - val_mae: 118.9761 - 91ms/epoch - 18ms/step\n",
      "Epoch 239/300\n",
      "5/5 - 0s - loss: 11.5359 - mae: 71.3204 - val_loss: 15.5595 - val_mae: 119.4649 - 87ms/epoch - 17ms/step\n",
      "Epoch 240/300\n",
      "5/5 - 0s - loss: 11.5016 - mae: 71.2531 - val_loss: 15.5201 - val_mae: 118.0773 - 86ms/epoch - 17ms/step\n",
      "Epoch 241/300\n",
      "5/5 - 0s - loss: 11.4819 - mae: 70.9710 - val_loss: 15.4806 - val_mae: 118.8142 - 90ms/epoch - 18ms/step\n",
      "Epoch 242/300\n",
      "5/5 - 0s - loss: 11.4552 - mae: 71.0915 - val_loss: 15.4389 - val_mae: 119.3968 - 89ms/epoch - 18ms/step\n",
      "Epoch 243/300\n",
      "5/5 - 0s - loss: 11.4270 - mae: 70.8636 - val_loss: 15.3990 - val_mae: 119.9559 - 89ms/epoch - 18ms/step\n",
      "Epoch 244/300\n",
      "5/5 - 0s - loss: 11.4022 - mae: 70.7359 - val_loss: 15.3606 - val_mae: 119.8864 - 118ms/epoch - 24ms/step\n",
      "Epoch 245/300\n",
      "5/5 - 0s - loss: 11.3807 - mae: 70.9273 - val_loss: 15.3214 - val_mae: 118.6349 - 88ms/epoch - 18ms/step\n",
      "Epoch 246/300\n",
      "5/5 - 0s - loss: 11.3574 - mae: 70.6045 - val_loss: 15.2797 - val_mae: 120.6054 - 109ms/epoch - 22ms/step\n",
      "Epoch 247/300\n",
      "5/5 - 0s - loss: 11.3309 - mae: 70.9328 - val_loss: 15.2394 - val_mae: 119.3342 - 88ms/epoch - 18ms/step\n",
      "Epoch 248/300\n",
      "5/5 - 0s - loss: 11.3114 - mae: 70.8391 - val_loss: 15.1991 - val_mae: 119.1896 - 88ms/epoch - 18ms/step\n",
      "Epoch 249/300\n",
      "5/5 - 0s - loss: 11.2873 - mae: 71.0061 - val_loss: 15.1607 - val_mae: 117.7048 - 102ms/epoch - 20ms/step\n",
      "Epoch 250/300\n",
      "5/5 - 0s - loss: 11.2599 - mae: 70.8900 - val_loss: 15.1240 - val_mae: 118.9027 - 161ms/epoch - 32ms/step\n",
      "Epoch 251/300\n",
      "5/5 - 0s - loss: 11.2345 - mae: 70.7484 - val_loss: 15.0862 - val_mae: 118.7231 - 150ms/epoch - 30ms/step\n",
      "Epoch 252/300\n",
      "5/5 - 0s - loss: 11.2074 - mae: 70.3298 - val_loss: 15.0493 - val_mae: 119.4215 - 158ms/epoch - 32ms/step\n",
      "Epoch 253/300\n",
      "5/5 - 0s - loss: 11.1844 - mae: 70.7136 - val_loss: 15.0121 - val_mae: 118.5210 - 162ms/epoch - 32ms/step\n",
      "Epoch 254/300\n",
      "5/5 - 0s - loss: 11.1683 - mae: 70.6511 - val_loss: 14.9770 - val_mae: 118.1351 - 147ms/epoch - 29ms/step\n",
      "Epoch 255/300\n",
      "5/5 - 0s - loss: 11.1429 - mae: 70.6008 - val_loss: 14.9418 - val_mae: 117.7525 - 143ms/epoch - 29ms/step\n",
      "Epoch 256/300\n",
      "5/5 - 0s - loss: 11.1182 - mae: 70.5484 - val_loss: 14.9064 - val_mae: 118.4579 - 155ms/epoch - 31ms/step\n",
      "Epoch 257/300\n",
      "5/5 - 0s - loss: 11.0962 - mae: 70.4244 - val_loss: 14.8701 - val_mae: 118.1897 - 160ms/epoch - 32ms/step\n",
      "Epoch 258/300\n",
      "5/5 - 0s - loss: 11.0720 - mae: 70.3373 - val_loss: 14.8352 - val_mae: 118.0514 - 145ms/epoch - 29ms/step\n",
      "Epoch 259/300\n",
      "5/5 - 0s - loss: 11.0528 - mae: 70.2542 - val_loss: 14.8007 - val_mae: 119.1328 - 164ms/epoch - 33ms/step\n",
      "Epoch 260/300\n",
      "5/5 - 0s - loss: 11.0273 - mae: 70.5661 - val_loss: 14.7637 - val_mae: 117.4683 - 152ms/epoch - 30ms/step\n",
      "Epoch 261/300\n",
      "5/5 - 0s - loss: 11.0083 - mae: 70.4865 - val_loss: 14.7224 - val_mae: 116.9737 - 161ms/epoch - 32ms/step\n",
      "Epoch 262/300\n",
      "5/5 - 0s - loss: 10.9837 - mae: 70.4524 - val_loss: 14.6826 - val_mae: 117.3163 - 145ms/epoch - 29ms/step\n",
      "Epoch 263/300\n",
      "5/5 - 0s - loss: 10.9657 - mae: 70.4464 - val_loss: 14.6457 - val_mae: 117.6571 - 147ms/epoch - 29ms/step\n",
      "Epoch 264/300\n",
      "5/5 - 0s - loss: 10.9440 - mae: 70.2872 - val_loss: 14.6078 - val_mae: 117.9433 - 129ms/epoch - 26ms/step\n",
      "Epoch 265/300\n",
      "5/5 - 0s - loss: 10.9202 - mae: 70.5814 - val_loss: 14.5728 - val_mae: 117.8464 - 89ms/epoch - 18ms/step\n",
      "Epoch 266/300\n",
      "5/5 - 0s - loss: 10.8960 - mae: 70.1867 - val_loss: 14.5394 - val_mae: 117.9762 - 91ms/epoch - 18ms/step\n",
      "Epoch 267/300\n",
      "5/5 - 0s - loss: 10.8753 - mae: 70.0929 - val_loss: 14.5068 - val_mae: 116.9642 - 89ms/epoch - 18ms/step\n",
      "Epoch 268/300\n",
      "5/5 - 0s - loss: 10.8560 - mae: 70.2648 - val_loss: 14.4723 - val_mae: 117.4424 - 122ms/epoch - 24ms/step\n",
      "Epoch 269/300\n",
      "5/5 - 0s - loss: 10.8362 - mae: 70.2835 - val_loss: 14.4406 - val_mae: 117.1606 - 89ms/epoch - 18ms/step\n",
      "Epoch 270/300\n",
      "5/5 - 0s - loss: 10.8185 - mae: 69.9448 - val_loss: 14.4035 - val_mae: 118.5838 - 86ms/epoch - 17ms/step\n",
      "Epoch 271/300\n",
      "5/5 - 0s - loss: 10.7943 - mae: 70.2173 - val_loss: 14.3716 - val_mae: 117.4804 - 103ms/epoch - 21ms/step\n",
      "Epoch 272/300\n",
      "5/5 - 0s - loss: 10.7763 - mae: 70.1056 - val_loss: 14.3384 - val_mae: 116.4071 - 89ms/epoch - 18ms/step\n",
      "Epoch 273/300\n",
      "5/5 - 0s - loss: 10.7539 - mae: 69.9570 - val_loss: 14.3057 - val_mae: 116.8049 - 87ms/epoch - 17ms/step\n",
      "Epoch 274/300\n",
      "5/5 - 0s - loss: 10.7376 - mae: 69.9604 - val_loss: 14.2747 - val_mae: 117.1950 - 88ms/epoch - 18ms/step\n",
      "Epoch 275/300\n",
      "5/5 - 0s - loss: 10.7137 - mae: 69.9854 - val_loss: 14.2407 - val_mae: 117.1817 - 91ms/epoch - 18ms/step\n",
      "Epoch 276/300\n",
      "5/5 - 0s - loss: 10.6949 - mae: 69.9862 - val_loss: 14.2097 - val_mae: 115.9500 - 94ms/epoch - 19ms/step\n",
      "Epoch 277/300\n",
      "5/5 - 0s - loss: 10.6775 - mae: 69.9127 - val_loss: 14.1787 - val_mae: 117.8519 - 90ms/epoch - 18ms/step\n",
      "Epoch 278/300\n",
      "5/5 - 0s - loss: 10.6592 - mae: 70.1313 - val_loss: 14.1474 - val_mae: 114.9189 - 85ms/epoch - 17ms/step\n",
      "Epoch 279/300\n",
      "5/5 - 0s - loss: 10.6392 - mae: 70.0158 - val_loss: 14.1133 - val_mae: 115.5989 - 108ms/epoch - 22ms/step\n",
      "Epoch 280/300\n",
      "5/5 - 0s - loss: 10.6207 - mae: 69.9964 - val_loss: 14.0819 - val_mae: 115.9593 - 84ms/epoch - 17ms/step\n",
      "Epoch 281/300\n",
      "5/5 - 0s - loss: 10.5998 - mae: 69.7881 - val_loss: 14.0489 - val_mae: 116.3247 - 86ms/epoch - 17ms/step\n",
      "Epoch 282/300\n",
      "5/5 - 0s - loss: 10.5822 - mae: 69.8345 - val_loss: 14.0186 - val_mae: 115.8180 - 88ms/epoch - 18ms/step\n",
      "Epoch 283/300\n",
      "5/5 - 0s - loss: 10.5595 - mae: 69.7118 - val_loss: 13.9885 - val_mae: 115.3319 - 91ms/epoch - 18ms/step\n",
      "Epoch 284/300\n",
      "5/5 - 0s - loss: 10.5422 - mae: 69.8326 - val_loss: 13.9575 - val_mae: 115.9931 - 83ms/epoch - 17ms/step\n",
      "Epoch 285/300\n",
      "5/5 - 0s - loss: 10.5270 - mae: 69.4924 - val_loss: 13.9274 - val_mae: 114.5292 - 85ms/epoch - 17ms/step\n",
      "Epoch 286/300\n",
      "5/5 - 0s - loss: 10.5142 - mae: 69.4660 - val_loss: 13.8952 - val_mae: 115.9448 - 90ms/epoch - 18ms/step\n",
      "Epoch 287/300\n",
      "5/5 - 0s - loss: 10.4893 - mae: 69.5258 - val_loss: 13.8652 - val_mae: 116.0997 - 97ms/epoch - 19ms/step\n",
      "Epoch 288/300\n",
      "5/5 - 0s - loss: 10.4652 - mae: 69.5190 - val_loss: 13.8339 - val_mae: 115.0122 - 92ms/epoch - 18ms/step\n",
      "Epoch 289/300\n",
      "5/5 - 0s - loss: 10.4514 - mae: 69.5050 - val_loss: 13.8059 - val_mae: 115.4697 - 91ms/epoch - 18ms/step\n",
      "Epoch 290/300\n",
      "5/5 - 0s - loss: 10.4325 - mae: 69.6991 - val_loss: 13.7771 - val_mae: 113.5270 - 109ms/epoch - 22ms/step\n",
      "Epoch 291/300\n",
      "5/5 - 0s - loss: 10.4158 - mae: 69.3994 - val_loss: 13.7496 - val_mae: 115.4495 - 89ms/epoch - 18ms/step\n",
      "Epoch 292/300\n",
      "5/5 - 0s - loss: 10.3982 - mae: 69.7702 - val_loss: 13.7204 - val_mae: 115.5559 - 87ms/epoch - 17ms/step\n",
      "Epoch 293/300\n",
      "5/5 - 0s - loss: 10.3833 - mae: 69.6104 - val_loss: 13.6928 - val_mae: 114.3327 - 91ms/epoch - 18ms/step\n",
      "Epoch 294/300\n",
      "5/5 - 0s - loss: 10.3649 - mae: 69.6902 - val_loss: 13.6658 - val_mae: 115.2236 - 90ms/epoch - 18ms/step\n",
      "Epoch 295/300\n",
      "5/5 - 0s - loss: 10.3448 - mae: 69.6031 - val_loss: 13.6379 - val_mae: 114.0708 - 90ms/epoch - 18ms/step\n",
      "Epoch 296/300\n",
      "5/5 - 0s - loss: 10.3277 - mae: 69.3984 - val_loss: 13.6060 - val_mae: 114.8018 - 93ms/epoch - 19ms/step\n",
      "Epoch 297/300\n",
      "5/5 - 0s - loss: 10.3146 - mae: 69.3321 - val_loss: 13.5758 - val_mae: 115.0598 - 95ms/epoch - 19ms/step\n",
      "Epoch 298/300\n",
      "5/5 - 0s - loss: 10.2947 - mae: 69.3428 - val_loss: 13.5473 - val_mae: 114.2322 - 92ms/epoch - 18ms/step\n",
      "Epoch 299/300\n",
      "5/5 - 0s - loss: 10.2737 - mae: 69.2001 - val_loss: 13.5198 - val_mae: 114.5840 - 88ms/epoch - 18ms/step\n",
      "Epoch 300/300\n",
      "5/5 - 0s - loss: 10.2595 - mae: 69.2298 - val_loss: 13.4905 - val_mae: 113.5709 - 89ms/epoch - 18ms/step\n",
      "Epoch 1/300\n",
      "5/5 - 1s - loss: 3700.7849 - mae: 98.8462 - val_loss: 760.7561 - val_mae: 105.1857 - 1s/epoch - 240ms/step\n",
      "Epoch 2/300\n",
      "5/5 - 0s - loss: 991.3365 - mae: 98.4650 - val_loss: 299.1337 - val_mae: 105.1401 - 88ms/epoch - 18ms/step\n",
      "Epoch 3/300\n",
      "5/5 - 0s - loss: 491.7426 - mae: 98.1008 - val_loss: 181.3113 - val_mae: 104.7589 - 88ms/epoch - 18ms/step\n",
      "Epoch 4/300\n",
      "5/5 - 0s - loss: 314.6090 - mae: 97.8348 - val_loss: 132.9037 - val_mae: 104.4532 - 86ms/epoch - 17ms/step\n",
      "Epoch 5/300\n",
      "5/5 - 0s - loss: 230.0569 - mae: 97.5877 - val_loss: 107.3246 - val_mae: 104.3630 - 87ms/epoch - 17ms/step\n",
      "Epoch 6/300\n",
      "5/5 - 0s - loss: 182.3716 - mae: 97.4456 - val_loss: 92.3052 - val_mae: 104.1695 - 87ms/epoch - 17ms/step\n",
      "Epoch 7/300\n",
      "5/5 - 0s - loss: 154.1826 - mae: 97.1594 - val_loss: 82.4001 - val_mae: 104.1366 - 106ms/epoch - 21ms/step\n",
      "Epoch 8/300\n",
      "5/5 - 0s - loss: 134.4267 - mae: 97.0782 - val_loss: 75.4653 - val_mae: 103.7282 - 88ms/epoch - 18ms/step\n",
      "Epoch 9/300\n",
      "5/5 - 0s - loss: 120.2282 - mae: 96.8896 - val_loss: 70.2533 - val_mae: 103.9994 - 85ms/epoch - 17ms/step\n",
      "Epoch 10/300\n",
      "5/5 - 0s - loss: 110.2025 - mae: 96.8178 - val_loss: 66.1516 - val_mae: 103.7206 - 90ms/epoch - 18ms/step\n",
      "Epoch 11/300\n",
      "5/5 - 0s - loss: 102.1296 - mae: 96.7069 - val_loss: 62.8841 - val_mae: 103.2481 - 98ms/epoch - 20ms/step\n",
      "Epoch 12/300\n",
      "5/5 - 0s - loss: 95.4830 - mae: 96.5139 - val_loss: 60.1480 - val_mae: 103.3993 - 87ms/epoch - 17ms/step\n",
      "Epoch 13/300\n",
      "5/5 - 0s - loss: 90.0747 - mae: 96.4165 - val_loss: 57.8454 - val_mae: 102.8316 - 88ms/epoch - 18ms/step\n",
      "Epoch 14/300\n",
      "5/5 - 0s - loss: 85.4032 - mae: 96.3097 - val_loss: 55.8217 - val_mae: 103.2988 - 117ms/epoch - 23ms/step\n",
      "Epoch 15/300\n",
      "5/5 - 0s - loss: 81.2311 - mae: 96.1345 - val_loss: 54.0467 - val_mae: 103.1572 - 90ms/epoch - 18ms/step\n",
      "Epoch 16/300\n",
      "5/5 - 0s - loss: 77.5687 - mae: 96.0040 - val_loss: 52.4491 - val_mae: 102.6871 - 91ms/epoch - 18ms/step\n",
      "Epoch 17/300\n",
      "5/5 - 0s - loss: 74.2207 - mae: 95.9060 - val_loss: 50.9969 - val_mae: 102.8914 - 93ms/epoch - 19ms/step\n",
      "Epoch 18/300\n",
      "5/5 - 0s - loss: 71.1996 - mae: 95.8307 - val_loss: 49.6858 - val_mae: 102.8266 - 106ms/epoch - 21ms/step\n",
      "Epoch 19/300\n",
      "5/5 - 0s - loss: 68.5048 - mae: 95.7954 - val_loss: 48.4495 - val_mae: 102.7184 - 87ms/epoch - 17ms/step\n",
      "Epoch 20/300\n",
      "5/5 - 0s - loss: 66.2502 - mae: 95.5826 - val_loss: 47.3217 - val_mae: 102.4973 - 86ms/epoch - 17ms/step\n",
      "Epoch 21/300\n",
      "5/5 - 0s - loss: 63.8760 - mae: 95.5052 - val_loss: 46.2518 - val_mae: 102.3846 - 98ms/epoch - 20ms/step\n",
      "Epoch 22/300\n",
      "5/5 - 0s - loss: 61.9297 - mae: 95.3409 - val_loss: 45.3220 - val_mae: 102.0137 - 90ms/epoch - 18ms/step\n",
      "Epoch 23/300\n",
      "5/5 - 0s - loss: 60.0671 - mae: 95.3001 - val_loss: 44.4040 - val_mae: 102.2534 - 100ms/epoch - 20ms/step\n",
      "Epoch 24/300\n",
      "5/5 - 0s - loss: 58.2095 - mae: 95.1937 - val_loss: 43.5278 - val_mae: 102.1283 - 93ms/epoch - 19ms/step\n",
      "Epoch 25/300\n",
      "5/5 - 0s - loss: 56.7296 - mae: 95.1405 - val_loss: 42.7401 - val_mae: 102.0148 - 89ms/epoch - 18ms/step\n",
      "Epoch 26/300\n",
      "5/5 - 0s - loss: 54.9396 - mae: 95.0375 - val_loss: 41.9817 - val_mae: 101.9008 - 90ms/epoch - 18ms/step\n",
      "Epoch 27/300\n",
      "5/5 - 0s - loss: 53.4774 - mae: 94.9211 - val_loss: 41.2776 - val_mae: 101.6095 - 86ms/epoch - 17ms/step\n",
      "Epoch 28/300\n",
      "5/5 - 0s - loss: 52.2417 - mae: 94.6843 - val_loss: 40.6082 - val_mae: 101.7592 - 86ms/epoch - 17ms/step\n",
      "Epoch 29/300\n",
      "5/5 - 0s - loss: 51.1290 - mae: 94.6826 - val_loss: 39.9546 - val_mae: 101.5943 - 109ms/epoch - 22ms/step\n",
      "Epoch 30/300\n",
      "5/5 - 0s - loss: 49.9038 - mae: 94.6385 - val_loss: 39.3294 - val_mae: 101.7297 - 88ms/epoch - 18ms/step\n",
      "Epoch 31/300\n",
      "5/5 - 0s - loss: 48.7828 - mae: 94.4396 - val_loss: 38.7370 - val_mae: 101.2269 - 95ms/epoch - 19ms/step\n",
      "Epoch 32/300\n",
      "5/5 - 0s - loss: 47.7487 - mae: 94.4244 - val_loss: 38.1903 - val_mae: 101.0222 - 95ms/epoch - 19ms/step\n",
      "Epoch 33/300\n",
      "5/5 - 0s - loss: 46.7508 - mae: 94.2212 - val_loss: 37.6447 - val_mae: 101.4113 - 114ms/epoch - 23ms/step\n",
      "Epoch 34/300\n",
      "5/5 - 0s - loss: 46.0427 - mae: 94.3853 - val_loss: 37.1305 - val_mae: 100.8781 - 93ms/epoch - 19ms/step\n",
      "Epoch 35/300\n",
      "5/5 - 0s - loss: 44.9756 - mae: 94.0932 - val_loss: 36.6398 - val_mae: 100.8053 - 103ms/epoch - 21ms/step\n",
      "Epoch 36/300\n",
      "5/5 - 0s - loss: 44.1716 - mae: 93.8500 - val_loss: 36.1487 - val_mae: 101.1201 - 111ms/epoch - 22ms/step\n",
      "Epoch 37/300\n",
      "5/5 - 0s - loss: 43.3895 - mae: 93.7911 - val_loss: 35.6955 - val_mae: 100.4744 - 93ms/epoch - 19ms/step\n",
      "Epoch 38/300\n",
      "5/5 - 0s - loss: 42.6401 - mae: 93.8743 - val_loss: 35.2515 - val_mae: 100.7654 - 87ms/epoch - 17ms/step\n",
      "Epoch 39/300\n",
      "5/5 - 0s - loss: 42.0204 - mae: 93.9501 - val_loss: 34.8329 - val_mae: 100.9103 - 114ms/epoch - 23ms/step\n",
      "Epoch 40/300\n",
      "5/5 - 0s - loss: 41.3200 - mae: 93.5601 - val_loss: 34.4533 - val_mae: 100.4918 - 96ms/epoch - 19ms/step\n",
      "Epoch 41/300\n",
      "5/5 - 0s - loss: 40.6544 - mae: 93.4399 - val_loss: 34.0403 - val_mae: 100.8292 - 100ms/epoch - 20ms/step\n",
      "Epoch 42/300\n",
      "5/5 - 0s - loss: 40.0724 - mae: 93.4074 - val_loss: 33.6507 - val_mae: 99.8984 - 89ms/epoch - 18ms/step\n",
      "Epoch 43/300\n",
      "5/5 - 0s - loss: 39.5208 - mae: 93.1307 - val_loss: 33.2644 - val_mae: 99.8778 - 90ms/epoch - 18ms/step\n",
      "Epoch 44/300\n",
      "5/5 - 0s - loss: 38.9417 - mae: 93.3274 - val_loss: 32.8736 - val_mae: 100.1000 - 87ms/epoch - 17ms/step\n",
      "Epoch 45/300\n",
      "5/5 - 0s - loss: 38.5049 - mae: 93.1814 - val_loss: 32.5224 - val_mae: 100.0040 - 91ms/epoch - 18ms/step\n",
      "Epoch 46/300\n",
      "5/5 - 0s - loss: 37.8360 - mae: 93.1087 - val_loss: 32.1787 - val_mae: 99.9196 - 90ms/epoch - 18ms/step\n",
      "Epoch 47/300\n",
      "5/5 - 0s - loss: 37.4993 - mae: 93.0565 - val_loss: 31.8271 - val_mae: 100.0142 - 93ms/epoch - 19ms/step\n",
      "Epoch 48/300\n",
      "5/5 - 0s - loss: 36.9218 - mae: 93.0835 - val_loss: 31.4854 - val_mae: 99.7388 - 90ms/epoch - 18ms/step\n",
      "Epoch 49/300\n",
      "5/5 - 0s - loss: 36.4963 - mae: 92.7018 - val_loss: 31.1470 - val_mae: 99.3569 - 89ms/epoch - 18ms/step\n",
      "Epoch 50/300\n",
      "5/5 - 0s - loss: 36.0732 - mae: 92.8238 - val_loss: 30.8527 - val_mae: 99.4651 - 113ms/epoch - 23ms/step\n",
      "Epoch 51/300\n",
      "5/5 - 0s - loss: 35.5625 - mae: 92.6093 - val_loss: 30.5335 - val_mae: 99.8214 - 95ms/epoch - 19ms/step\n",
      "Epoch 52/300\n",
      "5/5 - 0s - loss: 35.1671 - mae: 92.4922 - val_loss: 30.2331 - val_mae: 98.9237 - 90ms/epoch - 18ms/step\n",
      "Epoch 53/300\n",
      "5/5 - 0s - loss: 34.8643 - mae: 92.4715 - val_loss: 29.9211 - val_mae: 99.1421 - 89ms/epoch - 18ms/step\n",
      "Epoch 54/300\n",
      "5/5 - 0s - loss: 34.3510 - mae: 92.4193 - val_loss: 29.6247 - val_mae: 99.7766 - 88ms/epoch - 18ms/step\n",
      "Epoch 55/300\n",
      "5/5 - 0s - loss: 34.0045 - mae: 92.3005 - val_loss: 29.3332 - val_mae: 98.4358 - 87ms/epoch - 17ms/step\n",
      "Epoch 56/300\n",
      "5/5 - 0s - loss: 33.5870 - mae: 92.5352 - val_loss: 29.0649 - val_mae: 98.7553 - 88ms/epoch - 18ms/step\n",
      "Epoch 57/300\n",
      "5/5 - 0s - loss: 33.3123 - mae: 92.1353 - val_loss: 28.7642 - val_mae: 98.7175 - 85ms/epoch - 17ms/step\n",
      "Epoch 58/300\n",
      "5/5 - 0s - loss: 32.8528 - mae: 91.9697 - val_loss: 28.4991 - val_mae: 98.5102 - 90ms/epoch - 18ms/step\n",
      "Epoch 59/300\n",
      "5/5 - 0s - loss: 32.5386 - mae: 92.0007 - val_loss: 28.2383 - val_mae: 99.1062 - 89ms/epoch - 18ms/step\n",
      "Epoch 60/300\n",
      "5/5 - 0s - loss: 32.2290 - mae: 91.8112 - val_loss: 27.9827 - val_mae: 98.2170 - 86ms/epoch - 17ms/step\n",
      "Epoch 61/300\n",
      "5/5 - 0s - loss: 31.8981 - mae: 91.8439 - val_loss: 27.7382 - val_mae: 98.3539 - 113ms/epoch - 23ms/step\n",
      "Epoch 62/300\n",
      "5/5 - 0s - loss: 31.6094 - mae: 91.7512 - val_loss: 27.4810 - val_mae: 98.0387 - 94ms/epoch - 19ms/step\n",
      "Epoch 63/300\n",
      "5/5 - 0s - loss: 31.4534 - mae: 91.5933 - val_loss: 27.2454 - val_mae: 98.9879 - 87ms/epoch - 17ms/step\n",
      "Epoch 64/300\n",
      "5/5 - 0s - loss: 30.9870 - mae: 91.6230 - val_loss: 27.0192 - val_mae: 98.2133 - 87ms/epoch - 17ms/step\n",
      "Epoch 65/300\n",
      "5/5 - 0s - loss: 30.7544 - mae: 91.4675 - val_loss: 26.8013 - val_mae: 98.0685 - 86ms/epoch - 17ms/step\n",
      "Epoch 66/300\n",
      "5/5 - 0s - loss: 30.4531 - mae: 91.5183 - val_loss: 26.5653 - val_mae: 98.1743 - 87ms/epoch - 17ms/step\n",
      "Epoch 67/300\n",
      "5/5 - 0s - loss: 30.1540 - mae: 91.2014 - val_loss: 26.3447 - val_mae: 97.6967 - 94ms/epoch - 19ms/step\n",
      "Epoch 68/300\n",
      "5/5 - 0s - loss: 29.9257 - mae: 91.2690 - val_loss: 26.1269 - val_mae: 98.1342 - 89ms/epoch - 18ms/step\n",
      "Epoch 69/300\n",
      "5/5 - 0s - loss: 29.6315 - mae: 91.0401 - val_loss: 25.9028 - val_mae: 97.8505 - 88ms/epoch - 18ms/step\n",
      "Epoch 70/300\n",
      "5/5 - 0s - loss: 29.3657 - mae: 91.0667 - val_loss: 25.7110 - val_mae: 97.9608 - 88ms/epoch - 18ms/step\n",
      "Epoch 71/300\n",
      "5/5 - 0s - loss: 29.1031 - mae: 91.0284 - val_loss: 25.4998 - val_mae: 97.6474 - 88ms/epoch - 18ms/step\n",
      "Epoch 72/300\n",
      "5/5 - 0s - loss: 28.9486 - mae: 90.9255 - val_loss: 25.3045 - val_mae: 97.0632 - 115ms/epoch - 23ms/step\n",
      "Epoch 73/300\n",
      "5/5 - 0s - loss: 28.6328 - mae: 90.7375 - val_loss: 25.1065 - val_mae: 97.5730 - 92ms/epoch - 18ms/step\n",
      "Epoch 74/300\n",
      "5/5 - 0s - loss: 28.4250 - mae: 90.8425 - val_loss: 24.9232 - val_mae: 97.7681 - 89ms/epoch - 18ms/step\n",
      "Epoch 75/300\n",
      "5/5 - 0s - loss: 28.2401 - mae: 90.7580 - val_loss: 24.7454 - val_mae: 96.4720 - 88ms/epoch - 18ms/step\n",
      "Epoch 76/300\n",
      "5/5 - 0s - loss: 27.9416 - mae: 90.7671 - val_loss: 24.5393 - val_mae: 97.2595 - 141ms/epoch - 28ms/step\n",
      "Epoch 77/300\n",
      "5/5 - 0s - loss: 27.7342 - mae: 90.6093 - val_loss: 24.3537 - val_mae: 97.1536 - 149ms/epoch - 30ms/step\n",
      "Epoch 78/300\n",
      "5/5 - 0s - loss: 27.5382 - mae: 90.6068 - val_loss: 24.1732 - val_mae: 96.8217 - 148ms/epoch - 30ms/step\n",
      "Epoch 79/300\n",
      "5/5 - 0s - loss: 27.3554 - mae: 90.5313 - val_loss: 24.0031 - val_mae: 96.8339 - 146ms/epoch - 29ms/step\n",
      "Epoch 80/300\n",
      "5/5 - 0s - loss: 27.1989 - mae: 90.1825 - val_loss: 23.8167 - val_mae: 97.6884 - 159ms/epoch - 32ms/step\n",
      "Epoch 81/300\n",
      "5/5 - 0s - loss: 26.9994 - mae: 90.2606 - val_loss: 23.6648 - val_mae: 96.5960 - 153ms/epoch - 31ms/step\n",
      "Epoch 82/300\n",
      "5/5 - 0s - loss: 26.7668 - mae: 90.0281 - val_loss: 23.4887 - val_mae: 97.1193 - 142ms/epoch - 28ms/step\n",
      "Epoch 83/300\n",
      "5/5 - 0s - loss: 26.5846 - mae: 90.0552 - val_loss: 23.3190 - val_mae: 96.1353 - 153ms/epoch - 31ms/step\n",
      "Epoch 84/300\n",
      "5/5 - 0s - loss: 26.3953 - mae: 90.2517 - val_loss: 23.1548 - val_mae: 96.8340 - 150ms/epoch - 30ms/step\n",
      "Epoch 85/300\n",
      "5/5 - 0s - loss: 26.1870 - mae: 90.0323 - val_loss: 22.9833 - val_mae: 97.0730 - 143ms/epoch - 29ms/step\n",
      "Epoch 86/300\n",
      "5/5 - 0s - loss: 26.0929 - mae: 89.8334 - val_loss: 22.8205 - val_mae: 96.3478 - 141ms/epoch - 28ms/step\n",
      "Epoch 87/300\n",
      "5/5 - 0s - loss: 25.8208 - mae: 89.7894 - val_loss: 22.6619 - val_mae: 96.2408 - 173ms/epoch - 35ms/step\n",
      "Epoch 88/300\n",
      "5/5 - 0s - loss: 25.7031 - mae: 89.7352 - val_loss: 22.5081 - val_mae: 96.5986 - 153ms/epoch - 31ms/step\n",
      "Epoch 89/300\n",
      "5/5 - 0s - loss: 25.4907 - mae: 89.7625 - val_loss: 22.3714 - val_mae: 95.8826 - 168ms/epoch - 34ms/step\n",
      "Epoch 90/300\n",
      "5/5 - 0s - loss: 25.3008 - mae: 89.6295 - val_loss: 22.2216 - val_mae: 96.2217 - 149ms/epoch - 30ms/step\n",
      "Epoch 91/300\n",
      "5/5 - 0s - loss: 25.1348 - mae: 89.4316 - val_loss: 22.0809 - val_mae: 96.1196 - 111ms/epoch - 22ms/step\n",
      "Epoch 92/300\n",
      "5/5 - 0s - loss: 24.9973 - mae: 89.5098 - val_loss: 21.9315 - val_mae: 95.7087 - 103ms/epoch - 21ms/step\n",
      "Epoch 93/300\n",
      "5/5 - 0s - loss: 24.8372 - mae: 89.2809 - val_loss: 21.7873 - val_mae: 95.6222 - 87ms/epoch - 17ms/step\n",
      "Epoch 94/300\n",
      "5/5 - 0s - loss: 24.7092 - mae: 89.4479 - val_loss: 21.6593 - val_mae: 95.6194 - 111ms/epoch - 22ms/step\n",
      "Epoch 95/300\n",
      "5/5 - 0s - loss: 24.5053 - mae: 89.3515 - val_loss: 21.5313 - val_mae: 95.0704 - 91ms/epoch - 18ms/step\n",
      "Epoch 96/300\n",
      "5/5 - 0s - loss: 24.4086 - mae: 89.0871 - val_loss: 21.3969 - val_mae: 95.4505 - 109ms/epoch - 22ms/step\n",
      "Epoch 97/300\n",
      "5/5 - 0s - loss: 24.2297 - mae: 89.1504 - val_loss: 21.2681 - val_mae: 94.8395 - 91ms/epoch - 18ms/step\n",
      "Epoch 98/300\n",
      "5/5 - 0s - loss: 24.0963 - mae: 89.1794 - val_loss: 21.1314 - val_mae: 95.4327 - 88ms/epoch - 18ms/step\n",
      "Epoch 99/300\n",
      "5/5 - 0s - loss: 23.9456 - mae: 89.0050 - val_loss: 21.0052 - val_mae: 95.6031 - 88ms/epoch - 18ms/step\n",
      "Epoch 100/300\n",
      "5/5 - 0s - loss: 23.8211 - mae: 88.8871 - val_loss: 20.8721 - val_mae: 95.2780 - 86ms/epoch - 17ms/step\n",
      "Epoch 101/300\n",
      "5/5 - 0s - loss: 23.6936 - mae: 89.1179 - val_loss: 20.7384 - val_mae: 94.9941 - 91ms/epoch - 18ms/step\n",
      "Epoch 102/300\n",
      "5/5 - 0s - loss: 23.5240 - mae: 88.6442 - val_loss: 20.6250 - val_mae: 94.8043 - 87ms/epoch - 17ms/step\n",
      "Epoch 103/300\n",
      "5/5 - 0s - loss: 23.3887 - mae: 88.7293 - val_loss: 20.4996 - val_mae: 95.1169 - 87ms/epoch - 17ms/step\n",
      "Epoch 104/300\n",
      "5/5 - 0s - loss: 23.2532 - mae: 88.5538 - val_loss: 20.3892 - val_mae: 94.3646 - 91ms/epoch - 18ms/step\n",
      "Epoch 105/300\n",
      "5/5 - 0s - loss: 23.1435 - mae: 88.3809 - val_loss: 20.2710 - val_mae: 94.4146 - 89ms/epoch - 18ms/step\n",
      "Epoch 106/300\n",
      "5/5 - 0s - loss: 23.0775 - mae: 88.4245 - val_loss: 20.1652 - val_mae: 94.7121 - 90ms/epoch - 18ms/step\n",
      "Epoch 107/300\n",
      "5/5 - 0s - loss: 22.9608 - mae: 88.4404 - val_loss: 20.0450 - val_mae: 94.8790 - 110ms/epoch - 22ms/step\n",
      "Epoch 108/300\n",
      "5/5 - 0s - loss: 22.7501 - mae: 88.3964 - val_loss: 19.9313 - val_mae: 94.0265 - 88ms/epoch - 18ms/step\n",
      "Epoch 109/300\n",
      "5/5 - 0s - loss: 22.6329 - mae: 88.3781 - val_loss: 19.8284 - val_mae: 94.5752 - 92ms/epoch - 18ms/step\n",
      "Epoch 110/300\n",
      "5/5 - 0s - loss: 22.5281 - mae: 88.1349 - val_loss: 19.7156 - val_mae: 94.3412 - 91ms/epoch - 18ms/step\n",
      "Epoch 111/300\n",
      "5/5 - 0s - loss: 22.3994 - mae: 88.0558 - val_loss: 19.6131 - val_mae: 94.4530 - 90ms/epoch - 18ms/step\n",
      "Epoch 112/300\n",
      "5/5 - 0s - loss: 22.2893 - mae: 88.0905 - val_loss: 19.5102 - val_mae: 94.8550 - 91ms/epoch - 18ms/step\n",
      "Epoch 113/300\n",
      "5/5 - 0s - loss: 22.1694 - mae: 87.9911 - val_loss: 19.4087 - val_mae: 94.4626 - 86ms/epoch - 17ms/step\n",
      "Epoch 114/300\n",
      "5/5 - 0s - loss: 22.0486 - mae: 87.9459 - val_loss: 19.3085 - val_mae: 94.1058 - 90ms/epoch - 18ms/step\n",
      "Epoch 115/300\n",
      "5/5 - 0s - loss: 21.9221 - mae: 87.7159 - val_loss: 19.2041 - val_mae: 94.1401 - 95ms/epoch - 19ms/step\n",
      "Epoch 116/300\n",
      "5/5 - 0s - loss: 21.8255 - mae: 87.6839 - val_loss: 19.0965 - val_mae: 93.7172 - 95ms/epoch - 19ms/step\n",
      "Epoch 117/300\n",
      "5/5 - 0s - loss: 21.6891 - mae: 87.8217 - val_loss: 18.9991 - val_mae: 93.2564 - 85ms/epoch - 17ms/step\n",
      "Epoch 118/300\n",
      "5/5 - 0s - loss: 21.5788 - mae: 87.7310 - val_loss: 18.9082 - val_mae: 93.5997 - 112ms/epoch - 22ms/step\n",
      "Epoch 119/300\n",
      "5/5 - 0s - loss: 21.5368 - mae: 87.4763 - val_loss: 18.8092 - val_mae: 94.0209 - 87ms/epoch - 17ms/step\n",
      "Epoch 120/300\n",
      "5/5 - 0s - loss: 21.3709 - mae: 87.4801 - val_loss: 18.7141 - val_mae: 93.8250 - 93ms/epoch - 19ms/step\n",
      "Epoch 121/300\n",
      "5/5 - 0s - loss: 21.2975 - mae: 87.7913 - val_loss: 18.6280 - val_mae: 93.5502 - 91ms/epoch - 18ms/step\n",
      "Epoch 122/300\n",
      "5/5 - 0s - loss: 21.1853 - mae: 87.4353 - val_loss: 18.5282 - val_mae: 93.5121 - 88ms/epoch - 18ms/step\n",
      "Epoch 123/300\n",
      "5/5 - 0s - loss: 21.0670 - mae: 87.4128 - val_loss: 18.4462 - val_mae: 93.8380 - 86ms/epoch - 17ms/step\n",
      "Epoch 124/300\n",
      "5/5 - 0s - loss: 20.9839 - mae: 87.3518 - val_loss: 18.3652 - val_mae: 93.5440 - 90ms/epoch - 18ms/step\n",
      "Epoch 125/300\n",
      "5/5 - 0s - loss: 20.8858 - mae: 87.2492 - val_loss: 18.2756 - val_mae: 93.6830 - 90ms/epoch - 18ms/step\n",
      "Epoch 126/300\n",
      "5/5 - 0s - loss: 20.8089 - mae: 87.1548 - val_loss: 18.1887 - val_mae: 93.2595 - 93ms/epoch - 19ms/step\n",
      "Epoch 127/300\n",
      "5/5 - 0s - loss: 20.7038 - mae: 87.1736 - val_loss: 18.1024 - val_mae: 92.8801 - 101ms/epoch - 20ms/step\n",
      "Epoch 128/300\n",
      "5/5 - 0s - loss: 20.5782 - mae: 87.1079 - val_loss: 18.0149 - val_mae: 93.3910 - 90ms/epoch - 18ms/step\n",
      "Epoch 129/300\n",
      "5/5 - 0s - loss: 20.5032 - mae: 86.8675 - val_loss: 17.9409 - val_mae: 93.5158 - 109ms/epoch - 22ms/step\n",
      "Epoch 130/300\n",
      "5/5 - 0s - loss: 20.3880 - mae: 87.1653 - val_loss: 17.8575 - val_mae: 93.0973 - 85ms/epoch - 17ms/step\n",
      "Epoch 131/300\n",
      "5/5 - 0s - loss: 20.2982 - mae: 86.9260 - val_loss: 17.7773 - val_mae: 92.7024 - 90ms/epoch - 18ms/step\n",
      "Epoch 132/300\n",
      "5/5 - 0s - loss: 20.2088 - mae: 86.7821 - val_loss: 17.6977 - val_mae: 92.5506 - 88ms/epoch - 18ms/step\n",
      "Epoch 133/300\n",
      "5/5 - 0s - loss: 20.1345 - mae: 86.6848 - val_loss: 17.6179 - val_mae: 93.2244 - 93ms/epoch - 19ms/step\n",
      "Epoch 134/300\n",
      "5/5 - 0s - loss: 20.0189 - mae: 86.9369 - val_loss: 17.5440 - val_mae: 91.9159 - 89ms/epoch - 18ms/step\n",
      "Epoch 135/300\n",
      "5/5 - 0s - loss: 19.9195 - mae: 86.5995 - val_loss: 17.4632 - val_mae: 92.7629 - 98ms/epoch - 20ms/step\n",
      "Epoch 136/300\n",
      "5/5 - 0s - loss: 19.8541 - mae: 86.4470 - val_loss: 17.3886 - val_mae: 91.9146 - 95ms/epoch - 19ms/step\n",
      "Epoch 137/300\n",
      "5/5 - 0s - loss: 19.7947 - mae: 86.5281 - val_loss: 17.3121 - val_mae: 92.5475 - 93ms/epoch - 19ms/step\n",
      "Epoch 138/300\n",
      "5/5 - 0s - loss: 19.7032 - mae: 86.4783 - val_loss: 17.2285 - val_mae: 92.5793 - 88ms/epoch - 18ms/step\n",
      "Epoch 139/300\n",
      "5/5 - 0s - loss: 19.5924 - mae: 86.3698 - val_loss: 17.1536 - val_mae: 92.9757 - 91ms/epoch - 18ms/step\n",
      "Epoch 140/300\n",
      "5/5 - 0s - loss: 19.5178 - mae: 86.3832 - val_loss: 17.0822 - val_mae: 91.9428 - 103ms/epoch - 21ms/step\n",
      "Epoch 141/300\n",
      "5/5 - 0s - loss: 19.4471 - mae: 86.2095 - val_loss: 17.0141 - val_mae: 91.9288 - 86ms/epoch - 17ms/step\n",
      "Epoch 142/300\n",
      "5/5 - 0s - loss: 19.3598 - mae: 86.1658 - val_loss: 16.9488 - val_mae: 92.1974 - 86ms/epoch - 17ms/step\n",
      "Epoch 143/300\n",
      "5/5 - 0s - loss: 19.2860 - mae: 86.3640 - val_loss: 16.8807 - val_mae: 91.9813 - 90ms/epoch - 18ms/step\n",
      "Epoch 144/300\n",
      "5/5 - 0s - loss: 19.2021 - mae: 86.2378 - val_loss: 16.8104 - val_mae: 92.2174 - 87ms/epoch - 17ms/step\n",
      "Epoch 145/300\n",
      "5/5 - 0s - loss: 19.1310 - mae: 86.2935 - val_loss: 16.7365 - val_mae: 92.4060 - 93ms/epoch - 19ms/step\n",
      "Epoch 146/300\n",
      "5/5 - 0s - loss: 19.0434 - mae: 86.0320 - val_loss: 16.6722 - val_mae: 92.1454 - 93ms/epoch - 19ms/step\n",
      "Epoch 147/300\n",
      "5/5 - 0s - loss: 18.9632 - mae: 86.0054 - val_loss: 16.6059 - val_mae: 91.8685 - 95ms/epoch - 19ms/step\n",
      "Epoch 148/300\n",
      "5/5 - 0s - loss: 18.8877 - mae: 86.0446 - val_loss: 16.5342 - val_mae: 91.6444 - 93ms/epoch - 19ms/step\n",
      "Epoch 149/300\n",
      "5/5 - 0s - loss: 18.8393 - mae: 85.7593 - val_loss: 16.4729 - val_mae: 91.0706 - 86ms/epoch - 17ms/step\n",
      "Epoch 150/300\n",
      "5/5 - 0s - loss: 18.7425 - mae: 85.7097 - val_loss: 16.4100 - val_mae: 90.3854 - 84ms/epoch - 17ms/step\n",
      "Epoch 151/300\n",
      "5/5 - 0s - loss: 18.6994 - mae: 85.6722 - val_loss: 16.3432 - val_mae: 90.7286 - 107ms/epoch - 21ms/step\n",
      "Epoch 152/300\n",
      "5/5 - 0s - loss: 18.6338 - mae: 85.6777 - val_loss: 16.2835 - val_mae: 91.2930 - 85ms/epoch - 17ms/step\n",
      "Epoch 153/300\n",
      "5/5 - 0s - loss: 18.5578 - mae: 85.8121 - val_loss: 16.2150 - val_mae: 91.2095 - 86ms/epoch - 17ms/step\n",
      "Epoch 154/300\n",
      "5/5 - 0s - loss: 18.4714 - mae: 85.5016 - val_loss: 16.1545 - val_mae: 91.4012 - 90ms/epoch - 18ms/step\n",
      "Epoch 155/300\n",
      "5/5 - 0s - loss: 18.4002 - mae: 85.5254 - val_loss: 16.0889 - val_mae: 91.4762 - 87ms/epoch - 17ms/step\n",
      "Epoch 156/300\n",
      "5/5 - 0s - loss: 18.3358 - mae: 85.5297 - val_loss: 16.0268 - val_mae: 90.8104 - 88ms/epoch - 18ms/step\n",
      "Epoch 157/300\n",
      "5/5 - 0s - loss: 18.2766 - mae: 85.5469 - val_loss: 15.9661 - val_mae: 90.2914 - 96ms/epoch - 19ms/step\n",
      "Epoch 158/300\n",
      "5/5 - 0s - loss: 18.2082 - mae: 85.3941 - val_loss: 15.9087 - val_mae: 91.3815 - 91ms/epoch - 18ms/step\n",
      "Epoch 159/300\n",
      "5/5 - 0s - loss: 18.1392 - mae: 84.9471 - val_loss: 15.8553 - val_mae: 90.7742 - 92ms/epoch - 18ms/step\n",
      "Epoch 160/300\n",
      "5/5 - 0s - loss: 18.0731 - mae: 85.2142 - val_loss: 15.7980 - val_mae: 90.2926 - 87ms/epoch - 17ms/step\n",
      "Epoch 161/300\n",
      "5/5 - 0s - loss: 18.0067 - mae: 84.9851 - val_loss: 15.7350 - val_mae: 90.2721 - 86ms/epoch - 17ms/step\n",
      "Epoch 162/300\n",
      "5/5 - 0s - loss: 17.9276 - mae: 85.2876 - val_loss: 15.6781 - val_mae: 90.0075 - 109ms/epoch - 22ms/step\n",
      "Epoch 163/300\n",
      "5/5 - 0s - loss: 17.8525 - mae: 85.0495 - val_loss: 15.6237 - val_mae: 90.7461 - 92ms/epoch - 18ms/step\n",
      "Epoch 164/300\n",
      "5/5 - 0s - loss: 17.7982 - mae: 85.1733 - val_loss: 15.5700 - val_mae: 89.9761 - 86ms/epoch - 17ms/step\n",
      "Epoch 165/300\n",
      "5/5 - 0s - loss: 17.7250 - mae: 84.8728 - val_loss: 15.5120 - val_mae: 90.6857 - 91ms/epoch - 18ms/step\n",
      "Epoch 166/300\n",
      "5/5 - 0s - loss: 17.6817 - mae: 85.2187 - val_loss: 15.4504 - val_mae: 89.8960 - 88ms/epoch - 18ms/step\n",
      "Epoch 167/300\n",
      "5/5 - 0s - loss: 17.6050 - mae: 85.1311 - val_loss: 15.3937 - val_mae: 90.0877 - 89ms/epoch - 18ms/step\n",
      "Epoch 168/300\n",
      "5/5 - 0s - loss: 17.5405 - mae: 84.6138 - val_loss: 15.3436 - val_mae: 89.9213 - 91ms/epoch - 18ms/step\n",
      "Epoch 169/300\n",
      "5/5 - 0s - loss: 17.4874 - mae: 84.9828 - val_loss: 15.2891 - val_mae: 89.5137 - 97ms/epoch - 19ms/step\n",
      "Epoch 170/300\n",
      "5/5 - 0s - loss: 17.4166 - mae: 84.7112 - val_loss: 15.2351 - val_mae: 89.2776 - 86ms/epoch - 17ms/step\n",
      "Epoch 171/300\n",
      "5/5 - 0s - loss: 17.3586 - mae: 84.7811 - val_loss: 15.1858 - val_mae: 90.1059 - 87ms/epoch - 17ms/step\n",
      "Epoch 172/300\n",
      "5/5 - 0s - loss: 17.3235 - mae: 84.5717 - val_loss: 15.1392 - val_mae: 89.7356 - 85ms/epoch - 17ms/step\n",
      "Epoch 173/300\n",
      "5/5 - 0s - loss: 17.2378 - mae: 84.4045 - val_loss: 15.0877 - val_mae: 89.4835 - 111ms/epoch - 22ms/step\n",
      "Epoch 174/300\n",
      "5/5 - 0s - loss: 17.1790 - mae: 84.4310 - val_loss: 15.0376 - val_mae: 89.4736 - 85ms/epoch - 17ms/step\n",
      "Epoch 175/300\n",
      "5/5 - 0s - loss: 17.1279 - mae: 84.4213 - val_loss: 14.9871 - val_mae: 89.9188 - 89ms/epoch - 18ms/step\n",
      "Epoch 176/300\n",
      "5/5 - 0s - loss: 17.0733 - mae: 84.3627 - val_loss: 14.9324 - val_mae: 90.0987 - 88ms/epoch - 18ms/step\n",
      "Epoch 177/300\n",
      "5/5 - 0s - loss: 17.0209 - mae: 84.4987 - val_loss: 14.8837 - val_mae: 89.3889 - 87ms/epoch - 17ms/step\n",
      "Epoch 178/300\n",
      "5/5 - 0s - loss: 16.9775 - mae: 84.4510 - val_loss: 14.8399 - val_mae: 88.7515 - 95ms/epoch - 19ms/step\n",
      "Epoch 179/300\n",
      "5/5 - 0s - loss: 16.8911 - mae: 84.2028 - val_loss: 14.7880 - val_mae: 89.9415 - 88ms/epoch - 18ms/step\n",
      "Epoch 180/300\n",
      "5/5 - 0s - loss: 16.8478 - mae: 84.0539 - val_loss: 14.7381 - val_mae: 89.6676 - 106ms/epoch - 21ms/step\n",
      "Epoch 181/300\n",
      "5/5 - 0s - loss: 16.8145 - mae: 84.3353 - val_loss: 14.6939 - val_mae: 89.5526 - 85ms/epoch - 17ms/step\n",
      "Epoch 182/300\n",
      "5/5 - 0s - loss: 16.7401 - mae: 83.9610 - val_loss: 14.6448 - val_mae: 89.1203 - 86ms/epoch - 17ms/step\n",
      "Epoch 183/300\n",
      "5/5 - 0s - loss: 16.6833 - mae: 84.1238 - val_loss: 14.5984 - val_mae: 89.6822 - 85ms/epoch - 17ms/step\n",
      "Epoch 184/300\n",
      "5/5 - 0s - loss: 16.6515 - mae: 84.0268 - val_loss: 14.5572 - val_mae: 88.9145 - 108ms/epoch - 22ms/step\n",
      "Epoch 185/300\n",
      "5/5 - 0s - loss: 16.5876 - mae: 83.8569 - val_loss: 14.5066 - val_mae: 89.3952 - 85ms/epoch - 17ms/step\n",
      "Epoch 186/300\n",
      "5/5 - 0s - loss: 16.5333 - mae: 83.8883 - val_loss: 14.4579 - val_mae: 88.5894 - 86ms/epoch - 17ms/step\n",
      "Epoch 187/300\n",
      "5/5 - 0s - loss: 16.4834 - mae: 84.0586 - val_loss: 14.4132 - val_mae: 88.6466 - 89ms/epoch - 18ms/step\n",
      "Epoch 188/300\n",
      "5/5 - 0s - loss: 16.4381 - mae: 83.8621 - val_loss: 14.3703 - val_mae: 89.4056 - 88ms/epoch - 18ms/step\n",
      "Epoch 189/300\n",
      "5/5 - 0s - loss: 16.3935 - mae: 83.7054 - val_loss: 14.3224 - val_mae: 87.9928 - 94ms/epoch - 19ms/step\n",
      "Epoch 190/300\n",
      "5/5 - 0s - loss: 16.3246 - mae: 83.6416 - val_loss: 14.2774 - val_mae: 88.8849 - 92ms/epoch - 18ms/step\n",
      "Epoch 191/300\n",
      "5/5 - 0s - loss: 16.2744 - mae: 83.4211 - val_loss: 14.2344 - val_mae: 88.8817 - 89ms/epoch - 18ms/step\n",
      "Epoch 192/300\n",
      "5/5 - 0s - loss: 16.2271 - mae: 83.8096 - val_loss: 14.1903 - val_mae: 88.7542 - 83ms/epoch - 17ms/step\n",
      "Epoch 193/300\n",
      "5/5 - 0s - loss: 16.1859 - mae: 83.5170 - val_loss: 14.1493 - val_mae: 88.5732 - 86ms/epoch - 17ms/step\n",
      "Epoch 194/300\n",
      "5/5 - 0s - loss: 16.1232 - mae: 83.3577 - val_loss: 14.1080 - val_mae: 88.3205 - 87ms/epoch - 17ms/step\n",
      "Epoch 195/300\n",
      "5/5 - 0s - loss: 16.1038 - mae: 83.5393 - val_loss: 14.0648 - val_mae: 88.2953 - 105ms/epoch - 21ms/step\n",
      "Epoch 196/300\n",
      "5/5 - 0s - loss: 16.0385 - mae: 83.5302 - val_loss: 14.0165 - val_mae: 88.1566 - 146ms/epoch - 29ms/step\n",
      "Epoch 197/300\n",
      "5/5 - 0s - loss: 15.9816 - mae: 83.5068 - val_loss: 13.9745 - val_mae: 88.4251 - 145ms/epoch - 29ms/step\n",
      "Epoch 198/300\n",
      "5/5 - 0s - loss: 15.9336 - mae: 83.3843 - val_loss: 13.9304 - val_mae: 88.3281 - 156ms/epoch - 31ms/step\n",
      "Epoch 199/300\n",
      "5/5 - 0s - loss: 15.8909 - mae: 83.1428 - val_loss: 13.8903 - val_mae: 87.1727 - 160ms/epoch - 32ms/step\n",
      "Epoch 200/300\n",
      "5/5 - 0s - loss: 15.8500 - mae: 83.0783 - val_loss: 13.8487 - val_mae: 87.4019 - 144ms/epoch - 29ms/step\n",
      "Epoch 201/300\n",
      "5/5 - 0s - loss: 15.7949 - mae: 82.9415 - val_loss: 13.8092 - val_mae: 88.5534 - 141ms/epoch - 28ms/step\n",
      "Epoch 202/300\n",
      "5/5 - 0s - loss: 15.7518 - mae: 83.0226 - val_loss: 13.7711 - val_mae: 88.0347 - 149ms/epoch - 30ms/step\n",
      "Epoch 203/300\n",
      "5/5 - 0s - loss: 15.7318 - mae: 83.2766 - val_loss: 13.7310 - val_mae: 87.4384 - 142ms/epoch - 28ms/step\n",
      "Epoch 204/300\n",
      "5/5 - 0s - loss: 15.6691 - mae: 83.3582 - val_loss: 13.6919 - val_mae: 86.8017 - 162ms/epoch - 32ms/step\n",
      "Epoch 205/300\n",
      "5/5 - 0s - loss: 15.6222 - mae: 82.7916 - val_loss: 13.6518 - val_mae: 86.9665 - 162ms/epoch - 32ms/step\n",
      "Epoch 206/300\n",
      "5/5 - 0s - loss: 15.5772 - mae: 83.3967 - val_loss: 13.6126 - val_mae: 87.4745 - 146ms/epoch - 29ms/step\n",
      "Epoch 207/300\n",
      "5/5 - 0s - loss: 15.5348 - mae: 82.6975 - val_loss: 13.5757 - val_mae: 87.5807 - 147ms/epoch - 29ms/step\n",
      "Epoch 208/300\n",
      "5/5 - 0s - loss: 15.4896 - mae: 83.0361 - val_loss: 13.5376 - val_mae: 88.0900 - 152ms/epoch - 30ms/step\n",
      "Epoch 209/300\n",
      "5/5 - 0s - loss: 15.4494 - mae: 82.8052 - val_loss: 13.5021 - val_mae: 86.7803 - 159ms/epoch - 32ms/step\n",
      "Epoch 210/300\n",
      "5/5 - 0s - loss: 15.4694 - mae: 82.8553 - val_loss: 13.4586 - val_mae: 87.4616 - 158ms/epoch - 32ms/step\n",
      "Epoch 211/300\n",
      "5/5 - 0s - loss: 15.3610 - mae: 82.8466 - val_loss: 13.4205 - val_mae: 87.2053 - 114ms/epoch - 23ms/step\n",
      "Epoch 212/300\n",
      "5/5 - 0s - loss: 15.3249 - mae: 82.6726 - val_loss: 13.3820 - val_mae: 87.9018 - 93ms/epoch - 19ms/step\n",
      "Epoch 213/300\n",
      "5/5 - 0s - loss: 15.2733 - mae: 83.1371 - val_loss: 13.3494 - val_mae: 85.9918 - 90ms/epoch - 18ms/step\n",
      "Epoch 214/300\n",
      "5/5 - 0s - loss: 15.2376 - mae: 82.6024 - val_loss: 13.3127 - val_mae: 87.3591 - 85ms/epoch - 17ms/step\n",
      "Epoch 215/300\n",
      "5/5 - 0s - loss: 15.1953 - mae: 82.3451 - val_loss: 13.2742 - val_mae: 87.8497 - 88ms/epoch - 18ms/step\n",
      "Epoch 216/300\n",
      "5/5 - 0s - loss: 15.1531 - mae: 82.6466 - val_loss: 13.2376 - val_mae: 86.4320 - 87ms/epoch - 17ms/step\n",
      "Epoch 217/300\n",
      "5/5 - 0s - loss: 15.1161 - mae: 82.4161 - val_loss: 13.2000 - val_mae: 86.7063 - 85ms/epoch - 17ms/step\n",
      "Epoch 218/300\n",
      "5/5 - 0s - loss: 15.0725 - mae: 82.4195 - val_loss: 13.1661 - val_mae: 86.7258 - 87ms/epoch - 17ms/step\n",
      "Epoch 219/300\n",
      "5/5 - 0s - loss: 15.0288 - mae: 82.1060 - val_loss: 13.1322 - val_mae: 86.1883 - 93ms/epoch - 19ms/step\n",
      "Epoch 220/300\n",
      "5/5 - 0s - loss: 14.9911 - mae: 82.2660 - val_loss: 13.0974 - val_mae: 85.6345 - 95ms/epoch - 19ms/step\n",
      "Epoch 221/300\n",
      "5/5 - 0s - loss: 14.9542 - mae: 82.2869 - val_loss: 13.0650 - val_mae: 86.4811 - 92ms/epoch - 18ms/step\n",
      "Epoch 222/300\n",
      "5/5 - 0s - loss: 14.9783 - mae: 82.3521 - val_loss: 13.0255 - val_mae: 85.5657 - 89ms/epoch - 18ms/step\n",
      "Epoch 223/300\n",
      "5/5 - 0s - loss: 14.8841 - mae: 82.2869 - val_loss: 12.9896 - val_mae: 85.9420 - 86ms/epoch - 17ms/step\n",
      "Epoch 224/300\n",
      "5/5 - 0s - loss: 14.8699 - mae: 82.1486 - val_loss: 12.9558 - val_mae: 85.8574 - 104ms/epoch - 21ms/step\n",
      "Epoch 225/300\n",
      "5/5 - 0s - loss: 14.8307 - mae: 82.1525 - val_loss: 12.9213 - val_mae: 86.1301 - 91ms/epoch - 18ms/step\n",
      "Epoch 226/300\n",
      "5/5 - 0s - loss: 14.7646 - mae: 81.9304 - val_loss: 12.8902 - val_mae: 86.2015 - 112ms/epoch - 22ms/step\n",
      "Epoch 227/300\n",
      "5/5 - 0s - loss: 14.7319 - mae: 81.9404 - val_loss: 12.8565 - val_mae: 86.0215 - 90ms/epoch - 18ms/step\n",
      "Epoch 228/300\n",
      "5/5 - 0s - loss: 14.6943 - mae: 82.0753 - val_loss: 12.8237 - val_mae: 85.0740 - 86ms/epoch - 17ms/step\n",
      "Epoch 229/300\n",
      "5/5 - 0s - loss: 14.6620 - mae: 81.8327 - val_loss: 12.7921 - val_mae: 85.1965 - 90ms/epoch - 18ms/step\n",
      "Epoch 230/300\n",
      "5/5 - 0s - loss: 14.6260 - mae: 81.8163 - val_loss: 12.7583 - val_mae: 85.5721 - 107ms/epoch - 21ms/step\n",
      "Epoch 231/300\n",
      "5/5 - 0s - loss: 14.5841 - mae: 81.9001 - val_loss: 12.7287 - val_mae: 86.3387 - 90ms/epoch - 18ms/step\n",
      "Epoch 232/300\n",
      "5/5 - 0s - loss: 14.5447 - mae: 81.8014 - val_loss: 12.6971 - val_mae: 85.4462 - 93ms/epoch - 19ms/step\n",
      "Epoch 233/300\n",
      "5/5 - 0s - loss: 14.5133 - mae: 81.6660 - val_loss: 12.6640 - val_mae: 87.8238 - 92ms/epoch - 18ms/step\n",
      "Epoch 234/300\n",
      "5/5 - 0s - loss: 14.4814 - mae: 81.8759 - val_loss: 12.6353 - val_mae: 86.4607 - 91ms/epoch - 18ms/step\n",
      "Epoch 235/300\n",
      "5/5 - 0s - loss: 14.4389 - mae: 81.8413 - val_loss: 12.6064 - val_mae: 85.4129 - 89ms/epoch - 18ms/step\n",
      "Epoch 236/300\n",
      "5/5 - 0s - loss: 14.4098 - mae: 81.6364 - val_loss: 12.5719 - val_mae: 84.2929 - 90ms/epoch - 18ms/step\n",
      "Epoch 237/300\n",
      "5/5 - 0s - loss: 14.3842 - mae: 81.9153 - val_loss: 12.5434 - val_mae: 85.7137 - 92ms/epoch - 18ms/step\n",
      "Epoch 238/300\n",
      "5/5 - 0s - loss: 14.3531 - mae: 81.6043 - val_loss: 12.5141 - val_mae: 84.8698 - 90ms/epoch - 18ms/step\n",
      "Epoch 239/300\n",
      "5/5 - 0s - loss: 14.3107 - mae: 81.5316 - val_loss: 12.4835 - val_mae: 85.8121 - 90ms/epoch - 18ms/step\n",
      "Epoch 240/300\n",
      "5/5 - 0s - loss: 14.2770 - mae: 81.6031 - val_loss: 12.4569 - val_mae: 84.8643 - 88ms/epoch - 18ms/step\n",
      "Epoch 241/300\n",
      "5/5 - 0s - loss: 14.2615 - mae: 81.5541 - val_loss: 12.4248 - val_mae: 84.3214 - 105ms/epoch - 21ms/step\n",
      "Epoch 242/300\n",
      "5/5 - 0s - loss: 14.2040 - mae: 81.5274 - val_loss: 12.3983 - val_mae: 84.7859 - 92ms/epoch - 18ms/step\n",
      "Epoch 243/300\n",
      "5/5 - 0s - loss: 14.1726 - mae: 81.4267 - val_loss: 12.3696 - val_mae: 85.3054 - 91ms/epoch - 18ms/step\n",
      "Epoch 244/300\n",
      "5/5 - 0s - loss: 14.1531 - mae: 81.3011 - val_loss: 12.3434 - val_mae: 85.6138 - 93ms/epoch - 19ms/step\n",
      "Epoch 245/300\n",
      "5/5 - 0s - loss: 14.1312 - mae: 81.1596 - val_loss: 12.3116 - val_mae: 84.4927 - 90ms/epoch - 18ms/step\n",
      "Epoch 246/300\n",
      "5/5 - 0s - loss: 14.0842 - mae: 81.2739 - val_loss: 12.2821 - val_mae: 83.9879 - 85ms/epoch - 17ms/step\n",
      "Epoch 247/300\n",
      "5/5 - 0s - loss: 14.0407 - mae: 81.1915 - val_loss: 12.2546 - val_mae: 85.7210 - 88ms/epoch - 18ms/step\n",
      "Epoch 248/300\n",
      "5/5 - 0s - loss: 14.0097 - mae: 81.2866 - val_loss: 12.2255 - val_mae: 85.5387 - 89ms/epoch - 18ms/step\n",
      "Epoch 249/300\n",
      "5/5 - 0s - loss: 13.9760 - mae: 80.8551 - val_loss: 12.1980 - val_mae: 84.6016 - 87ms/epoch - 17ms/step\n",
      "Epoch 250/300\n",
      "5/5 - 0s - loss: 13.9606 - mae: 81.1549 - val_loss: 12.1725 - val_mae: 84.5206 - 89ms/epoch - 18ms/step\n",
      "Epoch 251/300\n",
      "5/5 - 0s - loss: 13.9154 - mae: 81.1074 - val_loss: 12.1450 - val_mae: 85.2151 - 87ms/epoch - 17ms/step\n",
      "Epoch 252/300\n",
      "5/5 - 0s - loss: 13.8880 - mae: 80.9942 - val_loss: 12.1170 - val_mae: 83.9745 - 109ms/epoch - 22ms/step\n",
      "Epoch 253/300\n",
      "5/5 - 0s - loss: 13.8580 - mae: 80.9727 - val_loss: 12.0882 - val_mae: 85.6145 - 97ms/epoch - 19ms/step\n",
      "Epoch 254/300\n",
      "5/5 - 0s - loss: 13.8285 - mae: 80.9341 - val_loss: 12.0600 - val_mae: 84.3439 - 89ms/epoch - 18ms/step\n",
      "Epoch 255/300\n",
      "5/5 - 0s - loss: 13.7956 - mae: 81.1072 - val_loss: 12.0343 - val_mae: 84.4616 - 95ms/epoch - 19ms/step\n",
      "Epoch 256/300\n",
      "5/5 - 0s - loss: 13.7685 - mae: 81.0220 - val_loss: 12.0073 - val_mae: 84.5610 - 89ms/epoch - 18ms/step\n",
      "Epoch 257/300\n",
      "5/5 - 0s - loss: 13.7347 - mae: 81.1267 - val_loss: 11.9801 - val_mae: 84.5757 - 92ms/epoch - 18ms/step\n",
      "Epoch 258/300\n",
      "5/5 - 0s - loss: 13.7034 - mae: 80.9679 - val_loss: 11.9537 - val_mae: 83.6402 - 88ms/epoch - 18ms/step\n",
      "Epoch 259/300\n",
      "5/5 - 0s - loss: 13.6739 - mae: 80.4111 - val_loss: 11.9296 - val_mae: 83.5921 - 90ms/epoch - 18ms/step\n",
      "Epoch 260/300\n",
      "5/5 - 0s - loss: 13.6458 - mae: 80.8073 - val_loss: 11.9054 - val_mae: 84.9601 - 89ms/epoch - 18ms/step\n",
      "Epoch 261/300\n",
      "5/5 - 0s - loss: 13.6587 - mae: 80.8592 - val_loss: 11.8779 - val_mae: 83.8762 - 90ms/epoch - 18ms/step\n",
      "Epoch 262/300\n",
      "5/5 - 0s - loss: 13.5804 - mae: 80.7571 - val_loss: 11.8521 - val_mae: 84.1641 - 90ms/epoch - 18ms/step\n",
      "Epoch 263/300\n",
      "5/5 - 0s - loss: 13.5547 - mae: 80.6209 - val_loss: 11.8282 - val_mae: 83.6379 - 115ms/epoch - 23ms/step\n",
      "Epoch 264/300\n",
      "5/5 - 0s - loss: 13.5244 - mae: 80.8886 - val_loss: 11.8020 - val_mae: 82.9926 - 89ms/epoch - 18ms/step\n",
      "Epoch 265/300\n",
      "5/5 - 0s - loss: 13.5174 - mae: 80.5153 - val_loss: 11.7759 - val_mae: 83.6587 - 98ms/epoch - 20ms/step\n",
      "Epoch 266/300\n",
      "5/5 - 0s - loss: 13.4660 - mae: 80.3189 - val_loss: 11.7511 - val_mae: 83.7986 - 90ms/epoch - 18ms/step\n",
      "Epoch 267/300\n",
      "5/5 - 0s - loss: 13.4410 - mae: 80.7571 - val_loss: 11.7258 - val_mae: 83.5142 - 86ms/epoch - 17ms/step\n",
      "Epoch 268/300\n",
      "5/5 - 0s - loss: 13.4099 - mae: 80.5624 - val_loss: 11.7021 - val_mae: 82.8459 - 86ms/epoch - 17ms/step\n",
      "Epoch 269/300\n",
      "5/5 - 0s - loss: 13.3854 - mae: 80.5517 - val_loss: 11.6774 - val_mae: 84.4026 - 90ms/epoch - 18ms/step\n",
      "Epoch 270/300\n",
      "5/5 - 0s - loss: 13.3749 - mae: 80.4413 - val_loss: 11.6557 - val_mae: 83.1945 - 90ms/epoch - 18ms/step\n",
      "Epoch 271/300\n",
      "5/5 - 0s - loss: 13.3275 - mae: 80.2168 - val_loss: 11.6314 - val_mae: 82.5710 - 90ms/epoch - 18ms/step\n",
      "Epoch 272/300\n",
      "5/5 - 0s - loss: 13.3020 - mae: 80.2633 - val_loss: 11.6081 - val_mae: 84.0533 - 91ms/epoch - 18ms/step\n",
      "Epoch 273/300\n",
      "5/5 - 0s - loss: 13.2733 - mae: 80.3612 - val_loss: 11.5849 - val_mae: 83.5583 - 87ms/epoch - 17ms/step\n",
      "Epoch 274/300\n",
      "5/5 - 0s - loss: 13.2507 - mae: 80.1820 - val_loss: 11.5611 - val_mae: 83.2833 - 117ms/epoch - 23ms/step\n",
      "Epoch 275/300\n",
      "5/5 - 0s - loss: 13.2158 - mae: 80.2012 - val_loss: 11.5372 - val_mae: 83.0508 - 88ms/epoch - 18ms/step\n",
      "Epoch 276/300\n",
      "5/5 - 0s - loss: 13.1905 - mae: 80.0227 - val_loss: 11.5112 - val_mae: 83.2370 - 94ms/epoch - 19ms/step\n",
      "Epoch 277/300\n",
      "5/5 - 0s - loss: 13.1626 - mae: 80.1713 - val_loss: 11.4885 - val_mae: 83.2554 - 91ms/epoch - 18ms/step\n",
      "Epoch 278/300\n",
      "5/5 - 0s - loss: 13.1416 - mae: 80.1627 - val_loss: 11.4672 - val_mae: 82.8677 - 87ms/epoch - 17ms/step\n",
      "Epoch 279/300\n",
      "5/5 - 0s - loss: 13.1115 - mae: 80.3021 - val_loss: 11.4435 - val_mae: 83.1431 - 88ms/epoch - 18ms/step\n",
      "Epoch 280/300\n",
      "5/5 - 0s - loss: 13.0812 - mae: 80.3342 - val_loss: 11.4212 - val_mae: 81.9156 - 87ms/epoch - 17ms/step\n",
      "Epoch 281/300\n",
      "5/5 - 0s - loss: 13.0570 - mae: 79.7188 - val_loss: 11.3965 - val_mae: 82.1535 - 84ms/epoch - 17ms/step\n",
      "Epoch 282/300\n",
      "5/5 - 0s - loss: 13.0335 - mae: 79.7035 - val_loss: 11.3755 - val_mae: 82.6159 - 89ms/epoch - 18ms/step\n",
      "Epoch 283/300\n",
      "5/5 - 0s - loss: 13.0037 - mae: 80.0555 - val_loss: 11.3499 - val_mae: 83.7708 - 88ms/epoch - 18ms/step\n",
      "Epoch 284/300\n",
      "5/5 - 0s - loss: 12.9792 - mae: 80.0740 - val_loss: 11.3264 - val_mae: 82.3835 - 94ms/epoch - 19ms/step\n",
      "Epoch 285/300\n",
      "5/5 - 0s - loss: 12.9578 - mae: 79.8961 - val_loss: 11.3047 - val_mae: 82.0038 - 108ms/epoch - 22ms/step\n",
      "Epoch 286/300\n",
      "5/5 - 0s - loss: 12.9295 - mae: 80.0308 - val_loss: 11.2808 - val_mae: 81.5231 - 88ms/epoch - 18ms/step\n",
      "Epoch 287/300\n",
      "5/5 - 0s - loss: 12.8974 - mae: 79.7952 - val_loss: 11.2594 - val_mae: 82.3403 - 90ms/epoch - 18ms/step\n",
      "Epoch 288/300\n",
      "5/5 - 0s - loss: 12.8702 - mae: 80.0963 - val_loss: 11.2368 - val_mae: 82.8629 - 85ms/epoch - 17ms/step\n",
      "Epoch 289/300\n",
      "5/5 - 0s - loss: 12.8440 - mae: 79.6992 - val_loss: 11.2148 - val_mae: 82.1217 - 86ms/epoch - 17ms/step\n",
      "Epoch 290/300\n",
      "5/5 - 0s - loss: 12.8212 - mae: 79.6494 - val_loss: 11.1932 - val_mae: 81.9545 - 88ms/epoch - 18ms/step\n",
      "Epoch 291/300\n",
      "5/5 - 0s - loss: 12.7972 - mae: 79.6111 - val_loss: 11.1720 - val_mae: 82.2465 - 86ms/epoch - 17ms/step\n",
      "Epoch 292/300\n",
      "5/5 - 0s - loss: 12.7876 - mae: 79.5530 - val_loss: 11.1511 - val_mae: 82.2762 - 91ms/epoch - 18ms/step\n",
      "Epoch 293/300\n",
      "5/5 - 0s - loss: 12.7495 - mae: 79.8502 - val_loss: 11.1309 - val_mae: 82.3874 - 88ms/epoch - 18ms/step\n",
      "Epoch 294/300\n",
      "5/5 - 0s - loss: 12.7244 - mae: 79.7264 - val_loss: 11.1089 - val_mae: 82.8083 - 88ms/epoch - 18ms/step\n",
      "Epoch 295/300\n",
      "5/5 - 0s - loss: 12.7054 - mae: 79.2210 - val_loss: 11.0882 - val_mae: 82.1683 - 93ms/epoch - 19ms/step\n",
      "Epoch 296/300\n",
      "5/5 - 0s - loss: 12.6772 - mae: 79.3162 - val_loss: 11.0659 - val_mae: 81.3450 - 108ms/epoch - 22ms/step\n",
      "Epoch 297/300\n",
      "5/5 - 0s - loss: 12.6623 - mae: 79.4250 - val_loss: 11.0440 - val_mae: 82.6348 - 91ms/epoch - 18ms/step\n",
      "Epoch 298/300\n",
      "5/5 - 0s - loss: 12.6307 - mae: 79.2153 - val_loss: 11.0225 - val_mae: 82.8479 - 90ms/epoch - 18ms/step\n",
      "Epoch 299/300\n",
      "5/5 - 0s - loss: 12.6124 - mae: 79.3740 - val_loss: 11.0020 - val_mae: 81.7787 - 89ms/epoch - 18ms/step\n",
      "Epoch 300/300\n",
      "5/5 - 0s - loss: 12.6099 - mae: 79.2779 - val_loss: 10.9796 - val_mae: 81.0315 - 88ms/epoch - 18ms/step\n",
      "Epoch 1/300\n",
      "5/5 - 1s - loss: 725.8528 - mae: 69.4107 - val_loss: 292.8866 - val_mae: 214.1361 - 1s/epoch - 246ms/step\n",
      "Epoch 2/300\n",
      "5/5 - 0s - loss: 112.0613 - mae: 68.3464 - val_loss: 80.8211 - val_mae: 211.6235 - 85ms/epoch - 17ms/step\n",
      "Epoch 3/300\n",
      "5/5 - 0s - loss: 44.0591 - mae: 67.1897 - val_loss: 45.3544 - val_mae: 208.9736 - 88ms/epoch - 18ms/step\n",
      "Epoch 4/300\n",
      "5/5 - 0s - loss: 25.4377 - mae: 65.9528 - val_loss: 33.2766 - val_mae: 207.9558 - 84ms/epoch - 17ms/step\n",
      "Epoch 5/300\n",
      "5/5 - 0s - loss: 18.8217 - mae: 64.8985 - val_loss: 27.5299 - val_mae: 205.0560 - 86ms/epoch - 17ms/step\n",
      "Epoch 6/300\n",
      "5/5 - 0s - loss: 15.9376 - mae: 64.1243 - val_loss: 24.2443 - val_mae: 204.9360 - 101ms/epoch - 20ms/step\n",
      "Epoch 7/300\n",
      "5/5 - 0s - loss: 14.3953 - mae: 63.4561 - val_loss: 22.2654 - val_mae: 202.5687 - 84ms/epoch - 17ms/step\n",
      "Epoch 8/300\n",
      "5/5 - 0s - loss: 13.3109 - mae: 62.8368 - val_loss: 20.8725 - val_mae: 202.4320 - 87ms/epoch - 17ms/step\n",
      "Epoch 9/300\n",
      "5/5 - 0s - loss: 12.7315 - mae: 62.3882 - val_loss: 19.8246 - val_mae: 200.3943 - 86ms/epoch - 17ms/step\n",
      "Epoch 10/300\n",
      "5/5 - 0s - loss: 12.3492 - mae: 61.8910 - val_loss: 19.0219 - val_mae: 201.1545 - 90ms/epoch - 18ms/step\n",
      "Epoch 11/300\n",
      "5/5 - 0s - loss: 12.0458 - mae: 61.9267 - val_loss: 18.3752 - val_mae: 198.1947 - 87ms/epoch - 17ms/step\n",
      "Epoch 12/300\n",
      "5/5 - 0s - loss: 11.7537 - mae: 61.2781 - val_loss: 17.8151 - val_mae: 197.2292 - 83ms/epoch - 17ms/step\n",
      "Epoch 13/300\n",
      "5/5 - 0s - loss: 11.5581 - mae: 60.9324 - val_loss: 17.3118 - val_mae: 198.0906 - 85ms/epoch - 17ms/step\n",
      "Epoch 14/300\n",
      "5/5 - 0s - loss: 11.4206 - mae: 60.7694 - val_loss: 16.8915 - val_mae: 197.0255 - 83ms/epoch - 17ms/step\n",
      "Epoch 15/300\n",
      "5/5 - 0s - loss: 11.2079 - mae: 60.5309 - val_loss: 16.5138 - val_mae: 195.9140 - 82ms/epoch - 16ms/step\n",
      "Epoch 16/300\n",
      "5/5 - 0s - loss: 11.1672 - mae: 60.1736 - val_loss: 16.1710 - val_mae: 194.5353 - 83ms/epoch - 17ms/step\n",
      "Epoch 17/300\n",
      "5/5 - 0s - loss: 10.9919 - mae: 60.1588 - val_loss: 15.8560 - val_mae: 193.9057 - 80ms/epoch - 16ms/step\n",
      "Epoch 18/300\n",
      "5/5 - 0s - loss: 10.8415 - mae: 59.8546 - val_loss: 15.5862 - val_mae: 190.7907 - 98ms/epoch - 20ms/step\n",
      "Epoch 19/300\n",
      "5/5 - 0s - loss: 10.7624 - mae: 59.3812 - val_loss: 15.3036 - val_mae: 191.5340 - 82ms/epoch - 16ms/step\n",
      "Epoch 20/300\n",
      "5/5 - 0s - loss: 10.6202 - mae: 59.3525 - val_loss: 15.0517 - val_mae: 191.7738 - 81ms/epoch - 16ms/step\n",
      "Epoch 21/300\n",
      "5/5 - 0s - loss: 10.5580 - mae: 59.1605 - val_loss: 14.8030 - val_mae: 192.2184 - 89ms/epoch - 18ms/step\n",
      "Epoch 22/300\n",
      "5/5 - 0s - loss: 10.4623 - mae: 58.6901 - val_loss: 14.5809 - val_mae: 191.4490 - 81ms/epoch - 16ms/step\n",
      "Epoch 23/300\n",
      "5/5 - 0s - loss: 10.3680 - mae: 58.5604 - val_loss: 14.3781 - val_mae: 190.9964 - 81ms/epoch - 16ms/step\n",
      "Epoch 24/300\n",
      "5/5 - 0s - loss: 10.2658 - mae: 57.8490 - val_loss: 14.1987 - val_mae: 190.3184 - 81ms/epoch - 16ms/step\n",
      "Epoch 25/300\n",
      "5/5 - 0s - loss: 10.2100 - mae: 57.8308 - val_loss: 14.0229 - val_mae: 189.6009 - 87ms/epoch - 17ms/step\n",
      "Epoch 26/300\n",
      "5/5 - 0s - loss: 10.1518 - mae: 57.3248 - val_loss: 13.8540 - val_mae: 187.1862 - 81ms/epoch - 16ms/step\n",
      "Epoch 27/300\n",
      "5/5 - 0s - loss: 10.0895 - mae: 57.5254 - val_loss: 13.6974 - val_mae: 186.1745 - 83ms/epoch - 17ms/step\n",
      "Epoch 28/300\n",
      "5/5 - 0s - loss: 9.9863 - mae: 57.3408 - val_loss: 13.5513 - val_mae: 185.5161 - 80ms/epoch - 16ms/step\n",
      "Epoch 29/300\n",
      "5/5 - 0s - loss: 9.9515 - mae: 57.0649 - val_loss: 13.4161 - val_mae: 183.2444 - 83ms/epoch - 17ms/step\n",
      "Epoch 30/300\n",
      "5/5 - 0s - loss: 9.9082 - mae: 56.7322 - val_loss: 13.2841 - val_mae: 184.5602 - 105ms/epoch - 21ms/step\n",
      "Epoch 31/300\n",
      "5/5 - 0s - loss: 9.8581 - mae: 56.2080 - val_loss: 13.1575 - val_mae: 181.6390 - 82ms/epoch - 16ms/step\n",
      "Epoch 32/300\n",
      "5/5 - 0s - loss: 9.7868 - mae: 55.9127 - val_loss: 13.0395 - val_mae: 180.9034 - 88ms/epoch - 18ms/step\n",
      "Epoch 33/300\n",
      "5/5 - 0s - loss: 9.7372 - mae: 55.8529 - val_loss: 12.9251 - val_mae: 180.9886 - 86ms/epoch - 17ms/step\n",
      "Epoch 34/300\n",
      "5/5 - 0s - loss: 9.6875 - mae: 55.6192 - val_loss: 12.8195 - val_mae: 180.3267 - 82ms/epoch - 16ms/step\n",
      "Epoch 35/300\n",
      "5/5 - 0s - loss: 9.5991 - mae: 55.2646 - val_loss: 12.7199 - val_mae: 178.2076 - 93ms/epoch - 19ms/step\n",
      "Epoch 36/300\n",
      "5/5 - 0s - loss: 9.6072 - mae: 54.9717 - val_loss: 12.6236 - val_mae: 176.9159 - 87ms/epoch - 17ms/step\n",
      "Epoch 37/300\n",
      "5/5 - 0s - loss: 9.5191 - mae: 54.7662 - val_loss: 12.5329 - val_mae: 179.9051 - 81ms/epoch - 16ms/step\n",
      "Epoch 38/300\n",
      "5/5 - 0s - loss: 9.4993 - mae: 54.6668 - val_loss: 12.4416 - val_mae: 178.2604 - 86ms/epoch - 17ms/step\n",
      "Epoch 39/300\n",
      "5/5 - 0s - loss: 9.4569 - mae: 54.2193 - val_loss: 12.3616 - val_mae: 175.8197 - 81ms/epoch - 16ms/step\n",
      "Epoch 40/300\n",
      "5/5 - 0s - loss: 9.4234 - mae: 54.2000 - val_loss: 12.2822 - val_mae: 176.1453 - 82ms/epoch - 16ms/step\n",
      "Epoch 41/300\n",
      "5/5 - 0s - loss: 9.3562 - mae: 53.5951 - val_loss: 12.2034 - val_mae: 174.9509 - 92ms/epoch - 18ms/step\n",
      "Epoch 42/300\n",
      "5/5 - 0s - loss: 9.3603 - mae: 53.9186 - val_loss: 12.1277 - val_mae: 173.6276 - 90ms/epoch - 18ms/step\n",
      "Epoch 43/300\n",
      "5/5 - 0s - loss: 9.3127 - mae: 53.2799 - val_loss: 12.0531 - val_mae: 170.2227 - 83ms/epoch - 17ms/step\n",
      "Epoch 44/300\n",
      "5/5 - 0s - loss: 9.2845 - mae: 53.1814 - val_loss: 11.9872 - val_mae: 172.7414 - 89ms/epoch - 18ms/step\n",
      "Epoch 45/300\n",
      "5/5 - 0s - loss: 9.2341 - mae: 53.2191 - val_loss: 11.9185 - val_mae: 172.6606 - 80ms/epoch - 16ms/step\n",
      "Epoch 46/300\n",
      "5/5 - 0s - loss: 9.1999 - mae: 52.5488 - val_loss: 11.8552 - val_mae: 171.6422 - 86ms/epoch - 17ms/step\n",
      "Epoch 47/300\n",
      "5/5 - 0s - loss: 9.1897 - mae: 52.1521 - val_loss: 11.7936 - val_mae: 170.3514 - 87ms/epoch - 17ms/step\n",
      "Epoch 48/300\n",
      "5/5 - 0s - loss: 9.1493 - mae: 52.4409 - val_loss: 11.7379 - val_mae: 168.4163 - 127ms/epoch - 25ms/step\n",
      "Epoch 49/300\n",
      "5/5 - 0s - loss: 9.1181 - mae: 51.5787 - val_loss: 11.6781 - val_mae: 168.2993 - 135ms/epoch - 27ms/step\n",
      "Epoch 50/300\n",
      "5/5 - 0s - loss: 9.0940 - mae: 51.4753 - val_loss: 11.6235 - val_mae: 168.6239 - 152ms/epoch - 30ms/step\n",
      "Epoch 51/300\n",
      "5/5 - 0s - loss: 9.0612 - mae: 51.1787 - val_loss: 11.5665 - val_mae: 167.1729 - 176ms/epoch - 35ms/step\n",
      "Epoch 52/300\n",
      "5/5 - 0s - loss: 9.0469 - mae: 50.9584 - val_loss: 11.5171 - val_mae: 164.2784 - 153ms/epoch - 31ms/step\n",
      "Epoch 53/300\n",
      "5/5 - 0s - loss: 8.9996 - mae: 51.2619 - val_loss: 11.4685 - val_mae: 165.4290 - 146ms/epoch - 29ms/step\n",
      "Epoch 54/300\n",
      "5/5 - 0s - loss: 8.9934 - mae: 50.7534 - val_loss: 11.4138 - val_mae: 163.7732 - 136ms/epoch - 27ms/step\n",
      "Epoch 55/300\n",
      "5/5 - 0s - loss: 8.9445 - mae: 50.5008 - val_loss: 11.3668 - val_mae: 164.2443 - 146ms/epoch - 29ms/step\n",
      "Epoch 56/300\n",
      "5/5 - 0s - loss: 8.9246 - mae: 50.0576 - val_loss: 11.3207 - val_mae: 161.4074 - 135ms/epoch - 27ms/step\n",
      "Epoch 57/300\n",
      "5/5 - 0s - loss: 8.9231 - mae: 50.3697 - val_loss: 11.2745 - val_mae: 160.1595 - 139ms/epoch - 28ms/step\n",
      "Epoch 58/300\n",
      "5/5 - 0s - loss: 8.8874 - mae: 49.5162 - val_loss: 11.2317 - val_mae: 164.6791 - 159ms/epoch - 32ms/step\n",
      "Epoch 59/300\n",
      "5/5 - 0s - loss: 8.8692 - mae: 49.1664 - val_loss: 11.1873 - val_mae: 159.1341 - 156ms/epoch - 31ms/step\n",
      "Epoch 60/300\n",
      "5/5 - 0s - loss: 8.8424 - mae: 49.2576 - val_loss: 11.1465 - val_mae: 157.6412 - 149ms/epoch - 30ms/step\n",
      "Epoch 61/300\n",
      "5/5 - 0s - loss: 8.8146 - mae: 49.2161 - val_loss: 11.1068 - val_mae: 159.0795 - 157ms/epoch - 31ms/step\n",
      "Epoch 62/300\n",
      "5/5 - 0s - loss: 8.8116 - mae: 48.9677 - val_loss: 11.0644 - val_mae: 157.9394 - 150ms/epoch - 30ms/step\n",
      "Epoch 63/300\n",
      "5/5 - 0s - loss: 8.7868 - mae: 48.5202 - val_loss: 11.0233 - val_mae: 157.5641 - 95ms/epoch - 19ms/step\n",
      "Epoch 64/300\n",
      "5/5 - 0s - loss: 8.7530 - mae: 48.7666 - val_loss: 10.9864 - val_mae: 155.4046 - 83ms/epoch - 17ms/step\n",
      "Epoch 65/300\n",
      "5/5 - 0s - loss: 8.7504 - mae: 48.4402 - val_loss: 10.9498 - val_mae: 155.6655 - 87ms/epoch - 17ms/step\n",
      "Epoch 66/300\n",
      "5/5 - 0s - loss: 8.7321 - mae: 48.5172 - val_loss: 10.9140 - val_mae: 155.0938 - 86ms/epoch - 17ms/step\n",
      "Epoch 67/300\n",
      "5/5 - 0s - loss: 8.7115 - mae: 47.8564 - val_loss: 10.8798 - val_mae: 152.0113 - 99ms/epoch - 20ms/step\n",
      "Epoch 68/300\n",
      "5/5 - 0s - loss: 8.6851 - mae: 47.4403 - val_loss: 10.8452 - val_mae: 150.3131 - 93ms/epoch - 19ms/step\n",
      "Epoch 69/300\n",
      "5/5 - 0s - loss: 8.6608 - mae: 47.3069 - val_loss: 10.8111 - val_mae: 152.4862 - 82ms/epoch - 16ms/step\n",
      "Epoch 70/300\n",
      "5/5 - 0s - loss: 8.6570 - mae: 47.0448 - val_loss: 10.7776 - val_mae: 154.5878 - 83ms/epoch - 17ms/step\n",
      "Epoch 71/300\n",
      "5/5 - 0s - loss: 8.6305 - mae: 46.7656 - val_loss: 10.7449 - val_mae: 150.2137 - 86ms/epoch - 17ms/step\n",
      "Epoch 72/300\n",
      "5/5 - 0s - loss: 8.5993 - mae: 46.7338 - val_loss: 10.7150 - val_mae: 152.0473 - 84ms/epoch - 17ms/step\n",
      "Epoch 73/300\n",
      "5/5 - 0s - loss: 8.5875 - mae: 46.5554 - val_loss: 10.6831 - val_mae: 150.0264 - 83ms/epoch - 17ms/step\n",
      "Epoch 74/300\n",
      "5/5 - 0s - loss: 8.5902 - mae: 45.8211 - val_loss: 10.6517 - val_mae: 149.0318 - 84ms/epoch - 17ms/step\n",
      "Epoch 75/300\n",
      "5/5 - 0s - loss: 8.5635 - mae: 46.2010 - val_loss: 10.6233 - val_mae: 148.9230 - 83ms/epoch - 17ms/step\n",
      "Epoch 76/300\n",
      "5/5 - 0s - loss: 8.5609 - mae: 45.7125 - val_loss: 10.5923 - val_mae: 147.1171 - 85ms/epoch - 17ms/step\n",
      "Epoch 77/300\n",
      "5/5 - 0s - loss: 8.5229 - mae: 46.0537 - val_loss: 10.5601 - val_mae: 146.4250 - 89ms/epoch - 18ms/step\n",
      "Epoch 78/300\n",
      "5/5 - 0s - loss: 8.5137 - mae: 45.0515 - val_loss: 10.5326 - val_mae: 147.2505 - 88ms/epoch - 18ms/step\n",
      "Epoch 79/300\n",
      "5/5 - 0s - loss: 8.4914 - mae: 45.1731 - val_loss: 10.5047 - val_mae: 143.8666 - 105ms/epoch - 21ms/step\n",
      "Epoch 80/300\n",
      "5/5 - 0s - loss: 8.4599 - mae: 44.9329 - val_loss: 10.4761 - val_mae: 144.1537 - 103ms/epoch - 21ms/step\n",
      "Epoch 81/300\n",
      "5/5 - 0s - loss: 8.4595 - mae: 45.1323 - val_loss: 10.4497 - val_mae: 144.3705 - 99ms/epoch - 20ms/step\n",
      "Epoch 82/300\n",
      "5/5 - 0s - loss: 8.4579 - mae: 44.2101 - val_loss: 10.4251 - val_mae: 143.9111 - 103ms/epoch - 21ms/step\n",
      "Epoch 83/300\n",
      "5/5 - 0s - loss: 8.4266 - mae: 44.4611 - val_loss: 10.3996 - val_mae: 140.7324 - 88ms/epoch - 18ms/step\n",
      "Epoch 84/300\n",
      "5/5 - 0s - loss: 8.4064 - mae: 44.2765 - val_loss: 10.3730 - val_mae: 142.1195 - 83ms/epoch - 17ms/step\n",
      "Epoch 85/300\n",
      "5/5 - 0s - loss: 8.3973 - mae: 44.2005 - val_loss: 10.3471 - val_mae: 139.6333 - 80ms/epoch - 16ms/step\n",
      "Epoch 86/300\n",
      "5/5 - 0s - loss: 8.3803 - mae: 43.7509 - val_loss: 10.3207 - val_mae: 140.1062 - 83ms/epoch - 17ms/step\n",
      "Epoch 87/300\n",
      "5/5 - 0s - loss: 8.3569 - mae: 43.9186 - val_loss: 10.2947 - val_mae: 142.2349 - 87ms/epoch - 17ms/step\n",
      "Epoch 88/300\n",
      "5/5 - 0s - loss: 8.3424 - mae: 43.4507 - val_loss: 10.2709 - val_mae: 141.1947 - 89ms/epoch - 18ms/step\n",
      "Epoch 89/300\n",
      "5/5 - 0s - loss: 8.3508 - mae: 42.6141 - val_loss: 10.2474 - val_mae: 136.9594 - 90ms/epoch - 18ms/step\n",
      "Epoch 90/300\n",
      "5/5 - 0s - loss: 8.3030 - mae: 42.9094 - val_loss: 10.2235 - val_mae: 138.8281 - 105ms/epoch - 21ms/step\n",
      "Epoch 91/300\n",
      "5/5 - 0s - loss: 8.3017 - mae: 43.0490 - val_loss: 10.2010 - val_mae: 137.2068 - 83ms/epoch - 17ms/step\n",
      "Epoch 92/300\n",
      "5/5 - 0s - loss: 8.2809 - mae: 42.6066 - val_loss: 10.1761 - val_mae: 140.2107 - 89ms/epoch - 18ms/step\n",
      "Epoch 93/300\n",
      "5/5 - 0s - loss: 8.2812 - mae: 42.0406 - val_loss: 10.1554 - val_mae: 134.9459 - 85ms/epoch - 17ms/step\n",
      "Epoch 94/300\n",
      "5/5 - 0s - loss: 8.2440 - mae: 42.1081 - val_loss: 10.1317 - val_mae: 135.9005 - 91ms/epoch - 18ms/step\n",
      "Epoch 95/300\n",
      "5/5 - 0s - loss: 8.2329 - mae: 42.1135 - val_loss: 10.1091 - val_mae: 136.0771 - 84ms/epoch - 17ms/step\n",
      "Epoch 96/300\n",
      "5/5 - 0s - loss: 8.2194 - mae: 41.6357 - val_loss: 10.0873 - val_mae: 133.3123 - 83ms/epoch - 17ms/step\n",
      "Epoch 97/300\n",
      "5/5 - 0s - loss: 8.2141 - mae: 41.5836 - val_loss: 10.0648 - val_mae: 132.8090 - 81ms/epoch - 16ms/step\n",
      "Epoch 98/300\n",
      "5/5 - 0s - loss: 8.1855 - mae: 41.2445 - val_loss: 10.0437 - val_mae: 135.9570 - 83ms/epoch - 17ms/step\n",
      "Epoch 99/300\n",
      "5/5 - 0s - loss: 8.1790 - mae: 41.3926 - val_loss: 10.0241 - val_mae: 132.5822 - 85ms/epoch - 17ms/step\n",
      "Epoch 100/300\n",
      "5/5 - 0s - loss: 8.1762 - mae: 41.0263 - val_loss: 10.0044 - val_mae: 132.2546 - 86ms/epoch - 17ms/step\n",
      "Epoch 101/300\n",
      "5/5 - 0s - loss: 8.1527 - mae: 40.7047 - val_loss: 9.9839 - val_mae: 130.5156 - 85ms/epoch - 17ms/step\n",
      "Epoch 102/300\n",
      "5/5 - 0s - loss: 8.1435 - mae: 40.7963 - val_loss: 9.9654 - val_mae: 130.1851 - 102ms/epoch - 20ms/step\n",
      "Epoch 103/300\n",
      "5/5 - 0s - loss: 8.1230 - mae: 40.0519 - val_loss: 9.9469 - val_mae: 129.1253 - 86ms/epoch - 17ms/step\n",
      "Epoch 104/300\n",
      "5/5 - 0s - loss: 8.1077 - mae: 40.1279 - val_loss: 9.9278 - val_mae: 128.8838 - 86ms/epoch - 17ms/step\n",
      "Epoch 105/300\n",
      "5/5 - 0s - loss: 8.0927 - mae: 39.8786 - val_loss: 9.9085 - val_mae: 130.0403 - 84ms/epoch - 17ms/step\n",
      "Epoch 106/300\n",
      "5/5 - 0s - loss: 8.0756 - mae: 39.8478 - val_loss: 9.8892 - val_mae: 129.4401 - 82ms/epoch - 16ms/step\n",
      "Epoch 107/300\n",
      "5/5 - 0s - loss: 8.0648 - mae: 39.5025 - val_loss: 9.8707 - val_mae: 126.7839 - 83ms/epoch - 17ms/step\n",
      "Epoch 108/300\n",
      "5/5 - 0s - loss: 8.0628 - mae: 39.6253 - val_loss: 9.8523 - val_mae: 129.9536 - 80ms/epoch - 16ms/step\n",
      "Epoch 109/300\n",
      "5/5 - 0s - loss: 8.0468 - mae: 39.4906 - val_loss: 9.8337 - val_mae: 127.3542 - 89ms/epoch - 18ms/step\n",
      "Epoch 110/300\n",
      "5/5 - 0s - loss: 8.0421 - mae: 38.9738 - val_loss: 9.8165 - val_mae: 126.5472 - 92ms/epoch - 18ms/step\n",
      "Epoch 111/300\n",
      "5/5 - 0s - loss: 8.0088 - mae: 38.9453 - val_loss: 9.8000 - val_mae: 125.4089 - 85ms/epoch - 17ms/step\n",
      "Epoch 112/300\n",
      "5/5 - 0s - loss: 7.9954 - mae: 38.9390 - val_loss: 9.7836 - val_mae: 124.5490 - 83ms/epoch - 17ms/step\n",
      "Epoch 113/300\n",
      "5/5 - 0s - loss: 7.9746 - mae: 38.5380 - val_loss: 9.7675 - val_mae: 126.4229 - 101ms/epoch - 20ms/step\n",
      "Epoch 114/300\n",
      "5/5 - 0s - loss: 7.9614 - mae: 38.2966 - val_loss: 9.7508 - val_mae: 122.0910 - 84ms/epoch - 17ms/step\n",
      "Epoch 115/300\n",
      "5/5 - 0s - loss: 7.9488 - mae: 37.8838 - val_loss: 9.7344 - val_mae: 120.0763 - 82ms/epoch - 16ms/step\n",
      "Epoch 116/300\n",
      "5/5 - 0s - loss: 7.9566 - mae: 38.0974 - val_loss: 9.7201 - val_mae: 124.9339 - 87ms/epoch - 17ms/step\n",
      "Epoch 117/300\n",
      "5/5 - 0s - loss: 7.9224 - mae: 37.7549 - val_loss: 9.7031 - val_mae: 121.7878 - 80ms/epoch - 16ms/step\n",
      "Epoch 118/300\n",
      "5/5 - 0s - loss: 7.9128 - mae: 37.1427 - val_loss: 9.6871 - val_mae: 121.1626 - 82ms/epoch - 16ms/step\n",
      "Epoch 119/300\n",
      "5/5 - 0s - loss: 7.8931 - mae: 37.1051 - val_loss: 9.6711 - val_mae: 124.6154 - 85ms/epoch - 17ms/step\n",
      "Epoch 120/300\n",
      "5/5 - 0s - loss: 7.8770 - mae: 37.1289 - val_loss: 9.6540 - val_mae: 121.0889 - 87ms/epoch - 17ms/step\n",
      "Epoch 121/300\n",
      "5/5 - 0s - loss: 7.8559 - mae: 36.8953 - val_loss: 9.6389 - val_mae: 117.8434 - 82ms/epoch - 16ms/step\n",
      "Epoch 122/300\n",
      "5/5 - 0s - loss: 7.8415 - mae: 36.5887 - val_loss: 9.6243 - val_mae: 121.3470 - 89ms/epoch - 18ms/step\n",
      "Epoch 123/300\n",
      "5/5 - 0s - loss: 7.8443 - mae: 36.6245 - val_loss: 9.6110 - val_mae: 119.5652 - 84ms/epoch - 17ms/step\n",
      "Epoch 124/300\n",
      "5/5 - 0s - loss: 7.8282 - mae: 36.3120 - val_loss: 9.5971 - val_mae: 116.5347 - 85ms/epoch - 17ms/step\n",
      "Epoch 125/300\n",
      "5/5 - 0s - loss: 7.8020 - mae: 36.0053 - val_loss: 9.5838 - val_mae: 118.5488 - 105ms/epoch - 21ms/step\n",
      "Epoch 126/300\n",
      "5/5 - 0s - loss: 7.8004 - mae: 36.0385 - val_loss: 9.5721 - val_mae: 119.1358 - 84ms/epoch - 17ms/step\n",
      "Epoch 127/300\n",
      "5/5 - 0s - loss: 7.7883 - mae: 36.1421 - val_loss: 9.5589 - val_mae: 116.1940 - 85ms/epoch - 17ms/step\n",
      "Epoch 128/300\n",
      "5/5 - 0s - loss: 7.7712 - mae: 35.6263 - val_loss: 9.5448 - val_mae: 117.9129 - 84ms/epoch - 17ms/step\n",
      "Epoch 129/300\n",
      "5/5 - 0s - loss: 7.7652 - mae: 35.4092 - val_loss: 9.5309 - val_mae: 114.8086 - 81ms/epoch - 16ms/step\n",
      "Epoch 130/300\n",
      "5/5 - 0s - loss: 7.7430 - mae: 35.4667 - val_loss: 9.5179 - val_mae: 115.2992 - 82ms/epoch - 16ms/step\n",
      "Epoch 131/300\n",
      "5/5 - 0s - loss: 7.7316 - mae: 35.3492 - val_loss: 9.5051 - val_mae: 115.7501 - 88ms/epoch - 18ms/step\n",
      "Epoch 132/300\n",
      "5/5 - 0s - loss: 7.7165 - mae: 34.8592 - val_loss: 9.4923 - val_mae: 115.5701 - 81ms/epoch - 16ms/step\n",
      "Epoch 133/300\n",
      "5/5 - 0s - loss: 7.7006 - mae: 34.8096 - val_loss: 9.4790 - val_mae: 113.4282 - 84ms/epoch - 17ms/step\n",
      "Epoch 134/300\n",
      "5/5 - 0s - loss: 7.6805 - mae: 34.1816 - val_loss: 9.4665 - val_mae: 115.8473 - 86ms/epoch - 17ms/step\n",
      "Epoch 135/300\n",
      "5/5 - 0s - loss: 7.6775 - mae: 34.6679 - val_loss: 9.4544 - val_mae: 112.4149 - 96ms/epoch - 19ms/step\n",
      "Epoch 136/300\n",
      "5/5 - 0s - loss: 7.6584 - mae: 34.3912 - val_loss: 9.4428 - val_mae: 114.3122 - 84ms/epoch - 17ms/step\n",
      "Epoch 137/300\n",
      "5/5 - 0s - loss: 7.6592 - mae: 33.9181 - val_loss: 9.4336 - val_mae: 111.9230 - 101ms/epoch - 20ms/step\n",
      "Epoch 138/300\n",
      "5/5 - 0s - loss: 7.6364 - mae: 33.7230 - val_loss: 9.4235 - val_mae: 114.7624 - 85ms/epoch - 17ms/step\n",
      "Epoch 139/300\n",
      "5/5 - 0s - loss: 7.6179 - mae: 33.7145 - val_loss: 9.4137 - val_mae: 112.4632 - 83ms/epoch - 17ms/step\n",
      "Epoch 140/300\n",
      "5/5 - 0s - loss: 7.6003 - mae: 33.6298 - val_loss: 9.4052 - val_mae: 110.7227 - 85ms/epoch - 17ms/step\n",
      "Epoch 141/300\n",
      "5/5 - 0s - loss: 7.5905 - mae: 33.2152 - val_loss: 9.3940 - val_mae: 108.5790 - 84ms/epoch - 17ms/step\n",
      "Epoch 142/300\n",
      "5/5 - 0s - loss: 7.5847 - mae: 33.5169 - val_loss: 9.3834 - val_mae: 109.5144 - 82ms/epoch - 16ms/step\n",
      "Epoch 143/300\n",
      "5/5 - 0s - loss: 7.5782 - mae: 33.4940 - val_loss: 9.3731 - val_mae: 109.1941 - 85ms/epoch - 17ms/step\n",
      "Epoch 144/300\n",
      "5/5 - 0s - loss: 7.5483 - mae: 33.0877 - val_loss: 9.3618 - val_mae: 110.9833 - 89ms/epoch - 18ms/step\n",
      "Epoch 145/300\n",
      "5/5 - 0s - loss: 7.5334 - mae: 32.8777 - val_loss: 9.3520 - val_mae: 106.6687 - 84ms/epoch - 17ms/step\n",
      "Epoch 146/300\n",
      "5/5 - 0s - loss: 7.5165 - mae: 32.8121 - val_loss: 9.3433 - val_mae: 108.0295 - 84ms/epoch - 17ms/step\n",
      "Epoch 147/300\n",
      "5/5 - 0s - loss: 7.5125 - mae: 32.5324 - val_loss: 9.3372 - val_mae: 110.7502 - 84ms/epoch - 17ms/step\n",
      "Epoch 148/300\n",
      "5/5 - 0s - loss: 7.5049 - mae: 32.4877 - val_loss: 9.3297 - val_mae: 107.0637 - 102ms/epoch - 20ms/step\n",
      "Epoch 149/300\n",
      "5/5 - 0s - loss: 7.4815 - mae: 32.3102 - val_loss: 9.3231 - val_mae: 107.2039 - 89ms/epoch - 18ms/step\n",
      "Epoch 150/300\n",
      "5/5 - 0s - loss: 7.4715 - mae: 32.0872 - val_loss: 9.3165 - val_mae: 105.4804 - 85ms/epoch - 17ms/step\n",
      "Epoch 151/300\n",
      "5/5 - 0s - loss: 7.4601 - mae: 31.8154 - val_loss: 9.3112 - val_mae: 107.4706 - 82ms/epoch - 16ms/step\n",
      "Epoch 152/300\n",
      "5/5 - 0s - loss: 7.4383 - mae: 31.7508 - val_loss: 9.3050 - val_mae: 105.7190 - 84ms/epoch - 17ms/step\n",
      "Epoch 153/300\n",
      "5/5 - 0s - loss: 7.4315 - mae: 31.8916 - val_loss: 9.2975 - val_mae: 105.2769 - 81ms/epoch - 16ms/step\n",
      "Epoch 154/300\n",
      "5/5 - 0s - loss: 7.4188 - mae: 31.2157 - val_loss: 9.2911 - val_mae: 106.2096 - 81ms/epoch - 16ms/step\n",
      "Epoch 155/300\n",
      "5/5 - 0s - loss: 7.4217 - mae: 31.2617 - val_loss: 9.2858 - val_mae: 105.3351 - 90ms/epoch - 18ms/step\n",
      "Epoch 156/300\n",
      "5/5 - 0s - loss: 7.3975 - mae: 31.1972 - val_loss: 9.2791 - val_mae: 106.2076 - 83ms/epoch - 17ms/step\n",
      "Epoch 157/300\n",
      "5/5 - 0s - loss: 7.3657 - mae: 30.8526 - val_loss: 9.2725 - val_mae: 105.1631 - 83ms/epoch - 17ms/step\n",
      "Epoch 158/300\n",
      "5/5 - 0s - loss: 7.3522 - mae: 30.9029 - val_loss: 9.2665 - val_mae: 103.8747 - 88ms/epoch - 18ms/step\n",
      "Epoch 159/300\n",
      "5/5 - 0s - loss: 7.3464 - mae: 30.6846 - val_loss: 9.2594 - val_mae: 104.8937 - 82ms/epoch - 16ms/step\n",
      "Epoch 160/300\n",
      "5/5 - 0s - loss: 7.3347 - mae: 30.4401 - val_loss: 9.2530 - val_mae: 102.6740 - 105ms/epoch - 21ms/step\n",
      "Epoch 161/300\n",
      "5/5 - 0s - loss: 7.3212 - mae: 30.3446 - val_loss: 9.2460 - val_mae: 104.2110 - 91ms/epoch - 18ms/step\n",
      "Epoch 162/300\n",
      "5/5 - 0s - loss: 7.3215 - mae: 30.4782 - val_loss: 9.2418 - val_mae: 104.2689 - 82ms/epoch - 16ms/step\n",
      "Epoch 163/300\n",
      "5/5 - 0s - loss: 7.2966 - mae: 29.7941 - val_loss: 9.2358 - val_mae: 102.7333 - 84ms/epoch - 17ms/step\n",
      "Epoch 164/300\n",
      "5/5 - 0s - loss: 7.2878 - mae: 30.0637 - val_loss: 9.2298 - val_mae: 102.6419 - 87ms/epoch - 17ms/step\n",
      "Epoch 165/300\n",
      "5/5 - 0s - loss: 7.2898 - mae: 30.2657 - val_loss: 9.2255 - val_mae: 102.1982 - 84ms/epoch - 17ms/step\n",
      "Epoch 166/300\n",
      "5/5 - 0s - loss: 7.2770 - mae: 29.9654 - val_loss: 9.2224 - val_mae: 100.0476 - 89ms/epoch - 18ms/step\n",
      "Epoch 167/300\n",
      "5/5 - 0s - loss: 7.2642 - mae: 29.9156 - val_loss: 9.2215 - val_mae: 100.0764 - 85ms/epoch - 17ms/step\n",
      "Epoch 168/300\n",
      "5/5 - 0s - loss: 7.2309 - mae: 29.2636 - val_loss: 9.2186 - val_mae: 99.2278 - 87ms/epoch - 17ms/step\n",
      "Epoch 169/300\n",
      "5/5 - 0s - loss: 7.2235 - mae: 29.4224 - val_loss: 9.2136 - val_mae: 102.5089 - 85ms/epoch - 17ms/step\n",
      "Epoch 170/300\n",
      "5/5 - 0s - loss: 7.2041 - mae: 29.3511 - val_loss: 9.2074 - val_mae: 100.6862 - 86ms/epoch - 17ms/step\n",
      "Epoch 171/300\n",
      "5/5 - 0s - loss: 7.1960 - mae: 29.2230 - val_loss: 9.2029 - val_mae: 99.4090 - 101ms/epoch - 20ms/step\n",
      "Epoch 172/300\n",
      "5/5 - 0s - loss: 7.1947 - mae: 29.5094 - val_loss: 9.2005 - val_mae: 98.8338 - 82ms/epoch - 16ms/step\n",
      "Epoch 173/300\n",
      "5/5 - 0s - loss: 7.1767 - mae: 29.2854 - val_loss: 9.2019 - val_mae: 98.5701 - 88ms/epoch - 18ms/step\n",
      "Epoch 174/300\n",
      "5/5 - 0s - loss: 7.1556 - mae: 28.9208 - val_loss: 9.2007 - val_mae: 101.1681 - 137ms/epoch - 27ms/step\n",
      "Epoch 175/300\n",
      "5/5 - 0s - loss: 7.1528 - mae: 28.9614 - val_loss: 9.1963 - val_mae: 97.8749 - 143ms/epoch - 29ms/step\n",
      "Epoch 176/300\n",
      "5/5 - 0s - loss: 7.1476 - mae: 28.9033 - val_loss: 9.1899 - val_mae: 99.3804 - 137ms/epoch - 27ms/step\n",
      "Epoch 177/300\n",
      "5/5 - 0s - loss: 7.1156 - mae: 28.1108 - val_loss: 9.1755 - val_mae: 98.2366 - 138ms/epoch - 28ms/step\n",
      "Epoch 178/300\n",
      "5/5 - 0s - loss: 7.1029 - mae: 28.2353 - val_loss: 9.1698 - val_mae: 98.2087 - 144ms/epoch - 29ms/step\n",
      "Epoch 179/300\n",
      "5/5 - 0s - loss: 7.1029 - mae: 28.0749 - val_loss: 9.1651 - val_mae: 96.5289 - 155ms/epoch - 31ms/step\n",
      "Epoch 180/300\n",
      "5/5 - 0s - loss: 7.0915 - mae: 28.1436 - val_loss: 9.1607 - val_mae: 95.2299 - 140ms/epoch - 28ms/step\n",
      "Epoch 181/300\n",
      "5/5 - 0s - loss: 7.0756 - mae: 28.2485 - val_loss: 9.1578 - val_mae: 99.0974 - 137ms/epoch - 27ms/step\n",
      "Epoch 182/300\n",
      "5/5 - 0s - loss: 7.0551 - mae: 27.7894 - val_loss: 9.1565 - val_mae: 95.2181 - 152ms/epoch - 30ms/step\n",
      "Epoch 183/300\n",
      "5/5 - 0s - loss: 7.0518 - mae: 27.6849 - val_loss: 9.1595 - val_mae: 94.4781 - 146ms/epoch - 29ms/step\n",
      "Epoch 184/300\n",
      "5/5 - 0s - loss: 7.0378 - mae: 27.5156 - val_loss: 9.1650 - val_mae: 96.4786 - 140ms/epoch - 28ms/step\n",
      "Epoch 185/300\n",
      "5/5 - 0s - loss: 7.0191 - mae: 27.4583 - val_loss: 9.1686 - val_mae: 96.9171 - 138ms/epoch - 28ms/step\n",
      "Epoch 186/300\n",
      "5/5 - 0s - loss: 7.0079 - mae: 27.4066 - val_loss: 9.1686 - val_mae: 93.8721 - 137ms/epoch - 27ms/step\n",
      "Epoch 187/300\n",
      "5/5 - 0s - loss: 6.9935 - mae: 27.1175 - val_loss: 9.1694 - val_mae: 94.9277 - 154ms/epoch - 31ms/step\n",
      "Epoch 188/300\n",
      "5/5 - 0s - loss: 6.9964 - mae: 27.1458 - val_loss: 9.1719 - val_mae: 94.3596 - 135ms/epoch - 27ms/step\n",
      "Epoch 189/300\n",
      "5/5 - 0s - loss: 6.9644 - mae: 26.9600 - val_loss: 9.1749 - val_mae: 93.3247 - 145ms/epoch - 29ms/step\n",
      "Epoch 190/300\n",
      "5/5 - 0s - loss: 6.9696 - mae: 27.0884 - val_loss: 9.1743 - val_mae: 92.8573 - 100ms/epoch - 20ms/step\n",
      "Epoch 191/300\n",
      "5/5 - 0s - loss: 6.9552 - mae: 26.8461 - val_loss: 9.1748 - val_mae: 94.9409 - 80ms/epoch - 16ms/step\n",
      "Epoch 192/300\n",
      "5/5 - 0s - loss: 6.9434 - mae: 26.3002 - val_loss: 9.1774 - val_mae: 94.3562 - 82ms/epoch - 16ms/step\n",
      "Epoch 193/300\n",
      "5/5 - 0s - loss: 6.9319 - mae: 26.4498 - val_loss: 9.1796 - val_mae: 92.7099 - 83ms/epoch - 17ms/step\n",
      "Epoch 194/300\n",
      "5/5 - 0s - loss: 6.9165 - mae: 26.5104 - val_loss: 9.1744 - val_mae: 93.1816 - 91ms/epoch - 18ms/step\n",
      "Epoch 195/300\n",
      "5/5 - 0s - loss: 6.8942 - mae: 26.4010 - val_loss: 9.1706 - val_mae: 93.0748 - 83ms/epoch - 17ms/step\n",
      "Epoch 196/300\n",
      "5/5 - 0s - loss: 6.8779 - mae: 26.1543 - val_loss: 9.1712 - val_mae: 93.3415 - 81ms/epoch - 16ms/step\n",
      "Epoch 197/300\n",
      "5/5 - 0s - loss: 6.8638 - mae: 26.1363 - val_loss: 9.1709 - val_mae: 93.1326 - 96ms/epoch - 19ms/step\n",
      "Epoch 198/300\n",
      "5/5 - 0s - loss: 6.8553 - mae: 26.0374 - val_loss: 9.1722 - val_mae: 94.2797 - 81ms/epoch - 16ms/step\n",
      "Epoch 199/300\n",
      "5/5 - 0s - loss: 6.8566 - mae: 26.0348 - val_loss: 9.1724 - val_mae: 90.1042 - 81ms/epoch - 16ms/step\n",
      "Epoch 200/300\n",
      "5/5 - 0s - loss: 6.8256 - mae: 25.8513 - val_loss: 9.1728 - val_mae: 92.3091 - 84ms/epoch - 17ms/step\n",
      "Epoch 201/300\n",
      "5/5 - 0s - loss: 6.8367 - mae: 26.0200 - val_loss: 9.1829 - val_mae: 91.8092 - 89ms/epoch - 18ms/step\n",
      "Epoch 202/300\n",
      "5/5 - 0s - loss: 6.8085 - mae: 25.4735 - val_loss: 9.1912 - val_mae: 89.3610 - 84ms/epoch - 17ms/step\n",
      "Epoch 203/300\n",
      "5/5 - 0s - loss: 6.8048 - mae: 25.4493 - val_loss: 9.1985 - val_mae: 91.6876 - 83ms/epoch - 17ms/step\n",
      "Epoch 204/300\n",
      "5/5 - 0s - loss: 6.8125 - mae: 25.9057 - val_loss: 9.2067 - val_mae: 91.6179 - 79ms/epoch - 16ms/step\n",
      "Epoch 205/300\n",
      "5/5 - 0s - loss: 6.7748 - mae: 25.1243 - val_loss: 9.2094 - val_mae: 93.0777 - 82ms/epoch - 16ms/step\n",
      "Epoch 206/300\n",
      "5/5 - 0s - loss: 6.7591 - mae: 24.9389 - val_loss: 9.2090 - val_mae: 89.4780 - 82ms/epoch - 16ms/step\n",
      "Epoch 207/300\n",
      "5/5 - 0s - loss: 6.7675 - mae: 25.2057 - val_loss: 9.2074 - val_mae: 89.5733 - 82ms/epoch - 16ms/step\n",
      "Epoch 208/300\n",
      "5/5 - 0s - loss: 6.7446 - mae: 24.8296 - val_loss: 9.2111 - val_mae: 91.6860 - 79ms/epoch - 16ms/step\n",
      "Epoch 209/300\n",
      "5/5 - 0s - loss: 6.7319 - mae: 25.1529 - val_loss: 9.2148 - val_mae: 89.0560 - 98ms/epoch - 20ms/step\n",
      "Epoch 210/300\n",
      "5/5 - 0s - loss: 6.7157 - mae: 24.7457 - val_loss: 9.2149 - val_mae: 90.4349 - 81ms/epoch - 16ms/step\n",
      "Epoch 211/300\n",
      "5/5 - 0s - loss: 6.7207 - mae: 25.0842 - val_loss: 9.2140 - val_mae: 87.2757 - 84ms/epoch - 17ms/step\n",
      "Epoch 212/300\n",
      "5/5 - 0s - loss: 6.7110 - mae: 25.0906 - val_loss: 9.2145 - val_mae: 89.0203 - 87ms/epoch - 17ms/step\n",
      "Epoch 213/300\n",
      "5/5 - 0s - loss: 6.6991 - mae: 24.9408 - val_loss: 9.2202 - val_mae: 88.2318 - 100ms/epoch - 20ms/step\n",
      "Epoch 214/300\n",
      "5/5 - 0s - loss: 6.6950 - mae: 24.6970 - val_loss: 9.2311 - val_mae: 89.2322 - 84ms/epoch - 17ms/step\n",
      "Epoch 215/300\n",
      "5/5 - 0s - loss: 6.6684 - mae: 24.4721 - val_loss: 9.2443 - val_mae: 87.6004 - 86ms/epoch - 17ms/step\n",
      "Epoch 216/300\n",
      "5/5 - 0s - loss: 6.6516 - mae: 24.7460 - val_loss: 9.2496 - val_mae: 88.6663 - 84ms/epoch - 17ms/step\n",
      "Epoch 217/300\n",
      "5/5 - 0s - loss: 6.6659 - mae: 24.5424 - val_loss: 9.2528 - val_mae: 89.3104 - 91ms/epoch - 18ms/step\n",
      "Epoch 218/300\n",
      "5/5 - 0s - loss: 6.6255 - mae: 24.3487 - val_loss: 9.2559 - val_mae: 88.4826 - 101ms/epoch - 20ms/step\n",
      "Epoch 219/300\n",
      "5/5 - 0s - loss: 6.6248 - mae: 24.1664 - val_loss: 9.2471 - val_mae: 85.5808 - 78ms/epoch - 16ms/step\n",
      "Epoch 220/300\n",
      "5/5 - 0s - loss: 6.6092 - mae: 24.0870 - val_loss: 9.2415 - val_mae: 87.2539 - 90ms/epoch - 18ms/step\n",
      "Epoch 221/300\n",
      "5/5 - 0s - loss: 6.5899 - mae: 23.7873 - val_loss: 9.2256 - val_mae: 86.5781 - 86ms/epoch - 17ms/step\n",
      "Epoch 222/300\n",
      "5/5 - 0s - loss: 6.5798 - mae: 23.9320 - val_loss: 9.2228 - val_mae: 85.4629 - 84ms/epoch - 17ms/step\n",
      "Epoch 223/300\n",
      "5/5 - 0s - loss: 6.5884 - mae: 23.8368 - val_loss: 9.2243 - val_mae: 85.1438 - 86ms/epoch - 17ms/step\n",
      "Epoch 224/300\n",
      "5/5 - 0s - loss: 6.5797 - mae: 23.7857 - val_loss: 9.2346 - val_mae: 85.2803 - 83ms/epoch - 17ms/step\n",
      "Epoch 225/300\n",
      "5/5 - 0s - loss: 6.5585 - mae: 23.3260 - val_loss: 9.2390 - val_mae: 86.1235 - 86ms/epoch - 17ms/step\n",
      "Epoch 226/300\n",
      "5/5 - 0s - loss: 6.5448 - mae: 23.5937 - val_loss: 9.2445 - val_mae: 85.3791 - 82ms/epoch - 16ms/step\n",
      "Epoch 227/300\n",
      "5/5 - 0s - loss: 6.5629 - mae: 23.7384 - val_loss: 9.2546 - val_mae: 87.6255 - 82ms/epoch - 16ms/step\n",
      "Epoch 228/300\n",
      "5/5 - 0s - loss: 6.5536 - mae: 23.4376 - val_loss: 9.2663 - val_mae: 84.4897 - 84ms/epoch - 17ms/step\n",
      "Epoch 229/300\n",
      "5/5 - 0s - loss: 6.5361 - mae: 23.6304 - val_loss: 9.2631 - val_mae: 85.3688 - 85ms/epoch - 17ms/step\n",
      "Epoch 230/300\n",
      "5/5 - 0s - loss: 6.5024 - mae: 23.0790 - val_loss: 9.2690 - val_mae: 85.6990 - 84ms/epoch - 17ms/step\n",
      "Epoch 231/300\n",
      "5/5 - 0s - loss: 6.4988 - mae: 23.4696 - val_loss: 9.2791 - val_mae: 84.9969 - 80ms/epoch - 16ms/step\n",
      "Epoch 232/300\n",
      "5/5 - 0s - loss: 6.4882 - mae: 23.3823 - val_loss: 9.2879 - val_mae: 84.6718 - 98ms/epoch - 20ms/step\n",
      "Epoch 1/300\n",
      "5/5 - 1s - loss: 1359.7325 - mae: 87.6997 - val_loss: 369.4503 - val_mae: 145.3988 - 1s/epoch - 252ms/step\n",
      "Epoch 2/300\n",
      "5/5 - 0s - loss: 220.5493 - mae: 86.7136 - val_loss: 84.7327 - val_mae: 143.4459 - 87ms/epoch - 17ms/step\n",
      "Epoch 3/300\n",
      "5/5 - 0s - loss: 86.0579 - mae: 85.4452 - val_loss: 44.6186 - val_mae: 140.9210 - 84ms/epoch - 17ms/step\n",
      "Epoch 4/300\n",
      "5/5 - 0s - loss: 47.8033 - mae: 83.9689 - val_loss: 31.8314 - val_mae: 139.3190 - 85ms/epoch - 17ms/step\n",
      "Epoch 5/300\n",
      "5/5 - 0s - loss: 32.0744 - mae: 82.8166 - val_loss: 26.1099 - val_mae: 137.9623 - 83ms/epoch - 17ms/step\n",
      "Epoch 6/300\n",
      "5/5 - 0s - loss: 24.8940 - mae: 82.0959 - val_loss: 22.7646 - val_mae: 136.6689 - 84ms/epoch - 17ms/step\n",
      "Epoch 7/300\n",
      "5/5 - 0s - loss: 22.3609 - mae: 81.2415 - val_loss: 20.8145 - val_mae: 136.0662 - 105ms/epoch - 21ms/step\n",
      "Epoch 8/300\n",
      "5/5 - 0s - loss: 19.5931 - mae: 80.6134 - val_loss: 19.4467 - val_mae: 134.3870 - 91ms/epoch - 18ms/step\n",
      "Epoch 9/300\n",
      "5/5 - 0s - loss: 18.0427 - mae: 80.4082 - val_loss: 18.5507 - val_mae: 134.5819 - 85ms/epoch - 17ms/step\n",
      "Epoch 10/300\n",
      "5/5 - 0s - loss: 16.8332 - mae: 79.9240 - val_loss: 17.8062 - val_mae: 133.1760 - 87ms/epoch - 17ms/step\n",
      "Epoch 11/300\n",
      "5/5 - 0s - loss: 16.3513 - mae: 79.5658 - val_loss: 17.2622 - val_mae: 132.8101 - 86ms/epoch - 17ms/step\n",
      "Epoch 12/300\n",
      "5/5 - 0s - loss: 16.0398 - mae: 78.5876 - val_loss: 16.8254 - val_mae: 133.7038 - 84ms/epoch - 17ms/step\n",
      "Epoch 13/300\n",
      "5/5 - 0s - loss: 15.2073 - mae: 78.3247 - val_loss: 16.4754 - val_mae: 132.3336 - 87ms/epoch - 17ms/step\n",
      "Epoch 14/300\n",
      "5/5 - 0s - loss: 15.1770 - mae: 78.0079 - val_loss: 16.1333 - val_mae: 131.1966 - 86ms/epoch - 17ms/step\n",
      "Epoch 15/300\n",
      "5/5 - 0s - loss: 14.6608 - mae: 77.7657 - val_loss: 15.8289 - val_mae: 131.8981 - 82ms/epoch - 16ms/step\n",
      "Epoch 16/300\n",
      "5/5 - 0s - loss: 14.7787 - mae: 77.4711 - val_loss: 15.5314 - val_mae: 129.8747 - 83ms/epoch - 17ms/step\n",
      "Epoch 17/300\n",
      "5/5 - 0s - loss: 14.3172 - mae: 77.3865 - val_loss: 15.2986 - val_mae: 130.6826 - 85ms/epoch - 17ms/step\n",
      "Epoch 18/300\n",
      "5/5 - 0s - loss: 13.9230 - mae: 77.0147 - val_loss: 15.0610 - val_mae: 129.7848 - 88ms/epoch - 18ms/step\n",
      "Epoch 19/300\n",
      "5/5 - 0s - loss: 13.6513 - mae: 76.3453 - val_loss: 14.8545 - val_mae: 130.0459 - 110ms/epoch - 22ms/step\n",
      "Epoch 20/300\n",
      "5/5 - 0s - loss: 13.3942 - mae: 76.5350 - val_loss: 14.6515 - val_mae: 128.9669 - 82ms/epoch - 16ms/step\n",
      "Epoch 21/300\n",
      "5/5 - 0s - loss: 13.0726 - mae: 76.1173 - val_loss: 14.4549 - val_mae: 127.6547 - 83ms/epoch - 17ms/step\n",
      "Epoch 22/300\n",
      "5/5 - 0s - loss: 13.1112 - mae: 75.8613 - val_loss: 14.2980 - val_mae: 127.7167 - 86ms/epoch - 17ms/step\n",
      "Epoch 23/300\n",
      "5/5 - 0s - loss: 12.7112 - mae: 75.4874 - val_loss: 14.1076 - val_mae: 125.6549 - 83ms/epoch - 17ms/step\n",
      "Epoch 24/300\n",
      "5/5 - 0s - loss: 12.7521 - mae: 74.9172 - val_loss: 13.9441 - val_mae: 126.7533 - 84ms/epoch - 17ms/step\n",
      "Epoch 25/300\n",
      "5/5 - 0s - loss: 12.5120 - mae: 74.6138 - val_loss: 13.7705 - val_mae: 125.5858 - 83ms/epoch - 17ms/step\n",
      "Epoch 26/300\n",
      "5/5 - 0s - loss: 12.5623 - mae: 74.6754 - val_loss: 13.6073 - val_mae: 125.6486 - 83ms/epoch - 17ms/step\n",
      "Epoch 27/300\n",
      "5/5 - 0s - loss: 12.1708 - mae: 74.6904 - val_loss: 13.4512 - val_mae: 124.2664 - 82ms/epoch - 16ms/step\n",
      "Epoch 28/300\n",
      "5/5 - 0s - loss: 12.2904 - mae: 74.2883 - val_loss: 13.3157 - val_mae: 123.6221 - 82ms/epoch - 16ms/step\n",
      "Epoch 29/300\n",
      "5/5 - 0s - loss: 11.9064 - mae: 73.8751 - val_loss: 13.1892 - val_mae: 122.8983 - 85ms/epoch - 17ms/step\n",
      "Epoch 30/300\n",
      "5/5 - 0s - loss: 11.8034 - mae: 73.6751 - val_loss: 13.0584 - val_mae: 124.0280 - 107ms/epoch - 21ms/step\n",
      "Epoch 31/300\n",
      "5/5 - 0s - loss: 11.7836 - mae: 72.9512 - val_loss: 12.9533 - val_mae: 123.2603 - 87ms/epoch - 17ms/step\n",
      "Epoch 32/300\n",
      "5/5 - 0s - loss: 11.8011 - mae: 73.5468 - val_loss: 12.8388 - val_mae: 122.8279 - 88ms/epoch - 18ms/step\n",
      "Epoch 33/300\n",
      "5/5 - 0s - loss: 11.6250 - mae: 73.2763 - val_loss: 12.7246 - val_mae: 121.4764 - 84ms/epoch - 17ms/step\n",
      "Epoch 34/300\n",
      "5/5 - 0s - loss: 11.5360 - mae: 72.5009 - val_loss: 12.6193 - val_mae: 119.9178 - 83ms/epoch - 17ms/step\n",
      "Epoch 35/300\n",
      "5/5 - 0s - loss: 11.3114 - mae: 72.2800 - val_loss: 12.5186 - val_mae: 121.5939 - 85ms/epoch - 17ms/step\n",
      "Epoch 36/300\n",
      "5/5 - 0s - loss: 11.3670 - mae: 71.9249 - val_loss: 12.4213 - val_mae: 119.9684 - 85ms/epoch - 17ms/step\n",
      "Epoch 37/300\n",
      "5/5 - 0s - loss: 11.1154 - mae: 71.4453 - val_loss: 12.3322 - val_mae: 119.0741 - 79ms/epoch - 16ms/step\n",
      "Epoch 38/300\n",
      "5/5 - 0s - loss: 11.2437 - mae: 71.5740 - val_loss: 12.2491 - val_mae: 119.0758 - 84ms/epoch - 17ms/step\n",
      "Epoch 39/300\n",
      "5/5 - 0s - loss: 11.1634 - mae: 71.7528 - val_loss: 12.1673 - val_mae: 119.5539 - 84ms/epoch - 17ms/step\n",
      "Epoch 40/300\n",
      "5/5 - 0s - loss: 10.9738 - mae: 70.8932 - val_loss: 12.0942 - val_mae: 120.1030 - 83ms/epoch - 17ms/step\n",
      "Epoch 41/300\n",
      "5/5 - 0s - loss: 10.9732 - mae: 71.0400 - val_loss: 12.0180 - val_mae: 119.3202 - 90ms/epoch - 18ms/step\n",
      "Epoch 42/300\n",
      "5/5 - 0s - loss: 10.8774 - mae: 70.9669 - val_loss: 11.9536 - val_mae: 117.2939 - 102ms/epoch - 20ms/step\n",
      "Epoch 43/300\n",
      "5/5 - 0s - loss: 10.7243 - mae: 70.4400 - val_loss: 11.8836 - val_mae: 117.4545 - 80ms/epoch - 16ms/step\n",
      "Epoch 44/300\n",
      "5/5 - 0s - loss: 10.7359 - mae: 70.0022 - val_loss: 11.8291 - val_mae: 115.9645 - 85ms/epoch - 17ms/step\n",
      "Epoch 45/300\n",
      "5/5 - 0s - loss: 10.6030 - mae: 69.7396 - val_loss: 11.7691 - val_mae: 116.2692 - 81ms/epoch - 16ms/step\n",
      "Epoch 46/300\n",
      "5/5 - 0s - loss: 10.5081 - mae: 69.3444 - val_loss: 11.7060 - val_mae: 114.9713 - 82ms/epoch - 16ms/step\n",
      "Epoch 47/300\n",
      "5/5 - 0s - loss: 10.5651 - mae: 69.8314 - val_loss: 11.6348 - val_mae: 115.0804 - 90ms/epoch - 18ms/step\n",
      "Epoch 48/300\n",
      "5/5 - 0s - loss: 10.4843 - mae: 68.9511 - val_loss: 11.5705 - val_mae: 115.1318 - 81ms/epoch - 16ms/step\n",
      "Epoch 49/300\n",
      "5/5 - 0s - loss: 10.5224 - mae: 68.8920 - val_loss: 11.5171 - val_mae: 113.6766 - 82ms/epoch - 16ms/step\n",
      "Epoch 50/300\n",
      "5/5 - 0s - loss: 10.4140 - mae: 68.2501 - val_loss: 11.4638 - val_mae: 113.4599 - 82ms/epoch - 16ms/step\n",
      "Epoch 51/300\n",
      "5/5 - 0s - loss: 10.4950 - mae: 68.1643 - val_loss: 11.4096 - val_mae: 111.7258 - 78ms/epoch - 16ms/step\n",
      "Epoch 52/300\n",
      "5/5 - 0s - loss: 10.2756 - mae: 68.3062 - val_loss: 11.3361 - val_mae: 113.3859 - 84ms/epoch - 17ms/step\n",
      "Epoch 53/300\n",
      "5/5 - 0s - loss: 10.2984 - mae: 67.7671 - val_loss: 11.2715 - val_mae: 112.1806 - 91ms/epoch - 18ms/step\n",
      "Epoch 54/300\n",
      "5/5 - 0s - loss: 10.2001 - mae: 67.5852 - val_loss: 11.2129 - val_mae: 110.6490 - 170ms/epoch - 34ms/step\n",
      "Epoch 55/300\n",
      "5/5 - 0s - loss: 10.2615 - mae: 67.5531 - val_loss: 11.1533 - val_mae: 109.9558 - 138ms/epoch - 28ms/step\n",
      "Epoch 56/300\n",
      "5/5 - 0s - loss: 10.1005 - mae: 67.5554 - val_loss: 11.1045 - val_mae: 110.8919 - 137ms/epoch - 27ms/step\n",
      "Epoch 57/300\n",
      "5/5 - 0s - loss: 10.0419 - mae: 66.1499 - val_loss: 11.0592 - val_mae: 107.9408 - 156ms/epoch - 31ms/step\n",
      "Epoch 58/300\n",
      "5/5 - 0s - loss: 10.0281 - mae: 66.5973 - val_loss: 11.0132 - val_mae: 110.1769 - 147ms/epoch - 29ms/step\n",
      "Epoch 59/300\n",
      "5/5 - 0s - loss: 9.9547 - mae: 66.3813 - val_loss: 10.9727 - val_mae: 108.5446 - 146ms/epoch - 29ms/step\n",
      "Epoch 60/300\n",
      "5/5 - 0s - loss: 9.9795 - mae: 66.3079 - val_loss: 10.9311 - val_mae: 107.9415 - 136ms/epoch - 27ms/step\n",
      "Epoch 61/300\n",
      "5/5 - 0s - loss: 9.9486 - mae: 66.0108 - val_loss: 10.8908 - val_mae: 108.9891 - 136ms/epoch - 27ms/step\n",
      "Epoch 62/300\n",
      "5/5 - 0s - loss: 9.8830 - mae: 66.2516 - val_loss: 10.8521 - val_mae: 108.2391 - 153ms/epoch - 31ms/step\n",
      "Epoch 63/300\n",
      "5/5 - 0s - loss: 9.8730 - mae: 65.8888 - val_loss: 10.8118 - val_mae: 107.3995 - 149ms/epoch - 30ms/step\n",
      "Epoch 64/300\n",
      "5/5 - 0s - loss: 9.8055 - mae: 65.3036 - val_loss: 10.7751 - val_mae: 107.4225 - 140ms/epoch - 28ms/step\n",
      "Epoch 65/300\n",
      "5/5 - 0s - loss: 9.7927 - mae: 65.6766 - val_loss: 10.7391 - val_mae: 106.0309 - 148ms/epoch - 30ms/step\n",
      "Epoch 66/300\n",
      "5/5 - 0s - loss: 9.7360 - mae: 64.8010 - val_loss: 10.7054 - val_mae: 105.8434 - 135ms/epoch - 27ms/step\n",
      "Epoch 67/300\n",
      "5/5 - 0s - loss: 9.7311 - mae: 64.7862 - val_loss: 10.6716 - val_mae: 104.5918 - 157ms/epoch - 31ms/step\n",
      "Epoch 68/300\n",
      "5/5 - 0s - loss: 9.7626 - mae: 64.0695 - val_loss: 10.6370 - val_mae: 103.6776 - 154ms/epoch - 31ms/step\n",
      "Epoch 69/300\n",
      "5/5 - 0s - loss: 9.6926 - mae: 63.8752 - val_loss: 10.6060 - val_mae: 103.4975 - 133ms/epoch - 27ms/step\n",
      "Epoch 70/300\n",
      "5/5 - 0s - loss: 9.7098 - mae: 64.4083 - val_loss: 10.5766 - val_mae: 104.9165 - 93ms/epoch - 19ms/step\n",
      "Epoch 71/300\n",
      "5/5 - 0s - loss: 9.6148 - mae: 64.0822 - val_loss: 10.5427 - val_mae: 102.5346 - 85ms/epoch - 17ms/step\n",
      "Epoch 72/300\n",
      "5/5 - 0s - loss: 9.6680 - mae: 63.7690 - val_loss: 10.5144 - val_mae: 102.9365 - 84ms/epoch - 17ms/step\n",
      "Epoch 73/300\n",
      "5/5 - 0s - loss: 9.7105 - mae: 63.8557 - val_loss: 10.4814 - val_mae: 103.9923 - 81ms/epoch - 16ms/step\n",
      "Epoch 74/300\n",
      "5/5 - 0s - loss: 9.5785 - mae: 63.4245 - val_loss: 10.4507 - val_mae: 103.5573 - 82ms/epoch - 16ms/step\n",
      "Epoch 75/300\n",
      "5/5 - 0s - loss: 9.5556 - mae: 63.4373 - val_loss: 10.4227 - val_mae: 103.3267 - 94ms/epoch - 19ms/step\n",
      "Epoch 76/300\n",
      "5/5 - 0s - loss: 9.4750 - mae: 63.2663 - val_loss: 10.3933 - val_mae: 101.0223 - 92ms/epoch - 18ms/step\n",
      "Epoch 77/300\n",
      "5/5 - 0s - loss: 9.5186 - mae: 63.1876 - val_loss: 10.3688 - val_mae: 98.3543 - 86ms/epoch - 17ms/step\n",
      "Epoch 78/300\n",
      "5/5 - 0s - loss: 9.4317 - mae: 62.3849 - val_loss: 10.3433 - val_mae: 101.9623 - 89ms/epoch - 18ms/step\n",
      "Epoch 79/300\n",
      "5/5 - 0s - loss: 9.4431 - mae: 62.6012 - val_loss: 10.3166 - val_mae: 99.0794 - 99ms/epoch - 20ms/step\n",
      "Epoch 80/300\n",
      "5/5 - 0s - loss: 9.4454 - mae: 62.1927 - val_loss: 10.2910 - val_mae: 102.4324 - 85ms/epoch - 17ms/step\n",
      "Epoch 81/300\n",
      "5/5 - 0s - loss: 9.4750 - mae: 62.1777 - val_loss: 10.2655 - val_mae: 100.7994 - 91ms/epoch - 18ms/step\n",
      "Epoch 82/300\n",
      "5/5 - 0s - loss: 9.3725 - mae: 61.2686 - val_loss: 10.2398 - val_mae: 97.9272 - 83ms/epoch - 17ms/step\n",
      "Epoch 83/300\n",
      "5/5 - 0s - loss: 9.3809 - mae: 61.5021 - val_loss: 10.2143 - val_mae: 99.5629 - 81ms/epoch - 16ms/step\n",
      "Epoch 84/300\n",
      "5/5 - 0s - loss: 9.3903 - mae: 61.3513 - val_loss: 10.1923 - val_mae: 99.9158 - 88ms/epoch - 18ms/step\n",
      "Epoch 85/300\n",
      "5/5 - 0s - loss: 9.3349 - mae: 60.6290 - val_loss: 10.1689 - val_mae: 97.1741 - 82ms/epoch - 16ms/step\n",
      "Epoch 86/300\n",
      "5/5 - 0s - loss: 9.2678 - mae: 60.6366 - val_loss: 10.1448 - val_mae: 95.9821 - 89ms/epoch - 18ms/step\n",
      "Epoch 87/300\n",
      "5/5 - 0s - loss: 9.3229 - mae: 60.9718 - val_loss: 10.1217 - val_mae: 98.4199 - 91ms/epoch - 18ms/step\n",
      "Epoch 88/300\n",
      "5/5 - 0s - loss: 9.2843 - mae: 60.5371 - val_loss: 10.1001 - val_mae: 96.7630 - 85ms/epoch - 17ms/step\n",
      "Epoch 89/300\n",
      "5/5 - 0s - loss: 9.2448 - mae: 60.1456 - val_loss: 10.0756 - val_mae: 97.5245 - 87ms/epoch - 17ms/step\n",
      "Epoch 90/300\n",
      "5/5 - 0s - loss: 9.2488 - mae: 60.0747 - val_loss: 10.0538 - val_mae: 93.5619 - 86ms/epoch - 17ms/step\n",
      "Epoch 91/300\n",
      "5/5 - 0s - loss: 9.2260 - mae: 59.9162 - val_loss: 10.0323 - val_mae: 97.2181 - 102ms/epoch - 20ms/step\n",
      "Epoch 92/300\n",
      "5/5 - 0s - loss: 9.2170 - mae: 59.8114 - val_loss: 10.0124 - val_mae: 92.7651 - 86ms/epoch - 17ms/step\n",
      "Epoch 93/300\n",
      "5/5 - 0s - loss: 9.1911 - mae: 59.5665 - val_loss: 9.9892 - val_mae: 95.5013 - 86ms/epoch - 17ms/step\n",
      "Epoch 94/300\n",
      "5/5 - 0s - loss: 9.2258 - mae: 59.9291 - val_loss: 9.9692 - val_mae: 93.2195 - 83ms/epoch - 17ms/step\n",
      "Epoch 95/300\n",
      "5/5 - 0s - loss: 9.2311 - mae: 59.0065 - val_loss: 9.9485 - val_mae: 94.6077 - 88ms/epoch - 18ms/step\n",
      "Epoch 96/300\n",
      "5/5 - 0s - loss: 9.1737 - mae: 58.9058 - val_loss: 9.9279 - val_mae: 92.3129 - 87ms/epoch - 17ms/step\n",
      "Epoch 97/300\n",
      "5/5 - 0s - loss: 9.1207 - mae: 59.0908 - val_loss: 9.9081 - val_mae: 93.4390 - 96ms/epoch - 19ms/step\n",
      "Epoch 98/300\n",
      "5/5 - 0s - loss: 9.1068 - mae: 58.0309 - val_loss: 9.8895 - val_mae: 93.1697 - 94ms/epoch - 19ms/step\n",
      "Epoch 99/300\n",
      "5/5 - 0s - loss: 9.0719 - mae: 58.1619 - val_loss: 9.8712 - val_mae: 93.2426 - 86ms/epoch - 17ms/step\n",
      "Epoch 100/300\n",
      "5/5 - 0s - loss: 9.0476 - mae: 57.6847 - val_loss: 9.8534 - val_mae: 93.2275 - 86ms/epoch - 17ms/step\n",
      "Epoch 101/300\n",
      "5/5 - 0s - loss: 9.0555 - mae: 57.5592 - val_loss: 9.8353 - val_mae: 90.9900 - 85ms/epoch - 17ms/step\n",
      "Epoch 102/300\n",
      "5/5 - 0s - loss: 9.0674 - mae: 58.0932 - val_loss: 9.8160 - val_mae: 91.4348 - 104ms/epoch - 21ms/step\n",
      "Epoch 103/300\n",
      "5/5 - 0s - loss: 8.9952 - mae: 57.6096 - val_loss: 9.7974 - val_mae: 90.8883 - 89ms/epoch - 18ms/step\n",
      "Epoch 104/300\n",
      "5/5 - 0s - loss: 8.9921 - mae: 57.3032 - val_loss: 9.7815 - val_mae: 91.7057 - 86ms/epoch - 17ms/step\n",
      "Epoch 105/300\n",
      "5/5 - 0s - loss: 8.9675 - mae: 56.9997 - val_loss: 9.7590 - val_mae: 90.7809 - 86ms/epoch - 17ms/step\n",
      "Epoch 106/300\n",
      "5/5 - 0s - loss: 8.9571 - mae: 56.9189 - val_loss: 9.7415 - val_mae: 90.6141 - 85ms/epoch - 17ms/step\n",
      "Epoch 107/300\n",
      "5/5 - 0s - loss: 9.0059 - mae: 56.5765 - val_loss: 9.7239 - val_mae: 90.7018 - 81ms/epoch - 16ms/step\n",
      "Epoch 108/300\n",
      "5/5 - 0s - loss: 8.9795 - mae: 56.7833 - val_loss: 9.7088 - val_mae: 88.8478 - 90ms/epoch - 18ms/step\n",
      "Epoch 109/300\n",
      "5/5 - 0s - loss: 8.9312 - mae: 56.1580 - val_loss: 9.6916 - val_mae: 89.3396 - 83ms/epoch - 17ms/step\n",
      "Epoch 110/300\n",
      "5/5 - 0s - loss: 8.9536 - mae: 56.3489 - val_loss: 9.6762 - val_mae: 89.2168 - 91ms/epoch - 18ms/step\n",
      "Epoch 111/300\n",
      "5/5 - 0s - loss: 8.9560 - mae: 56.0012 - val_loss: 9.6617 - val_mae: 90.0333 - 85ms/epoch - 17ms/step\n",
      "Epoch 112/300\n",
      "5/5 - 0s - loss: 8.9041 - mae: 55.8928 - val_loss: 9.6441 - val_mae: 88.6502 - 82ms/epoch - 16ms/step\n",
      "Epoch 113/300\n",
      "5/5 - 0s - loss: 8.9278 - mae: 56.0272 - val_loss: 9.6280 - val_mae: 89.0914 - 87ms/epoch - 17ms/step\n",
      "Epoch 114/300\n",
      "5/5 - 0s - loss: 8.8629 - mae: 55.4960 - val_loss: 9.6142 - val_mae: 86.3051 - 104ms/epoch - 21ms/step\n",
      "Epoch 115/300\n",
      "5/5 - 0s - loss: 8.9039 - mae: 55.7671 - val_loss: 9.6017 - val_mae: 88.1240 - 82ms/epoch - 16ms/step\n",
      "Epoch 116/300\n",
      "5/5 - 0s - loss: 8.8537 - mae: 55.3490 - val_loss: 9.5876 - val_mae: 88.5393 - 83ms/epoch - 17ms/step\n",
      "Epoch 117/300\n",
      "5/5 - 0s - loss: 8.8934 - mae: 55.3223 - val_loss: 9.5734 - val_mae: 87.3653 - 88ms/epoch - 18ms/step\n",
      "Epoch 118/300\n",
      "5/5 - 0s - loss: 8.8130 - mae: 54.8597 - val_loss: 9.5581 - val_mae: 86.9179 - 85ms/epoch - 17ms/step\n",
      "Epoch 119/300\n",
      "5/5 - 0s - loss: 8.8016 - mae: 54.9586 - val_loss: 9.5441 - val_mae: 87.7493 - 87ms/epoch - 17ms/step\n",
      "Epoch 120/300\n",
      "5/5 - 0s - loss: 8.8264 - mae: 54.5142 - val_loss: 9.5284 - val_mae: 86.6564 - 91ms/epoch - 18ms/step\n",
      "Epoch 121/300\n",
      "5/5 - 0s - loss: 8.7856 - mae: 54.0320 - val_loss: 9.5144 - val_mae: 86.3468 - 85ms/epoch - 17ms/step\n",
      "Epoch 122/300\n",
      "5/5 - 0s - loss: 8.7799 - mae: 54.2670 - val_loss: 9.5001 - val_mae: 85.4236 - 86ms/epoch - 17ms/step\n",
      "Epoch 123/300\n",
      "5/5 - 0s - loss: 8.8083 - mae: 54.0382 - val_loss: 9.4856 - val_mae: 86.1400 - 85ms/epoch - 17ms/step\n",
      "Epoch 124/300\n",
      "5/5 - 0s - loss: 8.7989 - mae: 54.3600 - val_loss: 9.4703 - val_mae: 84.9032 - 85ms/epoch - 17ms/step\n",
      "Epoch 125/300\n",
      "5/5 - 0s - loss: 8.7465 - mae: 53.3999 - val_loss: 9.4558 - val_mae: 82.9492 - 108ms/epoch - 22ms/step\n",
      "Epoch 126/300\n",
      "5/5 - 0s - loss: 8.7456 - mae: 53.2598 - val_loss: 9.4419 - val_mae: 82.9467 - 87ms/epoch - 17ms/step\n",
      "Epoch 127/300\n",
      "5/5 - 0s - loss: 8.7160 - mae: 53.3482 - val_loss: 9.4285 - val_mae: 85.8032 - 83ms/epoch - 17ms/step\n",
      "Epoch 128/300\n",
      "5/5 - 0s - loss: 8.7303 - mae: 53.0405 - val_loss: 9.4170 - val_mae: 82.5594 - 84ms/epoch - 17ms/step\n",
      "Epoch 129/300\n",
      "5/5 - 0s - loss: 8.7041 - mae: 52.9652 - val_loss: 9.4029 - val_mae: 83.9071 - 87ms/epoch - 17ms/step\n",
      "Epoch 130/300\n",
      "5/5 - 0s - loss: 8.7073 - mae: 53.2637 - val_loss: 9.3913 - val_mae: 85.7923 - 92ms/epoch - 18ms/step\n",
      "Epoch 131/300\n",
      "5/5 - 0s - loss: 8.6605 - mae: 52.9927 - val_loss: 9.3766 - val_mae: 82.8685 - 89ms/epoch - 18ms/step\n",
      "Epoch 132/300\n",
      "5/5 - 0s - loss: 8.6653 - mae: 52.8838 - val_loss: 9.3640 - val_mae: 83.1455 - 91ms/epoch - 18ms/step\n",
      "Epoch 133/300\n",
      "5/5 - 0s - loss: 8.6737 - mae: 52.4620 - val_loss: 9.3469 - val_mae: 83.6422 - 84ms/epoch - 17ms/step\n",
      "Epoch 134/300\n",
      "5/5 - 0s - loss: 8.6506 - mae: 52.2932 - val_loss: 9.3327 - val_mae: 83.1311 - 85ms/epoch - 17ms/step\n",
      "Epoch 135/300\n",
      "5/5 - 0s - loss: 8.6404 - mae: 52.2932 - val_loss: 9.3191 - val_mae: 81.9102 - 88ms/epoch - 18ms/step\n",
      "Epoch 136/300\n",
      "5/5 - 0s - loss: 8.6176 - mae: 52.0369 - val_loss: 9.3061 - val_mae: 81.4451 - 95ms/epoch - 19ms/step\n",
      "Epoch 137/300\n",
      "5/5 - 0s - loss: 8.6050 - mae: 52.0449 - val_loss: 9.2948 - val_mae: 81.9307 - 87ms/epoch - 17ms/step\n",
      "Epoch 138/300\n",
      "5/5 - 0s - loss: 8.6029 - mae: 51.8621 - val_loss: 9.2837 - val_mae: 80.6081 - 85ms/epoch - 17ms/step\n",
      "Epoch 139/300\n",
      "5/5 - 0s - loss: 8.6207 - mae: 51.2826 - val_loss: 9.2727 - val_mae: 79.6808 - 86ms/epoch - 17ms/step\n",
      "Epoch 140/300\n",
      "5/5 - 0s - loss: 8.5587 - mae: 51.5347 - val_loss: 9.2615 - val_mae: 80.4842 - 85ms/epoch - 17ms/step\n",
      "Epoch 141/300\n",
      "5/5 - 0s - loss: 8.5845 - mae: 51.9414 - val_loss: 9.2502 - val_mae: 81.7093 - 90ms/epoch - 18ms/step\n",
      "Epoch 142/300\n",
      "5/5 - 0s - loss: 8.5874 - mae: 50.7909 - val_loss: 9.2404 - val_mae: 80.2300 - 85ms/epoch - 17ms/step\n",
      "Epoch 143/300\n",
      "5/5 - 0s - loss: 8.5388 - mae: 51.0572 - val_loss: 9.2294 - val_mae: 81.0564 - 87ms/epoch - 17ms/step\n",
      "Epoch 144/300\n",
      "5/5 - 0s - loss: 8.4962 - mae: 50.9493 - val_loss: 9.2188 - val_mae: 79.4876 - 111ms/epoch - 22ms/step\n",
      "Epoch 145/300\n",
      "5/5 - 0s - loss: 8.5176 - mae: 50.7807 - val_loss: 9.2064 - val_mae: 80.2104 - 100ms/epoch - 20ms/step\n",
      "Epoch 146/300\n",
      "5/5 - 0s - loss: 8.5149 - mae: 50.5161 - val_loss: 9.1944 - val_mae: 80.1779 - 134ms/epoch - 27ms/step\n",
      "Epoch 147/300\n",
      "5/5 - 0s - loss: 8.4873 - mae: 50.9401 - val_loss: 9.1804 - val_mae: 79.3319 - 103ms/epoch - 21ms/step\n",
      "Epoch 148/300\n",
      "5/5 - 0s - loss: 8.4898 - mae: 50.3780 - val_loss: 9.1697 - val_mae: 77.5400 - 82ms/epoch - 16ms/step\n",
      "Epoch 149/300\n",
      "5/5 - 0s - loss: 8.4939 - mae: 49.9802 - val_loss: 9.1580 - val_mae: 77.8782 - 84ms/epoch - 17ms/step\n",
      "Epoch 150/300\n",
      "5/5 - 0s - loss: 8.4636 - mae: 49.4753 - val_loss: 9.1472 - val_mae: 77.5199 - 85ms/epoch - 17ms/step\n",
      "Epoch 151/300\n",
      "5/5 - 0s - loss: 8.4794 - mae: 49.6514 - val_loss: 9.1361 - val_mae: 78.0680 - 94ms/epoch - 19ms/step\n",
      "Epoch 152/300\n",
      "5/5 - 0s - loss: 8.4328 - mae: 49.7828 - val_loss: 9.1251 - val_mae: 78.2783 - 86ms/epoch - 17ms/step\n",
      "Epoch 153/300\n",
      "5/5 - 0s - loss: 8.4228 - mae: 49.1331 - val_loss: 9.1131 - val_mae: 79.5901 - 85ms/epoch - 17ms/step\n",
      "Epoch 154/300\n",
      "5/5 - 0s - loss: 8.4246 - mae: 48.5648 - val_loss: 9.1008 - val_mae: 80.4485 - 84ms/epoch - 17ms/step\n",
      "Epoch 155/300\n",
      "5/5 - 0s - loss: 8.4038 - mae: 49.3183 - val_loss: 9.0883 - val_mae: 75.5450 - 85ms/epoch - 17ms/step\n",
      "Epoch 156/300\n",
      "5/5 - 0s - loss: 8.4144 - mae: 49.1371 - val_loss: 9.0761 - val_mae: 77.8960 - 84ms/epoch - 17ms/step\n",
      "Epoch 157/300\n",
      "5/5 - 0s - loss: 8.4105 - mae: 49.4370 - val_loss: 9.0658 - val_mae: 76.9611 - 84ms/epoch - 17ms/step\n",
      "Epoch 158/300\n",
      "5/5 - 0s - loss: 8.4387 - mae: 49.2862 - val_loss: 9.0563 - val_mae: 75.2967 - 83ms/epoch - 17ms/step\n",
      "Epoch 159/300\n",
      "5/5 - 0s - loss: 8.4116 - mae: 48.8430 - val_loss: 9.0463 - val_mae: 75.2568 - 100ms/epoch - 20ms/step\n",
      "Epoch 160/300\n",
      "5/5 - 0s - loss: 8.3427 - mae: 48.7000 - val_loss: 9.0359 - val_mae: 76.0328 - 82ms/epoch - 16ms/step\n",
      "Epoch 161/300\n",
      "5/5 - 0s - loss: 8.3610 - mae: 47.4434 - val_loss: 9.0251 - val_mae: 75.4519 - 82ms/epoch - 16ms/step\n",
      "Epoch 162/300\n",
      "5/5 - 0s - loss: 8.3237 - mae: 48.1045 - val_loss: 9.0148 - val_mae: 76.3407 - 89ms/epoch - 18ms/step\n",
      "Epoch 163/300\n",
      "5/5 - 0s - loss: 8.3331 - mae: 48.3416 - val_loss: 9.0058 - val_mae: 75.1748 - 88ms/epoch - 18ms/step\n",
      "Epoch 164/300\n",
      "5/5 - 0s - loss: 8.3468 - mae: 47.8666 - val_loss: 8.9963 - val_mae: 76.1951 - 90ms/epoch - 18ms/step\n",
      "Epoch 165/300\n",
      "5/5 - 0s - loss: 8.3158 - mae: 47.6530 - val_loss: 8.9844 - val_mae: 73.6999 - 84ms/epoch - 17ms/step\n",
      "Epoch 166/300\n",
      "5/5 - 0s - loss: 8.3183 - mae: 47.7135 - val_loss: 8.9740 - val_mae: 74.5539 - 81ms/epoch - 16ms/step\n",
      "Epoch 167/300\n",
      "5/5 - 0s - loss: 8.2764 - mae: 46.9303 - val_loss: 8.9639 - val_mae: 73.9348 - 82ms/epoch - 16ms/step\n",
      "Epoch 168/300\n",
      "5/5 - 0s - loss: 8.2933 - mae: 47.3859 - val_loss: 8.9526 - val_mae: 73.7144 - 84ms/epoch - 17ms/step\n",
      "Epoch 169/300\n",
      "5/5 - 0s - loss: 8.3040 - mae: 46.8619 - val_loss: 8.9423 - val_mae: 75.6995 - 88ms/epoch - 18ms/step\n",
      "Epoch 170/300\n",
      "5/5 - 0s - loss: 8.2646 - mae: 46.8598 - val_loss: 8.9324 - val_mae: 75.2053 - 94ms/epoch - 19ms/step\n",
      "Epoch 171/300\n",
      "5/5 - 0s - loss: 8.2650 - mae: 46.9406 - val_loss: 8.9224 - val_mae: 72.6636 - 83ms/epoch - 17ms/step\n",
      "Epoch 172/300\n",
      "5/5 - 0s - loss: 8.2691 - mae: 46.9126 - val_loss: 8.9120 - val_mae: 73.4889 - 82ms/epoch - 16ms/step\n",
      "Epoch 173/300\n",
      "5/5 - 0s - loss: 8.2817 - mae: 46.9771 - val_loss: 8.9023 - val_mae: 73.9475 - 85ms/epoch - 17ms/step\n",
      "Epoch 174/300\n",
      "5/5 - 0s - loss: 8.2187 - mae: 46.5462 - val_loss: 8.8928 - val_mae: 73.9926 - 95ms/epoch - 19ms/step\n",
      "Epoch 175/300\n",
      "5/5 - 0s - loss: 8.2341 - mae: 46.3802 - val_loss: 8.8825 - val_mae: 71.9830 - 86ms/epoch - 17ms/step\n",
      "Epoch 176/300\n",
      "5/5 - 0s - loss: 8.2000 - mae: 46.2924 - val_loss: 8.8717 - val_mae: 73.8515 - 85ms/epoch - 17ms/step\n",
      "Epoch 177/300\n",
      "5/5 - 0s - loss: 8.1977 - mae: 46.0808 - val_loss: 8.8624 - val_mae: 71.8236 - 87ms/epoch - 17ms/step\n",
      "Epoch 178/300\n",
      "5/5 - 0s - loss: 8.1658 - mae: 45.9524 - val_loss: 8.8517 - val_mae: 72.3850 - 84ms/epoch - 17ms/step\n",
      "Epoch 179/300\n",
      "5/5 - 0s - loss: 8.2033 - mae: 46.1103 - val_loss: 8.8403 - val_mae: 72.7035 - 150ms/epoch - 30ms/step\n",
      "Epoch 180/300\n",
      "5/5 - 0s - loss: 8.1813 - mae: 45.6058 - val_loss: 8.8308 - val_mae: 72.5154 - 136ms/epoch - 27ms/step\n",
      "Epoch 181/300\n",
      "5/5 - 0s - loss: 8.1656 - mae: 45.7927 - val_loss: 8.8206 - val_mae: 71.3796 - 145ms/epoch - 29ms/step\n",
      "Epoch 182/300\n",
      "5/5 - 0s - loss: 8.1679 - mae: 45.7979 - val_loss: 8.8104 - val_mae: 73.3407 - 153ms/epoch - 31ms/step\n",
      "Epoch 183/300\n",
      "5/5 - 0s - loss: 8.1238 - mae: 45.3876 - val_loss: 8.8010 - val_mae: 72.6128 - 142ms/epoch - 28ms/step\n",
      "Epoch 184/300\n",
      "5/5 - 0s - loss: 8.1137 - mae: 45.3160 - val_loss: 8.7920 - val_mae: 70.5574 - 137ms/epoch - 27ms/step\n",
      "Epoch 185/300\n",
      "5/5 - 0s - loss: 8.1521 - mae: 45.4230 - val_loss: 8.7825 - val_mae: 69.6807 - 150ms/epoch - 30ms/step\n",
      "Epoch 186/300\n",
      "5/5 - 0s - loss: 8.1244 - mae: 45.4028 - val_loss: 8.7738 - val_mae: 70.7552 - 141ms/epoch - 28ms/step\n",
      "Epoch 187/300\n",
      "5/5 - 0s - loss: 8.0820 - mae: 45.0092 - val_loss: 8.7624 - val_mae: 70.6349 - 136ms/epoch - 27ms/step\n",
      "Epoch 188/300\n",
      "5/5 - 0s - loss: 8.1117 - mae: 45.0564 - val_loss: 8.7510 - val_mae: 70.3920 - 139ms/epoch - 28ms/step\n",
      "Epoch 189/300\n",
      "5/5 - 0s - loss: 8.1386 - mae: 44.7310 - val_loss: 8.7418 - val_mae: 70.4626 - 148ms/epoch - 30ms/step\n",
      "Epoch 190/300\n",
      "5/5 - 0s - loss: 8.0796 - mae: 45.3295 - val_loss: 8.7315 - val_mae: 69.4958 - 147ms/epoch - 29ms/step\n",
      "Epoch 191/300\n",
      "5/5 - 0s - loss: 8.0813 - mae: 44.7144 - val_loss: 8.7230 - val_mae: 71.1827 - 160ms/epoch - 32ms/step\n",
      "Epoch 192/300\n",
      "5/5 - 0s - loss: 8.0570 - mae: 43.9107 - val_loss: 8.7113 - val_mae: 69.4044 - 145ms/epoch - 29ms/step\n",
      "Epoch 193/300\n",
      "5/5 - 0s - loss: 8.0595 - mae: 44.6582 - val_loss: 8.7007 - val_mae: 69.4997 - 160ms/epoch - 32ms/step\n",
      "Epoch 194/300\n",
      "5/5 - 0s - loss: 8.0379 - mae: 44.4947 - val_loss: 8.6911 - val_mae: 69.1283 - 101ms/epoch - 20ms/step\n",
      "Epoch 195/300\n",
      "5/5 - 0s - loss: 8.0771 - mae: 44.4807 - val_loss: 8.6828 - val_mae: 70.0288 - 85ms/epoch - 17ms/step\n",
      "Epoch 196/300\n",
      "5/5 - 0s - loss: 8.0070 - mae: 43.8775 - val_loss: 8.6735 - val_mae: 68.7825 - 105ms/epoch - 21ms/step\n",
      "Epoch 197/300\n",
      "5/5 - 0s - loss: 8.0116 - mae: 43.6894 - val_loss: 8.6635 - val_mae: 68.5439 - 91ms/epoch - 18ms/step\n",
      "Epoch 198/300\n",
      "5/5 - 0s - loss: 7.9780 - mae: 43.7010 - val_loss: 8.6540 - val_mae: 69.9739 - 85ms/epoch - 17ms/step\n",
      "Epoch 199/300\n",
      "5/5 - 0s - loss: 7.9742 - mae: 43.7512 - val_loss: 8.6450 - val_mae: 68.5861 - 88ms/epoch - 18ms/step\n",
      "Epoch 200/300\n",
      "5/5 - 0s - loss: 7.9772 - mae: 43.4295 - val_loss: 8.6349 - val_mae: 68.5463 - 86ms/epoch - 17ms/step\n",
      "Epoch 201/300\n",
      "5/5 - 0s - loss: 7.9515 - mae: 43.4454 - val_loss: 8.6252 - val_mae: 68.6721 - 82ms/epoch - 16ms/step\n",
      "Epoch 202/300\n",
      "5/5 - 0s - loss: 7.9755 - mae: 43.2322 - val_loss: 8.6158 - val_mae: 68.5375 - 86ms/epoch - 17ms/step\n",
      "Epoch 203/300\n",
      "5/5 - 0s - loss: 7.9559 - mae: 43.3294 - val_loss: 8.6062 - val_mae: 67.0098 - 84ms/epoch - 17ms/step\n",
      "Epoch 204/300\n",
      "5/5 - 0s - loss: 7.9535 - mae: 43.0822 - val_loss: 8.5966 - val_mae: 67.4598 - 85ms/epoch - 17ms/step\n",
      "Epoch 205/300\n",
      "5/5 - 0s - loss: 7.9400 - mae: 43.1242 - val_loss: 8.5859 - val_mae: 66.6197 - 81ms/epoch - 16ms/step\n",
      "Epoch 206/300\n",
      "5/5 - 0s - loss: 7.9663 - mae: 43.1655 - val_loss: 8.5772 - val_mae: 68.5498 - 86ms/epoch - 17ms/step\n",
      "Epoch 207/300\n",
      "5/5 - 0s - loss: 7.9107 - mae: 43.0468 - val_loss: 8.5679 - val_mae: 68.1613 - 89ms/epoch - 18ms/step\n",
      "Epoch 208/300\n",
      "5/5 - 0s - loss: 7.9045 - mae: 42.3541 - val_loss: 8.5581 - val_mae: 66.4913 - 93ms/epoch - 19ms/step\n",
      "Epoch 209/300\n",
      "5/5 - 0s - loss: 7.9293 - mae: 43.0449 - val_loss: 8.5490 - val_mae: 66.2790 - 86ms/epoch - 17ms/step\n",
      "Epoch 210/300\n",
      "5/5 - 0s - loss: 7.8855 - mae: 42.6765 - val_loss: 8.5396 - val_mae: 66.6347 - 84ms/epoch - 17ms/step\n",
      "Epoch 211/300\n",
      "5/5 - 0s - loss: 7.8337 - mae: 41.9711 - val_loss: 8.5306 - val_mae: 66.8860 - 83ms/epoch - 17ms/step\n",
      "Epoch 212/300\n",
      "5/5 - 0s - loss: 7.8707 - mae: 42.4072 - val_loss: 8.5212 - val_mae: 65.0587 - 83ms/epoch - 17ms/step\n",
      "Epoch 213/300\n",
      "5/5 - 0s - loss: 7.8551 - mae: 41.9433 - val_loss: 8.5124 - val_mae: 66.4274 - 86ms/epoch - 17ms/step\n",
      "Epoch 214/300\n",
      "5/5 - 0s - loss: 7.8114 - mae: 41.8485 - val_loss: 8.5025 - val_mae: 65.2152 - 85ms/epoch - 17ms/step\n",
      "Epoch 215/300\n",
      "5/5 - 0s - loss: 7.8347 - mae: 42.4739 - val_loss: 8.4930 - val_mae: 67.1333 - 90ms/epoch - 18ms/step\n",
      "Epoch 216/300\n",
      "5/5 - 0s - loss: 7.8419 - mae: 42.0294 - val_loss: 8.4833 - val_mae: 64.6815 - 86ms/epoch - 17ms/step\n",
      "Epoch 217/300\n",
      "5/5 - 0s - loss: 7.8184 - mae: 41.9266 - val_loss: 8.4741 - val_mae: 65.1191 - 84ms/epoch - 17ms/step\n",
      "Epoch 218/300\n",
      "5/5 - 0s - loss: 7.8192 - mae: 41.6904 - val_loss: 8.4644 - val_mae: 65.3869 - 82ms/epoch - 16ms/step\n",
      "Epoch 219/300\n",
      "5/5 - 0s - loss: 7.7946 - mae: 41.6770 - val_loss: 8.4542 - val_mae: 65.3441 - 110ms/epoch - 22ms/step\n",
      "Epoch 220/300\n",
      "5/5 - 0s - loss: 7.7785 - mae: 41.6858 - val_loss: 8.4439 - val_mae: 64.9361 - 84ms/epoch - 17ms/step\n",
      "Epoch 221/300\n",
      "5/5 - 0s - loss: 7.7845 - mae: 41.4375 - val_loss: 8.4345 - val_mae: 65.1621 - 85ms/epoch - 17ms/step\n",
      "Epoch 222/300\n",
      "5/5 - 0s - loss: 7.7586 - mae: 41.5113 - val_loss: 8.4250 - val_mae: 65.9771 - 82ms/epoch - 16ms/step\n",
      "Epoch 223/300\n",
      "5/5 - 0s - loss: 7.7811 - mae: 41.2820 - val_loss: 8.4162 - val_mae: 64.4386 - 85ms/epoch - 17ms/step\n",
      "Epoch 224/300\n",
      "5/5 - 0s - loss: 7.7360 - mae: 41.2573 - val_loss: 8.4063 - val_mae: 65.3671 - 84ms/epoch - 17ms/step\n",
      "Epoch 225/300\n",
      "5/5 - 0s - loss: 7.7502 - mae: 41.0696 - val_loss: 8.3971 - val_mae: 65.4052 - 84ms/epoch - 17ms/step\n",
      "Epoch 226/300\n",
      "5/5 - 0s - loss: 7.7302 - mae: 40.8360 - val_loss: 8.3881 - val_mae: 64.2030 - 86ms/epoch - 17ms/step\n",
      "Epoch 227/300\n",
      "5/5 - 0s - loss: 7.7253 - mae: 40.8289 - val_loss: 8.3786 - val_mae: 64.7790 - 84ms/epoch - 17ms/step\n",
      "Epoch 228/300\n",
      "5/5 - 0s - loss: 7.7270 - mae: 40.8411 - val_loss: 8.3695 - val_mae: 63.5019 - 82ms/epoch - 16ms/step\n",
      "Epoch 229/300\n",
      "5/5 - 0s - loss: 7.7084 - mae: 40.4341 - val_loss: 8.3602 - val_mae: 64.7450 - 86ms/epoch - 17ms/step\n",
      "Epoch 230/300\n",
      "5/5 - 0s - loss: 7.7050 - mae: 40.6640 - val_loss: 8.3517 - val_mae: 64.5793 - 90ms/epoch - 18ms/step\n",
      "Epoch 231/300\n",
      "5/5 - 0s - loss: 7.7458 - mae: 40.7150 - val_loss: 8.3421 - val_mae: 62.9327 - 102ms/epoch - 20ms/step\n",
      "Epoch 232/300\n",
      "5/5 - 0s - loss: 7.6899 - mae: 40.2839 - val_loss: 8.3330 - val_mae: 64.3811 - 83ms/epoch - 17ms/step\n",
      "Epoch 233/300\n",
      "5/5 - 0s - loss: 7.6608 - mae: 40.3058 - val_loss: 8.3235 - val_mae: 62.5793 - 85ms/epoch - 17ms/step\n",
      "Epoch 234/300\n",
      "5/5 - 0s - loss: 7.6460 - mae: 39.9188 - val_loss: 8.3150 - val_mae: 64.0255 - 84ms/epoch - 17ms/step\n",
      "Epoch 235/300\n",
      "5/5 - 0s - loss: 7.6502 - mae: 39.7200 - val_loss: 8.3065 - val_mae: 64.2688 - 99ms/epoch - 20ms/step\n",
      "Epoch 236/300\n",
      "5/5 - 0s - loss: 7.6505 - mae: 39.3905 - val_loss: 8.2976 - val_mae: 62.8551 - 90ms/epoch - 18ms/step\n",
      "Epoch 237/300\n",
      "5/5 - 0s - loss: 7.6300 - mae: 40.1796 - val_loss: 8.2879 - val_mae: 63.5350 - 87ms/epoch - 17ms/step\n",
      "Epoch 238/300\n",
      "5/5 - 0s - loss: 7.6079 - mae: 39.6857 - val_loss: 8.2790 - val_mae: 62.3751 - 82ms/epoch - 16ms/step\n",
      "Epoch 239/300\n",
      "5/5 - 0s - loss: 7.6216 - mae: 39.7626 - val_loss: 8.2701 - val_mae: 63.3675 - 86ms/epoch - 17ms/step\n",
      "Epoch 240/300\n",
      "5/5 - 0s - loss: 7.6162 - mae: 39.7174 - val_loss: 8.2622 - val_mae: 61.7261 - 85ms/epoch - 17ms/step\n",
      "Epoch 241/300\n",
      "5/5 - 0s - loss: 7.5961 - mae: 39.2702 - val_loss: 8.2536 - val_mae: 61.8300 - 91ms/epoch - 18ms/step\n",
      "Epoch 242/300\n",
      "5/5 - 0s - loss: 7.5893 - mae: 38.9298 - val_loss: 8.2439 - val_mae: 62.8372 - 108ms/epoch - 22ms/step\n",
      "Epoch 243/300\n",
      "5/5 - 0s - loss: 7.6050 - mae: 39.4318 - val_loss: 8.2362 - val_mae: 61.4085 - 96ms/epoch - 19ms/step\n",
      "Epoch 244/300\n",
      "5/5 - 0s - loss: 7.6020 - mae: 39.7121 - val_loss: 8.2300 - val_mae: 62.3558 - 83ms/epoch - 17ms/step\n",
      "Epoch 245/300\n",
      "5/5 - 0s - loss: 7.5667 - mae: 39.5030 - val_loss: 8.2219 - val_mae: 62.0546 - 84ms/epoch - 17ms/step\n",
      "Epoch 246/300\n",
      "5/5 - 0s - loss: 7.5285 - mae: 38.7548 - val_loss: 8.2129 - val_mae: 61.7171 - 83ms/epoch - 17ms/step\n",
      "Epoch 247/300\n",
      "5/5 - 0s - loss: 7.5310 - mae: 38.7773 - val_loss: 8.2040 - val_mae: 60.1952 - 84ms/epoch - 17ms/step\n",
      "Epoch 248/300\n",
      "5/5 - 0s - loss: 7.5310 - mae: 39.1676 - val_loss: 8.1947 - val_mae: 61.6247 - 87ms/epoch - 17ms/step\n",
      "Epoch 249/300\n",
      "5/5 - 0s - loss: 7.5276 - mae: 38.8553 - val_loss: 8.1859 - val_mae: 61.5076 - 84ms/epoch - 17ms/step\n",
      "Epoch 250/300\n",
      "5/5 - 0s - loss: 7.5006 - mae: 38.9204 - val_loss: 8.1775 - val_mae: 60.7687 - 85ms/epoch - 17ms/step\n",
      "Epoch 251/300\n",
      "5/5 - 0s - loss: 7.5009 - mae: 38.7157 - val_loss: 8.1686 - val_mae: 61.1535 - 83ms/epoch - 17ms/step\n",
      "Epoch 252/300\n",
      "5/5 - 0s - loss: 7.5242 - mae: 38.3127 - val_loss: 8.1599 - val_mae: 60.8922 - 92ms/epoch - 18ms/step\n",
      "Epoch 253/300\n",
      "5/5 - 0s - loss: 7.4738 - mae: 37.9156 - val_loss: 8.1510 - val_mae: 61.5626 - 97ms/epoch - 19ms/step\n",
      "Epoch 254/300\n",
      "5/5 - 0s - loss: 7.4803 - mae: 38.4955 - val_loss: 8.1419 - val_mae: 61.4775 - 85ms/epoch - 17ms/step\n",
      "Epoch 255/300\n",
      "5/5 - 0s - loss: 7.4710 - mae: 38.1510 - val_loss: 8.1324 - val_mae: 60.3411 - 81ms/epoch - 16ms/step\n",
      "Epoch 256/300\n",
      "5/5 - 0s - loss: 7.4691 - mae: 38.4031 - val_loss: 8.1236 - val_mae: 60.7654 - 85ms/epoch - 17ms/step\n",
      "Epoch 257/300\n",
      "5/5 - 0s - loss: 7.4524 - mae: 38.3345 - val_loss: 8.1145 - val_mae: 60.2647 - 88ms/epoch - 18ms/step\n",
      "Epoch 258/300\n",
      "5/5 - 0s - loss: 7.4455 - mae: 37.6550 - val_loss: 8.1060 - val_mae: 61.1221 - 82ms/epoch - 16ms/step\n",
      "Epoch 259/300\n",
      "5/5 - 0s - loss: 7.4300 - mae: 37.6900 - val_loss: 8.0971 - val_mae: 60.1319 - 84ms/epoch - 17ms/step\n",
      "Epoch 260/300\n",
      "5/5 - 0s - loss: 7.4381 - mae: 38.1824 - val_loss: 8.0875 - val_mae: 59.9633 - 88ms/epoch - 18ms/step\n",
      "Epoch 261/300\n",
      "5/5 - 0s - loss: 7.4718 - mae: 37.4875 - val_loss: 8.0792 - val_mae: 60.3368 - 86ms/epoch - 17ms/step\n",
      "Epoch 262/300\n",
      "5/5 - 0s - loss: 7.4023 - mae: 37.7296 - val_loss: 8.0710 - val_mae: 58.8418 - 85ms/epoch - 17ms/step\n",
      "Epoch 263/300\n",
      "5/5 - 0s - loss: 7.4357 - mae: 37.9753 - val_loss: 8.0628 - val_mae: 59.8081 - 93ms/epoch - 19ms/step\n",
      "Epoch 264/300\n",
      "5/5 - 0s - loss: 7.3974 - mae: 37.7256 - val_loss: 8.0536 - val_mae: 59.4158 - 84ms/epoch - 17ms/step\n",
      "Epoch 265/300\n",
      "5/5 - 0s - loss: 7.3934 - mae: 37.6622 - val_loss: 8.0448 - val_mae: 59.1848 - 101ms/epoch - 20ms/step\n",
      "Epoch 266/300\n",
      "5/5 - 0s - loss: 7.3547 - mae: 37.3510 - val_loss: 8.0357 - val_mae: 59.3266 - 84ms/epoch - 17ms/step\n",
      "Epoch 267/300\n",
      "5/5 - 0s - loss: 7.3508 - mae: 37.6629 - val_loss: 8.0265 - val_mae: 58.5838 - 80ms/epoch - 16ms/step\n",
      "Epoch 268/300\n",
      "5/5 - 0s - loss: 7.3569 - mae: 37.3351 - val_loss: 8.0169 - val_mae: 58.0499 - 86ms/epoch - 17ms/step\n",
      "Epoch 269/300\n",
      "5/5 - 0s - loss: 7.3496 - mae: 36.7706 - val_loss: 8.0073 - val_mae: 58.0758 - 84ms/epoch - 17ms/step\n",
      "Epoch 270/300\n",
      "5/5 - 0s - loss: 7.3239 - mae: 37.2130 - val_loss: 7.9983 - val_mae: 58.8003 - 84ms/epoch - 17ms/step\n",
      "Epoch 271/300\n",
      "5/5 - 0s - loss: 7.3102 - mae: 36.6653 - val_loss: 7.9902 - val_mae: 59.1151 - 91ms/epoch - 18ms/step\n",
      "Epoch 272/300\n",
      "5/5 - 0s - loss: 7.3032 - mae: 36.8641 - val_loss: 7.9820 - val_mae: 58.6256 - 89ms/epoch - 18ms/step\n",
      "Epoch 273/300\n",
      "5/5 - 0s - loss: 7.3111 - mae: 36.6061 - val_loss: 7.9742 - val_mae: 58.3496 - 87ms/epoch - 17ms/step\n",
      "Epoch 274/300\n",
      "5/5 - 0s - loss: 7.3149 - mae: 36.6337 - val_loss: 7.9665 - val_mae: 59.2737 - 93ms/epoch - 19ms/step\n",
      "Epoch 275/300\n",
      "5/5 - 0s - loss: 7.3175 - mae: 37.1270 - val_loss: 7.9587 - val_mae: 57.6773 - 95ms/epoch - 19ms/step\n",
      "Epoch 276/300\n",
      "5/5 - 0s - loss: 7.2703 - mae: 36.8107 - val_loss: 7.9505 - val_mae: 58.8343 - 100ms/epoch - 20ms/step\n",
      "Epoch 277/300\n",
      "5/5 - 0s - loss: 7.2756 - mae: 36.4967 - val_loss: 7.9430 - val_mae: 59.2100 - 84ms/epoch - 17ms/step\n",
      "Epoch 278/300\n",
      "5/5 - 0s - loss: 7.2562 - mae: 36.2801 - val_loss: 7.9349 - val_mae: 58.6236 - 85ms/epoch - 17ms/step\n",
      "Epoch 279/300\n",
      "5/5 - 0s - loss: 7.2493 - mae: 35.8456 - val_loss: 7.9267 - val_mae: 58.5513 - 84ms/epoch - 17ms/step\n",
      "Epoch 280/300\n",
      "5/5 - 0s - loss: 7.2611 - mae: 36.3950 - val_loss: 7.9186 - val_mae: 58.7825 - 89ms/epoch - 18ms/step\n",
      "Epoch 281/300\n",
      "5/5 - 0s - loss: 7.2412 - mae: 36.3327 - val_loss: 7.9107 - val_mae: 58.2782 - 120ms/epoch - 24ms/step\n",
      "Epoch 282/300\n",
      "5/5 - 0s - loss: 7.2496 - mae: 36.4564 - val_loss: 7.9029 - val_mae: 56.7783 - 83ms/epoch - 17ms/step\n",
      "Epoch 283/300\n",
      "5/5 - 0s - loss: 7.2195 - mae: 35.7770 - val_loss: 7.8949 - val_mae: 57.2442 - 84ms/epoch - 17ms/step\n",
      "Epoch 284/300\n",
      "5/5 - 0s - loss: 7.1983 - mae: 35.2031 - val_loss: 7.8867 - val_mae: 57.0383 - 83ms/epoch - 17ms/step\n",
      "Epoch 285/300\n",
      "5/5 - 0s - loss: 7.2169 - mae: 36.1920 - val_loss: 7.8790 - val_mae: 56.3368 - 91ms/epoch - 18ms/step\n",
      "Epoch 286/300\n",
      "5/5 - 0s - loss: 7.1816 - mae: 35.8886 - val_loss: 7.8716 - val_mae: 58.0253 - 87ms/epoch - 17ms/step\n",
      "Epoch 287/300\n",
      "5/5 - 0s - loss: 7.1981 - mae: 35.8532 - val_loss: 7.8638 - val_mae: 57.9994 - 99ms/epoch - 20ms/step\n",
      "Epoch 288/300\n",
      "5/5 - 0s - loss: 7.1946 - mae: 36.1976 - val_loss: 7.8562 - val_mae: 57.8001 - 87ms/epoch - 17ms/step\n",
      "Epoch 289/300\n",
      "5/5 - 0s - loss: 7.1574 - mae: 35.1395 - val_loss: 7.8485 - val_mae: 58.5672 - 84ms/epoch - 17ms/step\n",
      "Epoch 290/300\n",
      "5/5 - 0s - loss: 7.2235 - mae: 35.2976 - val_loss: 7.8410 - val_mae: 56.9763 - 88ms/epoch - 18ms/step\n",
      "Epoch 291/300\n",
      "5/5 - 0s - loss: 7.1153 - mae: 34.8986 - val_loss: 7.8364 - val_mae: 56.4292 - 87ms/epoch - 17ms/step\n",
      "Epoch 292/300\n",
      "5/5 - 0s - loss: 7.1325 - mae: 35.0779 - val_loss: 7.8291 - val_mae: 57.1396 - 90ms/epoch - 18ms/step\n",
      "Epoch 293/300\n",
      "5/5 - 0s - loss: 7.1153 - mae: 34.3641 - val_loss: 7.8216 - val_mae: 56.3031 - 86ms/epoch - 17ms/step\n",
      "Epoch 294/300\n",
      "5/5 - 0s - loss: 7.1127 - mae: 35.3323 - val_loss: 7.8129 - val_mae: 56.4766 - 90ms/epoch - 18ms/step\n",
      "Epoch 295/300\n",
      "5/5 - 0s - loss: 7.1328 - mae: 35.5642 - val_loss: 7.8044 - val_mae: 57.6986 - 86ms/epoch - 17ms/step\n",
      "Epoch 296/300\n",
      "5/5 - 0s - loss: 7.0926 - mae: 34.9123 - val_loss: 7.7961 - val_mae: 56.2936 - 94ms/epoch - 19ms/step\n",
      "Epoch 297/300\n",
      "5/5 - 0s - loss: 7.0911 - mae: 34.9686 - val_loss: 7.7880 - val_mae: 55.6827 - 88ms/epoch - 18ms/step\n",
      "Epoch 298/300\n",
      "5/5 - 0s - loss: 7.0824 - mae: 34.8257 - val_loss: 7.7795 - val_mae: 55.3841 - 114ms/epoch - 23ms/step\n",
      "Epoch 299/300\n",
      "5/5 - 0s - loss: 7.0662 - mae: 34.4173 - val_loss: 7.7708 - val_mae: 56.0458 - 87ms/epoch - 17ms/step\n",
      "Epoch 300/300\n",
      "5/5 - 0s - loss: 7.0522 - mae: 34.6079 - val_loss: 7.7619 - val_mae: 56.0307 - 96ms/epoch - 19ms/step\n",
      "Epoch 1/300\n",
      "5/5 - 2s - loss: 1174.5543 - mae: 98.6995 - val_loss: 53.1776 - val_mae: 104.6173 - 2s/epoch - 462ms/step\n",
      "Epoch 2/300\n",
      "5/5 - 0s - loss: 162.0971 - mae: 97.3925 - val_loss: 23.9678 - val_mae: 102.0975 - 88ms/epoch - 18ms/step\n",
      "Epoch 3/300\n",
      "5/5 - 0s - loss: 52.3810 - mae: 95.6045 - val_loss: 18.0518 - val_mae: 100.7066 - 90ms/epoch - 18ms/step\n",
      "Epoch 4/300\n",
      "5/5 - 0s - loss: 26.9994 - mae: 93.8484 - val_loss: 15.5159 - val_mae: 99.4019 - 85ms/epoch - 17ms/step\n",
      "Epoch 5/300\n",
      "5/5 - 0s - loss: 20.7326 - mae: 92.6035 - val_loss: 14.1339 - val_mae: 98.1111 - 90ms/epoch - 18ms/step\n",
      "Epoch 6/300\n",
      "5/5 - 0s - loss: 16.9535 - mae: 91.6589 - val_loss: 13.3416 - val_mae: 96.5333 - 104ms/epoch - 21ms/step\n",
      "Epoch 7/300\n",
      "5/5 - 0s - loss: 15.2600 - mae: 91.1758 - val_loss: 12.8361 - val_mae: 96.4989 - 87ms/epoch - 17ms/step\n",
      "Epoch 8/300\n",
      "5/5 - 0s - loss: 14.2915 - mae: 91.0742 - val_loss: 12.4805 - val_mae: 95.8751 - 94ms/epoch - 19ms/step\n",
      "Epoch 9/300\n",
      "5/5 - 0s - loss: 13.7569 - mae: 90.4397 - val_loss: 12.2264 - val_mae: 96.8699 - 90ms/epoch - 18ms/step\n",
      "Epoch 10/300\n",
      "5/5 - 0s - loss: 13.3028 - mae: 89.9851 - val_loss: 12.0287 - val_mae: 95.6941 - 87ms/epoch - 17ms/step\n",
      "Epoch 11/300\n",
      "5/5 - 0s - loss: 13.4062 - mae: 90.1809 - val_loss: 11.8739 - val_mae: 94.2613 - 93ms/epoch - 19ms/step\n",
      "Epoch 12/300\n",
      "5/5 - 0s - loss: 12.6806 - mae: 89.1032 - val_loss: 11.7475 - val_mae: 95.9655 - 86ms/epoch - 17ms/step\n",
      "Epoch 13/300\n",
      "5/5 - 0s - loss: 12.6391 - mae: 89.2359 - val_loss: 11.6375 - val_mae: 94.6795 - 90ms/epoch - 18ms/step\n",
      "Epoch 14/300\n",
      "5/5 - 0s - loss: 12.3872 - mae: 88.5532 - val_loss: 11.5393 - val_mae: 94.5638 - 89ms/epoch - 18ms/step\n",
      "Epoch 15/300\n",
      "5/5 - 0s - loss: 12.3622 - mae: 88.8155 - val_loss: 11.4523 - val_mae: 94.0928 - 86ms/epoch - 17ms/step\n",
      "Epoch 16/300\n",
      "5/5 - 0s - loss: 12.1180 - mae: 88.3734 - val_loss: 11.3757 - val_mae: 93.9871 - 86ms/epoch - 17ms/step\n",
      "Epoch 17/300\n",
      "5/5 - 0s - loss: 12.0959 - mae: 88.3257 - val_loss: 11.3040 - val_mae: 92.5231 - 105ms/epoch - 21ms/step\n",
      "Epoch 18/300\n",
      "5/5 - 0s - loss: 11.8183 - mae: 88.1860 - val_loss: 11.2377 - val_mae: 92.7676 - 87ms/epoch - 17ms/step\n",
      "Epoch 19/300\n",
      "5/5 - 0s - loss: 11.7388 - mae: 87.6434 - val_loss: 11.1752 - val_mae: 92.4196 - 84ms/epoch - 17ms/step\n",
      "Epoch 20/300\n",
      "5/5 - 0s - loss: 11.7247 - mae: 87.3806 - val_loss: 11.1197 - val_mae: 92.6493 - 87ms/epoch - 17ms/step\n",
      "Epoch 21/300\n",
      "5/5 - 0s - loss: 11.5384 - mae: 87.2099 - val_loss: 11.0671 - val_mae: 92.3208 - 87ms/epoch - 17ms/step\n",
      "Epoch 22/300\n",
      "5/5 - 0s - loss: 11.6788 - mae: 86.6421 - val_loss: 11.0127 - val_mae: 91.6117 - 90ms/epoch - 18ms/step\n",
      "Epoch 23/300\n",
      "5/5 - 0s - loss: 11.3802 - mae: 86.7458 - val_loss: 10.9575 - val_mae: 91.2137 - 85ms/epoch - 17ms/step\n",
      "Epoch 24/300\n",
      "5/5 - 0s - loss: 11.3216 - mae: 86.3295 - val_loss: 10.9068 - val_mae: 90.9672 - 100ms/epoch - 20ms/step\n",
      "Epoch 25/300\n",
      "5/5 - 0s - loss: 11.3367 - mae: 86.0499 - val_loss: 10.8598 - val_mae: 89.4665 - 86ms/epoch - 17ms/step\n",
      "Epoch 26/300\n",
      "5/5 - 0s - loss: 11.2703 - mae: 85.5912 - val_loss: 10.8125 - val_mae: 90.7811 - 89ms/epoch - 18ms/step\n",
      "Epoch 27/300\n",
      "5/5 - 0s - loss: 11.0206 - mae: 85.0991 - val_loss: 10.7701 - val_mae: 88.5470 - 89ms/epoch - 18ms/step\n",
      "Epoch 28/300\n",
      "5/5 - 0s - loss: 11.0032 - mae: 84.6939 - val_loss: 10.7335 - val_mae: 90.0461 - 103ms/epoch - 21ms/step\n",
      "Epoch 29/300\n",
      "5/5 - 0s - loss: 10.7835 - mae: 84.7670 - val_loss: 10.6953 - val_mae: 86.9087 - 90ms/epoch - 18ms/step\n",
      "Epoch 30/300\n",
      "5/5 - 0s - loss: 10.8289 - mae: 84.1762 - val_loss: 10.6596 - val_mae: 88.9097 - 88ms/epoch - 18ms/step\n",
      "Epoch 31/300\n",
      "5/5 - 0s - loss: 10.8909 - mae: 84.0240 - val_loss: 10.6202 - val_mae: 88.9108 - 89ms/epoch - 18ms/step\n",
      "Epoch 32/300\n",
      "5/5 - 0s - loss: 10.8013 - mae: 83.1614 - val_loss: 10.5844 - val_mae: 88.4295 - 97ms/epoch - 19ms/step\n",
      "Epoch 33/300\n",
      "5/5 - 0s - loss: 10.6605 - mae: 83.3601 - val_loss: 10.5469 - val_mae: 88.7989 - 91ms/epoch - 18ms/step\n",
      "Epoch 34/300\n",
      "5/5 - 0s - loss: 10.6358 - mae: 83.0083 - val_loss: 10.5075 - val_mae: 87.8293 - 89ms/epoch - 18ms/step\n",
      "Epoch 35/300\n",
      "5/5 - 0s - loss: 10.5358 - mae: 82.5074 - val_loss: 10.4733 - val_mae: 86.2595 - 91ms/epoch - 18ms/step\n",
      "Epoch 36/300\n",
      "5/5 - 0s - loss: 10.4133 - mae: 81.9116 - val_loss: 10.4384 - val_mae: 87.5049 - 85ms/epoch - 17ms/step\n",
      "Epoch 37/300\n",
      "5/5 - 0s - loss: 10.5388 - mae: 81.6988 - val_loss: 10.4042 - val_mae: 86.3658 - 84ms/epoch - 17ms/step\n",
      "Epoch 38/300\n",
      "5/5 - 0s - loss: 10.3885 - mae: 81.8647 - val_loss: 10.3729 - val_mae: 86.1133 - 88ms/epoch - 18ms/step\n",
      "Epoch 39/300\n",
      "5/5 - 0s - loss: 10.3840 - mae: 81.2043 - val_loss: 10.3418 - val_mae: 84.8995 - 99ms/epoch - 20ms/step\n",
      "Epoch 40/300\n",
      "5/5 - 0s - loss: 10.5389 - mae: 81.0866 - val_loss: 10.3099 - val_mae: 85.0936 - 89ms/epoch - 18ms/step\n",
      "Epoch 41/300\n",
      "5/5 - 0s - loss: 10.3568 - mae: 80.7423 - val_loss: 10.2760 - val_mae: 84.8963 - 89ms/epoch - 18ms/step\n",
      "Epoch 42/300\n",
      "5/5 - 0s - loss: 10.1726 - mae: 80.4266 - val_loss: 10.2449 - val_mae: 84.9691 - 88ms/epoch - 18ms/step\n",
      "Epoch 43/300\n",
      "5/5 - 0s - loss: 10.1416 - mae: 79.7675 - val_loss: 10.2155 - val_mae: 84.0922 - 93ms/epoch - 19ms/step\n",
      "Epoch 44/300\n",
      "5/5 - 0s - loss: 10.0757 - mae: 79.4815 - val_loss: 10.1883 - val_mae: 83.7904 - 86ms/epoch - 17ms/step\n",
      "Epoch 45/300\n",
      "5/5 - 0s - loss: 10.0552 - mae: 79.0490 - val_loss: 10.1606 - val_mae: 83.2500 - 87ms/epoch - 17ms/step\n",
      "Epoch 46/300\n",
      "5/5 - 0s - loss: 10.3148 - mae: 79.0283 - val_loss: 10.1306 - val_mae: 83.3995 - 87ms/epoch - 17ms/step\n",
      "Epoch 47/300\n",
      "5/5 - 0s - loss: 10.0088 - mae: 78.4853 - val_loss: 10.1047 - val_mae: 83.3173 - 87ms/epoch - 17ms/step\n",
      "Epoch 48/300\n",
      "5/5 - 0s - loss: 10.1017 - mae: 78.6704 - val_loss: 10.0767 - val_mae: 81.9571 - 86ms/epoch - 17ms/step\n",
      "Epoch 49/300\n",
      "5/5 - 0s - loss: 9.8728 - mae: 78.2396 - val_loss: 10.0512 - val_mae: 81.5555 - 86ms/epoch - 17ms/step\n",
      "Epoch 50/300\n",
      "5/5 - 0s - loss: 9.8800 - mae: 78.1982 - val_loss: 10.0268 - val_mae: 82.4153 - 99ms/epoch - 20ms/step\n",
      "Epoch 51/300\n",
      "5/5 - 0s - loss: 10.0063 - mae: 78.0508 - val_loss: 10.0040 - val_mae: 80.9788 - 105ms/epoch - 21ms/step\n",
      "Epoch 52/300\n",
      "5/5 - 0s - loss: 9.8443 - mae: 77.7640 - val_loss: 9.9780 - val_mae: 81.0574 - 85ms/epoch - 17ms/step\n",
      "Epoch 53/300\n",
      "5/5 - 0s - loss: 9.8860 - mae: 77.5784 - val_loss: 9.9564 - val_mae: 80.2078 - 85ms/epoch - 17ms/step\n",
      "Epoch 54/300\n",
      "5/5 - 0s - loss: 9.8045 - mae: 76.6388 - val_loss: 9.9376 - val_mae: 81.0197 - 94ms/epoch - 19ms/step\n",
      "Epoch 55/300\n",
      "5/5 - 0s - loss: 9.7126 - mae: 76.7075 - val_loss: 9.9149 - val_mae: 81.0046 - 87ms/epoch - 17ms/step\n",
      "Epoch 56/300\n",
      "5/5 - 0s - loss: 9.8192 - mae: 76.1739 - val_loss: 9.8920 - val_mae: 81.0934 - 91ms/epoch - 18ms/step\n",
      "Epoch 57/300\n",
      "5/5 - 0s - loss: 9.6542 - mae: 75.6255 - val_loss: 9.8702 - val_mae: 81.5749 - 89ms/epoch - 18ms/step\n",
      "Epoch 58/300\n",
      "5/5 - 0s - loss: 9.6433 - mae: 76.2332 - val_loss: 9.8502 - val_mae: 80.8717 - 86ms/epoch - 17ms/step\n",
      "Epoch 59/300\n",
      "5/5 - 0s - loss: 9.6192 - mae: 75.3846 - val_loss: 9.8327 - val_mae: 79.7352 - 89ms/epoch - 18ms/step\n",
      "Epoch 60/300\n",
      "5/5 - 0s - loss: 9.6100 - mae: 75.1481 - val_loss: 9.8141 - val_mae: 78.4842 - 84ms/epoch - 17ms/step\n",
      "Epoch 61/300\n",
      "5/5 - 0s - loss: 9.5670 - mae: 75.4671 - val_loss: 9.7958 - val_mae: 80.1769 - 99ms/epoch - 20ms/step\n",
      "Epoch 62/300\n",
      "5/5 - 0s - loss: 9.5041 - mae: 74.0912 - val_loss: 9.7787 - val_mae: 78.1693 - 82ms/epoch - 16ms/step\n",
      "Epoch 63/300\n",
      "5/5 - 0s - loss: 9.5074 - mae: 74.2411 - val_loss: 9.7619 - val_mae: 79.1029 - 83ms/epoch - 17ms/step\n",
      "Epoch 64/300\n",
      "5/5 - 0s - loss: 9.5177 - mae: 73.7895 - val_loss: 9.7428 - val_mae: 78.8059 - 83ms/epoch - 17ms/step\n",
      "Epoch 65/300\n",
      "5/5 - 0s - loss: 9.5242 - mae: 73.9283 - val_loss: 9.7273 - val_mae: 78.4576 - 91ms/epoch - 18ms/step\n",
      "Epoch 66/300\n",
      "5/5 - 0s - loss: 9.4832 - mae: 73.4713 - val_loss: 9.7103 - val_mae: 76.9932 - 90ms/epoch - 18ms/step\n",
      "Epoch 67/300\n",
      "5/5 - 0s - loss: 9.4563 - mae: 73.1789 - val_loss: 9.6934 - val_mae: 77.4831 - 87ms/epoch - 17ms/step\n",
      "Epoch 68/300\n",
      "5/5 - 0s - loss: 9.4776 - mae: 72.7042 - val_loss: 9.6770 - val_mae: 77.4682 - 85ms/epoch - 17ms/step\n",
      "Epoch 69/300\n",
      "5/5 - 0s - loss: 9.5275 - mae: 72.9493 - val_loss: 9.6604 - val_mae: 77.1370 - 84ms/epoch - 17ms/step\n",
      "Epoch 70/300\n",
      "5/5 - 0s - loss: 9.3735 - mae: 72.4806 - val_loss: 9.6430 - val_mae: 77.2660 - 86ms/epoch - 17ms/step\n",
      "Epoch 71/300\n",
      "5/5 - 0s - loss: 9.3993 - mae: 71.9566 - val_loss: 9.6249 - val_mae: 76.4874 - 84ms/epoch - 17ms/step\n",
      "Epoch 72/300\n",
      "5/5 - 0s - loss: 9.5211 - mae: 71.4150 - val_loss: 9.6086 - val_mae: 76.2836 - 86ms/epoch - 17ms/step\n",
      "Epoch 73/300\n",
      "5/5 - 0s - loss: 9.3804 - mae: 71.1220 - val_loss: 9.5921 - val_mae: 76.5491 - 106ms/epoch - 21ms/step\n",
      "Epoch 74/300\n",
      "5/5 - 0s - loss: 9.3098 - mae: 71.3388 - val_loss: 9.5761 - val_mae: 75.7858 - 88ms/epoch - 18ms/step\n",
      "Epoch 75/300\n",
      "5/5 - 0s - loss: 9.3219 - mae: 70.8675 - val_loss: 9.5612 - val_mae: 76.2550 - 84ms/epoch - 17ms/step\n",
      "Epoch 76/300\n",
      "5/5 - 0s - loss: 9.2715 - mae: 70.7669 - val_loss: 9.5450 - val_mae: 74.0319 - 95ms/epoch - 19ms/step\n",
      "Epoch 77/300\n",
      "5/5 - 0s - loss: 9.2294 - mae: 70.0453 - val_loss: 9.5296 - val_mae: 74.9654 - 89ms/epoch - 18ms/step\n",
      "Epoch 78/300\n",
      "5/5 - 0s - loss: 9.2453 - mae: 69.6575 - val_loss: 9.5174 - val_mae: 74.6998 - 95ms/epoch - 19ms/step\n",
      "Epoch 79/300\n",
      "5/5 - 0s - loss: 9.3319 - mae: 69.5766 - val_loss: 9.4988 - val_mae: 75.9230 - 85ms/epoch - 17ms/step\n",
      "Epoch 80/300\n",
      "5/5 - 0s - loss: 9.2323 - mae: 69.2337 - val_loss: 9.4810 - val_mae: 74.0980 - 89ms/epoch - 18ms/step\n",
      "Epoch 81/300\n",
      "5/5 - 0s - loss: 9.1949 - mae: 69.0757 - val_loss: 9.4665 - val_mae: 73.4757 - 86ms/epoch - 17ms/step\n",
      "Epoch 82/300\n",
      "5/5 - 0s - loss: 9.1780 - mae: 69.1828 - val_loss: 9.4519 - val_mae: 73.7318 - 87ms/epoch - 17ms/step\n",
      "Epoch 83/300\n",
      "5/5 - 0s - loss: 9.1346 - mae: 68.3743 - val_loss: 9.4376 - val_mae: 73.0914 - 88ms/epoch - 18ms/step\n",
      "Epoch 84/300\n",
      "5/5 - 0s - loss: 9.1397 - mae: 67.6468 - val_loss: 9.4242 - val_mae: 74.1084 - 99ms/epoch - 20ms/step\n",
      "Epoch 85/300\n",
      "5/5 - 0s - loss: 9.1669 - mae: 67.9693 - val_loss: 9.4118 - val_mae: 72.8237 - 83ms/epoch - 17ms/step\n",
      "Epoch 86/300\n",
      "5/5 - 0s - loss: 9.1025 - mae: 67.6591 - val_loss: 9.3979 - val_mae: 73.9191 - 95ms/epoch - 19ms/step\n",
      "Epoch 87/300\n",
      "5/5 - 0s - loss: 9.1122 - mae: 67.0072 - val_loss: 9.3860 - val_mae: 73.4884 - 89ms/epoch - 18ms/step\n",
      "Epoch 88/300\n",
      "5/5 - 0s - loss: 9.0963 - mae: 66.5214 - val_loss: 9.3727 - val_mae: 72.4010 - 88ms/epoch - 18ms/step\n",
      "Epoch 89/300\n",
      "5/5 - 0s - loss: 9.0999 - mae: 66.8220 - val_loss: 9.3588 - val_mae: 72.4707 - 88ms/epoch - 18ms/step\n",
      "Epoch 90/300\n",
      "5/5 - 0s - loss: 9.0654 - mae: 66.2710 - val_loss: 9.3472 - val_mae: 75.1489 - 87ms/epoch - 17ms/step\n",
      "Epoch 91/300\n",
      "5/5 - 0s - loss: 9.0126 - mae: 66.5212 - val_loss: 9.3349 - val_mae: 71.4728 - 84ms/epoch - 17ms/step\n",
      "Epoch 92/300\n",
      "5/5 - 0s - loss: 9.0271 - mae: 65.9008 - val_loss: 9.3223 - val_mae: 73.1161 - 91ms/epoch - 18ms/step\n",
      "Epoch 93/300\n",
      "5/5 - 0s - loss: 9.0334 - mae: 65.4147 - val_loss: 9.3102 - val_mae: 72.5770 - 86ms/epoch - 17ms/step\n",
      "Epoch 94/300\n",
      "5/5 - 0s - loss: 9.0732 - mae: 65.5617 - val_loss: 9.2983 - val_mae: 71.3516 - 87ms/epoch - 17ms/step\n",
      "Epoch 95/300\n",
      "5/5 - 0s - loss: 8.9670 - mae: 65.1874 - val_loss: 9.2865 - val_mae: 70.9177 - 98ms/epoch - 20ms/step\n",
      "Epoch 96/300\n",
      "5/5 - 0s - loss: 8.9738 - mae: 64.7149 - val_loss: 9.2749 - val_mae: 70.5860 - 86ms/epoch - 17ms/step\n",
      "Epoch 97/300\n",
      "5/5 - 0s - loss: 8.9417 - mae: 64.7343 - val_loss: 9.2626 - val_mae: 71.4599 - 91ms/epoch - 18ms/step\n",
      "Epoch 98/300\n",
      "5/5 - 0s - loss: 8.9380 - mae: 64.4582 - val_loss: 9.2504 - val_mae: 70.9738 - 89ms/epoch - 18ms/step\n",
      "Epoch 99/300\n",
      "5/5 - 0s - loss: 8.9771 - mae: 63.9318 - val_loss: 9.2374 - val_mae: 71.1502 - 85ms/epoch - 17ms/step\n",
      "Epoch 100/300\n",
      "5/5 - 0s - loss: 8.8857 - mae: 64.1643 - val_loss: 9.2262 - val_mae: 71.0742 - 85ms/epoch - 17ms/step\n",
      "Epoch 101/300\n",
      "5/5 - 0s - loss: 8.8899 - mae: 63.3396 - val_loss: 9.2149 - val_mae: 69.9834 - 87ms/epoch - 17ms/step\n",
      "Epoch 102/300\n",
      "5/5 - 0s - loss: 8.8825 - mae: 63.4623 - val_loss: 9.2046 - val_mae: 70.4480 - 86ms/epoch - 17ms/step\n",
      "Epoch 103/300\n",
      "5/5 - 0s - loss: 8.8808 - mae: 63.0546 - val_loss: 9.1934 - val_mae: 68.7393 - 87ms/epoch - 17ms/step\n",
      "Epoch 104/300\n",
      "5/5 - 0s - loss: 8.8779 - mae: 63.1185 - val_loss: 9.1837 - val_mae: 70.5960 - 89ms/epoch - 18ms/step\n",
      "Epoch 105/300\n",
      "5/5 - 0s - loss: 8.8351 - mae: 62.6724 - val_loss: 9.1727 - val_mae: 70.9574 - 85ms/epoch - 17ms/step\n",
      "Epoch 106/300\n",
      "5/5 - 0s - loss: 8.8509 - mae: 62.3287 - val_loss: 9.1613 - val_mae: 69.6907 - 83ms/epoch - 17ms/step\n",
      "Epoch 107/300\n",
      "5/5 - 0s - loss: 8.8202 - mae: 62.0264 - val_loss: 9.1528 - val_mae: 70.5356 - 100ms/epoch - 20ms/step\n",
      "Epoch 108/300\n",
      "5/5 - 0s - loss: 8.8153 - mae: 61.1573 - val_loss: 9.1423 - val_mae: 70.3489 - 136ms/epoch - 27ms/step\n",
      "Epoch 109/300\n",
      "5/5 - 0s - loss: 8.8196 - mae: 61.6252 - val_loss: 9.1319 - val_mae: 69.2511 - 135ms/epoch - 27ms/step\n",
      "Epoch 110/300\n",
      "5/5 - 0s - loss: 8.7816 - mae: 61.0842 - val_loss: 9.1218 - val_mae: 67.5087 - 143ms/epoch - 29ms/step\n",
      "Epoch 111/300\n",
      "5/5 - 0s - loss: 8.7610 - mae: 60.5922 - val_loss: 9.1123 - val_mae: 69.9169 - 150ms/epoch - 30ms/step\n",
      "Epoch 112/300\n",
      "5/5 - 0s - loss: 8.8314 - mae: 60.6178 - val_loss: 9.1028 - val_mae: 68.8056 - 154ms/epoch - 31ms/step\n",
      "Epoch 113/300\n",
      "5/5 - 0s - loss: 8.9407 - mae: 61.3847 - val_loss: 9.0907 - val_mae: 70.5815 - 152ms/epoch - 30ms/step\n",
      "Epoch 114/300\n",
      "5/5 - 0s - loss: 8.7576 - mae: 60.0842 - val_loss: 9.0817 - val_mae: 67.8896 - 150ms/epoch - 30ms/step\n",
      "Epoch 115/300\n",
      "5/5 - 0s - loss: 8.7355 - mae: 59.5699 - val_loss: 9.0705 - val_mae: 67.9272 - 139ms/epoch - 28ms/step\n",
      "Epoch 116/300\n",
      "5/5 - 0s - loss: 8.7314 - mae: 59.9943 - val_loss: 9.0610 - val_mae: 66.9692 - 138ms/epoch - 28ms/step\n",
      "Epoch 117/300\n",
      "5/5 - 0s - loss: 8.7203 - mae: 59.8053 - val_loss: 9.0518 - val_mae: 69.2116 - 153ms/epoch - 31ms/step\n",
      "Epoch 118/300\n",
      "5/5 - 0s - loss: 8.6941 - mae: 59.3197 - val_loss: 9.0424 - val_mae: 68.8962 - 154ms/epoch - 31ms/step\n",
      "Epoch 119/300\n",
      "5/5 - 0s - loss: 8.6792 - mae: 59.1539 - val_loss: 9.0332 - val_mae: 66.9848 - 142ms/epoch - 28ms/step\n",
      "Epoch 120/300\n",
      "5/5 - 0s - loss: 8.6866 - mae: 59.0958 - val_loss: 9.0229 - val_mae: 68.1636 - 142ms/epoch - 28ms/step\n",
      "Epoch 121/300\n",
      "5/5 - 0s - loss: 8.6653 - mae: 59.0732 - val_loss: 9.0133 - val_mae: 67.7640 - 170ms/epoch - 34ms/step\n",
      "Epoch 122/300\n",
      "5/5 - 0s - loss: 8.6647 - mae: 58.2994 - val_loss: 9.0046 - val_mae: 68.3126 - 146ms/epoch - 29ms/step\n",
      "Epoch 123/300\n",
      "5/5 - 0s - loss: 8.6206 - mae: 58.0617 - val_loss: 8.9960 - val_mae: 66.6682 - 125ms/epoch - 25ms/step\n",
      "Epoch 124/300\n",
      "5/5 - 0s - loss: 8.6426 - mae: 58.1299 - val_loss: 8.9879 - val_mae: 67.1513 - 85ms/epoch - 17ms/step\n",
      "Epoch 125/300\n",
      "5/5 - 0s - loss: 8.6669 - mae: 57.7013 - val_loss: 8.9787 - val_mae: 67.1323 - 84ms/epoch - 17ms/step\n",
      "Epoch 126/300\n",
      "5/5 - 0s - loss: 8.5895 - mae: 57.8981 - val_loss: 8.9701 - val_mae: 66.8343 - 85ms/epoch - 17ms/step\n",
      "Epoch 127/300\n",
      "5/5 - 0s - loss: 8.5981 - mae: 57.1103 - val_loss: 8.9617 - val_mae: 67.8261 - 84ms/epoch - 17ms/step\n",
      "Epoch 128/300\n",
      "5/5 - 0s - loss: 8.5908 - mae: 56.9411 - val_loss: 8.9532 - val_mae: 65.7051 - 89ms/epoch - 18ms/step\n",
      "Epoch 129/300\n",
      "5/5 - 0s - loss: 8.5594 - mae: 56.9141 - val_loss: 8.9443 - val_mae: 66.6876 - 83ms/epoch - 17ms/step\n",
      "Epoch 130/300\n",
      "5/5 - 0s - loss: 8.5295 - mae: 56.4659 - val_loss: 8.9362 - val_mae: 65.5531 - 88ms/epoch - 18ms/step\n",
      "Epoch 131/300\n",
      "5/5 - 0s - loss: 8.5499 - mae: 56.1950 - val_loss: 8.9279 - val_mae: 65.4341 - 91ms/epoch - 18ms/step\n",
      "Epoch 132/300\n",
      "5/5 - 0s - loss: 8.5365 - mae: 56.2297 - val_loss: 8.9198 - val_mae: 65.7824 - 104ms/epoch - 21ms/step\n",
      "Epoch 133/300\n",
      "5/5 - 0s - loss: 8.5311 - mae: 56.0096 - val_loss: 8.9117 - val_mae: 66.9433 - 85ms/epoch - 17ms/step\n",
      "Epoch 134/300\n",
      "5/5 - 0s - loss: 8.5442 - mae: 56.1615 - val_loss: 8.9034 - val_mae: 64.1349 - 84ms/epoch - 17ms/step\n",
      "Epoch 135/300\n",
      "5/5 - 0s - loss: 8.5693 - mae: 55.5924 - val_loss: 8.8953 - val_mae: 66.2551 - 83ms/epoch - 17ms/step\n",
      "Epoch 136/300\n",
      "5/5 - 0s - loss: 8.6440 - mae: 54.8927 - val_loss: 8.8871 - val_mae: 66.2189 - 86ms/epoch - 17ms/step\n",
      "Epoch 137/300\n",
      "5/5 - 0s - loss: 8.4809 - mae: 54.2943 - val_loss: 8.8798 - val_mae: 66.0081 - 88ms/epoch - 18ms/step\n",
      "Epoch 138/300\n",
      "5/5 - 0s - loss: 8.5503 - mae: 54.9556 - val_loss: 8.8720 - val_mae: 66.6071 - 86ms/epoch - 17ms/step\n",
      "Epoch 139/300\n",
      "5/5 - 0s - loss: 8.4589 - mae: 54.2448 - val_loss: 8.8645 - val_mae: 65.0819 - 82ms/epoch - 16ms/step\n",
      "Epoch 140/300\n",
      "5/5 - 0s - loss: 8.4859 - mae: 54.4242 - val_loss: 8.8567 - val_mae: 65.8800 - 80ms/epoch - 16ms/step\n",
      "Epoch 141/300\n",
      "5/5 - 0s - loss: 8.4146 - mae: 53.9324 - val_loss: 8.8493 - val_mae: 65.8977 - 85ms/epoch - 17ms/step\n",
      "Epoch 142/300\n",
      "5/5 - 0s - loss: 8.5388 - mae: 53.7272 - val_loss: 8.8415 - val_mae: 64.8166 - 92ms/epoch - 18ms/step\n",
      "Epoch 143/300\n",
      "5/5 - 0s - loss: 8.4176 - mae: 53.6459 - val_loss: 8.8344 - val_mae: 65.7536 - 105ms/epoch - 21ms/step\n",
      "Epoch 144/300\n",
      "5/5 - 0s - loss: 8.4170 - mae: 54.0625 - val_loss: 8.8278 - val_mae: 65.6486 - 83ms/epoch - 17ms/step\n",
      "Epoch 145/300\n",
      "5/5 - 0s - loss: 8.4428 - mae: 53.1842 - val_loss: 8.8203 - val_mae: 65.1392 - 87ms/epoch - 17ms/step\n",
      "Epoch 146/300\n",
      "5/5 - 0s - loss: 8.3640 - mae: 53.0432 - val_loss: 8.8131 - val_mae: 66.4543 - 85ms/epoch - 17ms/step\n",
      "Epoch 147/300\n",
      "5/5 - 0s - loss: 8.3817 - mae: 52.5874 - val_loss: 8.8055 - val_mae: 65.4724 - 87ms/epoch - 17ms/step\n",
      "Epoch 148/300\n",
      "5/5 - 0s - loss: 8.3623 - mae: 52.9936 - val_loss: 8.7980 - val_mae: 64.5868 - 90ms/epoch - 18ms/step\n",
      "Epoch 149/300\n",
      "5/5 - 0s - loss: 8.3490 - mae: 52.5517 - val_loss: 8.7903 - val_mae: 64.6858 - 89ms/epoch - 18ms/step\n",
      "Epoch 150/300\n",
      "5/5 - 0s - loss: 8.3603 - mae: 52.3237 - val_loss: 8.7824 - val_mae: 66.4727 - 87ms/epoch - 17ms/step\n",
      "Epoch 151/300\n",
      "5/5 - 0s - loss: 8.3647 - mae: 52.2098 - val_loss: 8.7754 - val_mae: 64.0702 - 86ms/epoch - 17ms/step\n",
      "Epoch 152/300\n",
      "5/5 - 0s - loss: 8.3241 - mae: 52.0486 - val_loss: 8.7683 - val_mae: 64.9664 - 83ms/epoch - 17ms/step\n",
      "Epoch 153/300\n",
      "5/5 - 0s - loss: 8.2973 - mae: 51.5575 - val_loss: 8.7610 - val_mae: 64.8456 - 89ms/epoch - 18ms/step\n",
      "Epoch 154/300\n",
      "5/5 - 0s - loss: 8.2943 - mae: 51.5504 - val_loss: 8.7542 - val_mae: 64.4979 - 105ms/epoch - 21ms/step\n",
      "Epoch 155/300\n",
      "5/5 - 0s - loss: 8.2798 - mae: 51.0140 - val_loss: 8.7472 - val_mae: 63.2448 - 84ms/epoch - 17ms/step\n",
      "Epoch 156/300\n",
      "5/5 - 0s - loss: 8.2800 - mae: 51.1270 - val_loss: 8.7401 - val_mae: 64.2111 - 83ms/epoch - 17ms/step\n",
      "Epoch 157/300\n",
      "5/5 - 0s - loss: 8.2466 - mae: 50.8592 - val_loss: 8.7332 - val_mae: 66.1376 - 87ms/epoch - 17ms/step\n",
      "Epoch 158/300\n",
      "5/5 - 0s - loss: 8.2448 - mae: 50.9341 - val_loss: 8.7264 - val_mae: 64.5483 - 89ms/epoch - 18ms/step\n",
      "Epoch 159/300\n",
      "5/5 - 0s - loss: 8.2614 - mae: 50.4576 - val_loss: 8.7190 - val_mae: 65.3946 - 86ms/epoch - 17ms/step\n",
      "Epoch 160/300\n",
      "5/5 - 0s - loss: 8.2287 - mae: 50.0960 - val_loss: 8.7122 - val_mae: 64.0331 - 91ms/epoch - 18ms/step\n",
      "Epoch 161/300\n",
      "5/5 - 0s - loss: 8.2430 - mae: 50.1169 - val_loss: 8.7054 - val_mae: 63.7487 - 87ms/epoch - 17ms/step\n",
      "Epoch 162/300\n",
      "5/5 - 0s - loss: 8.2281 - mae: 50.1430 - val_loss: 8.6990 - val_mae: 65.6231 - 87ms/epoch - 17ms/step\n",
      "Epoch 163/300\n",
      "5/5 - 0s - loss: 8.1854 - mae: 49.4412 - val_loss: 8.6920 - val_mae: 62.9796 - 87ms/epoch - 17ms/step\n",
      "Epoch 164/300\n",
      "5/5 - 0s - loss: 8.2526 - mae: 49.3690 - val_loss: 8.6854 - val_mae: 64.5880 - 97ms/epoch - 19ms/step\n",
      "Epoch 165/300\n",
      "5/5 - 0s - loss: 8.1907 - mae: 49.1112 - val_loss: 8.6785 - val_mae: 67.7304 - 91ms/epoch - 18ms/step\n",
      "Epoch 166/300\n",
      "5/5 - 0s - loss: 8.1663 - mae: 49.1982 - val_loss: 8.6718 - val_mae: 63.8311 - 104ms/epoch - 21ms/step\n",
      "Epoch 167/300\n",
      "5/5 - 0s - loss: 8.1800 - mae: 49.1939 - val_loss: 8.6657 - val_mae: 63.4709 - 86ms/epoch - 17ms/step\n",
      "Epoch 168/300\n",
      "5/5 - 0s - loss: 8.1745 - mae: 48.9646 - val_loss: 8.6596 - val_mae: 64.8156 - 102ms/epoch - 20ms/step\n",
      "Epoch 169/300\n",
      "5/5 - 0s - loss: 8.2106 - mae: 48.7729 - val_loss: 8.6534 - val_mae: 63.8269 - 101ms/epoch - 20ms/step\n",
      "Epoch 170/300\n",
      "5/5 - 0s - loss: 8.2005 - mae: 49.0887 - val_loss: 8.6473 - val_mae: 64.3369 - 87ms/epoch - 17ms/step\n",
      "Epoch 171/300\n",
      "5/5 - 0s - loss: 8.1296 - mae: 48.7973 - val_loss: 8.6411 - val_mae: 63.4415 - 87ms/epoch - 17ms/step\n",
      "Epoch 172/300\n",
      "5/5 - 0s - loss: 8.1362 - mae: 48.1746 - val_loss: 8.6347 - val_mae: 63.0036 - 90ms/epoch - 18ms/step\n",
      "Epoch 173/300\n",
      "5/5 - 0s - loss: 8.1189 - mae: 47.9025 - val_loss: 8.6284 - val_mae: 63.8353 - 87ms/epoch - 17ms/step\n",
      "Epoch 174/300\n",
      "5/5 - 0s - loss: 8.1155 - mae: 47.9269 - val_loss: 8.6221 - val_mae: 64.1762 - 89ms/epoch - 18ms/step\n",
      "Epoch 175/300\n",
      "5/5 - 0s - loss: 8.0583 - mae: 47.9567 - val_loss: 8.6161 - val_mae: 63.5133 - 95ms/epoch - 19ms/step\n",
      "Epoch 176/300\n",
      "5/5 - 0s - loss: 8.0517 - mae: 47.1699 - val_loss: 8.6101 - val_mae: 64.1499 - 98ms/epoch - 20ms/step\n",
      "Epoch 177/300\n",
      "5/5 - 0s - loss: 8.1253 - mae: 47.3899 - val_loss: 8.6039 - val_mae: 63.0513 - 92ms/epoch - 18ms/step\n",
      "Epoch 178/300\n",
      "5/5 - 0s - loss: 8.0784 - mae: 47.5772 - val_loss: 8.5990 - val_mae: 63.7613 - 87ms/epoch - 17ms/step\n",
      "Epoch 179/300\n",
      "5/5 - 0s - loss: 8.0265 - mae: 47.1974 - val_loss: 8.5936 - val_mae: 64.8778 - 87ms/epoch - 17ms/step\n",
      "Epoch 180/300\n",
      "5/5 - 0s - loss: 8.0617 - mae: 47.3261 - val_loss: 8.5880 - val_mae: 63.6694 - 90ms/epoch - 18ms/step\n",
      "Epoch 181/300\n",
      "5/5 - 0s - loss: 8.0354 - mae: 46.8645 - val_loss: 8.5828 - val_mae: 62.2014 - 88ms/epoch - 18ms/step\n",
      "Epoch 182/300\n",
      "5/5 - 0s - loss: 8.0142 - mae: 46.4899 - val_loss: 8.5769 - val_mae: 63.5113 - 88ms/epoch - 18ms/step\n",
      "Epoch 183/300\n",
      "5/5 - 0s - loss: 8.0025 - mae: 46.6771 - val_loss: 8.5714 - val_mae: 63.1006 - 91ms/epoch - 18ms/step\n",
      "Epoch 184/300\n",
      "5/5 - 0s - loss: 8.0617 - mae: 46.7708 - val_loss: 8.5656 - val_mae: 63.7910 - 85ms/epoch - 17ms/step\n",
      "Epoch 185/300\n",
      "5/5 - 0s - loss: 8.0030 - mae: 46.0419 - val_loss: 8.5599 - val_mae: 63.0330 - 89ms/epoch - 18ms/step\n",
      "Epoch 186/300\n",
      "5/5 - 0s - loss: 7.9906 - mae: 46.1180 - val_loss: 8.5544 - val_mae: 64.4786 - 88ms/epoch - 18ms/step\n",
      "Epoch 187/300\n",
      "5/5 - 0s - loss: 7.9633 - mae: 45.7196 - val_loss: 8.5490 - val_mae: 63.3247 - 89ms/epoch - 18ms/step\n",
      "Epoch 188/300\n",
      "5/5 - 0s - loss: 7.9524 - mae: 45.7867 - val_loss: 8.5434 - val_mae: 63.9608 - 102ms/epoch - 20ms/step\n",
      "Epoch 189/300\n",
      "5/5 - 0s - loss: 7.9579 - mae: 45.5382 - val_loss: 8.5379 - val_mae: 63.4401 - 85ms/epoch - 17ms/step\n",
      "Epoch 190/300\n",
      "5/5 - 0s - loss: 7.9605 - mae: 45.3522 - val_loss: 8.5325 - val_mae: 62.1241 - 84ms/epoch - 17ms/step\n",
      "Epoch 191/300\n",
      "5/5 - 0s - loss: 7.9370 - mae: 45.6306 - val_loss: 8.5271 - val_mae: 63.5344 - 85ms/epoch - 17ms/step\n",
      "Epoch 192/300\n",
      "5/5 - 0s - loss: 7.9001 - mae: 44.8866 - val_loss: 8.5215 - val_mae: 61.9707 - 87ms/epoch - 17ms/step\n",
      "Epoch 193/300\n",
      "5/5 - 0s - loss: 7.9073 - mae: 44.9007 - val_loss: 8.5162 - val_mae: 63.6530 - 86ms/epoch - 17ms/step\n",
      "Epoch 194/300\n",
      "5/5 - 0s - loss: 7.8964 - mae: 45.2912 - val_loss: 8.5105 - val_mae: 61.2958 - 88ms/epoch - 18ms/step\n",
      "Epoch 195/300\n",
      "5/5 - 0s - loss: 7.8786 - mae: 44.9769 - val_loss: 8.5052 - val_mae: 63.9653 - 83ms/epoch - 17ms/step\n",
      "Epoch 196/300\n",
      "5/5 - 0s - loss: 7.8760 - mae: 44.8564 - val_loss: 8.4998 - val_mae: 62.8490 - 92ms/epoch - 18ms/step\n",
      "Epoch 197/300\n",
      "5/5 - 0s - loss: 7.9389 - mae: 44.5186 - val_loss: 8.4941 - val_mae: 63.4712 - 88ms/epoch - 18ms/step\n",
      "Epoch 198/300\n",
      "5/5 - 0s - loss: 7.8655 - mae: 44.7028 - val_loss: 8.4890 - val_mae: 63.4733 - 85ms/epoch - 17ms/step\n",
      "Epoch 199/300\n",
      "5/5 - 0s - loss: 7.8736 - mae: 44.3669 - val_loss: 8.4840 - val_mae: 63.0008 - 101ms/epoch - 20ms/step\n",
      "Epoch 200/300\n",
      "5/5 - 0s - loss: 7.9064 - mae: 44.2771 - val_loss: 8.4788 - val_mae: 62.8250 - 99ms/epoch - 20ms/step\n",
      "Epoch 201/300\n",
      "5/5 - 0s - loss: 7.8258 - mae: 43.9385 - val_loss: 8.4736 - val_mae: 62.0297 - 84ms/epoch - 17ms/step\n",
      "Epoch 202/300\n",
      "5/5 - 0s - loss: 7.8700 - mae: 43.9438 - val_loss: 8.4686 - val_mae: 61.8320 - 88ms/epoch - 18ms/step\n",
      "Epoch 203/300\n",
      "5/5 - 0s - loss: 7.8228 - mae: 43.5721 - val_loss: 8.4636 - val_mae: 63.5202 - 86ms/epoch - 17ms/step\n",
      "Epoch 204/300\n",
      "5/5 - 0s - loss: 7.8092 - mae: 44.0255 - val_loss: 8.4588 - val_mae: 62.6994 - 89ms/epoch - 18ms/step\n",
      "Epoch 205/300\n",
      "5/5 - 0s - loss: 7.8405 - mae: 43.9639 - val_loss: 8.4538 - val_mae: 61.9569 - 87ms/epoch - 17ms/step\n",
      "Epoch 206/300\n",
      "5/5 - 0s - loss: 7.8025 - mae: 43.3782 - val_loss: 8.4493 - val_mae: 63.9130 - 87ms/epoch - 17ms/step\n",
      "Epoch 207/300\n",
      "5/5 - 0s - loss: 7.7861 - mae: 43.3549 - val_loss: 8.4447 - val_mae: 62.0281 - 94ms/epoch - 19ms/step\n",
      "Epoch 208/300\n",
      "5/5 - 0s - loss: 7.7592 - mae: 43.4282 - val_loss: 8.4402 - val_mae: 64.0521 - 93ms/epoch - 19ms/step\n",
      "Epoch 209/300\n",
      "5/5 - 0s - loss: 7.7694 - mae: 43.4631 - val_loss: 8.4356 - val_mae: 63.0933 - 89ms/epoch - 18ms/step\n",
      "Epoch 210/300\n",
      "5/5 - 0s - loss: 7.8243 - mae: 43.2722 - val_loss: 8.4312 - val_mae: 61.6385 - 97ms/epoch - 19ms/step\n",
      "Epoch 211/300\n",
      "5/5 - 0s - loss: 7.7596 - mae: 43.2985 - val_loss: 8.4269 - val_mae: 62.2260 - 88ms/epoch - 18ms/step\n",
      "Epoch 212/300\n",
      "5/5 - 0s - loss: 7.7474 - mae: 43.2701 - val_loss: 8.4222 - val_mae: 62.6146 - 90ms/epoch - 18ms/step\n",
      "Epoch 213/300\n",
      "5/5 - 0s - loss: 7.7258 - mae: 43.3411 - val_loss: 8.4178 - val_mae: 60.4375 - 90ms/epoch - 18ms/step\n",
      "Epoch 214/300\n",
      "5/5 - 0s - loss: 7.7875 - mae: 43.2021 - val_loss: 8.4132 - val_mae: 62.5310 - 85ms/epoch - 17ms/step\n",
      "Epoch 215/300\n",
      "5/5 - 0s - loss: 7.7571 - mae: 43.1674 - val_loss: 8.4092 - val_mae: 63.0022 - 86ms/epoch - 17ms/step\n",
      "Epoch 216/300\n",
      "5/5 - 0s - loss: 7.7233 - mae: 43.0261 - val_loss: 8.4050 - val_mae: 62.4364 - 85ms/epoch - 17ms/step\n",
      "Epoch 217/300\n",
      "5/5 - 0s - loss: 7.6886 - mae: 42.6534 - val_loss: 8.4011 - val_mae: 62.6875 - 101ms/epoch - 20ms/step\n",
      "Epoch 218/300\n",
      "5/5 - 0s - loss: 7.7218 - mae: 41.8680 - val_loss: 8.3970 - val_mae: 62.1654 - 91ms/epoch - 18ms/step\n",
      "Epoch 219/300\n",
      "5/5 - 0s - loss: 7.6944 - mae: 42.2954 - val_loss: 8.3927 - val_mae: 61.2329 - 88ms/epoch - 18ms/step\n",
      "Epoch 220/300\n",
      "5/5 - 0s - loss: 7.6592 - mae: 42.2031 - val_loss: 8.3885 - val_mae: 62.5788 - 91ms/epoch - 18ms/step\n",
      "Epoch 221/300\n",
      "5/5 - 0s - loss: 7.6530 - mae: 41.8443 - val_loss: 8.3841 - val_mae: 62.6404 - 100ms/epoch - 20ms/step\n",
      "Epoch 222/300\n",
      "5/5 - 0s - loss: 7.6687 - mae: 41.7264 - val_loss: 8.3799 - val_mae: 61.7461 - 87ms/epoch - 17ms/step\n",
      "Epoch 223/300\n",
      "5/5 - 0s - loss: 7.6604 - mae: 41.7494 - val_loss: 8.3763 - val_mae: 62.4033 - 89ms/epoch - 18ms/step\n",
      "Epoch 224/300\n",
      "5/5 - 0s - loss: 7.6746 - mae: 41.9560 - val_loss: 8.3732 - val_mae: 61.8684 - 84ms/epoch - 17ms/step\n",
      "Epoch 225/300\n",
      "5/5 - 0s - loss: 7.6204 - mae: 41.1889 - val_loss: 8.3700 - val_mae: 61.8926 - 84ms/epoch - 17ms/step\n",
      "Epoch 226/300\n",
      "5/5 - 0s - loss: 7.6210 - mae: 42.0955 - val_loss: 8.3667 - val_mae: 61.6333 - 91ms/epoch - 18ms/step\n",
      "Epoch 227/300\n",
      "5/5 - 0s - loss: 7.6072 - mae: 41.0607 - val_loss: 8.3633 - val_mae: 62.2147 - 87ms/epoch - 17ms/step\n",
      "Epoch 228/300\n",
      "5/5 - 0s - loss: 7.6024 - mae: 41.6630 - val_loss: 8.3596 - val_mae: 61.1893 - 92ms/epoch - 18ms/step\n",
      "Epoch 229/300\n",
      "5/5 - 0s - loss: 7.6280 - mae: 41.2358 - val_loss: 8.3564 - val_mae: 60.9853 - 93ms/epoch - 19ms/step\n",
      "Epoch 230/300\n",
      "5/5 - 0s - loss: 7.6102 - mae: 41.3513 - val_loss: 8.3534 - val_mae: 62.4180 - 110ms/epoch - 22ms/step\n",
      "Epoch 231/300\n",
      "5/5 - 0s - loss: 7.5577 - mae: 41.2951 - val_loss: 8.3498 - val_mae: 62.3262 - 139ms/epoch - 28ms/step\n",
      "Epoch 232/300\n",
      "5/5 - 0s - loss: 7.5683 - mae: 40.8854 - val_loss: 8.3469 - val_mae: 61.9693 - 184ms/epoch - 37ms/step\n",
      "Epoch 233/300\n",
      "5/5 - 0s - loss: 7.5427 - mae: 41.0139 - val_loss: 8.3449 - val_mae: 61.8327 - 142ms/epoch - 28ms/step\n",
      "Epoch 234/300\n",
      "5/5 - 0s - loss: 7.5577 - mae: 41.0716 - val_loss: 8.3421 - val_mae: 61.1586 - 146ms/epoch - 29ms/step\n",
      "Epoch 235/300\n",
      "5/5 - 0s - loss: 7.5315 - mae: 40.7950 - val_loss: 8.3389 - val_mae: 60.8860 - 147ms/epoch - 29ms/step\n",
      "Epoch 236/300\n",
      "5/5 - 0s - loss: 7.5394 - mae: 40.9885 - val_loss: 8.3356 - val_mae: 61.5905 - 140ms/epoch - 28ms/step\n",
      "Epoch 237/300\n",
      "5/5 - 0s - loss: 7.5215 - mae: 40.6103 - val_loss: 8.3323 - val_mae: 61.1108 - 144ms/epoch - 29ms/step\n",
      "Epoch 238/300\n",
      "5/5 - 0s - loss: 7.5687 - mae: 40.6288 - val_loss: 8.3292 - val_mae: 61.6342 - 158ms/epoch - 32ms/step\n",
      "Epoch 239/300\n",
      "5/5 - 0s - loss: 7.5632 - mae: 40.1176 - val_loss: 8.3261 - val_mae: 62.2778 - 154ms/epoch - 31ms/step\n",
      "Epoch 240/300\n",
      "5/5 - 0s - loss: 7.4918 - mae: 40.3780 - val_loss: 8.3232 - val_mae: 61.2580 - 140ms/epoch - 28ms/step\n",
      "Epoch 241/300\n",
      "5/5 - 0s - loss: 7.5104 - mae: 40.2943 - val_loss: 8.3206 - val_mae: 61.1104 - 144ms/epoch - 29ms/step\n",
      "Epoch 242/300\n",
      "5/5 - 0s - loss: 7.5013 - mae: 40.1909 - val_loss: 8.3175 - val_mae: 61.8601 - 152ms/epoch - 30ms/step\n",
      "Epoch 243/300\n",
      "5/5 - 0s - loss: 7.4748 - mae: 39.8886 - val_loss: 8.3155 - val_mae: 61.9308 - 151ms/epoch - 30ms/step\n",
      "Epoch 244/300\n",
      "5/5 - 0s - loss: 7.4684 - mae: 39.7840 - val_loss: 8.3136 - val_mae: 62.6905 - 157ms/epoch - 31ms/step\n",
      "Epoch 245/300\n",
      "5/5 - 0s - loss: 7.4381 - mae: 39.6735 - val_loss: 8.3115 - val_mae: 61.4125 - 159ms/epoch - 32ms/step\n",
      "Epoch 246/300\n",
      "5/5 - 0s - loss: 7.4437 - mae: 40.2219 - val_loss: 8.3094 - val_mae: 60.6444 - 145ms/epoch - 29ms/step\n",
      "Epoch 247/300\n",
      "5/5 - 0s - loss: 7.4135 - mae: 39.6862 - val_loss: 8.3059 - val_mae: 61.1304 - 95ms/epoch - 19ms/step\n",
      "Epoch 248/300\n",
      "5/5 - 0s - loss: 7.4147 - mae: 39.5301 - val_loss: 8.3030 - val_mae: 61.8453 - 93ms/epoch - 19ms/step\n",
      "Epoch 249/300\n",
      "5/5 - 0s - loss: 7.4183 - mae: 39.4976 - val_loss: 8.3005 - val_mae: 59.9327 - 88ms/epoch - 18ms/step\n",
      "Epoch 250/300\n",
      "5/5 - 0s - loss: 7.4385 - mae: 39.4417 - val_loss: 8.2988 - val_mae: 61.3158 - 95ms/epoch - 19ms/step\n",
      "Epoch 251/300\n",
      "5/5 - 0s - loss: 7.4360 - mae: 39.2692 - val_loss: 8.2954 - val_mae: 61.8790 - 90ms/epoch - 18ms/step\n",
      "Epoch 252/300\n",
      "5/5 - 0s - loss: 7.4079 - mae: 39.0512 - val_loss: 8.2938 - val_mae: 62.1635 - 95ms/epoch - 19ms/step\n",
      "Epoch 253/300\n",
      "5/5 - 0s - loss: 7.3876 - mae: 39.0697 - val_loss: 8.2910 - val_mae: 61.9752 - 91ms/epoch - 18ms/step\n",
      "Epoch 254/300\n",
      "5/5 - 0s - loss: 7.3768 - mae: 38.8478 - val_loss: 8.2880 - val_mae: 62.6163 - 90ms/epoch - 18ms/step\n",
      "Epoch 255/300\n",
      "5/5 - 0s - loss: 7.3827 - mae: 38.7231 - val_loss: 8.2856 - val_mae: 59.4274 - 93ms/epoch - 19ms/step\n",
      "Epoch 256/300\n",
      "5/5 - 0s - loss: 7.3696 - mae: 38.6897 - val_loss: 8.2844 - val_mae: 60.4923 - 109ms/epoch - 22ms/step\n",
      "Epoch 257/300\n",
      "5/5 - 0s - loss: 7.3374 - mae: 38.7780 - val_loss: 8.2829 - val_mae: 61.5922 - 120ms/epoch - 24ms/step\n",
      "Epoch 258/300\n",
      "5/5 - 0s - loss: 7.3481 - mae: 38.7300 - val_loss: 8.2811 - val_mae: 60.7392 - 92ms/epoch - 18ms/step\n",
      "Epoch 259/300\n",
      "5/5 - 0s - loss: 7.3559 - mae: 38.5501 - val_loss: 8.2789 - val_mae: 60.9976 - 88ms/epoch - 18ms/step\n",
      "Epoch 260/300\n",
      "5/5 - 0s - loss: 7.3234 - mae: 38.6931 - val_loss: 8.2768 - val_mae: 61.8077 - 100ms/epoch - 20ms/step\n",
      "Epoch 261/300\n",
      "5/5 - 0s - loss: 7.3099 - mae: 38.5805 - val_loss: 8.2737 - val_mae: 60.7280 - 87ms/epoch - 17ms/step\n",
      "Epoch 262/300\n",
      "5/5 - 0s - loss: 7.3079 - mae: 38.1897 - val_loss: 8.2725 - val_mae: 61.4297 - 89ms/epoch - 18ms/step\n",
      "Epoch 263/300\n",
      "5/5 - 0s - loss: 7.3018 - mae: 38.4354 - val_loss: 8.2713 - val_mae: 60.6942 - 87ms/epoch - 17ms/step\n",
      "Epoch 264/300\n",
      "5/5 - 0s - loss: 7.3050 - mae: 38.0368 - val_loss: 8.2692 - val_mae: 60.0960 - 92ms/epoch - 18ms/step\n",
      "Epoch 265/300\n",
      "5/5 - 0s - loss: 7.3576 - mae: 37.8737 - val_loss: 8.2683 - val_mae: 60.6346 - 89ms/epoch - 18ms/step\n",
      "Epoch 266/300\n",
      "5/5 - 0s - loss: 7.2714 - mae: 38.3077 - val_loss: 8.2684 - val_mae: 60.3331 - 103ms/epoch - 21ms/step\n",
      "Epoch 267/300\n",
      "5/5 - 0s - loss: 7.2524 - mae: 37.9213 - val_loss: 8.2667 - val_mae: 61.0235 - 90ms/epoch - 18ms/step\n",
      "Epoch 268/300\n",
      "5/5 - 0s - loss: 7.2617 - mae: 37.6711 - val_loss: 8.2642 - val_mae: 60.9282 - 88ms/epoch - 18ms/step\n",
      "Epoch 269/300\n",
      "5/5 - 0s - loss: 7.3023 - mae: 38.1187 - val_loss: 8.2614 - val_mae: 60.7284 - 92ms/epoch - 18ms/step\n",
      "Epoch 270/300\n",
      "5/5 - 0s - loss: 7.2372 - mae: 38.0235 - val_loss: 8.2593 - val_mae: 61.0602 - 96ms/epoch - 19ms/step\n",
      "Epoch 271/300\n",
      "5/5 - 0s - loss: 7.2317 - mae: 37.8795 - val_loss: 8.2561 - val_mae: 59.8334 - 88ms/epoch - 18ms/step\n",
      "Epoch 272/300\n",
      "5/5 - 0s - loss: 7.2392 - mae: 37.4523 - val_loss: 8.2500 - val_mae: 58.5154 - 94ms/epoch - 19ms/step\n",
      "Epoch 273/300\n",
      "5/5 - 0s - loss: 7.2686 - mae: 37.4408 - val_loss: 8.2469 - val_mae: 59.7522 - 89ms/epoch - 18ms/step\n",
      "Epoch 274/300\n",
      "5/5 - 0s - loss: 7.1998 - mae: 37.3943 - val_loss: 8.2428 - val_mae: 59.8740 - 89ms/epoch - 18ms/step\n",
      "Epoch 275/300\n",
      "5/5 - 0s - loss: 7.1881 - mae: 37.4878 - val_loss: 8.2397 - val_mae: 59.5691 - 85ms/epoch - 17ms/step\n",
      "Epoch 276/300\n",
      "5/5 - 0s - loss: 7.2112 - mae: 37.0874 - val_loss: 8.2351 - val_mae: 58.9437 - 89ms/epoch - 18ms/step\n",
      "Epoch 277/300\n",
      "5/5 - 0s - loss: 7.2285 - mae: 37.6425 - val_loss: 8.2316 - val_mae: 60.5813 - 87ms/epoch - 17ms/step\n",
      "Epoch 278/300\n",
      "5/5 - 0s - loss: 7.1747 - mae: 36.9991 - val_loss: 8.2277 - val_mae: 59.4337 - 98ms/epoch - 20ms/step\n",
      "Epoch 279/300\n",
      "5/5 - 0s - loss: 7.1906 - mae: 37.2112 - val_loss: 8.2255 - val_mae: 59.5736 - 93ms/epoch - 19ms/step\n",
      "Epoch 280/300\n",
      "5/5 - 0s - loss: 7.1845 - mae: 36.8047 - val_loss: 8.2239 - val_mae: 60.4588 - 85ms/epoch - 17ms/step\n",
      "Epoch 281/300\n",
      "5/5 - 0s - loss: 7.1479 - mae: 36.5117 - val_loss: 8.2221 - val_mae: 60.6429 - 90ms/epoch - 18ms/step\n",
      "Epoch 282/300\n",
      "5/5 - 0s - loss: 7.1642 - mae: 36.5351 - val_loss: 8.2206 - val_mae: 59.6265 - 89ms/epoch - 18ms/step\n",
      "Epoch 283/300\n",
      "5/5 - 0s - loss: 7.1639 - mae: 36.5486 - val_loss: 8.2209 - val_mae: 59.7864 - 84ms/epoch - 17ms/step\n",
      "Epoch 284/300\n",
      "5/5 - 0s - loss: 7.1619 - mae: 36.6667 - val_loss: 8.2209 - val_mae: 61.5926 - 81ms/epoch - 16ms/step\n",
      "Epoch 285/300\n",
      "5/5 - 0s - loss: 7.1442 - mae: 36.5748 - val_loss: 8.2216 - val_mae: 59.6815 - 83ms/epoch - 17ms/step\n",
      "Epoch 286/300\n",
      "5/5 - 0s - loss: 7.1170 - mae: 36.6944 - val_loss: 8.2197 - val_mae: 59.9819 - 85ms/epoch - 17ms/step\n",
      "Epoch 287/300\n",
      "5/5 - 0s - loss: 7.1023 - mae: 36.5496 - val_loss: 8.2165 - val_mae: 60.9265 - 87ms/epoch - 17ms/step\n",
      "Epoch 288/300\n",
      "5/5 - 0s - loss: 7.0999 - mae: 36.4318 - val_loss: 8.2151 - val_mae: 59.4369 - 84ms/epoch - 17ms/step\n",
      "Epoch 289/300\n",
      "5/5 - 0s - loss: 7.1112 - mae: 36.4914 - val_loss: 8.2143 - val_mae: 59.7201 - 104ms/epoch - 21ms/step\n",
      "Epoch 290/300\n",
      "5/5 - 0s - loss: 7.1504 - mae: 36.3049 - val_loss: 8.2120 - val_mae: 59.9029 - 88ms/epoch - 18ms/step\n",
      "Epoch 291/300\n",
      "5/5 - 0s - loss: 7.0770 - mae: 36.0659 - val_loss: 8.2110 - val_mae: 59.3993 - 84ms/epoch - 17ms/step\n",
      "Epoch 292/300\n",
      "5/5 - 0s - loss: 7.0681 - mae: 36.0495 - val_loss: 8.2104 - val_mae: 60.8830 - 88ms/epoch - 18ms/step\n",
      "Epoch 293/300\n",
      "5/5 - 0s - loss: 7.0824 - mae: 36.1183 - val_loss: 8.2094 - val_mae: 59.9347 - 102ms/epoch - 20ms/step\n",
      "Epoch 294/300\n",
      "5/5 - 0s - loss: 7.0597 - mae: 35.8939 - val_loss: 8.2092 - val_mae: 60.0905 - 88ms/epoch - 18ms/step\n",
      "Epoch 295/300\n",
      "5/5 - 0s - loss: 7.0682 - mae: 36.2146 - val_loss: 8.2090 - val_mae: 59.2956 - 85ms/epoch - 17ms/step\n",
      "Epoch 296/300\n",
      "5/5 - 0s - loss: 7.0543 - mae: 35.7347 - val_loss: 8.2078 - val_mae: 60.4635 - 86ms/epoch - 17ms/step\n",
      "Epoch 297/300\n",
      "5/5 - 0s - loss: 7.0195 - mae: 35.4281 - val_loss: 8.2058 - val_mae: 60.0241 - 94ms/epoch - 19ms/step\n",
      "Epoch 298/300\n",
      "5/5 - 0s - loss: 7.0114 - mae: 35.8778 - val_loss: 8.2047 - val_mae: 60.2037 - 88ms/epoch - 18ms/step\n",
      "Epoch 299/300\n",
      "5/5 - 0s - loss: 7.0575 - mae: 35.7494 - val_loss: 8.2016 - val_mae: 58.4575 - 86ms/epoch - 17ms/step\n",
      "Epoch 300/300\n",
      "5/5 - 0s - loss: 7.0774 - mae: 35.5047 - val_loss: 8.1994 - val_mae: 59.5666 - 122ms/epoch - 24ms/step\n",
      "Epoch 1/300\n",
      "5/5 - 1s - loss: 1235.7880 - mae: 69.7512 - val_loss: 681702656.0000 - val_mae: 215.1662 - 1s/epoch - 260ms/step\n",
      "Epoch 2/300\n",
      "5/5 - 0s - loss: 749.1030 - mae: 69.7037 - val_loss: 65817908.0000 - val_mae: 215.7981 - 87ms/epoch - 17ms/step\n",
      "Epoch 3/300\n",
      "5/5 - 0s - loss: 543.2336 - mae: 69.6576 - val_loss: 97544.5312 - val_mae: 214.1304 - 90ms/epoch - 18ms/step\n",
      "Epoch 4/300\n",
      "5/5 - 0s - loss: 427.9312 - mae: 69.6125 - val_loss: 812.3373 - val_mae: 214.4391 - 85ms/epoch - 17ms/step\n",
      "Epoch 5/300\n",
      "5/5 - 0s - loss: 359.3619 - mae: 69.6635 - val_loss: 215.9725 - val_mae: 214.2320 - 87ms/epoch - 17ms/step\n",
      "Epoch 6/300\n",
      "5/5 - 0s - loss: 302.4268 - mae: 69.5828 - val_loss: 159.2931 - val_mae: 214.5380 - 95ms/epoch - 19ms/step\n",
      "Epoch 7/300\n",
      "5/5 - 0s - loss: 264.5014 - mae: 69.5260 - val_loss: 135.9784 - val_mae: 213.1209 - 93ms/epoch - 19ms/step\n",
      "Epoch 8/300\n",
      "5/5 - 0s - loss: 232.5133 - mae: 69.4913 - val_loss: 122.0757 - val_mae: 213.4786 - 102ms/epoch - 20ms/step\n",
      "Epoch 9/300\n",
      "5/5 - 0s - loss: 207.6553 - mae: 69.4524 - val_loss: 113.2236 - val_mae: 212.9319 - 87ms/epoch - 17ms/step\n",
      "Epoch 10/300\n",
      "5/5 - 0s - loss: 185.1920 - mae: 69.4390 - val_loss: 106.9322 - val_mae: 213.3608 - 86ms/epoch - 17ms/step\n",
      "Epoch 11/300\n",
      "5/5 - 0s - loss: 170.8052 - mae: 69.3805 - val_loss: 101.9186 - val_mae: 212.6191 - 90ms/epoch - 18ms/step\n",
      "Epoch 12/300\n",
      "5/5 - 0s - loss: 152.8058 - mae: 69.3172 - val_loss: 97.8628 - val_mae: 213.9604 - 86ms/epoch - 17ms/step\n",
      "Epoch 13/300\n",
      "5/5 - 0s - loss: 139.1207 - mae: 69.2549 - val_loss: 93.8520 - val_mae: 211.7482 - 86ms/epoch - 17ms/step\n",
      "Epoch 14/300\n",
      "5/5 - 0s - loss: 127.3342 - mae: 69.2618 - val_loss: 90.5329 - val_mae: 213.8905 - 97ms/epoch - 19ms/step\n",
      "Epoch 15/300\n",
      "5/5 - 0s - loss: 116.4985 - mae: 69.1837 - val_loss: 87.5094 - val_mae: 212.9560 - 102ms/epoch - 20ms/step\n",
      "Epoch 16/300\n",
      "5/5 - 0s - loss: 107.4935 - mae: 69.1590 - val_loss: 84.7939 - val_mae: 212.1605 - 89ms/epoch - 18ms/step\n",
      "Epoch 17/300\n",
      "5/5 - 0s - loss: 98.5425 - mae: 69.0376 - val_loss: 81.4979 - val_mae: 212.5496 - 88ms/epoch - 18ms/step\n",
      "Epoch 18/300\n",
      "5/5 - 0s - loss: 90.0390 - mae: 69.0322 - val_loss: 78.4302 - val_mae: 212.6191 - 85ms/epoch - 17ms/step\n",
      "Epoch 19/300\n",
      "5/5 - 0s - loss: 84.4814 - mae: 68.8682 - val_loss: 75.4444 - val_mae: 212.3866 - 103ms/epoch - 21ms/step\n",
      "Epoch 20/300\n",
      "5/5 - 0s - loss: 77.8022 - mae: 68.8641 - val_loss: 73.0169 - val_mae: 211.9193 - 85ms/epoch - 17ms/step\n",
      "Epoch 21/300\n",
      "5/5 - 0s - loss: 72.0507 - mae: 68.8662 - val_loss: 70.8778 - val_mae: 210.7587 - 81ms/epoch - 16ms/step\n",
      "Epoch 22/300\n",
      "5/5 - 0s - loss: 67.0838 - mae: 68.7353 - val_loss: 68.8216 - val_mae: 212.1800 - 87ms/epoch - 17ms/step\n",
      "Epoch 23/300\n",
      "5/5 - 0s - loss: 63.6051 - mae: 68.6146 - val_loss: 66.8967 - val_mae: 211.0352 - 88ms/epoch - 18ms/step\n",
      "Epoch 24/300\n",
      "5/5 - 0s - loss: 58.9123 - mae: 68.6560 - val_loss: 64.9614 - val_mae: 212.1186 - 82ms/epoch - 16ms/step\n",
      "Epoch 25/300\n",
      "5/5 - 0s - loss: 55.8832 - mae: 68.5767 - val_loss: 63.2111 - val_mae: 210.3198 - 82ms/epoch - 16ms/step\n",
      "Epoch 26/300\n",
      "5/5 - 0s - loss: 52.3810 - mae: 68.5321 - val_loss: 61.5349 - val_mae: 211.3814 - 87ms/epoch - 17ms/step\n",
      "Epoch 27/300\n",
      "5/5 - 0s - loss: 49.6991 - mae: 68.4037 - val_loss: 59.9902 - val_mae: 210.0320 - 87ms/epoch - 17ms/step\n",
      "Epoch 28/300\n",
      "5/5 - 0s - loss: 47.6544 - mae: 68.4087 - val_loss: 58.3583 - val_mae: 210.5777 - 89ms/epoch - 18ms/step\n",
      "Epoch 29/300\n",
      "5/5 - 0s - loss: 45.1198 - mae: 68.2635 - val_loss: 57.1659 - val_mae: 210.4506 - 90ms/epoch - 18ms/step\n",
      "Epoch 30/300\n",
      "5/5 - 0s - loss: 43.1766 - mae: 68.1750 - val_loss: 55.9284 - val_mae: 209.5637 - 89ms/epoch - 18ms/step\n",
      "Epoch 31/300\n",
      "5/5 - 0s - loss: 41.0528 - mae: 68.1469 - val_loss: 54.6653 - val_mae: 212.0363 - 100ms/epoch - 20ms/step\n",
      "Epoch 32/300\n",
      "5/5 - 0s - loss: 39.8197 - mae: 68.0847 - val_loss: 53.5056 - val_mae: 209.0874 - 83ms/epoch - 17ms/step\n",
      "Epoch 33/300\n",
      "5/5 - 0s - loss: 37.9288 - mae: 67.8913 - val_loss: 52.3559 - val_mae: 209.7330 - 86ms/epoch - 17ms/step\n",
      "Epoch 34/300\n",
      "5/5 - 0s - loss: 36.7219 - mae: 67.8470 - val_loss: 51.4393 - val_mae: 209.1967 - 83ms/epoch - 17ms/step\n",
      "Epoch 35/300\n",
      "5/5 - 0s - loss: 35.4190 - mae: 67.9057 - val_loss: 50.4821 - val_mae: 209.2197 - 85ms/epoch - 17ms/step\n",
      "Epoch 36/300\n",
      "5/5 - 0s - loss: 34.2674 - mae: 67.7029 - val_loss: 49.5886 - val_mae: 209.9624 - 84ms/epoch - 17ms/step\n",
      "Epoch 37/300\n",
      "5/5 - 0s - loss: 33.4294 - mae: 67.7794 - val_loss: 48.6792 - val_mae: 209.9554 - 80ms/epoch - 16ms/step\n",
      "Epoch 38/300\n",
      "5/5 - 0s - loss: 32.4495 - mae: 67.5941 - val_loss: 47.7298 - val_mae: 209.6948 - 93ms/epoch - 19ms/step\n",
      "Epoch 39/300\n",
      "5/5 - 0s - loss: 31.5666 - mae: 67.5283 - val_loss: 46.9597 - val_mae: 208.2965 - 88ms/epoch - 18ms/step\n",
      "Epoch 40/300\n",
      "5/5 - 0s - loss: 30.6402 - mae: 67.6001 - val_loss: 46.1829 - val_mae: 209.6185 - 86ms/epoch - 17ms/step\n",
      "Epoch 41/300\n",
      "5/5 - 0s - loss: 30.0542 - mae: 67.4594 - val_loss: 45.3956 - val_mae: 208.5350 - 92ms/epoch - 18ms/step\n",
      "Epoch 42/300\n",
      "5/5 - 0s - loss: 29.2577 - mae: 67.3979 - val_loss: 44.6467 - val_mae: 210.9727 - 100ms/epoch - 20ms/step\n",
      "Epoch 43/300\n",
      "5/5 - 0s - loss: 28.5210 - mae: 67.4187 - val_loss: 43.8730 - val_mae: 208.8844 - 82ms/epoch - 16ms/step\n",
      "Epoch 44/300\n",
      "5/5 - 0s - loss: 28.0814 - mae: 67.3412 - val_loss: 43.2702 - val_mae: 209.1344 - 89ms/epoch - 18ms/step\n",
      "Epoch 45/300\n",
      "5/5 - 0s - loss: 27.3751 - mae: 67.3566 - val_loss: 42.6910 - val_mae: 209.1408 - 83ms/epoch - 17ms/step\n",
      "Epoch 46/300\n",
      "5/5 - 0s - loss: 26.8223 - mae: 67.1276 - val_loss: 42.0864 - val_mae: 208.8836 - 87ms/epoch - 17ms/step\n",
      "Epoch 47/300\n",
      "5/5 - 0s - loss: 26.2645 - mae: 66.9706 - val_loss: 41.4437 - val_mae: 209.8372 - 84ms/epoch - 17ms/step\n",
      "Epoch 48/300\n",
      "5/5 - 0s - loss: 25.7906 - mae: 66.9096 - val_loss: 40.6954 - val_mae: 209.4785 - 82ms/epoch - 16ms/step\n",
      "Epoch 49/300\n",
      "5/5 - 0s - loss: 25.2170 - mae: 67.0657 - val_loss: 40.0813 - val_mae: 208.9763 - 84ms/epoch - 17ms/step\n",
      "Epoch 50/300\n",
      "5/5 - 0s - loss: 25.0197 - mae: 66.9746 - val_loss: 39.5864 - val_mae: 208.3708 - 93ms/epoch - 19ms/step\n",
      "Epoch 51/300\n",
      "5/5 - 0s - loss: 24.2629 - mae: 66.7956 - val_loss: 38.9174 - val_mae: 209.3482 - 83ms/epoch - 17ms/step\n",
      "Epoch 52/300\n",
      "5/5 - 0s - loss: 24.0329 - mae: 66.6336 - val_loss: 38.4828 - val_mae: 209.2866 - 87ms/epoch - 17ms/step\n",
      "Epoch 53/300\n",
      "5/5 - 0s - loss: 23.5994 - mae: 66.6051 - val_loss: 37.9220 - val_mae: 209.1886 - 85ms/epoch - 17ms/step\n",
      "Epoch 54/300\n",
      "5/5 - 0s - loss: 23.2101 - mae: 66.6831 - val_loss: 37.3530 - val_mae: 208.5157 - 100ms/epoch - 20ms/step\n",
      "Epoch 55/300\n",
      "5/5 - 0s - loss: 22.8228 - mae: 66.6242 - val_loss: 36.9421 - val_mae: 209.8598 - 87ms/epoch - 17ms/step\n",
      "Epoch 56/300\n",
      "5/5 - 0s - loss: 22.5208 - mae: 66.4121 - val_loss: 36.3637 - val_mae: 208.4273 - 86ms/epoch - 17ms/step\n",
      "Epoch 57/300\n",
      "5/5 - 0s - loss: 22.2406 - mae: 66.5093 - val_loss: 35.8880 - val_mae: 208.7753 - 86ms/epoch - 17ms/step\n",
      "Epoch 58/300\n",
      "5/5 - 0s - loss: 21.9541 - mae: 66.3679 - val_loss: 35.4775 - val_mae: 208.4820 - 85ms/epoch - 17ms/step\n",
      "Epoch 59/300\n",
      "5/5 - 0s - loss: 21.7709 - mae: 66.5598 - val_loss: 34.9698 - val_mae: 208.3156 - 83ms/epoch - 17ms/step\n",
      "Epoch 60/300\n",
      "5/5 - 0s - loss: 21.3905 - mae: 66.2508 - val_loss: 34.5400 - val_mae: 208.2822 - 86ms/epoch - 17ms/step\n",
      "Epoch 61/300\n",
      "5/5 - 0s - loss: 21.1764 - mae: 66.4896 - val_loss: 34.0765 - val_mae: 210.0216 - 91ms/epoch - 18ms/step\n",
      "Epoch 62/300\n",
      "5/5 - 0s - loss: 20.9185 - mae: 66.2618 - val_loss: 33.7299 - val_mae: 210.8037 - 87ms/epoch - 17ms/step\n",
      "Epoch 63/300\n",
      "5/5 - 0s - loss: 20.7789 - mae: 66.2326 - val_loss: 33.4068 - val_mae: 208.9514 - 89ms/epoch - 18ms/step\n",
      "Epoch 64/300\n",
      "5/5 - 0s - loss: 20.4461 - mae: 66.1125 - val_loss: 32.9947 - val_mae: 206.8909 - 84ms/epoch - 17ms/step\n",
      "Epoch 65/300\n",
      "5/5 - 0s - loss: 20.2358 - mae: 65.9500 - val_loss: 32.6638 - val_mae: 208.3451 - 104ms/epoch - 21ms/step\n",
      "Epoch 66/300\n",
      "5/5 - 0s - loss: 20.0889 - mae: 65.9253 - val_loss: 32.3406 - val_mae: 205.1998 - 84ms/epoch - 17ms/step\n",
      "Epoch 67/300\n",
      "5/5 - 0s - loss: 19.8742 - mae: 65.8221 - val_loss: 32.0033 - val_mae: 206.5606 - 86ms/epoch - 17ms/step\n",
      "Epoch 68/300\n",
      "5/5 - 0s - loss: 19.6052 - mae: 65.8742 - val_loss: 31.6756 - val_mae: 209.7659 - 84ms/epoch - 17ms/step\n",
      "Epoch 69/300\n",
      "5/5 - 0s - loss: 19.4970 - mae: 65.8683 - val_loss: 31.4050 - val_mae: 206.9646 - 81ms/epoch - 16ms/step\n",
      "Epoch 70/300\n",
      "5/5 - 0s - loss: 19.2730 - mae: 65.7506 - val_loss: 31.0825 - val_mae: 206.7099 - 82ms/epoch - 16ms/step\n",
      "Epoch 71/300\n",
      "5/5 - 0s - loss: 19.1415 - mae: 65.6135 - val_loss: 30.7412 - val_mae: 206.7469 - 92ms/epoch - 18ms/step\n",
      "Epoch 72/300\n",
      "5/5 - 0s - loss: 18.9266 - mae: 65.9120 - val_loss: 30.4774 - val_mae: 207.9773 - 86ms/epoch - 17ms/step\n",
      "Epoch 73/300\n",
      "5/5 - 0s - loss: 18.7138 - mae: 65.5889 - val_loss: 30.1837 - val_mae: 209.6581 - 87ms/epoch - 17ms/step\n",
      "Epoch 74/300\n",
      "5/5 - 0s - loss: 18.6231 - mae: 65.4908 - val_loss: 29.9334 - val_mae: 207.3191 - 90ms/epoch - 18ms/step\n",
      "Epoch 75/300\n",
      "5/5 - 0s - loss: 18.4497 - mae: 65.3995 - val_loss: 29.6655 - val_mae: 207.6707 - 85ms/epoch - 17ms/step\n",
      "Epoch 76/300\n",
      "5/5 - 0s - loss: 18.2791 - mae: 65.3314 - val_loss: 29.3611 - val_mae: 206.5480 - 92ms/epoch - 18ms/step\n",
      "Epoch 77/300\n",
      "5/5 - 0s - loss: 18.1924 - mae: 65.4845 - val_loss: 29.1317 - val_mae: 207.6383 - 102ms/epoch - 20ms/step\n",
      "Epoch 78/300\n",
      "5/5 - 0s - loss: 17.9943 - mae: 65.4355 - val_loss: 28.8738 - val_mae: 206.9458 - 87ms/epoch - 17ms/step\n",
      "Epoch 79/300\n",
      "5/5 - 0s - loss: 17.8456 - mae: 65.2355 - val_loss: 28.6505 - val_mae: 208.0890 - 85ms/epoch - 17ms/step\n",
      "Epoch 80/300\n",
      "5/5 - 0s - loss: 17.7629 - mae: 65.2957 - val_loss: 28.3615 - val_mae: 208.8677 - 85ms/epoch - 17ms/step\n",
      "Epoch 81/300\n",
      "5/5 - 0s - loss: 17.6645 - mae: 65.0794 - val_loss: 28.1587 - val_mae: 209.8726 - 86ms/epoch - 17ms/step\n",
      "Epoch 82/300\n",
      "5/5 - 0s - loss: 17.6080 - mae: 65.2779 - val_loss: 27.9647 - val_mae: 204.3765 - 87ms/epoch - 17ms/step\n",
      "Epoch 83/300\n",
      "5/5 - 0s - loss: 17.3893 - mae: 64.9293 - val_loss: 27.7329 - val_mae: 211.9021 - 88ms/epoch - 18ms/step\n",
      "Epoch 84/300\n",
      "5/5 - 0s - loss: 17.3141 - mae: 65.1778 - val_loss: 27.5159 - val_mae: 209.7552 - 173ms/epoch - 35ms/step\n",
      "Epoch 85/300\n",
      "5/5 - 0s - loss: 17.1419 - mae: 65.0630 - val_loss: 27.2735 - val_mae: 210.1844 - 137ms/epoch - 27ms/step\n",
      "Epoch 86/300\n",
      "5/5 - 0s - loss: 17.0408 - mae: 64.8432 - val_loss: 27.0753 - val_mae: 208.3746 - 194ms/epoch - 39ms/step\n",
      "Epoch 87/300\n",
      "5/5 - 0s - loss: 16.9664 - mae: 64.8451 - val_loss: 26.8656 - val_mae: 208.6871 - 135ms/epoch - 27ms/step\n",
      "Epoch 88/300\n",
      "5/5 - 0s - loss: 16.8944 - mae: 64.5677 - val_loss: 26.6674 - val_mae: 207.1243 - 142ms/epoch - 28ms/step\n",
      "Epoch 89/300\n",
      "5/5 - 0s - loss: 16.7625 - mae: 64.5335 - val_loss: 26.4609 - val_mae: 208.9755 - 157ms/epoch - 31ms/step\n",
      "Epoch 90/300\n",
      "5/5 - 0s - loss: 16.6440 - mae: 64.4063 - val_loss: 26.2718 - val_mae: 206.8705 - 135ms/epoch - 27ms/step\n",
      "Epoch 91/300\n",
      "5/5 - 0s - loss: 16.5723 - mae: 64.5238 - val_loss: 26.0885 - val_mae: 206.9274 - 150ms/epoch - 30ms/step\n",
      "Epoch 92/300\n",
      "5/5 - 0s - loss: 16.4910 - mae: 64.6029 - val_loss: 25.9010 - val_mae: 209.2623 - 140ms/epoch - 28ms/step\n",
      "Epoch 93/300\n",
      "5/5 - 0s - loss: 16.4081 - mae: 64.6959 - val_loss: 25.7363 - val_mae: 207.1692 - 144ms/epoch - 29ms/step\n",
      "Epoch 94/300\n",
      "5/5 - 0s - loss: 16.3440 - mae: 64.5548 - val_loss: 25.6037 - val_mae: 207.0715 - 145ms/epoch - 29ms/step\n",
      "Epoch 95/300\n",
      "5/5 - 0s - loss: 16.2498 - mae: 64.5042 - val_loss: 25.4143 - val_mae: 208.4684 - 142ms/epoch - 28ms/step\n",
      "Epoch 96/300\n",
      "5/5 - 0s - loss: 16.1374 - mae: 64.3869 - val_loss: 25.2185 - val_mae: 206.8900 - 143ms/epoch - 29ms/step\n",
      "Epoch 97/300\n",
      "5/5 - 0s - loss: 16.0966 - mae: 64.3623 - val_loss: 25.0935 - val_mae: 209.9303 - 160ms/epoch - 32ms/step\n",
      "Epoch 98/300\n",
      "5/5 - 0s - loss: 16.0152 - mae: 64.3389 - val_loss: 24.9408 - val_mae: 205.6151 - 146ms/epoch - 29ms/step\n",
      "Epoch 99/300\n",
      "5/5 - 0s - loss: 15.9090 - mae: 64.3165 - val_loss: 24.7795 - val_mae: 207.5587 - 142ms/epoch - 28ms/step\n",
      "Epoch 100/300\n",
      "5/5 - 0s - loss: 15.8642 - mae: 64.1139 - val_loss: 24.6087 - val_mae: 208.3635 - 99ms/epoch - 20ms/step\n",
      "Epoch 101/300\n",
      "5/5 - 0s - loss: 15.7635 - mae: 64.0667 - val_loss: 24.4597 - val_mae: 207.8110 - 104ms/epoch - 21ms/step\n",
      "Epoch 102/300\n",
      "5/5 - 0s - loss: 15.7355 - mae: 64.1545 - val_loss: 24.2921 - val_mae: 205.8141 - 87ms/epoch - 17ms/step\n",
      "Epoch 103/300\n",
      "5/5 - 0s - loss: 15.7226 - mae: 64.1277 - val_loss: 24.1390 - val_mae: 206.3244 - 88ms/epoch - 18ms/step\n",
      "Epoch 104/300\n",
      "5/5 - 0s - loss: 15.5937 - mae: 64.2202 - val_loss: 24.0093 - val_mae: 208.4789 - 94ms/epoch - 19ms/step\n",
      "Epoch 105/300\n",
      "5/5 - 0s - loss: 15.5119 - mae: 64.2393 - val_loss: 23.8661 - val_mae: 205.7811 - 87ms/epoch - 17ms/step\n",
      "Epoch 106/300\n",
      "5/5 - 0s - loss: 15.4867 - mae: 63.7891 - val_loss: 23.7243 - val_mae: 206.5983 - 88ms/epoch - 18ms/step\n",
      "Epoch 107/300\n",
      "5/5 - 0s - loss: 15.4162 - mae: 63.9480 - val_loss: 23.6101 - val_mae: 206.3937 - 92ms/epoch - 18ms/step\n",
      "Epoch 108/300\n",
      "5/5 - 0s - loss: 15.3474 - mae: 63.9018 - val_loss: 23.4896 - val_mae: 207.6943 - 89ms/epoch - 18ms/step\n",
      "Epoch 109/300\n",
      "5/5 - 0s - loss: 15.2956 - mae: 63.8867 - val_loss: 23.3801 - val_mae: 207.2420 - 87ms/epoch - 17ms/step\n",
      "Epoch 110/300\n",
      "5/5 - 0s - loss: 15.2935 - mae: 63.9050 - val_loss: 23.2938 - val_mae: 208.9427 - 87ms/epoch - 17ms/step\n",
      "Epoch 111/300\n",
      "5/5 - 0s - loss: 15.2457 - mae: 63.8600 - val_loss: 23.1538 - val_mae: 207.1178 - 88ms/epoch - 18ms/step\n",
      "Epoch 112/300\n",
      "5/5 - 0s - loss: 15.1300 - mae: 63.6367 - val_loss: 23.0328 - val_mae: 210.9284 - 108ms/epoch - 22ms/step\n",
      "Epoch 113/300\n",
      "5/5 - 0s - loss: 15.0862 - mae: 63.5987 - val_loss: 22.9326 - val_mae: 207.2947 - 90ms/epoch - 18ms/step\n",
      "Epoch 114/300\n",
      "5/5 - 0s - loss: 15.0391 - mae: 63.4892 - val_loss: 22.8228 - val_mae: 204.9431 - 88ms/epoch - 18ms/step\n",
      "Epoch 115/300\n",
      "5/5 - 0s - loss: 14.9808 - mae: 63.4543 - val_loss: 22.7042 - val_mae: 206.1672 - 96ms/epoch - 19ms/step\n",
      "Epoch 116/300\n",
      "5/5 - 0s - loss: 14.9433 - mae: 63.1867 - val_loss: 22.6076 - val_mae: 208.2058 - 94ms/epoch - 19ms/step\n",
      "Epoch 117/300\n",
      "5/5 - 0s - loss: 14.8834 - mae: 63.6494 - val_loss: 22.5257 - val_mae: 206.5676 - 88ms/epoch - 18ms/step\n",
      "Epoch 118/300\n",
      "5/5 - 0s - loss: 14.8573 - mae: 63.6429 - val_loss: 22.4557 - val_mae: 206.3044 - 89ms/epoch - 18ms/step\n",
      "Epoch 119/300\n",
      "5/5 - 0s - loss: 14.8106 - mae: 63.4311 - val_loss: 22.3702 - val_mae: 206.2968 - 93ms/epoch - 19ms/step\n",
      "Epoch 120/300\n",
      "5/5 - 0s - loss: 14.7699 - mae: 63.2816 - val_loss: 22.2793 - val_mae: 207.5389 - 92ms/epoch - 18ms/step\n",
      "Epoch 121/300\n",
      "5/5 - 0s - loss: 14.7340 - mae: 63.2893 - val_loss: 22.1738 - val_mae: 205.8901 - 91ms/epoch - 18ms/step\n",
      "Epoch 122/300\n",
      "5/5 - 0s - loss: 14.6594 - mae: 63.1050 - val_loss: 22.1000 - val_mae: 209.2907 - 94ms/epoch - 19ms/step\n",
      "Epoch 123/300\n",
      "5/5 - 0s - loss: 14.6391 - mae: 62.8434 - val_loss: 22.0047 - val_mae: 206.0403 - 101ms/epoch - 20ms/step\n",
      "Epoch 124/300\n",
      "5/5 - 0s - loss: 14.6063 - mae: 63.1042 - val_loss: 21.9075 - val_mae: 203.8643 - 89ms/epoch - 18ms/step\n",
      "Epoch 125/300\n",
      "5/5 - 0s - loss: 14.5363 - mae: 63.4093 - val_loss: 21.8235 - val_mae: 206.3100 - 97ms/epoch - 19ms/step\n",
      "Epoch 126/300\n",
      "5/5 - 0s - loss: 14.5289 - mae: 63.1330 - val_loss: 21.7466 - val_mae: 207.2941 - 91ms/epoch - 18ms/step\n",
      "Epoch 127/300\n",
      "5/5 - 0s - loss: 14.5367 - mae: 63.0253 - val_loss: 21.6974 - val_mae: 208.9348 - 98ms/epoch - 20ms/step\n",
      "Epoch 128/300\n",
      "5/5 - 0s - loss: 14.4195 - mae: 62.7094 - val_loss: 21.6229 - val_mae: 207.9587 - 89ms/epoch - 18ms/step\n",
      "Epoch 129/300\n",
      "5/5 - 0s - loss: 14.4196 - mae: 62.8747 - val_loss: 21.5426 - val_mae: 206.2345 - 87ms/epoch - 17ms/step\n",
      "Epoch 130/300\n",
      "5/5 - 0s - loss: 14.4100 - mae: 63.0596 - val_loss: 21.4414 - val_mae: 204.8941 - 117ms/epoch - 23ms/step\n",
      "Epoch 131/300\n",
      "5/5 - 0s - loss: 14.3237 - mae: 62.7050 - val_loss: 21.3694 - val_mae: 206.5025 - 90ms/epoch - 18ms/step\n",
      "Epoch 132/300\n",
      "5/5 - 0s - loss: 14.2789 - mae: 63.0033 - val_loss: 21.3151 - val_mae: 207.0836 - 103ms/epoch - 21ms/step\n",
      "Epoch 133/300\n",
      "5/5 - 0s - loss: 14.2611 - mae: 62.8803 - val_loss: 21.2379 - val_mae: 206.3485 - 104ms/epoch - 21ms/step\n",
      "Epoch 134/300\n",
      "5/5 - 0s - loss: 14.2455 - mae: 62.6206 - val_loss: 21.1614 - val_mae: 204.6929 - 90ms/epoch - 18ms/step\n",
      "Epoch 135/300\n",
      "5/5 - 0s - loss: 14.2293 - mae: 63.0108 - val_loss: 21.0754 - val_mae: 207.0806 - 95ms/epoch - 19ms/step\n",
      "Epoch 136/300\n",
      "5/5 - 0s - loss: 14.1815 - mae: 62.5736 - val_loss: 21.0219 - val_mae: 208.4518 - 96ms/epoch - 19ms/step\n",
      "Epoch 137/300\n",
      "5/5 - 0s - loss: 14.1442 - mae: 62.6551 - val_loss: 20.9519 - val_mae: 207.5495 - 92ms/epoch - 18ms/step\n",
      "Epoch 138/300\n",
      "5/5 - 0s - loss: 14.1141 - mae: 62.4188 - val_loss: 20.9050 - val_mae: 203.3359 - 89ms/epoch - 18ms/step\n",
      "Epoch 139/300\n",
      "5/5 - 0s - loss: 14.0680 - mae: 62.5393 - val_loss: 20.8507 - val_mae: 207.1221 - 86ms/epoch - 17ms/step\n",
      "Epoch 140/300\n",
      "5/5 - 0s - loss: 14.0539 - mae: 62.2825 - val_loss: 20.7975 - val_mae: 203.4335 - 88ms/epoch - 18ms/step\n",
      "Epoch 141/300\n",
      "5/5 - 0s - loss: 14.0369 - mae: 62.6074 - val_loss: 20.7440 - val_mae: 205.4946 - 93ms/epoch - 19ms/step\n",
      "Epoch 142/300\n",
      "5/5 - 0s - loss: 14.0232 - mae: 62.4023 - val_loss: 20.7004 - val_mae: 208.0812 - 89ms/epoch - 18ms/step\n",
      "Epoch 143/300\n",
      "5/5 - 0s - loss: 14.0167 - mae: 62.4628 - val_loss: 20.6210 - val_mae: 207.3753 - 89ms/epoch - 18ms/step\n",
      "Epoch 144/300\n",
      "5/5 - 0s - loss: 13.9521 - mae: 62.4482 - val_loss: 20.5693 - val_mae: 208.8117 - 101ms/epoch - 20ms/step\n",
      "Epoch 145/300\n",
      "5/5 - 0s - loss: 13.9095 - mae: 62.4087 - val_loss: 20.5175 - val_mae: 205.0885 - 88ms/epoch - 18ms/step\n",
      "Epoch 146/300\n",
      "5/5 - 0s - loss: 13.8882 - mae: 62.0934 - val_loss: 20.4644 - val_mae: 207.1580 - 99ms/epoch - 20ms/step\n",
      "Epoch 147/300\n",
      "5/5 - 0s - loss: 13.8552 - mae: 62.1217 - val_loss: 20.4045 - val_mae: 204.7224 - 85ms/epoch - 17ms/step\n",
      "Epoch 148/300\n",
      "5/5 - 0s - loss: 13.8807 - mae: 61.9595 - val_loss: 20.3748 - val_mae: 203.6303 - 89ms/epoch - 18ms/step\n",
      "Epoch 149/300\n",
      "5/5 - 0s - loss: 13.8440 - mae: 62.0892 - val_loss: 20.3339 - val_mae: 207.0992 - 86ms/epoch - 17ms/step\n",
      "Epoch 150/300\n",
      "5/5 - 0s - loss: 13.7944 - mae: 62.1479 - val_loss: 20.2710 - val_mae: 206.6542 - 88ms/epoch - 18ms/step\n",
      "Epoch 151/300\n",
      "5/5 - 0s - loss: 13.7909 - mae: 62.2908 - val_loss: 20.2207 - val_mae: 205.7594 - 98ms/epoch - 20ms/step\n",
      "Epoch 152/300\n",
      "5/5 - 0s - loss: 13.7572 - mae: 62.2677 - val_loss: 20.1636 - val_mae: 208.8992 - 93ms/epoch - 19ms/step\n",
      "Epoch 153/300\n",
      "5/5 - 0s - loss: 13.7340 - mae: 61.9203 - val_loss: 20.1092 - val_mae: 207.4898 - 88ms/epoch - 18ms/step\n",
      "Epoch 154/300\n",
      "5/5 - 0s - loss: 13.7013 - mae: 62.0994 - val_loss: 20.0595 - val_mae: 207.9250 - 83ms/epoch - 17ms/step\n",
      "Epoch 155/300\n",
      "5/5 - 0s - loss: 13.7372 - mae: 61.9890 - val_loss: 20.0509 - val_mae: 207.3517 - 107ms/epoch - 21ms/step\n",
      "Epoch 156/300\n",
      "5/5 - 0s - loss: 13.6764 - mae: 61.7055 - val_loss: 20.0243 - val_mae: 206.3038 - 91ms/epoch - 18ms/step\n",
      "Epoch 157/300\n",
      "5/5 - 0s - loss: 13.6274 - mae: 61.9289 - val_loss: 19.9706 - val_mae: 205.0559 - 91ms/epoch - 18ms/step\n",
      "Epoch 158/300\n",
      "5/5 - 0s - loss: 13.6312 - mae: 61.5234 - val_loss: 19.9363 - val_mae: 206.3332 - 88ms/epoch - 18ms/step\n",
      "Epoch 159/300\n",
      "5/5 - 0s - loss: 13.5871 - mae: 61.6948 - val_loss: 19.8955 - val_mae: 209.2988 - 86ms/epoch - 17ms/step\n",
      "Epoch 160/300\n",
      "5/5 - 0s - loss: 13.5841 - mae: 61.7725 - val_loss: 19.8437 - val_mae: 207.3424 - 88ms/epoch - 18ms/step\n",
      "Epoch 161/300\n",
      "5/5 - 0s - loss: 13.5594 - mae: 61.7251 - val_loss: 19.8100 - val_mae: 205.4156 - 84ms/epoch - 17ms/step\n",
      "Epoch 162/300\n",
      "5/5 - 0s - loss: 13.5310 - mae: 61.7099 - val_loss: 19.7788 - val_mae: 205.5004 - 85ms/epoch - 17ms/step\n",
      "Epoch 163/300\n",
      "5/5 - 0s - loss: 13.4993 - mae: 61.8658 - val_loss: 19.7380 - val_mae: 207.1686 - 84ms/epoch - 17ms/step\n",
      "Epoch 164/300\n",
      "5/5 - 0s - loss: 13.5119 - mae: 61.4921 - val_loss: 19.7012 - val_mae: 207.7327 - 86ms/epoch - 17ms/step\n",
      "Epoch 165/300\n",
      "5/5 - 0s - loss: 13.5145 - mae: 61.5285 - val_loss: 19.6772 - val_mae: 201.8999 - 105ms/epoch - 21ms/step\n",
      "Epoch 166/300\n",
      "5/5 - 0s - loss: 13.4711 - mae: 61.5247 - val_loss: 19.6461 - val_mae: 205.0449 - 98ms/epoch - 20ms/step\n",
      "Epoch 167/300\n",
      "5/5 - 0s - loss: 13.4304 - mae: 61.8113 - val_loss: 19.6153 - val_mae: 208.2118 - 106ms/epoch - 21ms/step\n",
      "Epoch 168/300\n",
      "5/5 - 0s - loss: 13.4341 - mae: 61.3683 - val_loss: 19.5844 - val_mae: 207.3322 - 85ms/epoch - 17ms/step\n",
      "Epoch 169/300\n",
      "5/5 - 0s - loss: 13.4439 - mae: 61.2780 - val_loss: 19.5355 - val_mae: 208.4909 - 86ms/epoch - 17ms/step\n",
      "Epoch 170/300\n",
      "5/5 - 0s - loss: 13.3969 - mae: 61.5770 - val_loss: 19.4976 - val_mae: 206.9920 - 89ms/epoch - 18ms/step\n",
      "Epoch 171/300\n",
      "5/5 - 0s - loss: 13.3775 - mae: 61.3315 - val_loss: 19.4673 - val_mae: 207.7601 - 87ms/epoch - 17ms/step\n",
      "Epoch 172/300\n",
      "5/5 - 0s - loss: 13.3579 - mae: 61.3979 - val_loss: 19.4388 - val_mae: 206.6659 - 87ms/epoch - 17ms/step\n",
      "Epoch 173/300\n",
      "5/5 - 0s - loss: 13.3681 - mae: 61.5263 - val_loss: 19.4057 - val_mae: 203.7237 - 86ms/epoch - 17ms/step\n",
      "Epoch 174/300\n",
      "5/5 - 0s - loss: 13.3463 - mae: 61.5750 - val_loss: 19.3884 - val_mae: 205.8947 - 90ms/epoch - 18ms/step\n",
      "Epoch 175/300\n",
      "5/5 - 0s - loss: 13.3050 - mae: 61.4158 - val_loss: 19.3569 - val_mae: 208.2041 - 86ms/epoch - 17ms/step\n",
      "Epoch 176/300\n",
      "5/5 - 0s - loss: 13.2998 - mae: 61.5220 - val_loss: 19.3157 - val_mae: 202.9697 - 88ms/epoch - 18ms/step\n",
      "Epoch 177/300\n",
      "5/5 - 0s - loss: 13.2833 - mae: 61.0745 - val_loss: 19.2882 - val_mae: 207.6587 - 103ms/epoch - 21ms/step\n",
      "Epoch 178/300\n",
      "5/5 - 0s - loss: 13.2711 - mae: 61.1459 - val_loss: 19.2521 - val_mae: 207.1827 - 98ms/epoch - 20ms/step\n",
      "Epoch 179/300\n",
      "5/5 - 0s - loss: 13.2642 - mae: 61.1265 - val_loss: 19.2215 - val_mae: 207.2500 - 90ms/epoch - 18ms/step\n",
      "Epoch 180/300\n",
      "5/5 - 0s - loss: 13.2331 - mae: 61.1422 - val_loss: 19.1937 - val_mae: 204.1297 - 111ms/epoch - 22ms/step\n",
      "Epoch 181/300\n",
      "5/5 - 0s - loss: 13.2616 - mae: 61.0252 - val_loss: 19.1647 - val_mae: 206.6389 - 94ms/epoch - 19ms/step\n",
      "Epoch 182/300\n",
      "5/5 - 0s - loss: 13.2214 - mae: 61.2678 - val_loss: 19.1464 - val_mae: 207.0871 - 109ms/epoch - 22ms/step\n",
      "Epoch 183/300\n",
      "5/5 - 0s - loss: 13.2007 - mae: 60.8842 - val_loss: 19.1190 - val_mae: 207.2124 - 89ms/epoch - 18ms/step\n",
      "Epoch 184/300\n",
      "5/5 - 0s - loss: 13.1889 - mae: 60.9113 - val_loss: 19.0969 - val_mae: 204.8615 - 88ms/epoch - 18ms/step\n",
      "Epoch 185/300\n",
      "5/5 - 0s - loss: 13.1794 - mae: 61.0357 - val_loss: 19.0577 - val_mae: 203.4966 - 89ms/epoch - 18ms/step\n",
      "Epoch 186/300\n",
      "5/5 - 0s - loss: 13.1611 - mae: 60.7398 - val_loss: 19.0362 - val_mae: 200.4439 - 82ms/epoch - 16ms/step\n",
      "Epoch 187/300\n",
      "5/5 - 0s - loss: 13.1646 - mae: 60.7766 - val_loss: 19.0187 - val_mae: 203.2013 - 84ms/epoch - 17ms/step\n",
      "Epoch 188/300\n",
      "5/5 - 0s - loss: 13.1323 - mae: 60.9632 - val_loss: 18.9951 - val_mae: 203.7123 - 106ms/epoch - 21ms/step\n",
      "Epoch 189/300\n",
      "5/5 - 0s - loss: 13.1625 - mae: 60.8513 - val_loss: 18.9760 - val_mae: 206.7327 - 88ms/epoch - 18ms/step\n",
      "Epoch 190/300\n",
      "5/5 - 0s - loss: 13.0970 - mae: 60.7203 - val_loss: 18.9508 - val_mae: 206.5921 - 87ms/epoch - 17ms/step\n",
      "Epoch 191/300\n",
      "5/5 - 0s - loss: 13.1138 - mae: 60.9454 - val_loss: 18.9402 - val_mae: 207.0608 - 89ms/epoch - 18ms/step\n",
      "Epoch 192/300\n",
      "5/5 - 0s - loss: 13.0808 - mae: 60.7201 - val_loss: 18.9129 - val_mae: 202.8775 - 87ms/epoch - 17ms/step\n",
      "Epoch 193/300\n",
      "5/5 - 0s - loss: 13.0712 - mae: 60.2410 - val_loss: 18.8921 - val_mae: 205.3418 - 85ms/epoch - 17ms/step\n",
      "Epoch 194/300\n",
      "5/5 - 0s - loss: 13.0557 - mae: 60.4851 - val_loss: 18.8717 - val_mae: 204.0703 - 87ms/epoch - 17ms/step\n",
      "Epoch 195/300\n",
      "5/5 - 0s - loss: 13.0625 - mae: 60.3441 - val_loss: 18.8423 - val_mae: 201.4786 - 100ms/epoch - 20ms/step\n",
      "Epoch 196/300\n",
      "5/5 - 0s - loss: 13.0382 - mae: 60.4555 - val_loss: 18.8160 - val_mae: 205.7634 - 83ms/epoch - 17ms/step\n",
      "Epoch 197/300\n",
      "5/5 - 0s - loss: 13.0312 - mae: 60.0815 - val_loss: 18.7949 - val_mae: 210.0589 - 84ms/epoch - 17ms/step\n",
      "Epoch 198/300\n",
      "5/5 - 0s - loss: 13.0179 - mae: 60.3328 - val_loss: 18.7754 - val_mae: 206.1412 - 82ms/epoch - 16ms/step\n",
      "Epoch 199/300\n",
      "5/5 - 0s - loss: 13.0035 - mae: 60.1971 - val_loss: 18.7638 - val_mae: 205.6651 - 104ms/epoch - 21ms/step\n",
      "Epoch 200/300\n",
      "5/5 - 0s - loss: 12.9918 - mae: 60.2803 - val_loss: 18.7408 - val_mae: 205.5218 - 99ms/epoch - 20ms/step\n",
      "Epoch 201/300\n",
      "5/5 - 0s - loss: 12.9744 - mae: 60.3957 - val_loss: 18.7241 - val_mae: 206.0406 - 80ms/epoch - 16ms/step\n",
      "Epoch 202/300\n",
      "5/5 - 0s - loss: 12.9922 - mae: 60.1369 - val_loss: 18.7019 - val_mae: 206.7848 - 81ms/epoch - 16ms/step\n",
      "Epoch 203/300\n",
      "5/5 - 0s - loss: 12.9699 - mae: 60.3577 - val_loss: 18.6797 - val_mae: 205.2025 - 85ms/epoch - 17ms/step\n",
      "Epoch 204/300\n",
      "5/5 - 0s - loss: 12.9389 - mae: 60.1728 - val_loss: 18.6661 - val_mae: 208.2940 - 85ms/epoch - 17ms/step\n",
      "Epoch 205/300\n",
      "5/5 - 0s - loss: 12.9396 - mae: 60.1266 - val_loss: 18.6476 - val_mae: 203.7451 - 112ms/epoch - 22ms/step\n",
      "Epoch 206/300\n",
      "5/5 - 0s - loss: 12.9230 - mae: 60.0715 - val_loss: 18.6348 - val_mae: 204.2830 - 141ms/epoch - 28ms/step\n",
      "Epoch 207/300\n",
      "5/5 - 0s - loss: 12.9114 - mae: 60.0413 - val_loss: 18.6157 - val_mae: 203.6563 - 151ms/epoch - 30ms/step\n",
      "Epoch 208/300\n",
      "5/5 - 0s - loss: 12.9320 - mae: 60.2582 - val_loss: 18.5968 - val_mae: 207.3862 - 156ms/epoch - 31ms/step\n",
      "Epoch 209/300\n",
      "5/5 - 0s - loss: 12.9010 - mae: 60.2037 - val_loss: 18.5839 - val_mae: 203.7110 - 138ms/epoch - 28ms/step\n",
      "Epoch 210/300\n",
      "5/5 - 0s - loss: 12.8853 - mae: 59.8799 - val_loss: 18.5693 - val_mae: 204.1930 - 135ms/epoch - 27ms/step\n",
      "Epoch 211/300\n",
      "5/5 - 0s - loss: 12.8930 - mae: 60.3327 - val_loss: 18.5518 - val_mae: 206.4677 - 136ms/epoch - 27ms/step\n",
      "Epoch 212/300\n",
      "5/5 - 0s - loss: 12.8590 - mae: 59.8959 - val_loss: 18.5335 - val_mae: 206.1317 - 135ms/epoch - 27ms/step\n",
      "Epoch 213/300\n",
      "5/5 - 0s - loss: 12.8570 - mae: 59.7754 - val_loss: 18.5163 - val_mae: 207.2213 - 147ms/epoch - 29ms/step\n",
      "Epoch 214/300\n",
      "5/5 - 0s - loss: 12.8510 - mae: 60.1957 - val_loss: 18.4993 - val_mae: 207.6566 - 133ms/epoch - 27ms/step\n",
      "Epoch 215/300\n",
      "5/5 - 0s - loss: 12.8420 - mae: 60.0556 - val_loss: 18.4845 - val_mae: 206.7003 - 147ms/epoch - 29ms/step\n",
      "Epoch 216/300\n",
      "5/5 - 0s - loss: 12.8308 - mae: 59.9032 - val_loss: 18.4696 - val_mae: 208.0696 - 157ms/epoch - 31ms/step\n",
      "Epoch 217/300\n",
      "5/5 - 0s - loss: 12.8286 - mae: 59.6470 - val_loss: 18.4546 - val_mae: 205.8994 - 143ms/epoch - 29ms/step\n",
      "Epoch 218/300\n",
      "5/5 - 0s - loss: 12.8142 - mae: 59.9727 - val_loss: 18.4353 - val_mae: 203.3892 - 133ms/epoch - 27ms/step\n",
      "Epoch 219/300\n",
      "5/5 - 0s - loss: 12.8098 - mae: 60.0539 - val_loss: 18.4193 - val_mae: 206.8394 - 153ms/epoch - 31ms/step\n",
      "Epoch 220/300\n",
      "5/5 - 0s - loss: 12.7828 - mae: 59.6923 - val_loss: 18.4032 - val_mae: 202.5030 - 155ms/epoch - 31ms/step\n",
      "Epoch 221/300\n",
      "5/5 - 0s - loss: 12.8032 - mae: 59.8946 - val_loss: 18.3918 - val_mae: 208.4190 - 81ms/epoch - 16ms/step\n",
      "Epoch 222/300\n",
      "5/5 - 0s - loss: 12.7816 - mae: 59.8170 - val_loss: 18.3800 - val_mae: 203.5630 - 88ms/epoch - 18ms/step\n",
      "Epoch 223/300\n",
      "5/5 - 0s - loss: 12.7724 - mae: 59.6366 - val_loss: 18.3698 - val_mae: 204.1067 - 85ms/epoch - 17ms/step\n",
      "Epoch 224/300\n",
      "5/5 - 0s - loss: 12.7718 - mae: 59.8361 - val_loss: 18.3542 - val_mae: 204.3173 - 95ms/epoch - 19ms/step\n",
      "Epoch 225/300\n",
      "5/5 - 0s - loss: 12.7595 - mae: 59.5191 - val_loss: 18.3400 - val_mae: 206.9940 - 108ms/epoch - 22ms/step\n",
      "Epoch 226/300\n",
      "5/5 - 0s - loss: 12.7485 - mae: 59.3126 - val_loss: 18.3277 - val_mae: 210.3044 - 85ms/epoch - 17ms/step\n",
      "Epoch 227/300\n",
      "5/5 - 0s - loss: 12.7433 - mae: 59.6633 - val_loss: 18.3097 - val_mae: 204.6685 - 83ms/epoch - 17ms/step\n",
      "Epoch 228/300\n",
      "5/5 - 0s - loss: 12.7354 - mae: 59.5058 - val_loss: 18.3005 - val_mae: 202.8111 - 82ms/epoch - 16ms/step\n",
      "Epoch 229/300\n",
      "5/5 - 0s - loss: 12.7430 - mae: 59.5454 - val_loss: 18.2823 - val_mae: 205.9208 - 83ms/epoch - 17ms/step\n",
      "Epoch 230/300\n",
      "5/5 - 0s - loss: 12.7143 - mae: 59.3364 - val_loss: 18.2689 - val_mae: 203.8058 - 86ms/epoch - 17ms/step\n",
      "Epoch 231/300\n",
      "5/5 - 0s - loss: 12.7217 - mae: 59.4785 - val_loss: 18.2562 - val_mae: 203.3876 - 84ms/epoch - 17ms/step\n",
      "Epoch 232/300\n",
      "5/5 - 0s - loss: 12.7181 - mae: 59.5494 - val_loss: 18.2413 - val_mae: 206.1622 - 84ms/epoch - 17ms/step\n",
      "Epoch 233/300\n",
      "5/5 - 0s - loss: 12.7012 - mae: 59.5816 - val_loss: 18.2359 - val_mae: 203.3817 - 92ms/epoch - 18ms/step\n",
      "Epoch 234/300\n",
      "5/5 - 0s - loss: 12.6814 - mae: 59.0953 - val_loss: 18.2220 - val_mae: 205.5371 - 87ms/epoch - 17ms/step\n",
      "Epoch 235/300\n",
      "5/5 - 0s - loss: 12.6802 - mae: 59.5251 - val_loss: 18.2152 - val_mae: 207.4475 - 84ms/epoch - 17ms/step\n",
      "Epoch 236/300\n",
      "5/5 - 0s - loss: 12.6771 - mae: 59.2430 - val_loss: 18.2094 - val_mae: 202.8213 - 100ms/epoch - 20ms/step\n",
      "Epoch 237/300\n",
      "5/5 - 0s - loss: 12.6686 - mae: 59.8475 - val_loss: 18.1941 - val_mae: 205.6518 - 84ms/epoch - 17ms/step\n",
      "Epoch 238/300\n",
      "5/5 - 0s - loss: 12.6650 - mae: 59.1890 - val_loss: 18.1827 - val_mae: 204.9173 - 90ms/epoch - 18ms/step\n",
      "Epoch 239/300\n",
      "5/5 - 0s - loss: 12.6576 - mae: 59.3968 - val_loss: 18.1736 - val_mae: 201.3027 - 86ms/epoch - 17ms/step\n",
      "Epoch 240/300\n",
      "5/5 - 0s - loss: 12.6689 - mae: 59.1996 - val_loss: 18.1562 - val_mae: 207.0085 - 87ms/epoch - 17ms/step\n",
      "Epoch 241/300\n",
      "5/5 - 0s - loss: 12.6562 - mae: 59.1084 - val_loss: 18.1418 - val_mae: 202.5444 - 89ms/epoch - 18ms/step\n",
      "Epoch 242/300\n",
      "5/5 - 0s - loss: 12.6344 - mae: 59.0452 - val_loss: 18.1329 - val_mae: 204.5663 - 85ms/epoch - 17ms/step\n",
      "Epoch 243/300\n",
      "5/5 - 0s - loss: 12.6317 - mae: 59.1184 - val_loss: 18.1235 - val_mae: 204.7528 - 84ms/epoch - 17ms/step\n",
      "Epoch 244/300\n",
      "5/5 - 0s - loss: 12.6212 - mae: 59.0236 - val_loss: 18.1114 - val_mae: 203.0020 - 91ms/epoch - 18ms/step\n",
      "Epoch 245/300\n",
      "5/5 - 0s - loss: 12.6069 - mae: 58.8776 - val_loss: 18.1021 - val_mae: 202.7171 - 86ms/epoch - 17ms/step\n",
      "Epoch 246/300\n",
      "5/5 - 0s - loss: 12.6115 - mae: 59.0268 - val_loss: 18.0955 - val_mae: 201.5893 - 86ms/epoch - 17ms/step\n",
      "Epoch 247/300\n",
      "5/5 - 0s - loss: 12.6114 - mae: 58.9554 - val_loss: 18.0886 - val_mae: 206.2776 - 95ms/epoch - 19ms/step\n",
      "Epoch 248/300\n",
      "5/5 - 0s - loss: 12.5997 - mae: 58.7615 - val_loss: 18.0814 - val_mae: 205.2165 - 90ms/epoch - 18ms/step\n",
      "Epoch 249/300\n",
      "5/5 - 0s - loss: 12.5897 - mae: 58.8802 - val_loss: 18.0694 - val_mae: 200.9368 - 83ms/epoch - 17ms/step\n",
      "Epoch 250/300\n",
      "5/5 - 0s - loss: 12.5873 - mae: 58.9922 - val_loss: 18.0625 - val_mae: 202.3696 - 88ms/epoch - 18ms/step\n",
      "Epoch 251/300\n",
      "5/5 - 0s - loss: 12.5840 - mae: 59.0017 - val_loss: 18.0566 - val_mae: 204.9837 - 85ms/epoch - 17ms/step\n",
      "Epoch 252/300\n",
      "5/5 - 0s - loss: 12.5877 - mae: 59.2368 - val_loss: 18.0504 - val_mae: 204.7942 - 85ms/epoch - 17ms/step\n",
      "Epoch 253/300\n",
      "5/5 - 0s - loss: 12.5671 - mae: 58.8550 - val_loss: 18.0397 - val_mae: 204.6738 - 84ms/epoch - 17ms/step\n",
      "Epoch 254/300\n",
      "5/5 - 0s - loss: 12.5594 - mae: 58.7030 - val_loss: 18.0297 - val_mae: 200.9927 - 85ms/epoch - 17ms/step\n",
      "Epoch 255/300\n",
      "5/5 - 0s - loss: 12.5573 - mae: 59.3477 - val_loss: 18.0188 - val_mae: 205.1182 - 90ms/epoch - 18ms/step\n",
      "Epoch 256/300\n",
      "5/5 - 0s - loss: 12.5575 - mae: 59.2907 - val_loss: 18.0068 - val_mae: 208.3101 - 89ms/epoch - 18ms/step\n",
      "Epoch 257/300\n",
      "5/5 - 0s - loss: 12.5477 - mae: 59.0276 - val_loss: 17.9973 - val_mae: 209.6541 - 86ms/epoch - 17ms/step\n",
      "Epoch 258/300\n",
      "5/5 - 0s - loss: 12.5309 - mae: 58.6839 - val_loss: 17.9871 - val_mae: 206.9599 - 83ms/epoch - 17ms/step\n",
      "Epoch 259/300\n",
      "5/5 - 0s - loss: 12.5288 - mae: 58.7046 - val_loss: 17.9805 - val_mae: 209.2577 - 103ms/epoch - 21ms/step\n",
      "Epoch 260/300\n",
      "5/5 - 0s - loss: 12.5245 - mae: 58.4496 - val_loss: 17.9755 - val_mae: 207.2798 - 82ms/epoch - 16ms/step\n",
      "Epoch 261/300\n",
      "5/5 - 0s - loss: 12.5179 - mae: 58.5181 - val_loss: 17.9685 - val_mae: 209.0672 - 84ms/epoch - 17ms/step\n",
      "Epoch 262/300\n",
      "5/5 - 0s - loss: 12.5167 - mae: 58.5580 - val_loss: 17.9618 - val_mae: 199.6989 - 85ms/epoch - 17ms/step\n",
      "Epoch 263/300\n",
      "5/5 - 0s - loss: 12.5114 - mae: 58.8658 - val_loss: 17.9564 - val_mae: 205.4235 - 79ms/epoch - 16ms/step\n",
      "Epoch 264/300\n",
      "5/5 - 0s - loss: 12.4991 - mae: 58.6433 - val_loss: 17.9468 - val_mae: 203.6892 - 81ms/epoch - 16ms/step\n",
      "Epoch 265/300\n",
      "5/5 - 0s - loss: 12.4974 - mae: 58.7831 - val_loss: 17.9398 - val_mae: 202.4665 - 85ms/epoch - 17ms/step\n",
      "Epoch 266/300\n",
      "5/5 - 0s - loss: 12.4944 - mae: 58.9602 - val_loss: 17.9326 - val_mae: 203.2707 - 93ms/epoch - 19ms/step\n",
      "Epoch 267/300\n",
      "5/5 - 0s - loss: 12.5043 - mae: 58.2482 - val_loss: 17.9234 - val_mae: 203.3190 - 90ms/epoch - 18ms/step\n",
      "Epoch 268/300\n",
      "5/5 - 0s - loss: 12.4857 - mae: 58.3990 - val_loss: 17.9137 - val_mae: 205.4053 - 85ms/epoch - 17ms/step\n",
      "Epoch 269/300\n",
      "5/5 - 0s - loss: 12.4690 - mae: 58.4456 - val_loss: 17.9057 - val_mae: 204.5526 - 87ms/epoch - 17ms/step\n",
      "Epoch 270/300\n",
      "5/5 - 0s - loss: 12.4812 - mae: 58.1875 - val_loss: 17.9007 - val_mae: 206.7475 - 92ms/epoch - 18ms/step\n",
      "Epoch 271/300\n",
      "5/5 - 0s - loss: 12.4746 - mae: 58.6685 - val_loss: 17.8917 - val_mae: 201.7806 - 95ms/epoch - 19ms/step\n",
      "Epoch 272/300\n",
      "5/5 - 0s - loss: 12.4577 - mae: 58.5379 - val_loss: 17.8854 - val_mae: 205.0613 - 87ms/epoch - 17ms/step\n",
      "Epoch 273/300\n",
      "5/5 - 0s - loss: 12.4517 - mae: 58.2805 - val_loss: 17.8784 - val_mae: 201.5002 - 83ms/epoch - 17ms/step\n",
      "Epoch 274/300\n",
      "5/5 - 0s - loss: 12.4446 - mae: 58.6862 - val_loss: 17.8701 - val_mae: 205.1674 - 85ms/epoch - 17ms/step\n",
      "Epoch 275/300\n",
      "5/5 - 0s - loss: 12.4377 - mae: 58.0768 - val_loss: 17.8635 - val_mae: 202.1184 - 82ms/epoch - 16ms/step\n",
      "Epoch 276/300\n",
      "5/5 - 0s - loss: 12.4503 - mae: 58.4256 - val_loss: 17.8546 - val_mae: 204.0002 - 84ms/epoch - 17ms/step\n",
      "Epoch 277/300\n",
      "5/5 - 0s - loss: 12.4347 - mae: 58.3452 - val_loss: 17.8484 - val_mae: 203.9420 - 95ms/epoch - 19ms/step\n",
      "Epoch 278/300\n",
      "5/5 - 0s - loss: 12.4249 - mae: 57.8551 - val_loss: 17.8441 - val_mae: 205.3476 - 90ms/epoch - 18ms/step\n",
      "Epoch 279/300\n",
      "5/5 - 0s - loss: 12.4260 - mae: 57.8562 - val_loss: 17.8395 - val_mae: 205.0881 - 91ms/epoch - 18ms/step\n",
      "Epoch 280/300\n",
      "5/5 - 0s - loss: 12.4078 - mae: 57.6583 - val_loss: 17.8315 - val_mae: 203.8870 - 90ms/epoch - 18ms/step\n",
      "Epoch 281/300\n",
      "5/5 - 0s - loss: 12.4063 - mae: 57.7485 - val_loss: 17.8227 - val_mae: 201.1570 - 83ms/epoch - 17ms/step\n",
      "Epoch 282/300\n",
      "5/5 - 0s - loss: 12.4047 - mae: 57.7986 - val_loss: 17.8167 - val_mae: 204.8075 - 102ms/epoch - 20ms/step\n",
      "Epoch 283/300\n",
      "5/5 - 0s - loss: 12.3973 - mae: 58.3140 - val_loss: 17.8116 - val_mae: 202.6595 - 85ms/epoch - 17ms/step\n",
      "Epoch 284/300\n",
      "5/5 - 0s - loss: 12.4056 - mae: 58.1183 - val_loss: 17.8070 - val_mae: 202.2787 - 81ms/epoch - 16ms/step\n",
      "Epoch 285/300\n",
      "5/5 - 0s - loss: 12.3920 - mae: 58.3976 - val_loss: 17.7992 - val_mae: 200.2897 - 82ms/epoch - 16ms/step\n",
      "Epoch 286/300\n",
      "5/5 - 0s - loss: 12.3875 - mae: 58.3055 - val_loss: 17.7925 - val_mae: 202.4673 - 86ms/epoch - 17ms/step\n",
      "Epoch 287/300\n",
      "5/5 - 0s - loss: 12.3799 - mae: 58.0241 - val_loss: 17.7844 - val_mae: 203.7723 - 83ms/epoch - 17ms/step\n",
      "Epoch 288/300\n",
      "5/5 - 0s - loss: 12.3799 - mae: 57.5927 - val_loss: 17.7779 - val_mae: 206.1115 - 94ms/epoch - 19ms/step\n",
      "Epoch 289/300\n",
      "5/5 - 0s - loss: 12.3738 - mae: 58.2444 - val_loss: 17.7719 - val_mae: 206.6849 - 92ms/epoch - 18ms/step\n",
      "Epoch 290/300\n",
      "5/5 - 0s - loss: 12.3675 - mae: 57.6975 - val_loss: 17.7667 - val_mae: 207.7788 - 88ms/epoch - 18ms/step\n",
      "Epoch 291/300\n",
      "5/5 - 0s - loss: 12.3726 - mae: 57.9934 - val_loss: 17.7601 - val_mae: 207.4945 - 84ms/epoch - 17ms/step\n",
      "Epoch 292/300\n",
      "5/5 - 0s - loss: 12.3547 - mae: 58.0247 - val_loss: 17.7557 - val_mae: 204.3298 - 87ms/epoch - 17ms/step\n",
      "Epoch 293/300\n",
      "5/5 - 0s - loss: 12.3573 - mae: 57.8245 - val_loss: 17.7500 - val_mae: 201.8261 - 101ms/epoch - 20ms/step\n",
      "Epoch 294/300\n",
      "5/5 - 0s - loss: 12.3675 - mae: 58.0759 - val_loss: 17.7464 - val_mae: 203.9362 - 85ms/epoch - 17ms/step\n",
      "Epoch 295/300\n",
      "5/5 - 0s - loss: 12.3394 - mae: 57.4470 - val_loss: 17.7415 - val_mae: 208.0865 - 83ms/epoch - 17ms/step\n",
      "Epoch 296/300\n",
      "5/5 - 0s - loss: 12.3443 - mae: 57.7948 - val_loss: 17.7364 - val_mae: 205.8396 - 80ms/epoch - 16ms/step\n",
      "Epoch 297/300\n",
      "5/5 - 0s - loss: 12.3352 - mae: 58.0092 - val_loss: 17.7320 - val_mae: 207.1115 - 80ms/epoch - 16ms/step\n",
      "Epoch 298/300\n",
      "5/5 - 0s - loss: 12.3298 - mae: 57.8756 - val_loss: 17.7265 - val_mae: 203.6205 - 85ms/epoch - 17ms/step\n",
      "Epoch 299/300\n",
      "5/5 - 0s - loss: 12.3375 - mae: 57.8000 - val_loss: 17.7180 - val_mae: 202.0783 - 88ms/epoch - 18ms/step\n",
      "Epoch 300/300\n",
      "5/5 - 0s - loss: 12.3277 - mae: 57.8408 - val_loss: 17.7121 - val_mae: 202.4005 - 82ms/epoch - 16ms/step\n",
      "Epoch 1/300\n",
      "5/5 - 1s - loss: 2955.9636 - mae: 87.8396 - val_loss: 475874496.0000 - val_mae: 143.9078 - 1s/epoch - 252ms/step\n",
      "Epoch 2/300\n",
      "5/5 - 0s - loss: 1540.6334 - mae: 87.8360 - val_loss: 3606886.0000 - val_mae: 144.6130 - 82ms/epoch - 16ms/step\n",
      "Epoch 3/300\n",
      "5/5 - 0s - loss: 1138.8553 - mae: 87.7783 - val_loss: 208408.1250 - val_mae: 144.4424 - 82ms/epoch - 16ms/step\n",
      "Epoch 4/300\n",
      "5/5 - 0s - loss: 919.4683 - mae: 87.7930 - val_loss: 20862.0273 - val_mae: 144.0007 - 82ms/epoch - 16ms/step\n",
      "Epoch 5/300\n",
      "5/5 - 0s - loss: 796.8602 - mae: 87.7418 - val_loss: 3268.6465 - val_mae: 143.9402 - 92ms/epoch - 18ms/step\n",
      "Epoch 6/300\n",
      "5/5 - 0s - loss: 687.2245 - mae: 87.7113 - val_loss: 950.1922 - val_mae: 144.2453 - 85ms/epoch - 17ms/step\n",
      "Epoch 7/300\n",
      "5/5 - 0s - loss: 607.1211 - mae: 87.7067 - val_loss: 442.2326 - val_mae: 143.7609 - 88ms/epoch - 18ms/step\n",
      "Epoch 8/300\n",
      "5/5 - 0s - loss: 543.6568 - mae: 87.6859 - val_loss: 265.5699 - val_mae: 144.1074 - 86ms/epoch - 17ms/step\n",
      "Epoch 9/300\n",
      "5/5 - 0s - loss: 487.2738 - mae: 87.5910 - val_loss: 186.6770 - val_mae: 143.9805 - 83ms/epoch - 17ms/step\n",
      "Epoch 10/300\n",
      "5/5 - 0s - loss: 442.7292 - mae: 87.5911 - val_loss: 150.0229 - val_mae: 143.1885 - 80ms/epoch - 16ms/step\n",
      "Epoch 11/300\n",
      "5/5 - 0s - loss: 400.9009 - mae: 87.5635 - val_loss: 127.2480 - val_mae: 143.7177 - 87ms/epoch - 17ms/step\n",
      "Epoch 12/300\n",
      "5/5 - 0s - loss: 363.8351 - mae: 87.5381 - val_loss: 110.2927 - val_mae: 144.6519 - 101ms/epoch - 20ms/step\n",
      "Epoch 13/300\n",
      "5/5 - 0s - loss: 332.4524 - mae: 87.5071 - val_loss: 96.5612 - val_mae: 143.5265 - 81ms/epoch - 16ms/step\n",
      "Epoch 14/300\n",
      "5/5 - 0s - loss: 302.0126 - mae: 87.4212 - val_loss: 84.9171 - val_mae: 142.6381 - 82ms/epoch - 16ms/step\n",
      "Epoch 15/300\n",
      "5/5 - 0s - loss: 274.7849 - mae: 87.3960 - val_loss: 75.0868 - val_mae: 143.3580 - 105ms/epoch - 21ms/step\n",
      "Epoch 16/300\n",
      "5/5 - 0s - loss: 249.5038 - mae: 87.4094 - val_loss: 67.7624 - val_mae: 142.6748 - 150ms/epoch - 30ms/step\n",
      "Epoch 17/300\n",
      "5/5 - 0s - loss: 223.5390 - mae: 87.2945 - val_loss: 61.3162 - val_mae: 143.0619 - 130ms/epoch - 26ms/step\n",
      "Epoch 18/300\n",
      "5/5 - 0s - loss: 206.8782 - mae: 87.2453 - val_loss: 56.3919 - val_mae: 143.0085 - 130ms/epoch - 26ms/step\n",
      "Epoch 19/300\n",
      "5/5 - 0s - loss: 190.6927 - mae: 87.1162 - val_loss: 52.0000 - val_mae: 142.3860 - 135ms/epoch - 27ms/step\n",
      "Epoch 20/300\n",
      "5/5 - 0s - loss: 172.0089 - mae: 87.1605 - val_loss: 48.1491 - val_mae: 142.6360 - 143ms/epoch - 29ms/step\n",
      "Epoch 21/300\n",
      "5/5 - 0s - loss: 159.4899 - mae: 87.0393 - val_loss: 44.9917 - val_mae: 142.2283 - 159ms/epoch - 32ms/step\n",
      "Epoch 22/300\n",
      "5/5 - 0s - loss: 147.3561 - mae: 87.0133 - val_loss: 42.7730 - val_mae: 142.7771 - 147ms/epoch - 29ms/step\n",
      "Epoch 23/300\n",
      "5/5 - 0s - loss: 139.8704 - mae: 86.9671 - val_loss: 40.4496 - val_mae: 141.5331 - 138ms/epoch - 28ms/step\n",
      "Epoch 24/300\n",
      "5/5 - 0s - loss: 126.3940 - mae: 86.8853 - val_loss: 38.9737 - val_mae: 141.0907 - 148ms/epoch - 30ms/step\n",
      "Epoch 25/300\n",
      "5/5 - 0s - loss: 116.4847 - mae: 86.7446 - val_loss: 37.0458 - val_mae: 141.2274 - 138ms/epoch - 28ms/step\n",
      "Epoch 26/300\n",
      "5/5 - 0s - loss: 111.9577 - mae: 86.6593 - val_loss: 35.3709 - val_mae: 141.2714 - 137ms/epoch - 27ms/step\n",
      "Epoch 27/300\n",
      "5/5 - 0s - loss: 107.6129 - mae: 86.6655 - val_loss: 34.0149 - val_mae: 141.0705 - 139ms/epoch - 28ms/step\n",
      "Epoch 28/300\n",
      "5/5 - 0s - loss: 98.6979 - mae: 86.6441 - val_loss: 33.0026 - val_mae: 141.0121 - 156ms/epoch - 31ms/step\n",
      "Epoch 29/300\n",
      "5/5 - 0s - loss: 93.1450 - mae: 86.4444 - val_loss: 32.0892 - val_mae: 141.5936 - 158ms/epoch - 32ms/step\n",
      "Epoch 30/300\n",
      "5/5 - 0s - loss: 90.3442 - mae: 86.5669 - val_loss: 31.1924 - val_mae: 141.1590 - 144ms/epoch - 29ms/step\n",
      "Epoch 31/300\n",
      "5/5 - 0s - loss: 85.3982 - mae: 86.3812 - val_loss: 30.4795 - val_mae: 140.0095 - 126ms/epoch - 25ms/step\n",
      "Epoch 32/300\n",
      "5/5 - 0s - loss: 82.8255 - mae: 86.4608 - val_loss: 29.6777 - val_mae: 140.8129 - 80ms/epoch - 16ms/step\n",
      "Epoch 33/300\n",
      "5/5 - 0s - loss: 78.9941 - mae: 86.3154 - val_loss: 28.9621 - val_mae: 140.0487 - 85ms/epoch - 17ms/step\n",
      "Epoch 34/300\n",
      "5/5 - 0s - loss: 76.2462 - mae: 86.2711 - val_loss: 28.2836 - val_mae: 139.1977 - 87ms/epoch - 17ms/step\n",
      "Epoch 35/300\n",
      "5/5 - 0s - loss: 72.8220 - mae: 86.1827 - val_loss: 27.5884 - val_mae: 139.4125 - 85ms/epoch - 17ms/step\n",
      "Epoch 36/300\n",
      "5/5 - 0s - loss: 68.1970 - mae: 86.0948 - val_loss: 27.0176 - val_mae: 140.4651 - 80ms/epoch - 16ms/step\n",
      "Epoch 37/300\n",
      "5/5 - 0s - loss: 66.4355 - mae: 86.0086 - val_loss: 26.5368 - val_mae: 141.0618 - 100ms/epoch - 20ms/step\n",
      "Epoch 38/300\n",
      "5/5 - 0s - loss: 64.4417 - mae: 86.1330 - val_loss: 26.1027 - val_mae: 139.6071 - 84ms/epoch - 17ms/step\n",
      "Epoch 39/300\n",
      "5/5 - 0s - loss: 63.1908 - mae: 85.9788 - val_loss: 25.6725 - val_mae: 139.6374 - 83ms/epoch - 17ms/step\n",
      "Epoch 40/300\n",
      "5/5 - 0s - loss: 60.0242 - mae: 85.8719 - val_loss: 25.3682 - val_mae: 138.9652 - 91ms/epoch - 18ms/step\n",
      "Epoch 41/300\n",
      "5/5 - 0s - loss: 58.5656 - mae: 85.7322 - val_loss: 24.9857 - val_mae: 138.1815 - 84ms/epoch - 17ms/step\n",
      "Epoch 42/300\n",
      "5/5 - 0s - loss: 55.2125 - mae: 85.7349 - val_loss: 24.5506 - val_mae: 138.2892 - 90ms/epoch - 18ms/step\n",
      "Epoch 43/300\n",
      "5/5 - 0s - loss: 55.7296 - mae: 85.7108 - val_loss: 24.2206 - val_mae: 137.7652 - 90ms/epoch - 18ms/step\n",
      "Epoch 44/300\n",
      "5/5 - 0s - loss: 53.5486 - mae: 85.6800 - val_loss: 23.8617 - val_mae: 138.6237 - 84ms/epoch - 17ms/step\n",
      "Epoch 45/300\n",
      "5/5 - 0s - loss: 52.0527 - mae: 85.6263 - val_loss: 23.6396 - val_mae: 138.4574 - 86ms/epoch - 17ms/step\n",
      "Epoch 46/300\n",
      "5/5 - 0s - loss: 49.1578 - mae: 85.4850 - val_loss: 23.3185 - val_mae: 139.3004 - 85ms/epoch - 17ms/step\n",
      "Epoch 47/300\n",
      "5/5 - 0s - loss: 48.7826 - mae: 85.3391 - val_loss: 23.0379 - val_mae: 138.3301 - 81ms/epoch - 16ms/step\n",
      "Epoch 48/300\n",
      "5/5 - 0s - loss: 47.9514 - mae: 85.4023 - val_loss: 22.7235 - val_mae: 136.2623 - 90ms/epoch - 18ms/step\n",
      "Epoch 49/300\n",
      "5/5 - 0s - loss: 46.5957 - mae: 85.1885 - val_loss: 22.4257 - val_mae: 138.4446 - 86ms/epoch - 17ms/step\n",
      "Epoch 50/300\n",
      "5/5 - 0s - loss: 45.7060 - mae: 85.2306 - val_loss: 22.1332 - val_mae: 137.6878 - 81ms/epoch - 16ms/step\n",
      "Epoch 51/300\n",
      "5/5 - 0s - loss: 45.1131 - mae: 85.2111 - val_loss: 21.9060 - val_mae: 138.0887 - 90ms/epoch - 18ms/step\n",
      "Epoch 52/300\n",
      "5/5 - 0s - loss: 43.8001 - mae: 85.1668 - val_loss: 21.6396 - val_mae: 137.2470 - 83ms/epoch - 17ms/step\n",
      "Epoch 53/300\n",
      "5/5 - 0s - loss: 42.7123 - mae: 85.1736 - val_loss: 21.4427 - val_mae: 137.3235 - 89ms/epoch - 18ms/step\n",
      "Epoch 54/300\n",
      "5/5 - 0s - loss: 41.3309 - mae: 84.8887 - val_loss: 21.2754 - val_mae: 138.3851 - 81ms/epoch - 16ms/step\n",
      "Epoch 55/300\n",
      "5/5 - 0s - loss: 41.4292 - mae: 84.9831 - val_loss: 21.1134 - val_mae: 136.9856 - 84ms/epoch - 17ms/step\n",
      "Epoch 56/300\n",
      "5/5 - 0s - loss: 40.0999 - mae: 84.9437 - val_loss: 20.9199 - val_mae: 137.0453 - 85ms/epoch - 17ms/step\n",
      "Epoch 57/300\n",
      "5/5 - 0s - loss: 39.1599 - mae: 84.8502 - val_loss: 20.7227 - val_mae: 136.4282 - 84ms/epoch - 17ms/step\n",
      "Epoch 58/300\n",
      "5/5 - 0s - loss: 38.5167 - mae: 84.7832 - val_loss: 20.5717 - val_mae: 137.2380 - 87ms/epoch - 17ms/step\n",
      "Epoch 59/300\n",
      "5/5 - 0s - loss: 37.2010 - mae: 84.8066 - val_loss: 20.3887 - val_mae: 136.3832 - 82ms/epoch - 16ms/step\n",
      "Epoch 60/300\n",
      "5/5 - 0s - loss: 37.2559 - mae: 84.7879 - val_loss: 20.1855 - val_mae: 136.3177 - 99ms/epoch - 20ms/step\n",
      "Epoch 61/300\n",
      "5/5 - 0s - loss: 36.4876 - mae: 84.5343 - val_loss: 20.0402 - val_mae: 136.4226 - 87ms/epoch - 17ms/step\n",
      "Epoch 62/300\n",
      "5/5 - 0s - loss: 35.6068 - mae: 84.4683 - val_loss: 19.8914 - val_mae: 136.5910 - 88ms/epoch - 18ms/step\n",
      "Epoch 63/300\n",
      "5/5 - 0s - loss: 35.0630 - mae: 84.6080 - val_loss: 19.7472 - val_mae: 135.5632 - 92ms/epoch - 18ms/step\n",
      "Epoch 64/300\n",
      "5/5 - 0s - loss: 33.5783 - mae: 84.4423 - val_loss: 19.6824 - val_mae: 136.1145 - 98ms/epoch - 20ms/step\n",
      "Epoch 65/300\n",
      "5/5 - 0s - loss: 33.9770 - mae: 84.4430 - val_loss: 19.5647 - val_mae: 135.7045 - 85ms/epoch - 17ms/step\n",
      "Epoch 66/300\n",
      "5/5 - 0s - loss: 33.2068 - mae: 84.4485 - val_loss: 19.4281 - val_mae: 136.0591 - 89ms/epoch - 18ms/step\n",
      "Epoch 67/300\n",
      "5/5 - 0s - loss: 33.1012 - mae: 84.2988 - val_loss: 19.2811 - val_mae: 135.1662 - 106ms/epoch - 21ms/step\n",
      "Epoch 68/300\n",
      "5/5 - 0s - loss: 32.9879 - mae: 84.1501 - val_loss: 19.1573 - val_mae: 136.2615 - 85ms/epoch - 17ms/step\n",
      "Epoch 69/300\n",
      "5/5 - 0s - loss: 32.0385 - mae: 84.3012 - val_loss: 19.0298 - val_mae: 134.7639 - 84ms/epoch - 17ms/step\n",
      "Epoch 70/300\n",
      "5/5 - 0s - loss: 31.4370 - mae: 84.2887 - val_loss: 18.8694 - val_mae: 133.5026 - 86ms/epoch - 17ms/step\n",
      "Epoch 71/300\n",
      "5/5 - 0s - loss: 31.0517 - mae: 84.0532 - val_loss: 18.7219 - val_mae: 133.8399 - 100ms/epoch - 20ms/step\n",
      "Epoch 72/300\n",
      "5/5 - 0s - loss: 30.7257 - mae: 84.1154 - val_loss: 18.6220 - val_mae: 134.5609 - 85ms/epoch - 17ms/step\n",
      "Epoch 73/300\n",
      "5/5 - 0s - loss: 29.6519 - mae: 84.1508 - val_loss: 18.5180 - val_mae: 135.6029 - 90ms/epoch - 18ms/step\n",
      "Epoch 74/300\n",
      "5/5 - 0s - loss: 29.9989 - mae: 83.8787 - val_loss: 18.4000 - val_mae: 133.9443 - 86ms/epoch - 17ms/step\n",
      "Epoch 75/300\n",
      "5/5 - 0s - loss: 29.3591 - mae: 83.9026 - val_loss: 18.3249 - val_mae: 133.7800 - 89ms/epoch - 18ms/step\n",
      "Epoch 76/300\n",
      "5/5 - 0s - loss: 29.1471 - mae: 83.6576 - val_loss: 18.2187 - val_mae: 134.1283 - 85ms/epoch - 17ms/step\n",
      "Epoch 77/300\n",
      "5/5 - 0s - loss: 28.6246 - mae: 83.8883 - val_loss: 18.1320 - val_mae: 134.7501 - 81ms/epoch - 16ms/step\n",
      "Epoch 78/300\n",
      "5/5 - 0s - loss: 28.2984 - mae: 84.0582 - val_loss: 18.0430 - val_mae: 133.6187 - 83ms/epoch - 17ms/step\n",
      "Epoch 79/300\n",
      "5/5 - 0s - loss: 27.6995 - mae: 83.5957 - val_loss: 17.9495 - val_mae: 134.0933 - 84ms/epoch - 17ms/step\n",
      "Epoch 80/300\n",
      "5/5 - 0s - loss: 27.5410 - mae: 83.6239 - val_loss: 17.8686 - val_mae: 134.1910 - 86ms/epoch - 17ms/step\n",
      "Epoch 81/300\n",
      "5/5 - 0s - loss: 27.3328 - mae: 83.4259 - val_loss: 17.7682 - val_mae: 133.3611 - 84ms/epoch - 17ms/step\n",
      "Epoch 82/300\n",
      "5/5 - 0s - loss: 26.7632 - mae: 83.2915 - val_loss: 17.6832 - val_mae: 131.9017 - 83ms/epoch - 17ms/step\n",
      "Epoch 83/300\n",
      "5/5 - 0s - loss: 26.2584 - mae: 83.4638 - val_loss: 17.6124 - val_mae: 132.1456 - 101ms/epoch - 20ms/step\n",
      "Epoch 84/300\n",
      "5/5 - 0s - loss: 25.7272 - mae: 83.5736 - val_loss: 17.5183 - val_mae: 133.1028 - 93ms/epoch - 19ms/step\n",
      "Epoch 85/300\n",
      "5/5 - 0s - loss: 26.0088 - mae: 83.5702 - val_loss: 17.4299 - val_mae: 132.0085 - 86ms/epoch - 17ms/step\n",
      "Epoch 86/300\n",
      "5/5 - 0s - loss: 25.3721 - mae: 83.5348 - val_loss: 17.3651 - val_mae: 132.8856 - 89ms/epoch - 18ms/step\n",
      "Epoch 87/300\n",
      "5/5 - 0s - loss: 25.4417 - mae: 83.2617 - val_loss: 17.2840 - val_mae: 132.8055 - 84ms/epoch - 17ms/step\n",
      "Epoch 88/300\n",
      "5/5 - 0s - loss: 24.7567 - mae: 83.3188 - val_loss: 17.2106 - val_mae: 132.9368 - 88ms/epoch - 18ms/step\n",
      "Epoch 89/300\n",
      "5/5 - 0s - loss: 24.9259 - mae: 83.2285 - val_loss: 17.1833 - val_mae: 132.8603 - 88ms/epoch - 18ms/step\n",
      "Epoch 90/300\n",
      "5/5 - 0s - loss: 24.7292 - mae: 83.0135 - val_loss: 17.1297 - val_mae: 133.2829 - 80ms/epoch - 16ms/step\n",
      "Epoch 91/300\n",
      "5/5 - 0s - loss: 24.6290 - mae: 82.8565 - val_loss: 17.0895 - val_mae: 132.0425 - 85ms/epoch - 17ms/step\n",
      "Epoch 92/300\n",
      "5/5 - 0s - loss: 24.2079 - mae: 83.1053 - val_loss: 17.0357 - val_mae: 132.2806 - 83ms/epoch - 17ms/step\n",
      "Epoch 93/300\n",
      "5/5 - 0s - loss: 23.9739 - mae: 82.8993 - val_loss: 16.9682 - val_mae: 130.7530 - 81ms/epoch - 16ms/step\n",
      "Epoch 94/300\n",
      "5/5 - 0s - loss: 23.8003 - mae: 83.0368 - val_loss: 16.9036 - val_mae: 130.6600 - 100ms/epoch - 20ms/step\n",
      "Epoch 95/300\n",
      "5/5 - 0s - loss: 23.3004 - mae: 83.0262 - val_loss: 16.8404 - val_mae: 131.4427 - 90ms/epoch - 18ms/step\n",
      "Epoch 96/300\n",
      "5/5 - 0s - loss: 23.2206 - mae: 82.6333 - val_loss: 16.8105 - val_mae: 130.1314 - 87ms/epoch - 17ms/step\n",
      "Epoch 97/300\n",
      "5/5 - 0s - loss: 22.9618 - mae: 82.8342 - val_loss: 16.7694 - val_mae: 130.6276 - 85ms/epoch - 17ms/step\n",
      "Epoch 98/300\n",
      "5/5 - 0s - loss: 23.1091 - mae: 82.9280 - val_loss: 16.7397 - val_mae: 132.9772 - 86ms/epoch - 17ms/step\n",
      "Epoch 99/300\n",
      "5/5 - 0s - loss: 22.8081 - mae: 82.7557 - val_loss: 16.7052 - val_mae: 131.8487 - 87ms/epoch - 17ms/step\n",
      "Epoch 100/300\n",
      "5/5 - 0s - loss: 22.7857 - mae: 82.6699 - val_loss: 16.6555 - val_mae: 131.3821 - 88ms/epoch - 18ms/step\n",
      "Epoch 101/300\n",
      "5/5 - 0s - loss: 22.8116 - mae: 82.5505 - val_loss: 16.6121 - val_mae: 132.4913 - 84ms/epoch - 17ms/step\n",
      "Epoch 102/300\n",
      "5/5 - 0s - loss: 22.4627 - mae: 82.5823 - val_loss: 16.5586 - val_mae: 131.6880 - 82ms/epoch - 16ms/step\n",
      "Epoch 103/300\n",
      "5/5 - 0s - loss: 22.5368 - mae: 82.3667 - val_loss: 16.5233 - val_mae: 131.6757 - 86ms/epoch - 17ms/step\n",
      "Epoch 104/300\n",
      "5/5 - 0s - loss: 21.9917 - mae: 82.3717 - val_loss: 16.4943 - val_mae: 131.9469 - 80ms/epoch - 16ms/step\n",
      "Epoch 105/300\n",
      "5/5 - 0s - loss: 21.8894 - mae: 82.5738 - val_loss: 16.4614 - val_mae: 131.5622 - 83ms/epoch - 17ms/step\n",
      "Epoch 106/300\n",
      "5/5 - 0s - loss: 21.7213 - mae: 82.2174 - val_loss: 16.4210 - val_mae: 130.3994 - 111ms/epoch - 22ms/step\n",
      "Epoch 107/300\n",
      "5/5 - 0s - loss: 21.3751 - mae: 82.0160 - val_loss: 16.3748 - val_mae: 129.8074 - 86ms/epoch - 17ms/step\n",
      "Epoch 108/300\n",
      "5/5 - 0s - loss: 21.8747 - mae: 82.4765 - val_loss: 16.3335 - val_mae: 128.0680 - 86ms/epoch - 17ms/step\n",
      "Epoch 109/300\n",
      "5/5 - 0s - loss: 21.4003 - mae: 82.1687 - val_loss: 16.2901 - val_mae: 128.7139 - 84ms/epoch - 17ms/step\n",
      "Epoch 110/300\n",
      "5/5 - 0s - loss: 21.2370 - mae: 82.3899 - val_loss: 16.2509 - val_mae: 131.0982 - 85ms/epoch - 17ms/step\n",
      "Epoch 111/300\n",
      "5/5 - 0s - loss: 21.1076 - mae: 82.2957 - val_loss: 16.2241 - val_mae: 130.5433 - 81ms/epoch - 16ms/step\n",
      "Epoch 112/300\n",
      "5/5 - 0s - loss: 21.1214 - mae: 82.1149 - val_loss: 16.1937 - val_mae: 129.7263 - 85ms/epoch - 17ms/step\n",
      "Epoch 113/300\n",
      "5/5 - 0s - loss: 20.8762 - mae: 82.1058 - val_loss: 16.1546 - val_mae: 128.3808 - 80ms/epoch - 16ms/step\n",
      "Epoch 114/300\n",
      "5/5 - 0s - loss: 20.6419 - mae: 82.3421 - val_loss: 16.1282 - val_mae: 127.2600 - 79ms/epoch - 16ms/step\n",
      "Epoch 115/300\n",
      "5/5 - 0s - loss: 20.5766 - mae: 82.2557 - val_loss: 16.1057 - val_mae: 127.6869 - 82ms/epoch - 16ms/step\n",
      "Epoch 116/300\n",
      "5/5 - 0s - loss: 20.4525 - mae: 82.2343 - val_loss: 16.0832 - val_mae: 128.9974 - 82ms/epoch - 16ms/step\n",
      "Epoch 117/300\n",
      "5/5 - 0s - loss: 19.8952 - mae: 82.2813 - val_loss: 16.0588 - val_mae: 129.3483 - 95ms/epoch - 19ms/step\n",
      "Epoch 118/300\n",
      "5/5 - 0s - loss: 19.9140 - mae: 81.9173 - val_loss: 16.0427 - val_mae: 131.3049 - 89ms/epoch - 18ms/step\n",
      "Epoch 119/300\n",
      "5/5 - 0s - loss: 20.0456 - mae: 81.9646 - val_loss: 16.0136 - val_mae: 130.2945 - 98ms/epoch - 20ms/step\n",
      "Epoch 120/300\n",
      "5/5 - 0s - loss: 19.8155 - mae: 81.8731 - val_loss: 15.9947 - val_mae: 129.9618 - 87ms/epoch - 17ms/step\n",
      "Epoch 121/300\n",
      "5/5 - 0s - loss: 19.8395 - mae: 81.6532 - val_loss: 15.9727 - val_mae: 128.1766 - 102ms/epoch - 20ms/step\n",
      "Epoch 122/300\n",
      "5/5 - 0s - loss: 19.9083 - mae: 81.6663 - val_loss: 15.9511 - val_mae: 127.3351 - 101ms/epoch - 20ms/step\n",
      "Epoch 123/300\n",
      "5/5 - 0s - loss: 19.6300 - mae: 81.9112 - val_loss: 15.9313 - val_mae: 129.2218 - 83ms/epoch - 17ms/step\n",
      "Epoch 124/300\n",
      "5/5 - 0s - loss: 19.6164 - mae: 81.4496 - val_loss: 15.9002 - val_mae: 128.3152 - 88ms/epoch - 18ms/step\n",
      "Epoch 125/300\n",
      "5/5 - 0s - loss: 19.5809 - mae: 81.5839 - val_loss: 15.8757 - val_mae: 128.5078 - 86ms/epoch - 17ms/step\n",
      "Epoch 126/300\n",
      "5/5 - 0s - loss: 19.3908 - mae: 81.6174 - val_loss: 15.8514 - val_mae: 127.6656 - 82ms/epoch - 16ms/step\n",
      "Epoch 127/300\n",
      "5/5 - 0s - loss: 19.3690 - mae: 81.5835 - val_loss: 15.8270 - val_mae: 128.7381 - 84ms/epoch - 17ms/step\n",
      "Epoch 128/300\n",
      "5/5 - 0s - loss: 19.0805 - mae: 81.6360 - val_loss: 15.8000 - val_mae: 127.3675 - 90ms/epoch - 18ms/step\n",
      "Epoch 129/300\n",
      "5/5 - 0s - loss: 19.1101 - mae: 81.5818 - val_loss: 15.7856 - val_mae: 127.0082 - 98ms/epoch - 20ms/step\n",
      "Epoch 130/300\n",
      "5/5 - 0s - loss: 19.0534 - mae: 81.5187 - val_loss: 15.7682 - val_mae: 127.7881 - 88ms/epoch - 18ms/step\n",
      "Epoch 131/300\n",
      "5/5 - 0s - loss: 19.0289 - mae: 81.3080 - val_loss: 15.7433 - val_mae: 127.9766 - 82ms/epoch - 16ms/step\n",
      "Epoch 132/300\n",
      "5/5 - 0s - loss: 18.8785 - mae: 81.3017 - val_loss: 15.7187 - val_mae: 128.1578 - 86ms/epoch - 17ms/step\n",
      "Epoch 133/300\n",
      "5/5 - 0s - loss: 18.6231 - mae: 81.1501 - val_loss: 15.7001 - val_mae: 126.2224 - 84ms/epoch - 17ms/step\n",
      "Epoch 134/300\n",
      "5/5 - 0s - loss: 18.6087 - mae: 81.3020 - val_loss: 15.6867 - val_mae: 127.9946 - 82ms/epoch - 16ms/step\n",
      "Epoch 135/300\n",
      "5/5 - 0s - loss: 18.5702 - mae: 81.1830 - val_loss: 15.6724 - val_mae: 127.2458 - 81ms/epoch - 16ms/step\n",
      "Epoch 136/300\n",
      "5/5 - 0s - loss: 18.5183 - mae: 81.4411 - val_loss: 15.6559 - val_mae: 127.0936 - 82ms/epoch - 16ms/step\n",
      "Epoch 137/300\n",
      "5/5 - 0s - loss: 18.5151 - mae: 81.2754 - val_loss: 15.6344 - val_mae: 127.1345 - 79ms/epoch - 16ms/step\n",
      "Epoch 138/300\n",
      "5/5 - 0s - loss: 18.4896 - mae: 81.2587 - val_loss: 15.6165 - val_mae: 126.5993 - 83ms/epoch - 17ms/step\n",
      "Epoch 139/300\n",
      "5/5 - 0s - loss: 18.3243 - mae: 81.2412 - val_loss: 15.5991 - val_mae: 127.6131 - 91ms/epoch - 18ms/step\n",
      "Epoch 140/300\n",
      "5/5 - 0s - loss: 18.1818 - mae: 80.9840 - val_loss: 15.5794 - val_mae: 127.6369 - 99ms/epoch - 20ms/step\n",
      "Epoch 141/300\n",
      "5/5 - 0s - loss: 18.1123 - mae: 81.0122 - val_loss: 15.5626 - val_mae: 127.4219 - 84ms/epoch - 17ms/step\n",
      "Epoch 142/300\n",
      "5/5 - 0s - loss: 17.8050 - mae: 80.9282 - val_loss: 15.5497 - val_mae: 126.1407 - 129ms/epoch - 26ms/step\n",
      "Epoch 143/300\n",
      "5/5 - 0s - loss: 18.1404 - mae: 80.9725 - val_loss: 15.5356 - val_mae: 126.8309 - 146ms/epoch - 29ms/step\n",
      "Epoch 144/300\n",
      "5/5 - 0s - loss: 17.7738 - mae: 81.0222 - val_loss: 15.5295 - val_mae: 125.8102 - 132ms/epoch - 26ms/step\n",
      "Epoch 145/300\n",
      "5/5 - 0s - loss: 17.8998 - mae: 80.6484 - val_loss: 15.5117 - val_mae: 124.8573 - 134ms/epoch - 27ms/step\n",
      "Epoch 146/300\n",
      "5/5 - 0s - loss: 17.7866 - mae: 81.0244 - val_loss: 15.4946 - val_mae: 126.9394 - 120ms/epoch - 24ms/step\n",
      "Epoch 147/300\n",
      "5/5 - 0s - loss: 17.5386 - mae: 80.6490 - val_loss: 15.4801 - val_mae: 125.8615 - 146ms/epoch - 29ms/step\n",
      "Epoch 148/300\n",
      "5/5 - 0s - loss: 17.5997 - mae: 80.7776 - val_loss: 15.4695 - val_mae: 125.9534 - 159ms/epoch - 32ms/step\n",
      "Epoch 149/300\n",
      "5/5 - 0s - loss: 17.6045 - mae: 80.5919 - val_loss: 15.4585 - val_mae: 124.2309 - 146ms/epoch - 29ms/step\n",
      "Epoch 150/300\n",
      "5/5 - 0s - loss: 17.4846 - mae: 80.8224 - val_loss: 15.4434 - val_mae: 125.7642 - 152ms/epoch - 30ms/step\n",
      "Epoch 151/300\n",
      "5/5 - 0s - loss: 17.5244 - mae: 81.0603 - val_loss: 15.4325 - val_mae: 126.7380 - 139ms/epoch - 28ms/step\n",
      "Epoch 152/300\n",
      "5/5 - 0s - loss: 17.4607 - mae: 80.4605 - val_loss: 15.4210 - val_mae: 126.3743 - 144ms/epoch - 29ms/step\n",
      "Epoch 153/300\n",
      "5/5 - 0s - loss: 17.3818 - mae: 80.3260 - val_loss: 15.4089 - val_mae: 126.8614 - 155ms/epoch - 31ms/step\n",
      "Epoch 154/300\n",
      "5/5 - 0s - loss: 17.2581 - mae: 80.4570 - val_loss: 15.3963 - val_mae: 125.9494 - 157ms/epoch - 31ms/step\n",
      "Epoch 155/300\n",
      "5/5 - 0s - loss: 17.2564 - mae: 80.4622 - val_loss: 15.3877 - val_mae: 127.5810 - 152ms/epoch - 30ms/step\n",
      "Epoch 156/300\n",
      "5/5 - 0s - loss: 17.0106 - mae: 80.3496 - val_loss: 15.3745 - val_mae: 126.9231 - 148ms/epoch - 30ms/step\n",
      "Epoch 157/300\n",
      "5/5 - 0s - loss: 17.1914 - mae: 80.1951 - val_loss: 15.3666 - val_mae: 126.1796 - 141ms/epoch - 28ms/step\n",
      "Epoch 158/300\n",
      "5/5 - 0s - loss: 17.0571 - mae: 80.4399 - val_loss: 15.3551 - val_mae: 125.1992 - 99ms/epoch - 20ms/step\n",
      "Epoch 159/300\n",
      "5/5 - 0s - loss: 17.1443 - mae: 80.3561 - val_loss: 15.3430 - val_mae: 123.7585 - 82ms/epoch - 16ms/step\n",
      "Epoch 160/300\n",
      "5/5 - 0s - loss: 17.0319 - mae: 80.5968 - val_loss: 15.3346 - val_mae: 127.2425 - 79ms/epoch - 16ms/step\n",
      "Epoch 161/300\n",
      "5/5 - 0s - loss: 16.9178 - mae: 80.0389 - val_loss: 15.3230 - val_mae: 127.0732 - 84ms/epoch - 17ms/step\n",
      "Epoch 162/300\n",
      "5/5 - 0s - loss: 16.5921 - mae: 80.1028 - val_loss: 15.3186 - val_mae: 124.9163 - 87ms/epoch - 17ms/step\n",
      "Epoch 163/300\n",
      "5/5 - 0s - loss: 16.6052 - mae: 80.2984 - val_loss: 15.3082 - val_mae: 121.9733 - 86ms/epoch - 17ms/step\n",
      "Epoch 164/300\n",
      "5/5 - 0s - loss: 16.7142 - mae: 80.0773 - val_loss: 15.2995 - val_mae: 125.7106 - 102ms/epoch - 20ms/step\n",
      "Epoch 165/300\n",
      "5/5 - 0s - loss: 16.8474 - mae: 80.0840 - val_loss: 15.2902 - val_mae: 125.1019 - 116ms/epoch - 23ms/step\n",
      "Epoch 166/300\n",
      "5/5 - 0s - loss: 16.8030 - mae: 80.0798 - val_loss: 15.2817 - val_mae: 124.2373 - 84ms/epoch - 17ms/step\n",
      "Epoch 167/300\n",
      "5/5 - 0s - loss: 16.6088 - mae: 80.0915 - val_loss: 15.2710 - val_mae: 125.7375 - 83ms/epoch - 17ms/step\n",
      "Epoch 168/300\n",
      "5/5 - 0s - loss: 16.4847 - mae: 79.7987 - val_loss: 15.2608 - val_mae: 125.7208 - 80ms/epoch - 16ms/step\n",
      "Epoch 169/300\n",
      "5/5 - 0s - loss: 16.5404 - mae: 80.1568 - val_loss: 15.2525 - val_mae: 124.5444 - 83ms/epoch - 17ms/step\n",
      "Epoch 170/300\n",
      "5/5 - 0s - loss: 16.4739 - mae: 80.1642 - val_loss: 15.2432 - val_mae: 125.2578 - 85ms/epoch - 17ms/step\n",
      "Epoch 171/300\n",
      "5/5 - 0s - loss: 16.4802 - mae: 79.9726 - val_loss: 15.2346 - val_mae: 124.3839 - 79ms/epoch - 16ms/step\n",
      "Epoch 172/300\n",
      "5/5 - 0s - loss: 16.4151 - mae: 79.9248 - val_loss: 15.2259 - val_mae: 126.1763 - 80ms/epoch - 16ms/step\n",
      "Epoch 173/300\n",
      "5/5 - 0s - loss: 16.4550 - mae: 79.8367 - val_loss: 15.2181 - val_mae: 123.9870 - 87ms/epoch - 17ms/step\n",
      "Epoch 174/300\n",
      "5/5 - 0s - loss: 16.2311 - mae: 80.1660 - val_loss: 15.2102 - val_mae: 124.7351 - 83ms/epoch - 17ms/step\n",
      "Epoch 175/300\n",
      "5/5 - 0s - loss: 16.2092 - mae: 79.8975 - val_loss: 15.2030 - val_mae: 124.3814 - 85ms/epoch - 17ms/step\n",
      "Epoch 176/300\n",
      "5/5 - 0s - loss: 16.3478 - mae: 79.4391 - val_loss: 15.1959 - val_mae: 124.7420 - 86ms/epoch - 17ms/step\n",
      "Epoch 177/300\n",
      "5/5 - 0s - loss: 16.1377 - mae: 79.8532 - val_loss: 15.1887 - val_mae: 123.4598 - 99ms/epoch - 20ms/step\n",
      "Epoch 178/300\n",
      "5/5 - 0s - loss: 16.1240 - mae: 79.3640 - val_loss: 15.1807 - val_mae: 124.1114 - 82ms/epoch - 16ms/step\n",
      "Epoch 179/300\n",
      "5/5 - 0s - loss: 16.0904 - mae: 80.0354 - val_loss: 15.1739 - val_mae: 124.3539 - 85ms/epoch - 17ms/step\n",
      "Epoch 180/300\n",
      "5/5 - 0s - loss: 16.1396 - mae: 79.7783 - val_loss: 15.1670 - val_mae: 124.3763 - 81ms/epoch - 16ms/step\n",
      "Epoch 181/300\n",
      "5/5 - 0s - loss: 16.0288 - mae: 79.5097 - val_loss: 15.1599 - val_mae: 123.6007 - 83ms/epoch - 17ms/step\n",
      "Epoch 182/300\n",
      "5/5 - 0s - loss: 16.0114 - mae: 79.5009 - val_loss: 15.1535 - val_mae: 124.3296 - 86ms/epoch - 17ms/step\n",
      "Epoch 183/300\n",
      "5/5 - 0s - loss: 15.9051 - mae: 79.3582 - val_loss: 15.1454 - val_mae: 124.3084 - 81ms/epoch - 16ms/step\n",
      "Epoch 184/300\n",
      "5/5 - 0s - loss: 15.7877 - mae: 79.5328 - val_loss: 15.1392 - val_mae: 124.9860 - 97ms/epoch - 19ms/step\n",
      "Epoch 185/300\n",
      "5/5 - 0s - loss: 15.9354 - mae: 79.5825 - val_loss: 15.1326 - val_mae: 124.4460 - 86ms/epoch - 17ms/step\n",
      "Epoch 186/300\n",
      "5/5 - 0s - loss: 15.8236 - mae: 79.3519 - val_loss: 15.1270 - val_mae: 124.7206 - 86ms/epoch - 17ms/step\n",
      "Epoch 187/300\n",
      "5/5 - 0s - loss: 15.9034 - mae: 79.3178 - val_loss: 15.1214 - val_mae: 125.0777 - 91ms/epoch - 18ms/step\n",
      "Epoch 188/300\n",
      "5/5 - 0s - loss: 15.7974 - mae: 79.4690 - val_loss: 15.1159 - val_mae: 123.7450 - 99ms/epoch - 20ms/step\n",
      "Epoch 189/300\n",
      "5/5 - 0s - loss: 15.8284 - mae: 79.0712 - val_loss: 15.1102 - val_mae: 125.4672 - 82ms/epoch - 16ms/step\n",
      "Epoch 190/300\n",
      "5/5 - 0s - loss: 15.7839 - mae: 79.5803 - val_loss: 15.1057 - val_mae: 123.3317 - 81ms/epoch - 16ms/step\n",
      "Epoch 191/300\n",
      "5/5 - 0s - loss: 15.7540 - mae: 79.1992 - val_loss: 15.0982 - val_mae: 125.9563 - 82ms/epoch - 16ms/step\n",
      "Epoch 192/300\n",
      "5/5 - 0s - loss: 15.7659 - mae: 79.3774 - val_loss: 15.0942 - val_mae: 121.9759 - 83ms/epoch - 17ms/step\n",
      "Epoch 193/300\n",
      "5/5 - 0s - loss: 15.6780 - mae: 79.1615 - val_loss: 15.0905 - val_mae: 124.6800 - 82ms/epoch - 16ms/step\n",
      "Epoch 194/300\n",
      "5/5 - 0s - loss: 15.5721 - mae: 79.6016 - val_loss: 15.0843 - val_mae: 124.2030 - 83ms/epoch - 17ms/step\n",
      "Epoch 195/300\n",
      "5/5 - 0s - loss: 15.5952 - mae: 78.8252 - val_loss: 15.0793 - val_mae: 122.1652 - 88ms/epoch - 18ms/step\n",
      "Epoch 196/300\n",
      "5/5 - 0s - loss: 15.5828 - mae: 78.8661 - val_loss: 15.0742 - val_mae: 125.4258 - 88ms/epoch - 18ms/step\n",
      "Epoch 197/300\n",
      "5/5 - 0s - loss: 15.5684 - mae: 79.2199 - val_loss: 15.0703 - val_mae: 124.0037 - 91ms/epoch - 18ms/step\n",
      "Epoch 198/300\n",
      "5/5 - 0s - loss: 15.4727 - mae: 78.9479 - val_loss: 15.0676 - val_mae: 124.1212 - 85ms/epoch - 17ms/step\n",
      "Epoch 199/300\n",
      "5/5 - 0s - loss: 15.4768 - mae: 79.0388 - val_loss: 15.0611 - val_mae: 122.4557 - 90ms/epoch - 18ms/step\n",
      "Epoch 200/300\n",
      "5/5 - 0s - loss: 15.4709 - mae: 78.5981 - val_loss: 15.0553 - val_mae: 122.2025 - 104ms/epoch - 21ms/step\n",
      "Epoch 201/300\n",
      "5/5 - 0s - loss: 15.3735 - mae: 78.6992 - val_loss: 15.0492 - val_mae: 121.0193 - 85ms/epoch - 17ms/step\n",
      "Epoch 202/300\n",
      "5/5 - 0s - loss: 15.4126 - mae: 78.6501 - val_loss: 15.0457 - val_mae: 124.9593 - 90ms/epoch - 18ms/step\n",
      "Epoch 203/300\n",
      "5/5 - 0s - loss: 15.4092 - mae: 78.7845 - val_loss: 15.0412 - val_mae: 125.1777 - 82ms/epoch - 16ms/step\n",
      "Epoch 204/300\n",
      "5/5 - 0s - loss: 15.3046 - mae: 78.6630 - val_loss: 15.0378 - val_mae: 123.0431 - 85ms/epoch - 17ms/step\n",
      "Epoch 205/300\n",
      "5/5 - 0s - loss: 15.2897 - mae: 78.6962 - val_loss: 15.0362 - val_mae: 122.9023 - 83ms/epoch - 17ms/step\n",
      "Epoch 206/300\n",
      "5/5 - 0s - loss: 15.2113 - mae: 78.6183 - val_loss: 15.0320 - val_mae: 121.8203 - 102ms/epoch - 20ms/step\n",
      "Epoch 207/300\n",
      "5/5 - 0s - loss: 15.1373 - mae: 78.7056 - val_loss: 15.0306 - val_mae: 124.8330 - 87ms/epoch - 17ms/step\n",
      "Epoch 208/300\n",
      "5/5 - 0s - loss: 15.2589 - mae: 78.4147 - val_loss: 15.0293 - val_mae: 124.2398 - 83ms/epoch - 17ms/step\n",
      "Epoch 209/300\n",
      "5/5 - 0s - loss: 15.1901 - mae: 78.8883 - val_loss: 15.0244 - val_mae: 123.4098 - 83ms/epoch - 17ms/step\n",
      "Epoch 210/300\n",
      "5/5 - 0s - loss: 15.1614 - mae: 78.5965 - val_loss: 15.0207 - val_mae: 123.7437 - 86ms/epoch - 17ms/step\n",
      "Epoch 211/300\n",
      "5/5 - 0s - loss: 15.1988 - mae: 78.7166 - val_loss: 15.0198 - val_mae: 122.5928 - 99ms/epoch - 20ms/step\n",
      "Epoch 212/300\n",
      "5/5 - 0s - loss: 15.1127 - mae: 78.8773 - val_loss: 15.0148 - val_mae: 124.2091 - 88ms/epoch - 18ms/step\n",
      "Epoch 213/300\n",
      "5/5 - 0s - loss: 15.1492 - mae: 78.3630 - val_loss: 15.0108 - val_mae: 124.2914 - 84ms/epoch - 17ms/step\n",
      "Epoch 214/300\n",
      "5/5 - 0s - loss: 15.0647 - mae: 78.1039 - val_loss: 15.0104 - val_mae: 121.6409 - 83ms/epoch - 17ms/step\n",
      "Epoch 215/300\n",
      "5/5 - 0s - loss: 15.1072 - mae: 78.5433 - val_loss: 15.0100 - val_mae: 123.0499 - 84ms/epoch - 17ms/step\n",
      "Epoch 216/300\n",
      "5/5 - 0s - loss: 15.0553 - mae: 78.4479 - val_loss: 15.0041 - val_mae: 122.7197 - 83ms/epoch - 17ms/step\n",
      "Epoch 217/300\n",
      "5/5 - 0s - loss: 15.0128 - mae: 78.5374 - val_loss: 15.0005 - val_mae: 123.9248 - 85ms/epoch - 17ms/step\n",
      "Epoch 218/300\n",
      "5/5 - 0s - loss: 15.0073 - mae: 77.9873 - val_loss: 15.0002 - val_mae: 124.9729 - 88ms/epoch - 18ms/step\n",
      "Epoch 219/300\n",
      "5/5 - 0s - loss: 14.9713 - mae: 78.5061 - val_loss: 14.9977 - val_mae: 122.5900 - 84ms/epoch - 17ms/step\n",
      "Epoch 220/300\n",
      "5/5 - 0s - loss: 14.8990 - mae: 78.4563 - val_loss: 14.9894 - val_mae: 123.3900 - 84ms/epoch - 17ms/step\n",
      "Epoch 221/300\n",
      "5/5 - 0s - loss: 14.8840 - mae: 78.3867 - val_loss: 14.9831 - val_mae: 123.5983 - 90ms/epoch - 18ms/step\n",
      "Epoch 222/300\n",
      "5/5 - 0s - loss: 14.9405 - mae: 78.0979 - val_loss: 14.9812 - val_mae: 122.2648 - 84ms/epoch - 17ms/step\n",
      "Epoch 223/300\n",
      "5/5 - 0s - loss: 14.9736 - mae: 78.4953 - val_loss: 14.9798 - val_mae: 120.5999 - 103ms/epoch - 21ms/step\n",
      "Epoch 224/300\n",
      "5/5 - 0s - loss: 14.7956 - mae: 77.9034 - val_loss: 14.9737 - val_mae: 121.3719 - 82ms/epoch - 16ms/step\n",
      "Epoch 225/300\n",
      "5/5 - 0s - loss: 14.8170 - mae: 78.4296 - val_loss: 14.9719 - val_mae: 124.5775 - 82ms/epoch - 16ms/step\n",
      "Epoch 226/300\n",
      "5/5 - 0s - loss: 14.8422 - mae: 78.2741 - val_loss: 14.9708 - val_mae: 122.4063 - 87ms/epoch - 17ms/step\n",
      "Epoch 227/300\n",
      "5/5 - 0s - loss: 14.7033 - mae: 78.3082 - val_loss: 14.9717 - val_mae: 122.0963 - 83ms/epoch - 17ms/step\n",
      "Epoch 228/300\n",
      "5/5 - 0s - loss: 14.7056 - mae: 78.2249 - val_loss: 14.9716 - val_mae: 123.6427 - 79ms/epoch - 16ms/step\n",
      "Epoch 229/300\n",
      "5/5 - 0s - loss: 14.8399 - mae: 77.7008 - val_loss: 14.9701 - val_mae: 119.8230 - 88ms/epoch - 18ms/step\n",
      "Epoch 230/300\n",
      "5/5 - 0s - loss: 14.7020 - mae: 78.2418 - val_loss: 14.9676 - val_mae: 123.1974 - 98ms/epoch - 20ms/step\n",
      "Epoch 231/300\n",
      "5/5 - 0s - loss: 14.7378 - mae: 78.6183 - val_loss: 14.9631 - val_mae: 119.3889 - 83ms/epoch - 17ms/step\n",
      "Epoch 232/300\n",
      "5/5 - 0s - loss: 14.6539 - mae: 78.3872 - val_loss: 14.9589 - val_mae: 123.2498 - 85ms/epoch - 17ms/step\n",
      "Epoch 233/300\n",
      "5/5 - 0s - loss: 14.7429 - mae: 78.3210 - val_loss: 14.9584 - val_mae: 123.7050 - 99ms/epoch - 20ms/step\n",
      "Epoch 234/300\n",
      "5/5 - 0s - loss: 14.6758 - mae: 78.3430 - val_loss: 14.9543 - val_mae: 121.4646 - 96ms/epoch - 19ms/step\n",
      "Epoch 235/300\n",
      "5/5 - 0s - loss: 14.6465 - mae: 78.0740 - val_loss: 14.9486 - val_mae: 122.1698 - 86ms/epoch - 17ms/step\n",
      "Epoch 236/300\n",
      "5/5 - 0s - loss: 14.5197 - mae: 77.9844 - val_loss: 14.9503 - val_mae: 122.7582 - 81ms/epoch - 16ms/step\n",
      "Epoch 237/300\n",
      "5/5 - 0s - loss: 14.6050 - mae: 77.5304 - val_loss: 14.9501 - val_mae: 123.2418 - 79ms/epoch - 16ms/step\n",
      "Epoch 238/300\n",
      "5/5 - 0s - loss: 14.5157 - mae: 77.8360 - val_loss: 14.9462 - val_mae: 122.1208 - 82ms/epoch - 16ms/step\n",
      "Epoch 239/300\n",
      "5/5 - 0s - loss: 14.5723 - mae: 77.8985 - val_loss: 14.9453 - val_mae: 121.8179 - 88ms/epoch - 18ms/step\n",
      "Epoch 240/300\n",
      "5/5 - 0s - loss: 14.5387 - mae: 77.9356 - val_loss: 14.9425 - val_mae: 124.3295 - 86ms/epoch - 17ms/step\n",
      "Epoch 241/300\n",
      "5/5 - 0s - loss: 14.5504 - mae: 77.5863 - val_loss: 14.9425 - val_mae: 121.9202 - 78ms/epoch - 16ms/step\n",
      "Epoch 242/300\n",
      "5/5 - 0s - loss: 14.5616 - mae: 77.8665 - val_loss: 14.9422 - val_mae: 121.6759 - 84ms/epoch - 17ms/step\n",
      "Epoch 243/300\n",
      "5/5 - 0s - loss: 14.4686 - mae: 77.6478 - val_loss: 14.9339 - val_mae: 121.5336 - 84ms/epoch - 17ms/step\n",
      "Epoch 244/300\n",
      "5/5 - 0s - loss: 14.4845 - mae: 77.8832 - val_loss: 14.9359 - val_mae: 120.7660 - 81ms/epoch - 16ms/step\n",
      "Epoch 245/300\n",
      "5/5 - 0s - loss: 14.4814 - mae: 77.4771 - val_loss: 14.9385 - val_mae: 123.7406 - 80ms/epoch - 16ms/step\n",
      "Epoch 246/300\n",
      "5/5 - 0s - loss: 14.4078 - mae: 76.9826 - val_loss: 14.9381 - val_mae: 122.4612 - 98ms/epoch - 20ms/step\n",
      "Epoch 247/300\n",
      "5/5 - 0s - loss: 14.4143 - mae: 77.5888 - val_loss: 14.9292 - val_mae: 122.4826 - 83ms/epoch - 17ms/step\n",
      "Epoch 248/300\n",
      "5/5 - 0s - loss: 14.3560 - mae: 77.4784 - val_loss: 14.9179 - val_mae: 123.4800 - 83ms/epoch - 17ms/step\n",
      "Epoch 249/300\n",
      "5/5 - 0s - loss: 14.3730 - mae: 77.9283 - val_loss: 14.9074 - val_mae: 122.0087 - 82ms/epoch - 16ms/step\n",
      "Epoch 250/300\n",
      "5/5 - 0s - loss: 14.3446 - mae: 77.4116 - val_loss: 14.9014 - val_mae: 122.5536 - 83ms/epoch - 17ms/step\n",
      "Epoch 251/300\n",
      "5/5 - 0s - loss: 14.4041 - mae: 77.9846 - val_loss: 14.9047 - val_mae: 120.3799 - 92ms/epoch - 18ms/step\n",
      "Epoch 252/300\n",
      "5/5 - 0s - loss: 14.3534 - mae: 77.8127 - val_loss: 14.9081 - val_mae: 122.8152 - 82ms/epoch - 16ms/step\n",
      "Epoch 253/300\n",
      "5/5 - 0s - loss: 14.3268 - mae: 77.3613 - val_loss: 14.9116 - val_mae: 119.6302 - 79ms/epoch - 16ms/step\n",
      "Epoch 254/300\n",
      "5/5 - 0s - loss: 14.2861 - mae: 77.3743 - val_loss: 14.9117 - val_mae: 123.9506 - 83ms/epoch - 17ms/step\n",
      "Epoch 255/300\n",
      "5/5 - 0s - loss: 14.2754 - mae: 77.1679 - val_loss: 14.9112 - val_mae: 121.0064 - 89ms/epoch - 18ms/step\n",
      "Epoch 256/300\n",
      "5/5 - 0s - loss: 14.3235 - mae: 77.7315 - val_loss: 14.9113 - val_mae: 123.6363 - 83ms/epoch - 17ms/step\n",
      "Epoch 257/300\n",
      "5/5 - 0s - loss: 14.2872 - mae: 77.2499 - val_loss: 14.9154 - val_mae: 121.9122 - 82ms/epoch - 16ms/step\n",
      "Epoch 258/300\n",
      "5/5 - 0s - loss: 14.2274 - mae: 77.3348 - val_loss: 14.9088 - val_mae: 122.2617 - 101ms/epoch - 20ms/step\n",
      "Epoch 259/300\n",
      "5/5 - 0s - loss: 14.2392 - mae: 77.3804 - val_loss: 14.9094 - val_mae: 122.2909 - 96ms/epoch - 19ms/step\n",
      "Epoch 260/300\n",
      "5/5 - 0s - loss: 14.2126 - mae: 76.9949 - val_loss: 14.9133 - val_mae: 120.8927 - 77ms/epoch - 15ms/step\n",
      "Epoch 261/300\n",
      "5/5 - 0s - loss: 14.2262 - mae: 77.5439 - val_loss: 14.9145 - val_mae: 122.4174 - 79ms/epoch - 16ms/step\n",
      "Epoch 262/300\n",
      "5/5 - 0s - loss: 14.2339 - mae: 77.3408 - val_loss: 14.9097 - val_mae: 123.5534 - 80ms/epoch - 16ms/step\n",
      "Epoch 263/300\n",
      "5/5 - 0s - loss: 14.1768 - mae: 76.9000 - val_loss: 14.9136 - val_mae: 122.3218 - 86ms/epoch - 17ms/step\n",
      "Epoch 264/300\n",
      "5/5 - 0s - loss: 14.0945 - mae: 77.3357 - val_loss: 14.9105 - val_mae: 122.1313 - 79ms/epoch - 16ms/step\n",
      "Epoch 265/300\n",
      "5/5 - 0s - loss: 14.1753 - mae: 77.1629 - val_loss: 14.9101 - val_mae: 125.5955 - 79ms/epoch - 16ms/step\n",
      "Epoch 266/300\n",
      "5/5 - 0s - loss: 14.0979 - mae: 77.3688 - val_loss: 14.9109 - val_mae: 122.0129 - 84ms/epoch - 17ms/step\n",
      "Epoch 267/300\n",
      "5/5 - 0s - loss: 14.1272 - mae: 77.0002 - val_loss: 14.9120 - val_mae: 120.5956 - 83ms/epoch - 17ms/step\n",
      "Epoch 268/300\n",
      "5/5 - 0s - loss: 14.1023 - mae: 77.7267 - val_loss: 14.9160 - val_mae: 124.2224 - 83ms/epoch - 17ms/step\n",
      "Epoch 269/300\n",
      "5/5 - 0s - loss: 14.1399 - mae: 77.3497 - val_loss: 14.9129 - val_mae: 124.4865 - 80ms/epoch - 16ms/step\n",
      "Epoch 270/300\n",
      "5/5 - 0s - loss: 14.0601 - mae: 77.1790 - val_loss: 14.9168 - val_mae: 123.0612 - 149ms/epoch - 30ms/step\n",
      "Epoch 271/300\n",
      "5/5 - 0s - loss: 14.0657 - mae: 76.9066 - val_loss: 14.9165 - val_mae: 124.6000 - 139ms/epoch - 28ms/step\n",
      "Epoch 272/300\n",
      "5/5 - 0s - loss: 14.0193 - mae: 76.7477 - val_loss: 14.9116 - val_mae: 122.8184 - 146ms/epoch - 29ms/step\n",
      "Epoch 273/300\n",
      "5/5 - 0s - loss: 13.9509 - mae: 76.8695 - val_loss: 14.9011 - val_mae: 124.3332 - 154ms/epoch - 31ms/step\n",
      "Epoch 274/300\n",
      "5/5 - 0s - loss: 14.0102 - mae: 77.0688 - val_loss: 14.8980 - val_mae: 122.8875 - 154ms/epoch - 31ms/step\n",
      "Epoch 275/300\n",
      "5/5 - 0s - loss: 14.0043 - mae: 76.7311 - val_loss: 14.8932 - val_mae: 122.2169 - 146ms/epoch - 29ms/step\n",
      "Epoch 276/300\n",
      "5/5 - 0s - loss: 13.8922 - mae: 76.7468 - val_loss: 14.8978 - val_mae: 122.8861 - 134ms/epoch - 27ms/step\n",
      "Epoch 277/300\n",
      "5/5 - 0s - loss: 14.0356 - mae: 76.9464 - val_loss: 14.8966 - val_mae: 123.7823 - 129ms/epoch - 26ms/step\n",
      "Epoch 278/300\n",
      "5/5 - 0s - loss: 13.9481 - mae: 76.5995 - val_loss: 14.8976 - val_mae: 121.5955 - 133ms/epoch - 27ms/step\n",
      "Epoch 279/300\n",
      "5/5 - 0s - loss: 13.9747 - mae: 76.4894 - val_loss: 14.8980 - val_mae: 122.3499 - 138ms/epoch - 28ms/step\n",
      "Epoch 280/300\n",
      "5/5 - 0s - loss: 13.9360 - mae: 76.9036 - val_loss: 14.9032 - val_mae: 122.2670 - 148ms/epoch - 30ms/step\n",
      "Epoch 281/300\n",
      "5/5 - 0s - loss: 13.9104 - mae: 76.3951 - val_loss: 14.9019 - val_mae: 121.5523 - 140ms/epoch - 28ms/step\n",
      "Epoch 282/300\n",
      "5/5 - 0s - loss: 13.9141 - mae: 76.7087 - val_loss: 14.9004 - val_mae: 125.9150 - 137ms/epoch - 27ms/step\n",
      "Epoch 283/300\n",
      "5/5 - 0s - loss: 13.9219 - mae: 76.6194 - val_loss: 14.9046 - val_mae: 123.8293 - 140ms/epoch - 28ms/step\n",
      "Epoch 284/300\n",
      "5/5 - 0s - loss: 13.8573 - mae: 76.2323 - val_loss: 14.8924 - val_mae: 123.6428 - 144ms/epoch - 29ms/step\n",
      "Epoch 285/300\n",
      "5/5 - 0s - loss: 13.8772 - mae: 76.5909 - val_loss: 14.8914 - val_mae: 121.5984 - 141ms/epoch - 28ms/step\n",
      "Epoch 286/300\n",
      "5/5 - 0s - loss: 13.8476 - mae: 76.5296 - val_loss: 14.8881 - val_mae: 121.5307 - 145ms/epoch - 29ms/step\n",
      "Epoch 287/300\n",
      "5/5 - 0s - loss: 13.8694 - mae: 76.5531 - val_loss: 14.8929 - val_mae: 120.8248 - 82ms/epoch - 16ms/step\n",
      "Epoch 288/300\n",
      "5/5 - 0s - loss: 13.8636 - mae: 76.5142 - val_loss: 14.8888 - val_mae: 123.6470 - 80ms/epoch - 16ms/step\n",
      "Epoch 289/300\n",
      "5/5 - 0s - loss: 13.8598 - mae: 76.7770 - val_loss: 14.8882 - val_mae: 122.0403 - 85ms/epoch - 17ms/step\n",
      "Epoch 290/300\n",
      "5/5 - 0s - loss: 13.8116 - mae: 76.4159 - val_loss: 14.8812 - val_mae: 124.2742 - 87ms/epoch - 17ms/step\n",
      "Epoch 291/300\n",
      "5/5 - 0s - loss: 13.8856 - mae: 76.3604 - val_loss: 14.8844 - val_mae: 122.0125 - 81ms/epoch - 16ms/step\n",
      "Epoch 292/300\n",
      "5/5 - 0s - loss: 13.8102 - mae: 76.2543 - val_loss: 14.8840 - val_mae: 122.6101 - 86ms/epoch - 17ms/step\n",
      "Epoch 293/300\n",
      "5/5 - 0s - loss: 13.7691 - mae: 76.3289 - val_loss: 14.8851 - val_mae: 122.6474 - 81ms/epoch - 16ms/step\n",
      "Epoch 294/300\n",
      "5/5 - 0s - loss: 13.8194 - mae: 76.5924 - val_loss: 14.8861 - val_mae: 122.2588 - 89ms/epoch - 18ms/step\n",
      "Epoch 295/300\n",
      "5/5 - 0s - loss: 13.8332 - mae: 76.3630 - val_loss: 14.8922 - val_mae: 118.2582 - 88ms/epoch - 18ms/step\n",
      "Epoch 296/300\n",
      "5/5 - 0s - loss: 13.8028 - mae: 76.0361 - val_loss: 14.8980 - val_mae: 122.2122 - 81ms/epoch - 16ms/step\n",
      "Epoch 297/300\n",
      "5/5 - 0s - loss: 13.7634 - mae: 76.0046 - val_loss: 14.8974 - val_mae: 123.0097 - 91ms/epoch - 18ms/step\n",
      "Epoch 298/300\n",
      "5/5 - 0s - loss: 13.7521 - mae: 76.4826 - val_loss: 14.8953 - val_mae: 123.3993 - 83ms/epoch - 17ms/step\n",
      "Epoch 299/300\n",
      "5/5 - 0s - loss: 13.7427 - mae: 76.1582 - val_loss: 14.9010 - val_mae: 121.7173 - 83ms/epoch - 17ms/step\n",
      "Epoch 300/300\n",
      "5/5 - 0s - loss: 13.7168 - mae: 75.9903 - val_loss: 14.9009 - val_mae: 125.7978 - 84ms/epoch - 17ms/step\n",
      "Epoch 1/300\n",
      "5/5 - 1s - loss: 3180.1716 - mae: 98.8853 - val_loss: 64594204.0000 - val_mae: 105.2000 - 1s/epoch - 253ms/step\n",
      "Epoch 2/300\n",
      "5/5 - 0s - loss: 1575.7518 - mae: 98.8733 - val_loss: 241550.2188 - val_mae: 105.5313 - 91ms/epoch - 18ms/step\n",
      "Epoch 3/300\n",
      "5/5 - 0s - loss: 1206.5200 - mae: 98.8344 - val_loss: 6454.4736 - val_mae: 104.3773 - 92ms/epoch - 18ms/step\n",
      "Epoch 4/300\n",
      "5/5 - 0s - loss: 985.8293 - mae: 98.7771 - val_loss: 960.9881 - val_mae: 104.7202 - 86ms/epoch - 17ms/step\n",
      "Epoch 5/300\n",
      "5/5 - 0s - loss: 836.2490 - mae: 98.7654 - val_loss: 382.5066 - val_mae: 104.9962 - 113ms/epoch - 23ms/step\n",
      "Epoch 6/300\n",
      "5/5 - 0s - loss: 726.4421 - mae: 98.7563 - val_loss: 236.9472 - val_mae: 104.6532 - 91ms/epoch - 18ms/step\n",
      "Epoch 7/300\n",
      "5/5 - 0s - loss: 637.0220 - mae: 98.7173 - val_loss: 182.0311 - val_mae: 104.8411 - 85ms/epoch - 17ms/step\n",
      "Epoch 8/300\n",
      "5/5 - 0s - loss: 567.7342 - mae: 98.6606 - val_loss: 155.4176 - val_mae: 104.5599 - 90ms/epoch - 18ms/step\n",
      "Epoch 9/300\n",
      "5/5 - 0s - loss: 513.8651 - mae: 98.6077 - val_loss: 139.4021 - val_mae: 104.8796 - 85ms/epoch - 17ms/step\n",
      "Epoch 10/300\n",
      "5/5 - 0s - loss: 462.2088 - mae: 98.5896 - val_loss: 129.4390 - val_mae: 104.1987 - 89ms/epoch - 18ms/step\n",
      "Epoch 11/300\n",
      "5/5 - 0s - loss: 420.0055 - mae: 98.5463 - val_loss: 122.6084 - val_mae: 104.8282 - 91ms/epoch - 18ms/step\n",
      "Epoch 12/300\n",
      "5/5 - 0s - loss: 385.8400 - mae: 98.5978 - val_loss: 117.8840 - val_mae: 104.0398 - 99ms/epoch - 20ms/step\n",
      "Epoch 13/300\n",
      "5/5 - 0s - loss: 352.7021 - mae: 98.4543 - val_loss: 113.9372 - val_mae: 104.3678 - 85ms/epoch - 17ms/step\n",
      "Epoch 14/300\n",
      "5/5 - 0s - loss: 321.3165 - mae: 98.4758 - val_loss: 110.4358 - val_mae: 104.3509 - 94ms/epoch - 19ms/step\n",
      "Epoch 15/300\n",
      "5/5 - 0s - loss: 294.1536 - mae: 98.3782 - val_loss: 107.1492 - val_mae: 104.4658 - 84ms/epoch - 17ms/step\n",
      "Epoch 16/300\n",
      "5/5 - 0s - loss: 271.3343 - mae: 98.3018 - val_loss: 103.7672 - val_mae: 104.1279 - 89ms/epoch - 18ms/step\n",
      "Epoch 17/300\n",
      "5/5 - 0s - loss: 247.9283 - mae: 98.2428 - val_loss: 100.7710 - val_mae: 104.4599 - 88ms/epoch - 18ms/step\n",
      "Epoch 18/300\n",
      "5/5 - 0s - loss: 229.9723 - mae: 98.1714 - val_loss: 97.7841 - val_mae: 104.1232 - 87ms/epoch - 17ms/step\n",
      "Epoch 19/300\n",
      "5/5 - 0s - loss: 211.2643 - mae: 98.1208 - val_loss: 94.4774 - val_mae: 104.4317 - 86ms/epoch - 17ms/step\n",
      "Epoch 20/300\n",
      "5/5 - 0s - loss: 195.2264 - mae: 98.0447 - val_loss: 91.8572 - val_mae: 104.2475 - 86ms/epoch - 17ms/step\n",
      "Epoch 21/300\n",
      "5/5 - 0s - loss: 180.7741 - mae: 98.0143 - val_loss: 88.8464 - val_mae: 104.1621 - 83ms/epoch - 17ms/step\n",
      "Epoch 22/300\n",
      "5/5 - 0s - loss: 170.3552 - mae: 97.8646 - val_loss: 85.9752 - val_mae: 104.1523 - 80ms/epoch - 16ms/step\n",
      "Epoch 23/300\n",
      "5/5 - 0s - loss: 156.0763 - mae: 97.8569 - val_loss: 83.7046 - val_mae: 103.9409 - 102ms/epoch - 20ms/step\n",
      "Epoch 24/300\n",
      "5/5 - 0s - loss: 145.7896 - mae: 97.7851 - val_loss: 81.3884 - val_mae: 104.2654 - 107ms/epoch - 21ms/step\n",
      "Epoch 25/300\n",
      "5/5 - 0s - loss: 135.2179 - mae: 97.6850 - val_loss: 79.2553 - val_mae: 103.8733 - 88ms/epoch - 18ms/step\n",
      "Epoch 26/300\n",
      "5/5 - 0s - loss: 127.2601 - mae: 97.6270 - val_loss: 77.0141 - val_mae: 103.9159 - 86ms/epoch - 17ms/step\n",
      "Epoch 27/300\n",
      "5/5 - 0s - loss: 118.5635 - mae: 97.7229 - val_loss: 74.8925 - val_mae: 104.1142 - 85ms/epoch - 17ms/step\n",
      "Epoch 28/300\n",
      "5/5 - 0s - loss: 110.2655 - mae: 97.5920 - val_loss: 73.0909 - val_mae: 103.9247 - 87ms/epoch - 17ms/step\n",
      "Epoch 29/300\n",
      "5/5 - 0s - loss: 103.9414 - mae: 97.5283 - val_loss: 71.3438 - val_mae: 103.6958 - 87ms/epoch - 17ms/step\n",
      "Epoch 30/300\n",
      "5/5 - 0s - loss: 99.2001 - mae: 97.4223 - val_loss: 69.5234 - val_mae: 103.7940 - 87ms/epoch - 17ms/step\n",
      "Epoch 31/300\n",
      "5/5 - 0s - loss: 93.6977 - mae: 97.3576 - val_loss: 68.0249 - val_mae: 103.3931 - 84ms/epoch - 17ms/step\n",
      "Epoch 32/300\n",
      "5/5 - 0s - loss: 88.3981 - mae: 97.2327 - val_loss: 66.5856 - val_mae: 103.5902 - 86ms/epoch - 17ms/step\n",
      "Epoch 33/300\n",
      "5/5 - 0s - loss: 84.9384 - mae: 97.1148 - val_loss: 65.3456 - val_mae: 103.4672 - 85ms/epoch - 17ms/step\n",
      "Epoch 34/300\n",
      "5/5 - 0s - loss: 80.9952 - mae: 97.0552 - val_loss: 63.9866 - val_mae: 103.7178 - 83ms/epoch - 17ms/step\n",
      "Epoch 35/300\n",
      "5/5 - 0s - loss: 78.4928 - mae: 97.0382 - val_loss: 62.6377 - val_mae: 103.6600 - 110ms/epoch - 22ms/step\n",
      "Epoch 36/300\n",
      "5/5 - 0s - loss: 74.1059 - mae: 96.9611 - val_loss: 61.3943 - val_mae: 103.3965 - 86ms/epoch - 17ms/step\n",
      "Epoch 37/300\n",
      "5/5 - 0s - loss: 71.8140 - mae: 96.9138 - val_loss: 60.1075 - val_mae: 103.5350 - 85ms/epoch - 17ms/step\n",
      "Epoch 38/300\n",
      "5/5 - 0s - loss: 68.3906 - mae: 96.9630 - val_loss: 59.2472 - val_mae: 103.0923 - 87ms/epoch - 17ms/step\n",
      "Epoch 39/300\n",
      "5/5 - 0s - loss: 65.9690 - mae: 96.8212 - val_loss: 58.1787 - val_mae: 102.7877 - 85ms/epoch - 17ms/step\n",
      "Epoch 40/300\n",
      "5/5 - 0s - loss: 64.0501 - mae: 96.7098 - val_loss: 57.2359 - val_mae: 103.1036 - 86ms/epoch - 17ms/step\n",
      "Epoch 41/300\n",
      "5/5 - 0s - loss: 61.5428 - mae: 96.6681 - val_loss: 56.2969 - val_mae: 103.0511 - 90ms/epoch - 18ms/step\n",
      "Epoch 42/300\n",
      "5/5 - 0s - loss: 58.9725 - mae: 96.5647 - val_loss: 55.3447 - val_mae: 102.7140 - 86ms/epoch - 17ms/step\n",
      "Epoch 43/300\n",
      "5/5 - 0s - loss: 57.0385 - mae: 96.3993 - val_loss: 54.4474 - val_mae: 103.1105 - 81ms/epoch - 16ms/step\n",
      "Epoch 44/300\n",
      "5/5 - 0s - loss: 55.6320 - mae: 96.6024 - val_loss: 53.6005 - val_mae: 102.5558 - 85ms/epoch - 17ms/step\n",
      "Epoch 45/300\n",
      "5/5 - 0s - loss: 54.3234 - mae: 96.3491 - val_loss: 52.9225 - val_mae: 102.6370 - 82ms/epoch - 16ms/step\n",
      "Epoch 46/300\n",
      "5/5 - 0s - loss: 52.4457 - mae: 96.2998 - val_loss: 51.9741 - val_mae: 102.6693 - 96ms/epoch - 19ms/step\n",
      "Epoch 47/300\n",
      "5/5 - 0s - loss: 51.3872 - mae: 96.2773 - val_loss: 51.3699 - val_mae: 103.0569 - 89ms/epoch - 18ms/step\n",
      "Epoch 48/300\n",
      "5/5 - 0s - loss: 49.6017 - mae: 96.2728 - val_loss: 50.4068 - val_mae: 102.9630 - 81ms/epoch - 16ms/step\n",
      "Epoch 49/300\n",
      "5/5 - 0s - loss: 47.6990 - mae: 96.1924 - val_loss: 49.7465 - val_mae: 102.8531 - 82ms/epoch - 16ms/step\n",
      "Epoch 50/300\n",
      "5/5 - 0s - loss: 46.7116 - mae: 96.1187 - val_loss: 49.0545 - val_mae: 102.3899 - 88ms/epoch - 18ms/step\n",
      "Epoch 51/300\n",
      "5/5 - 0s - loss: 45.4150 - mae: 96.0730 - val_loss: 48.3202 - val_mae: 102.7143 - 88ms/epoch - 18ms/step\n",
      "Epoch 52/300\n",
      "5/5 - 0s - loss: 45.3128 - mae: 96.0411 - val_loss: 47.6339 - val_mae: 102.2218 - 88ms/epoch - 18ms/step\n",
      "Epoch 53/300\n",
      "5/5 - 0s - loss: 43.7118 - mae: 95.9937 - val_loss: 47.0455 - val_mae: 102.9187 - 85ms/epoch - 17ms/step\n",
      "Epoch 54/300\n",
      "5/5 - 0s - loss: 42.7492 - mae: 95.6941 - val_loss: 46.2403 - val_mae: 101.9092 - 83ms/epoch - 17ms/step\n",
      "Epoch 55/300\n",
      "5/5 - 0s - loss: 42.2887 - mae: 95.7791 - val_loss: 45.5883 - val_mae: 102.5552 - 84ms/epoch - 17ms/step\n",
      "Epoch 56/300\n",
      "5/5 - 0s - loss: 41.0404 - mae: 95.6349 - val_loss: 44.8490 - val_mae: 102.4679 - 87ms/epoch - 17ms/step\n",
      "Epoch 57/300\n",
      "5/5 - 0s - loss: 39.7267 - mae: 95.6793 - val_loss: 44.2825 - val_mae: 102.4454 - 84ms/epoch - 17ms/step\n",
      "Epoch 58/300\n",
      "5/5 - 0s - loss: 39.3304 - mae: 95.4412 - val_loss: 43.7182 - val_mae: 102.2520 - 108ms/epoch - 22ms/step\n",
      "Epoch 59/300\n",
      "5/5 - 0s - loss: 38.8244 - mae: 95.5792 - val_loss: 42.9712 - val_mae: 102.1632 - 89ms/epoch - 18ms/step\n",
      "Epoch 60/300\n",
      "5/5 - 0s - loss: 37.6348 - mae: 95.4846 - val_loss: 42.3627 - val_mae: 102.0311 - 82ms/epoch - 16ms/step\n",
      "Epoch 61/300\n",
      "5/5 - 0s - loss: 36.6648 - mae: 95.5087 - val_loss: 41.7456 - val_mae: 102.0119 - 86ms/epoch - 17ms/step\n",
      "Epoch 62/300\n",
      "5/5 - 0s - loss: 35.9343 - mae: 95.2605 - val_loss: 41.2499 - val_mae: 102.8837 - 86ms/epoch - 17ms/step\n",
      "Epoch 63/300\n",
      "5/5 - 0s - loss: 35.4376 - mae: 95.1130 - val_loss: 40.6197 - val_mae: 101.8964 - 84ms/epoch - 17ms/step\n",
      "Epoch 64/300\n",
      "5/5 - 0s - loss: 34.9451 - mae: 95.1072 - val_loss: 40.1305 - val_mae: 101.8150 - 83ms/epoch - 17ms/step\n",
      "Epoch 65/300\n",
      "5/5 - 0s - loss: 34.3528 - mae: 95.2061 - val_loss: 39.5317 - val_mae: 101.9769 - 84ms/epoch - 17ms/step\n",
      "Epoch 66/300\n",
      "5/5 - 0s - loss: 33.8746 - mae: 95.0124 - val_loss: 39.0081 - val_mae: 101.5075 - 82ms/epoch - 16ms/step\n",
      "Epoch 67/300\n",
      "5/5 - 0s - loss: 33.0717 - mae: 95.1809 - val_loss: 38.5930 - val_mae: 101.7669 - 82ms/epoch - 16ms/step\n",
      "Epoch 68/300\n",
      "5/5 - 0s - loss: 33.2199 - mae: 95.0054 - val_loss: 38.2246 - val_mae: 102.3175 - 88ms/epoch - 18ms/step\n",
      "Epoch 69/300\n",
      "5/5 - 0s - loss: 32.3503 - mae: 95.0681 - val_loss: 37.7917 - val_mae: 101.4668 - 89ms/epoch - 18ms/step\n",
      "Epoch 70/300\n",
      "5/5 - 0s - loss: 31.5046 - mae: 94.8195 - val_loss: 37.3671 - val_mae: 101.8495 - 100ms/epoch - 20ms/step\n",
      "Epoch 71/300\n",
      "5/5 - 0s - loss: 31.8745 - mae: 94.8863 - val_loss: 36.7419 - val_mae: 101.3108 - 87ms/epoch - 17ms/step\n",
      "Epoch 72/300\n",
      "5/5 - 0s - loss: 30.8496 - mae: 94.9065 - val_loss: 36.2805 - val_mae: 102.5180 - 84ms/epoch - 17ms/step\n",
      "Epoch 73/300\n",
      "5/5 - 0s - loss: 30.5315 - mae: 94.6303 - val_loss: 35.8785 - val_mae: 101.6246 - 90ms/epoch - 18ms/step\n",
      "Epoch 74/300\n",
      "5/5 - 0s - loss: 29.9836 - mae: 94.8000 - val_loss: 35.4937 - val_mae: 101.4753 - 87ms/epoch - 17ms/step\n",
      "Epoch 75/300\n",
      "5/5 - 0s - loss: 30.3223 - mae: 94.7367 - val_loss: 35.0697 - val_mae: 102.0428 - 84ms/epoch - 17ms/step\n",
      "Epoch 76/300\n",
      "5/5 - 0s - loss: 29.2789 - mae: 94.5101 - val_loss: 34.5616 - val_mae: 101.4030 - 86ms/epoch - 17ms/step\n",
      "Epoch 77/300\n",
      "5/5 - 0s - loss: 29.2294 - mae: 94.6485 - val_loss: 34.1351 - val_mae: 100.7299 - 83ms/epoch - 17ms/step\n",
      "Epoch 78/300\n",
      "5/5 - 0s - loss: 28.6296 - mae: 94.4357 - val_loss: 33.7285 - val_mae: 101.2443 - 85ms/epoch - 17ms/step\n",
      "Epoch 79/300\n",
      "5/5 - 0s - loss: 28.2206 - mae: 94.5304 - val_loss: 33.4190 - val_mae: 101.5911 - 85ms/epoch - 17ms/step\n",
      "Epoch 80/300\n",
      "5/5 - 0s - loss: 28.0150 - mae: 94.6352 - val_loss: 33.0426 - val_mae: 101.4196 - 93ms/epoch - 19ms/step\n",
      "Epoch 81/300\n",
      "5/5 - 0s - loss: 27.4488 - mae: 94.3507 - val_loss: 32.7334 - val_mae: 101.5750 - 156ms/epoch - 31ms/step\n",
      "Epoch 82/300\n",
      "5/5 - 0s - loss: 27.5434 - mae: 94.3151 - val_loss: 32.4853 - val_mae: 101.1913 - 129ms/epoch - 26ms/step\n",
      "Epoch 83/300\n",
      "5/5 - 0s - loss: 27.3930 - mae: 94.2520 - val_loss: 32.1549 - val_mae: 101.1610 - 142ms/epoch - 28ms/step\n",
      "Epoch 84/300\n",
      "5/5 - 0s - loss: 26.7827 - mae: 94.2702 - val_loss: 31.8883 - val_mae: 100.8870 - 149ms/epoch - 30ms/step\n",
      "Epoch 85/300\n",
      "5/5 - 0s - loss: 26.6583 - mae: 94.1289 - val_loss: 31.5802 - val_mae: 100.8178 - 153ms/epoch - 31ms/step\n",
      "Epoch 86/300\n",
      "5/5 - 0s - loss: 27.0808 - mae: 94.1137 - val_loss: 31.3788 - val_mae: 101.1708 - 150ms/epoch - 30ms/step\n",
      "Epoch 87/300\n",
      "5/5 - 0s - loss: 25.7567 - mae: 94.0045 - val_loss: 31.0876 - val_mae: 101.3096 - 138ms/epoch - 28ms/step\n",
      "Epoch 88/300\n",
      "5/5 - 0s - loss: 25.8195 - mae: 93.7278 - val_loss: 30.7491 - val_mae: 101.0504 - 156ms/epoch - 31ms/step\n",
      "Epoch 89/300\n",
      "5/5 - 0s - loss: 25.2865 - mae: 94.0520 - val_loss: 30.4941 - val_mae: 100.4024 - 137ms/epoch - 27ms/step\n",
      "Epoch 90/300\n",
      "5/5 - 0s - loss: 25.1687 - mae: 94.0601 - val_loss: 30.1626 - val_mae: 101.4524 - 135ms/epoch - 27ms/step\n",
      "Epoch 91/300\n",
      "5/5 - 0s - loss: 24.9752 - mae: 93.9177 - val_loss: 29.9192 - val_mae: 99.9418 - 137ms/epoch - 27ms/step\n",
      "Epoch 92/300\n",
      "5/5 - 0s - loss: 25.0819 - mae: 93.7278 - val_loss: 29.6476 - val_mae: 100.9200 - 153ms/epoch - 31ms/step\n",
      "Epoch 93/300\n",
      "5/5 - 0s - loss: 24.4529 - mae: 93.7044 - val_loss: 29.3650 - val_mae: 100.7727 - 143ms/epoch - 29ms/step\n",
      "Epoch 94/300\n",
      "5/5 - 0s - loss: 24.3041 - mae: 93.7960 - val_loss: 29.0879 - val_mae: 101.4049 - 144ms/epoch - 29ms/step\n",
      "Epoch 95/300\n",
      "5/5 - 0s - loss: 23.9917 - mae: 93.5901 - val_loss: 28.8456 - val_mae: 101.0687 - 167ms/epoch - 33ms/step\n",
      "Epoch 96/300\n",
      "5/5 - 0s - loss: 23.7951 - mae: 93.8463 - val_loss: 28.6007 - val_mae: 100.2991 - 143ms/epoch - 29ms/step\n",
      "Epoch 97/300\n",
      "5/5 - 0s - loss: 23.5439 - mae: 93.3687 - val_loss: 28.4557 - val_mae: 100.5124 - 83ms/epoch - 17ms/step\n",
      "Epoch 98/300\n",
      "5/5 - 0s - loss: 23.6964 - mae: 93.5907 - val_loss: 28.2516 - val_mae: 100.2912 - 86ms/epoch - 17ms/step\n",
      "Epoch 99/300\n",
      "5/5 - 0s - loss: 23.7040 - mae: 93.7755 - val_loss: 28.1403 - val_mae: 100.2182 - 83ms/epoch - 17ms/step\n",
      "Epoch 100/300\n",
      "5/5 - 0s - loss: 23.0370 - mae: 93.4630 - val_loss: 27.9231 - val_mae: 100.1924 - 86ms/epoch - 17ms/step\n",
      "Epoch 101/300\n",
      "5/5 - 0s - loss: 22.6984 - mae: 93.4539 - val_loss: 27.7011 - val_mae: 100.9149 - 86ms/epoch - 17ms/step\n",
      "Epoch 102/300\n",
      "5/5 - 0s - loss: 22.7854 - mae: 93.3672 - val_loss: 27.4895 - val_mae: 100.6153 - 97ms/epoch - 19ms/step\n",
      "Epoch 103/300\n",
      "5/5 - 0s - loss: 22.6246 - mae: 93.4169 - val_loss: 27.2704 - val_mae: 99.9155 - 87ms/epoch - 17ms/step\n",
      "Epoch 104/300\n",
      "5/5 - 0s - loss: 22.4204 - mae: 93.2712 - val_loss: 27.0417 - val_mae: 100.5906 - 89ms/epoch - 18ms/step\n",
      "Epoch 105/300\n",
      "5/5 - 0s - loss: 22.3452 - mae: 93.4568 - val_loss: 26.7748 - val_mae: 100.1862 - 91ms/epoch - 18ms/step\n",
      "Epoch 106/300\n",
      "5/5 - 0s - loss: 21.9832 - mae: 93.2587 - val_loss: 26.6133 - val_mae: 99.7856 - 121ms/epoch - 24ms/step\n",
      "Epoch 107/300\n",
      "5/5 - 0s - loss: 22.1281 - mae: 93.0160 - val_loss: 26.3777 - val_mae: 99.4740 - 88ms/epoch - 18ms/step\n",
      "Epoch 108/300\n",
      "5/5 - 0s - loss: 21.7662 - mae: 93.2141 - val_loss: 26.1651 - val_mae: 100.4369 - 85ms/epoch - 17ms/step\n",
      "Epoch 109/300\n",
      "5/5 - 0s - loss: 21.6518 - mae: 93.1981 - val_loss: 25.9795 - val_mae: 100.4462 - 88ms/epoch - 18ms/step\n",
      "Epoch 110/300\n",
      "5/5 - 0s - loss: 21.4904 - mae: 92.7206 - val_loss: 25.8417 - val_mae: 99.1785 - 88ms/epoch - 18ms/step\n",
      "Epoch 111/300\n",
      "5/5 - 0s - loss: 21.5055 - mae: 92.8083 - val_loss: 25.7339 - val_mae: 99.5116 - 87ms/epoch - 17ms/step\n",
      "Epoch 112/300\n",
      "5/5 - 0s - loss: 21.3197 - mae: 92.9776 - val_loss: 25.6075 - val_mae: 99.5073 - 89ms/epoch - 18ms/step\n",
      "Epoch 113/300\n",
      "5/5 - 0s - loss: 21.2205 - mae: 92.8801 - val_loss: 25.4187 - val_mae: 100.6111 - 92ms/epoch - 18ms/step\n",
      "Epoch 114/300\n",
      "5/5 - 0s - loss: 21.1451 - mae: 93.0040 - val_loss: 25.2207 - val_mae: 100.0893 - 91ms/epoch - 18ms/step\n",
      "Epoch 115/300\n",
      "5/5 - 0s - loss: 21.0178 - mae: 92.7525 - val_loss: 24.9968 - val_mae: 99.1938 - 84ms/epoch - 17ms/step\n",
      "Epoch 116/300\n",
      "5/5 - 0s - loss: 20.6980 - mae: 93.0429 - val_loss: 24.8737 - val_mae: 99.8633 - 88ms/epoch - 18ms/step\n",
      "Epoch 117/300\n",
      "5/5 - 0s - loss: 20.7195 - mae: 93.0254 - val_loss: 24.7391 - val_mae: 99.7944 - 105ms/epoch - 21ms/step\n",
      "Epoch 118/300\n",
      "5/5 - 0s - loss: 20.5850 - mae: 92.6951 - val_loss: 24.6081 - val_mae: 99.2037 - 90ms/epoch - 18ms/step\n",
      "Epoch 119/300\n",
      "5/5 - 0s - loss: 20.8465 - mae: 92.7254 - val_loss: 24.4716 - val_mae: 99.7385 - 90ms/epoch - 18ms/step\n",
      "Epoch 120/300\n",
      "5/5 - 0s - loss: 20.4643 - mae: 92.7290 - val_loss: 24.2606 - val_mae: 100.0777 - 89ms/epoch - 18ms/step\n",
      "Epoch 121/300\n",
      "5/5 - 0s - loss: 20.2547 - mae: 92.4596 - val_loss: 24.0870 - val_mae: 99.7914 - 84ms/epoch - 17ms/step\n",
      "Epoch 122/300\n",
      "5/5 - 0s - loss: 20.0699 - mae: 92.5058 - val_loss: 23.9974 - val_mae: 99.3897 - 88ms/epoch - 18ms/step\n",
      "Epoch 123/300\n",
      "5/5 - 0s - loss: 20.2355 - mae: 92.6123 - val_loss: 23.8265 - val_mae: 98.9706 - 91ms/epoch - 18ms/step\n",
      "Epoch 124/300\n",
      "5/5 - 0s - loss: 20.1206 - mae: 92.4562 - val_loss: 23.7271 - val_mae: 99.6331 - 93ms/epoch - 19ms/step\n",
      "Epoch 125/300\n",
      "5/5 - 0s - loss: 19.8456 - mae: 92.1741 - val_loss: 23.6180 - val_mae: 99.2300 - 90ms/epoch - 18ms/step\n",
      "Epoch 126/300\n",
      "5/5 - 0s - loss: 19.6817 - mae: 92.5453 - val_loss: 23.5144 - val_mae: 100.0513 - 87ms/epoch - 17ms/step\n",
      "Epoch 127/300\n",
      "5/5 - 0s - loss: 19.6161 - mae: 92.2422 - val_loss: 23.4321 - val_mae: 99.8186 - 88ms/epoch - 18ms/step\n",
      "Epoch 128/300\n",
      "5/5 - 0s - loss: 19.6668 - mae: 92.5139 - val_loss: 23.3491 - val_mae: 98.9573 - 106ms/epoch - 21ms/step\n",
      "Epoch 129/300\n",
      "5/5 - 0s - loss: 19.3425 - mae: 92.2863 - val_loss: 23.2024 - val_mae: 99.4146 - 88ms/epoch - 18ms/step\n",
      "Epoch 130/300\n",
      "5/5 - 0s - loss: 19.4548 - mae: 92.2804 - val_loss: 23.0741 - val_mae: 99.2387 - 87ms/epoch - 17ms/step\n",
      "Epoch 131/300\n",
      "5/5 - 0s - loss: 19.2936 - mae: 92.2251 - val_loss: 22.9377 - val_mae: 98.9336 - 86ms/epoch - 17ms/step\n",
      "Epoch 132/300\n",
      "5/5 - 0s - loss: 19.1575 - mae: 91.9117 - val_loss: 22.8000 - val_mae: 98.9622 - 85ms/epoch - 17ms/step\n",
      "Epoch 133/300\n",
      "5/5 - 0s - loss: 19.4094 - mae: 92.2259 - val_loss: 22.6568 - val_mae: 98.5258 - 82ms/epoch - 16ms/step\n",
      "Epoch 134/300\n",
      "5/5 - 0s - loss: 18.9810 - mae: 91.8168 - val_loss: 22.5682 - val_mae: 99.8789 - 94ms/epoch - 19ms/step\n",
      "Epoch 135/300\n",
      "5/5 - 0s - loss: 18.9502 - mae: 92.3867 - val_loss: 22.4713 - val_mae: 98.2947 - 90ms/epoch - 18ms/step\n",
      "Epoch 136/300\n",
      "5/5 - 0s - loss: 19.1189 - mae: 91.9015 - val_loss: 22.4124 - val_mae: 98.9329 - 96ms/epoch - 19ms/step\n",
      "Epoch 137/300\n",
      "5/5 - 0s - loss: 18.8439 - mae: 92.0727 - val_loss: 22.3057 - val_mae: 98.8310 - 88ms/epoch - 18ms/step\n",
      "Epoch 138/300\n",
      "5/5 - 0s - loss: 18.7139 - mae: 91.9680 - val_loss: 22.1932 - val_mae: 98.8717 - 89ms/epoch - 18ms/step\n",
      "Epoch 139/300\n",
      "5/5 - 0s - loss: 18.7108 - mae: 91.8573 - val_loss: 22.0695 - val_mae: 98.5804 - 103ms/epoch - 21ms/step\n",
      "Epoch 140/300\n",
      "5/5 - 0s - loss: 18.6077 - mae: 91.8930 - val_loss: 21.9264 - val_mae: 98.6085 - 83ms/epoch - 17ms/step\n",
      "Epoch 141/300\n",
      "5/5 - 0s - loss: 18.6661 - mae: 91.6175 - val_loss: 21.8471 - val_mae: 98.0257 - 81ms/epoch - 16ms/step\n",
      "Epoch 142/300\n",
      "5/5 - 0s - loss: 18.4337 - mae: 91.3851 - val_loss: 21.7779 - val_mae: 98.9712 - 87ms/epoch - 17ms/step\n",
      "Epoch 143/300\n",
      "5/5 - 0s - loss: 18.3818 - mae: 91.7892 - val_loss: 21.7090 - val_mae: 98.9514 - 84ms/epoch - 17ms/step\n",
      "Epoch 144/300\n",
      "5/5 - 0s - loss: 18.1998 - mae: 91.7497 - val_loss: 21.5970 - val_mae: 97.8199 - 84ms/epoch - 17ms/step\n",
      "Epoch 145/300\n",
      "5/5 - 0s - loss: 18.2798 - mae: 91.5163 - val_loss: 21.5558 - val_mae: 98.7519 - 116ms/epoch - 23ms/step\n",
      "Epoch 146/300\n",
      "5/5 - 0s - loss: 18.1688 - mae: 91.4304 - val_loss: 21.4511 - val_mae: 98.4247 - 83ms/epoch - 17ms/step\n",
      "Epoch 147/300\n",
      "5/5 - 0s - loss: 18.2225 - mae: 91.4509 - val_loss: 21.3218 - val_mae: 98.8283 - 85ms/epoch - 17ms/step\n",
      "Epoch 148/300\n",
      "5/5 - 0s - loss: 18.0075 - mae: 91.7175 - val_loss: 21.1987 - val_mae: 98.2759 - 84ms/epoch - 17ms/step\n",
      "Epoch 149/300\n",
      "5/5 - 0s - loss: 18.1081 - mae: 91.3909 - val_loss: 21.1514 - val_mae: 98.5846 - 89ms/epoch - 18ms/step\n",
      "Epoch 150/300\n",
      "5/5 - 0s - loss: 17.9000 - mae: 91.6270 - val_loss: 21.0421 - val_mae: 97.6365 - 110ms/epoch - 22ms/step\n",
      "Epoch 151/300\n",
      "5/5 - 0s - loss: 17.8267 - mae: 91.3952 - val_loss: 20.9565 - val_mae: 98.4612 - 85ms/epoch - 17ms/step\n",
      "Epoch 152/300\n",
      "5/5 - 0s - loss: 17.9295 - mae: 91.4960 - val_loss: 20.8952 - val_mae: 97.9772 - 88ms/epoch - 18ms/step\n",
      "Epoch 153/300\n",
      "5/5 - 0s - loss: 17.7292 - mae: 91.7145 - val_loss: 20.8164 - val_mae: 97.8369 - 87ms/epoch - 17ms/step\n",
      "Epoch 154/300\n",
      "5/5 - 0s - loss: 17.6265 - mae: 91.5349 - val_loss: 20.7219 - val_mae: 97.4985 - 86ms/epoch - 17ms/step\n",
      "Epoch 155/300\n",
      "5/5 - 0s - loss: 17.8132 - mae: 91.3820 - val_loss: 20.6814 - val_mae: 97.5111 - 96ms/epoch - 19ms/step\n",
      "Epoch 156/300\n",
      "5/5 - 0s - loss: 17.5174 - mae: 91.2118 - val_loss: 20.6000 - val_mae: 98.3555 - 89ms/epoch - 18ms/step\n",
      "Epoch 157/300\n",
      "5/5 - 0s - loss: 17.5399 - mae: 91.4248 - val_loss: 20.5555 - val_mae: 97.4821 - 86ms/epoch - 17ms/step\n",
      "Epoch 158/300\n",
      "5/5 - 0s - loss: 17.3545 - mae: 90.9190 - val_loss: 20.5083 - val_mae: 98.5028 - 92ms/epoch - 18ms/step\n",
      "Epoch 159/300\n",
      "5/5 - 0s - loss: 17.3495 - mae: 91.0103 - val_loss: 20.4219 - val_mae: 97.5390 - 85ms/epoch - 17ms/step\n",
      "Epoch 160/300\n",
      "5/5 - 0s - loss: 17.3238 - mae: 91.3668 - val_loss: 20.3802 - val_mae: 98.6164 - 82ms/epoch - 16ms/step\n",
      "Epoch 161/300\n",
      "5/5 - 0s - loss: 17.2189 - mae: 91.1531 - val_loss: 20.3022 - val_mae: 98.1190 - 117ms/epoch - 23ms/step\n",
      "Epoch 162/300\n",
      "5/5 - 0s - loss: 17.2205 - mae: 91.0100 - val_loss: 20.1845 - val_mae: 97.5481 - 84ms/epoch - 17ms/step\n",
      "Epoch 163/300\n",
      "5/5 - 0s - loss: 17.3204 - mae: 90.8818 - val_loss: 20.0955 - val_mae: 96.9969 - 81ms/epoch - 16ms/step\n",
      "Epoch 164/300\n",
      "5/5 - 0s - loss: 17.0560 - mae: 90.8167 - val_loss: 20.0433 - val_mae: 98.2875 - 85ms/epoch - 17ms/step\n",
      "Epoch 165/300\n",
      "5/5 - 0s - loss: 17.1119 - mae: 90.9623 - val_loss: 19.9734 - val_mae: 97.9268 - 82ms/epoch - 16ms/step\n",
      "Epoch 166/300\n",
      "5/5 - 0s - loss: 16.9721 - mae: 90.7679 - val_loss: 19.8929 - val_mae: 98.3996 - 83ms/epoch - 17ms/step\n",
      "Epoch 167/300\n",
      "5/5 - 0s - loss: 17.0544 - mae: 90.7470 - val_loss: 19.7937 - val_mae: 97.6263 - 89ms/epoch - 18ms/step\n",
      "Epoch 168/300\n",
      "5/5 - 0s - loss: 17.1342 - mae: 91.0122 - val_loss: 19.7362 - val_mae: 98.1994 - 86ms/epoch - 17ms/step\n",
      "Epoch 169/300\n",
      "5/5 - 0s - loss: 16.8786 - mae: 90.5811 - val_loss: 19.6689 - val_mae: 98.2469 - 84ms/epoch - 17ms/step\n",
      "Epoch 170/300\n",
      "5/5 - 0s - loss: 16.8895 - mae: 90.6660 - val_loss: 19.5593 - val_mae: 96.8830 - 85ms/epoch - 17ms/step\n",
      "Epoch 171/300\n",
      "5/5 - 0s - loss: 16.8220 - mae: 90.5475 - val_loss: 19.4702 - val_mae: 97.4128 - 88ms/epoch - 18ms/step\n",
      "Epoch 172/300\n",
      "5/5 - 0s - loss: 16.6994 - mae: 90.7644 - val_loss: 19.4400 - val_mae: 98.0420 - 89ms/epoch - 18ms/step\n",
      "Epoch 173/300\n",
      "5/5 - 0s - loss: 16.7118 - mae: 90.9178 - val_loss: 19.4098 - val_mae: 96.5011 - 101ms/epoch - 20ms/step\n",
      "Epoch 174/300\n",
      "5/5 - 0s - loss: 16.7365 - mae: 90.5432 - val_loss: 19.3269 - val_mae: 97.5844 - 82ms/epoch - 16ms/step\n",
      "Epoch 175/300\n",
      "5/5 - 0s - loss: 16.6356 - mae: 90.0416 - val_loss: 19.2576 - val_mae: 97.8800 - 85ms/epoch - 17ms/step\n",
      "Epoch 176/300\n",
      "5/5 - 0s - loss: 16.5842 - mae: 90.6666 - val_loss: 19.2073 - val_mae: 97.1392 - 88ms/epoch - 18ms/step\n",
      "Epoch 177/300\n",
      "5/5 - 0s - loss: 16.8093 - mae: 90.9899 - val_loss: 19.1826 - val_mae: 97.7079 - 81ms/epoch - 16ms/step\n",
      "Epoch 178/300\n",
      "5/5 - 0s - loss: 16.5133 - mae: 90.1454 - val_loss: 19.1106 - val_mae: 97.6475 - 90ms/epoch - 18ms/step\n",
      "Epoch 179/300\n",
      "5/5 - 0s - loss: 16.4154 - mae: 89.9270 - val_loss: 19.0494 - val_mae: 97.3952 - 84ms/epoch - 17ms/step\n",
      "Epoch 180/300\n",
      "5/5 - 0s - loss: 16.4045 - mae: 90.0837 - val_loss: 18.9799 - val_mae: 97.0892 - 85ms/epoch - 17ms/step\n",
      "Epoch 181/300\n",
      "5/5 - 0s - loss: 16.3768 - mae: 89.8448 - val_loss: 18.9471 - val_mae: 97.3638 - 84ms/epoch - 17ms/step\n",
      "Epoch 182/300\n",
      "5/5 - 0s - loss: 16.4335 - mae: 90.1963 - val_loss: 18.9004 - val_mae: 97.4103 - 81ms/epoch - 16ms/step\n",
      "Epoch 183/300\n",
      "5/5 - 0s - loss: 16.2942 - mae: 90.3578 - val_loss: 18.8582 - val_mae: 96.7104 - 91ms/epoch - 18ms/step\n",
      "Epoch 184/300\n",
      "5/5 - 0s - loss: 16.4441 - mae: 90.6111 - val_loss: 18.8002 - val_mae: 96.6545 - 99ms/epoch - 20ms/step\n",
      "Epoch 185/300\n",
      "5/5 - 0s - loss: 16.3542 - mae: 90.5308 - val_loss: 18.7236 - val_mae: 96.7558 - 89ms/epoch - 18ms/step\n",
      "Epoch 186/300\n",
      "5/5 - 0s - loss: 16.1825 - mae: 90.2280 - val_loss: 18.6665 - val_mae: 97.1296 - 87ms/epoch - 17ms/step\n",
      "Epoch 187/300\n",
      "5/5 - 0s - loss: 16.2345 - mae: 90.2763 - val_loss: 18.5763 - val_mae: 96.8254 - 84ms/epoch - 17ms/step\n",
      "Epoch 188/300\n",
      "5/5 - 0s - loss: 16.3820 - mae: 90.2631 - val_loss: 18.5085 - val_mae: 98.1436 - 92ms/epoch - 18ms/step\n",
      "Epoch 189/300\n",
      "5/5 - 0s - loss: 16.1021 - mae: 90.0365 - val_loss: 18.4486 - val_mae: 96.7372 - 89ms/epoch - 18ms/step\n",
      "Epoch 190/300\n",
      "5/5 - 0s - loss: 16.0532 - mae: 90.4388 - val_loss: 18.4034 - val_mae: 97.6572 - 82ms/epoch - 16ms/step\n",
      "Epoch 191/300\n",
      "5/5 - 0s - loss: 16.0544 - mae: 90.0056 - val_loss: 18.3386 - val_mae: 96.0069 - 90ms/epoch - 18ms/step\n",
      "Epoch 192/300\n",
      "5/5 - 0s - loss: 16.0546 - mae: 90.0351 - val_loss: 18.2943 - val_mae: 96.7562 - 82ms/epoch - 16ms/step\n",
      "Epoch 193/300\n",
      "5/5 - 0s - loss: 15.9223 - mae: 89.9434 - val_loss: 18.2655 - val_mae: 97.0719 - 85ms/epoch - 17ms/step\n",
      "Epoch 194/300\n",
      "5/5 - 0s - loss: 16.0991 - mae: 89.8162 - val_loss: 18.2222 - val_mae: 97.0630 - 92ms/epoch - 18ms/step\n",
      "Epoch 195/300\n",
      "5/5 - 0s - loss: 15.9968 - mae: 89.5850 - val_loss: 18.1957 - val_mae: 96.5489 - 90ms/epoch - 18ms/step\n",
      "Epoch 196/300\n",
      "5/5 - 0s - loss: 15.8618 - mae: 90.0032 - val_loss: 18.1593 - val_mae: 97.5167 - 97ms/epoch - 19ms/step\n",
      "Epoch 197/300\n",
      "5/5 - 0s - loss: 15.9063 - mae: 89.8854 - val_loss: 18.1440 - val_mae: 95.5060 - 92ms/epoch - 18ms/step\n",
      "Epoch 198/300\n",
      "5/5 - 0s - loss: 15.9112 - mae: 89.6356 - val_loss: 18.0842 - val_mae: 96.0836 - 85ms/epoch - 17ms/step\n",
      "Epoch 199/300\n",
      "5/5 - 0s - loss: 15.7458 - mae: 89.4997 - val_loss: 18.0364 - val_mae: 97.0949 - 89ms/epoch - 18ms/step\n",
      "Epoch 200/300\n",
      "5/5 - 0s - loss: 15.8034 - mae: 90.1936 - val_loss: 17.9999 - val_mae: 96.5423 - 92ms/epoch - 18ms/step\n",
      "Epoch 201/300\n",
      "5/5 - 0s - loss: 15.7025 - mae: 89.9120 - val_loss: 17.9736 - val_mae: 97.3451 - 91ms/epoch - 18ms/step\n",
      "Epoch 202/300\n",
      "5/5 - 0s - loss: 15.9116 - mae: 89.4317 - val_loss: 17.9611 - val_mae: 94.5274 - 87ms/epoch - 17ms/step\n",
      "Epoch 203/300\n",
      "5/5 - 0s - loss: 15.7896 - mae: 89.6503 - val_loss: 17.9195 - val_mae: 96.4059 - 86ms/epoch - 17ms/step\n",
      "Epoch 204/300\n",
      "5/5 - 0s - loss: 15.7516 - mae: 89.4341 - val_loss: 17.8886 - val_mae: 97.2020 - 89ms/epoch - 18ms/step\n",
      "Epoch 205/300\n",
      "5/5 - 0s - loss: 15.5873 - mae: 89.3115 - val_loss: 17.8408 - val_mae: 95.8693 - 152ms/epoch - 30ms/step\n",
      "Epoch 206/300\n",
      "5/5 - 0s - loss: 15.6385 - mae: 89.5642 - val_loss: 17.7960 - val_mae: 95.9212 - 156ms/epoch - 31ms/step\n",
      "Epoch 207/300\n",
      "5/5 - 0s - loss: 15.6177 - mae: 89.2828 - val_loss: 17.7328 - val_mae: 96.5722 - 147ms/epoch - 29ms/step\n",
      "Epoch 208/300\n",
      "5/5 - 0s - loss: 15.5768 - mae: 89.7587 - val_loss: 17.7068 - val_mae: 95.3710 - 153ms/epoch - 31ms/step\n",
      "Epoch 209/300\n",
      "5/5 - 0s - loss: 15.6064 - mae: 89.2456 - val_loss: 17.6575 - val_mae: 96.3446 - 168ms/epoch - 34ms/step\n",
      "Epoch 210/300\n",
      "5/5 - 0s - loss: 15.4760 - mae: 89.1737 - val_loss: 17.6382 - val_mae: 96.0029 - 142ms/epoch - 28ms/step\n",
      "Epoch 211/300\n",
      "5/5 - 0s - loss: 15.5428 - mae: 89.3913 - val_loss: 17.6064 - val_mae: 95.2464 - 138ms/epoch - 28ms/step\n",
      "Epoch 212/300\n",
      "5/5 - 0s - loss: 15.4542 - mae: 88.8779 - val_loss: 17.5724 - val_mae: 95.1229 - 157ms/epoch - 31ms/step\n",
      "Epoch 213/300\n",
      "5/5 - 0s - loss: 15.4857 - mae: 89.6488 - val_loss: 17.5289 - val_mae: 95.4050 - 141ms/epoch - 28ms/step\n",
      "Epoch 214/300\n",
      "5/5 - 0s - loss: 15.4734 - mae: 89.2743 - val_loss: 17.5133 - val_mae: 95.7997 - 132ms/epoch - 26ms/step\n",
      "Epoch 215/300\n",
      "5/5 - 0s - loss: 15.3241 - mae: 89.3996 - val_loss: 17.4743 - val_mae: 96.3620 - 142ms/epoch - 28ms/step\n",
      "Epoch 216/300\n",
      "5/5 - 0s - loss: 15.3934 - mae: 89.2897 - val_loss: 17.4305 - val_mae: 95.5664 - 138ms/epoch - 28ms/step\n",
      "Epoch 217/300\n",
      "5/5 - 0s - loss: 15.3186 - mae: 89.3209 - val_loss: 17.3812 - val_mae: 96.7105 - 149ms/epoch - 30ms/step\n",
      "Epoch 218/300\n",
      "5/5 - 0s - loss: 15.3502 - mae: 89.6278 - val_loss: 17.3434 - val_mae: 95.9124 - 147ms/epoch - 29ms/step\n",
      "Epoch 219/300\n",
      "5/5 - 0s - loss: 15.2256 - mae: 89.3528 - val_loss: 17.3016 - val_mae: 96.3407 - 143ms/epoch - 29ms/step\n",
      "Epoch 220/300\n",
      "5/5 - 0s - loss: 15.3416 - mae: 88.9884 - val_loss: 17.2795 - val_mae: 95.3393 - 151ms/epoch - 30ms/step\n",
      "Epoch 221/300\n",
      "5/5 - 0s - loss: 15.2983 - mae: 88.7538 - val_loss: 17.2338 - val_mae: 96.0445 - 87ms/epoch - 17ms/step\n",
      "Epoch 222/300\n",
      "5/5 - 0s - loss: 15.2531 - mae: 89.2387 - val_loss: 17.2215 - val_mae: 95.5683 - 89ms/epoch - 18ms/step\n",
      "Epoch 223/300\n",
      "5/5 - 0s - loss: 15.1321 - mae: 88.5589 - val_loss: 17.1882 - val_mae: 96.3837 - 88ms/epoch - 18ms/step\n",
      "Epoch 224/300\n",
      "5/5 - 0s - loss: 15.1511 - mae: 88.8784 - val_loss: 17.1696 - val_mae: 96.0213 - 85ms/epoch - 17ms/step\n",
      "Epoch 225/300\n",
      "5/5 - 0s - loss: 15.1393 - mae: 88.9664 - val_loss: 17.1236 - val_mae: 95.8709 - 83ms/epoch - 17ms/step\n",
      "Epoch 226/300\n",
      "5/5 - 0s - loss: 15.2466 - mae: 89.0520 - val_loss: 17.0726 - val_mae: 96.8664 - 86ms/epoch - 17ms/step\n",
      "Epoch 227/300\n",
      "5/5 - 0s - loss: 15.1661 - mae: 89.1114 - val_loss: 17.0496 - val_mae: 95.9159 - 92ms/epoch - 18ms/step\n",
      "Epoch 228/300\n",
      "5/5 - 0s - loss: 15.1090 - mae: 89.0348 - val_loss: 16.9906 - val_mae: 95.1146 - 85ms/epoch - 17ms/step\n",
      "Epoch 229/300\n",
      "5/5 - 0s - loss: 15.0893 - mae: 89.3233 - val_loss: 16.9582 - val_mae: 95.5975 - 87ms/epoch - 17ms/step\n",
      "Epoch 230/300\n",
      "5/5 - 0s - loss: 15.0919 - mae: 88.9470 - val_loss: 16.9403 - val_mae: 95.4544 - 82ms/epoch - 16ms/step\n",
      "Epoch 231/300\n",
      "5/5 - 0s - loss: 15.0112 - mae: 88.8001 - val_loss: 16.9147 - val_mae: 94.5743 - 99ms/epoch - 20ms/step\n",
      "Epoch 232/300\n",
      "5/5 - 0s - loss: 15.0537 - mae: 88.6152 - val_loss: 16.9031 - val_mae: 94.9138 - 85ms/epoch - 17ms/step\n",
      "Epoch 233/300\n",
      "5/5 - 0s - loss: 15.0824 - mae: 88.8475 - val_loss: 16.8579 - val_mae: 96.3243 - 90ms/epoch - 18ms/step\n",
      "Epoch 234/300\n",
      "5/5 - 0s - loss: 14.9111 - mae: 88.6360 - val_loss: 16.8360 - val_mae: 95.1631 - 85ms/epoch - 17ms/step\n",
      "Epoch 235/300\n",
      "5/5 - 0s - loss: 14.9172 - mae: 88.7069 - val_loss: 16.8104 - val_mae: 96.5515 - 92ms/epoch - 18ms/step\n",
      "Epoch 236/300\n",
      "5/5 - 0s - loss: 14.9308 - mae: 88.7132 - val_loss: 16.7833 - val_mae: 94.4889 - 87ms/epoch - 17ms/step\n",
      "Epoch 237/300\n",
      "5/5 - 0s - loss: 15.1300 - mae: 88.7170 - val_loss: 16.7372 - val_mae: 96.0168 - 83ms/epoch - 17ms/step\n",
      "Epoch 238/300\n",
      "5/5 - 0s - loss: 14.8673 - mae: 88.5948 - val_loss: 16.7154 - val_mae: 95.2355 - 89ms/epoch - 18ms/step\n",
      "Epoch 239/300\n",
      "5/5 - 0s - loss: 14.9031 - mae: 88.7190 - val_loss: 16.6902 - val_mae: 95.8483 - 85ms/epoch - 17ms/step\n",
      "Epoch 240/300\n",
      "5/5 - 0s - loss: 14.8974 - mae: 88.2405 - val_loss: 16.6541 - val_mae: 95.9484 - 85ms/epoch - 17ms/step\n",
      "Epoch 241/300\n",
      "5/5 - 0s - loss: 14.8485 - mae: 88.6660 - val_loss: 16.6329 - val_mae: 95.1925 - 81ms/epoch - 16ms/step\n",
      "Epoch 242/300\n",
      "5/5 - 0s - loss: 14.9677 - mae: 88.4235 - val_loss: 16.5800 - val_mae: 95.5801 - 81ms/epoch - 16ms/step\n",
      "Epoch 243/300\n",
      "5/5 - 0s - loss: 14.8729 - mae: 88.3581 - val_loss: 16.5487 - val_mae: 95.0836 - 102ms/epoch - 20ms/step\n",
      "Epoch 244/300\n",
      "5/5 - 0s - loss: 14.8274 - mae: 88.6458 - val_loss: 16.5430 - val_mae: 96.0202 - 90ms/epoch - 18ms/step\n",
      "Epoch 245/300\n",
      "5/5 - 0s - loss: 14.7794 - mae: 88.5592 - val_loss: 16.5210 - val_mae: 94.8335 - 90ms/epoch - 18ms/step\n",
      "Epoch 246/300\n",
      "5/5 - 0s - loss: 14.7181 - mae: 88.0829 - val_loss: 16.4957 - val_mae: 95.1668 - 86ms/epoch - 17ms/step\n",
      "Epoch 247/300\n",
      "5/5 - 0s - loss: 14.7889 - mae: 88.2266 - val_loss: 16.4630 - val_mae: 94.1289 - 87ms/epoch - 17ms/step\n",
      "Epoch 248/300\n",
      "5/5 - 0s - loss: 14.7013 - mae: 88.5242 - val_loss: 16.4391 - val_mae: 95.0341 - 82ms/epoch - 16ms/step\n",
      "Epoch 249/300\n",
      "5/5 - 0s - loss: 14.7708 - mae: 88.3214 - val_loss: 16.4354 - val_mae: 95.2677 - 85ms/epoch - 17ms/step\n",
      "Epoch 250/300\n",
      "5/5 - 0s - loss: 14.7543 - mae: 87.5125 - val_loss: 16.4331 - val_mae: 95.1287 - 89ms/epoch - 18ms/step\n",
      "Epoch 251/300\n",
      "5/5 - 0s - loss: 14.6978 - mae: 88.4865 - val_loss: 16.4158 - val_mae: 95.5582 - 84ms/epoch - 17ms/step\n",
      "Epoch 252/300\n",
      "5/5 - 0s - loss: 14.6543 - mae: 88.4434 - val_loss: 16.4016 - val_mae: 94.4467 - 87ms/epoch - 17ms/step\n",
      "Epoch 253/300\n",
      "5/5 - 0s - loss: 14.5886 - mae: 88.3497 - val_loss: 16.3651 - val_mae: 95.7168 - 85ms/epoch - 17ms/step\n",
      "Epoch 254/300\n",
      "5/5 - 0s - loss: 14.6508 - mae: 87.7020 - val_loss: 16.3461 - val_mae: 94.3647 - 100ms/epoch - 20ms/step\n",
      "Epoch 255/300\n",
      "5/5 - 0s - loss: 14.6610 - mae: 87.7081 - val_loss: 16.3475 - val_mae: 94.9736 - 90ms/epoch - 18ms/step\n",
      "Epoch 256/300\n",
      "5/5 - 0s - loss: 14.5822 - mae: 87.9272 - val_loss: 16.3123 - val_mae: 94.3577 - 86ms/epoch - 17ms/step\n",
      "Epoch 257/300\n",
      "5/5 - 0s - loss: 14.6255 - mae: 88.0913 - val_loss: 16.2719 - val_mae: 95.1905 - 88ms/epoch - 18ms/step\n",
      "Epoch 258/300\n",
      "5/5 - 0s - loss: 14.5594 - mae: 87.8948 - val_loss: 16.2414 - val_mae: 94.9950 - 84ms/epoch - 17ms/step\n",
      "Epoch 259/300\n",
      "5/5 - 0s - loss: 14.5149 - mae: 88.0955 - val_loss: 16.2293 - val_mae: 94.0270 - 82ms/epoch - 16ms/step\n",
      "Epoch 260/300\n",
      "5/5 - 0s - loss: 14.5432 - mae: 87.9519 - val_loss: 16.1977 - val_mae: 94.8445 - 86ms/epoch - 17ms/step\n",
      "Epoch 261/300\n",
      "5/5 - 0s - loss: 14.4916 - mae: 87.8115 - val_loss: 16.1669 - val_mae: 93.1500 - 88ms/epoch - 18ms/step\n",
      "Epoch 262/300\n",
      "5/5 - 0s - loss: 14.5050 - mae: 87.5987 - val_loss: 16.1382 - val_mae: 94.3516 - 87ms/epoch - 17ms/step\n",
      "Epoch 263/300\n",
      "5/5 - 0s - loss: 14.4891 - mae: 87.9844 - val_loss: 16.1285 - val_mae: 95.5620 - 82ms/epoch - 16ms/step\n",
      "Epoch 264/300\n",
      "5/5 - 0s - loss: 14.4641 - mae: 87.7744 - val_loss: 16.0983 - val_mae: 94.4206 - 79ms/epoch - 16ms/step\n",
      "Epoch 265/300\n",
      "5/5 - 0s - loss: 14.4480 - mae: 88.4715 - val_loss: 16.0733 - val_mae: 95.0515 - 85ms/epoch - 17ms/step\n",
      "Epoch 266/300\n",
      "5/5 - 0s - loss: 14.4438 - mae: 87.3182 - val_loss: 16.0433 - val_mae: 94.9782 - 105ms/epoch - 21ms/step\n",
      "Epoch 267/300\n",
      "5/5 - 0s - loss: 14.4400 - mae: 87.9650 - val_loss: 16.0169 - val_mae: 92.9590 - 85ms/epoch - 17ms/step\n",
      "Epoch 268/300\n",
      "5/5 - 0s - loss: 14.4785 - mae: 87.7398 - val_loss: 16.0003 - val_mae: 94.4023 - 86ms/epoch - 17ms/step\n",
      "Epoch 269/300\n",
      "5/5 - 0s - loss: 14.3865 - mae: 87.7723 - val_loss: 15.9806 - val_mae: 95.4385 - 83ms/epoch - 17ms/step\n",
      "Epoch 270/300\n",
      "5/5 - 0s - loss: 14.3998 - mae: 87.7434 - val_loss: 15.9752 - val_mae: 94.7449 - 81ms/epoch - 16ms/step\n",
      "Epoch 271/300\n",
      "5/5 - 0s - loss: 14.3541 - mae: 86.9799 - val_loss: 15.9661 - val_mae: 95.1583 - 81ms/epoch - 16ms/step\n",
      "Epoch 272/300\n",
      "5/5 - 0s - loss: 14.3583 - mae: 87.3892 - val_loss: 15.9439 - val_mae: 94.5762 - 87ms/epoch - 17ms/step\n",
      "Epoch 273/300\n",
      "5/5 - 0s - loss: 14.3510 - mae: 87.9058 - val_loss: 15.9217 - val_mae: 94.0477 - 83ms/epoch - 17ms/step\n",
      "Epoch 274/300\n",
      "5/5 - 0s - loss: 14.3947 - mae: 87.8447 - val_loss: 15.8835 - val_mae: 94.1058 - 84ms/epoch - 17ms/step\n",
      "Epoch 275/300\n",
      "5/5 - 0s - loss: 14.4172 - mae: 87.4538 - val_loss: 15.8832 - val_mae: 95.2554 - 83ms/epoch - 17ms/step\n",
      "Epoch 276/300\n",
      "5/5 - 0s - loss: 14.3108 - mae: 87.6391 - val_loss: 15.8573 - val_mae: 95.6949 - 82ms/epoch - 16ms/step\n",
      "Epoch 277/300\n",
      "5/5 - 0s - loss: 14.3125 - mae: 86.9253 - val_loss: 15.8282 - val_mae: 95.6550 - 97ms/epoch - 19ms/step\n",
      "Epoch 278/300\n",
      "5/5 - 0s - loss: 14.2970 - mae: 87.6319 - val_loss: 15.8165 - val_mae: 95.0293 - 89ms/epoch - 18ms/step\n",
      "Epoch 279/300\n",
      "5/5 - 0s - loss: 14.3434 - mae: 87.2391 - val_loss: 15.7854 - val_mae: 95.2132 - 85ms/epoch - 17ms/step\n",
      "Epoch 280/300\n",
      "5/5 - 0s - loss: 14.2975 - mae: 87.5533 - val_loss: 15.7656 - val_mae: 94.9549 - 84ms/epoch - 17ms/step\n",
      "Epoch 281/300\n",
      "5/5 - 0s - loss: 14.2317 - mae: 87.4394 - val_loss: 15.7424 - val_mae: 95.4048 - 80ms/epoch - 16ms/step\n",
      "Epoch 282/300\n",
      "5/5 - 0s - loss: 14.2421 - mae: 87.1863 - val_loss: 15.7240 - val_mae: 93.5263 - 82ms/epoch - 16ms/step\n",
      "Epoch 283/300\n",
      "5/5 - 0s - loss: 14.2409 - mae: 87.3651 - val_loss: 15.7027 - val_mae: 95.7025 - 88ms/epoch - 18ms/step\n",
      "Epoch 284/300\n",
      "5/5 - 0s - loss: 14.1954 - mae: 87.0006 - val_loss: 15.6924 - val_mae: 92.4115 - 80ms/epoch - 16ms/step\n",
      "Epoch 285/300\n",
      "5/5 - 0s - loss: 14.1946 - mae: 87.3192 - val_loss: 15.6724 - val_mae: 94.2679 - 83ms/epoch - 17ms/step\n",
      "Epoch 286/300\n",
      "5/5 - 0s - loss: 14.1863 - mae: 87.1798 - val_loss: 15.6630 - val_mae: 93.3197 - 81ms/epoch - 16ms/step\n",
      "Epoch 287/300\n",
      "5/5 - 0s - loss: 14.1482 - mae: 87.0871 - val_loss: 15.6442 - val_mae: 94.8994 - 83ms/epoch - 17ms/step\n",
      "Epoch 288/300\n",
      "5/5 - 0s - loss: 14.1294 - mae: 87.0175 - val_loss: 15.6270 - val_mae: 93.1181 - 85ms/epoch - 17ms/step\n",
      "Epoch 289/300\n",
      "5/5 - 0s - loss: 14.1487 - mae: 87.4743 - val_loss: 15.6141 - val_mae: 94.6039 - 104ms/epoch - 21ms/step\n",
      "Epoch 290/300\n",
      "5/5 - 0s - loss: 14.1227 - mae: 86.8268 - val_loss: 15.5981 - val_mae: 94.1015 - 83ms/epoch - 17ms/step\n",
      "Epoch 291/300\n",
      "5/5 - 0s - loss: 14.1368 - mae: 86.9790 - val_loss: 15.5944 - val_mae: 93.3619 - 85ms/epoch - 17ms/step\n",
      "Epoch 292/300\n",
      "5/5 - 0s - loss: 14.1109 - mae: 86.8875 - val_loss: 15.5802 - val_mae: 93.5585 - 81ms/epoch - 16ms/step\n",
      "Epoch 293/300\n",
      "5/5 - 0s - loss: 14.1161 - mae: 86.9018 - val_loss: 15.5673 - val_mae: 93.4728 - 81ms/epoch - 16ms/step\n",
      "Epoch 294/300\n",
      "5/5 - 0s - loss: 14.1567 - mae: 86.9735 - val_loss: 15.5650 - val_mae: 93.7247 - 80ms/epoch - 16ms/step\n",
      "Epoch 295/300\n",
      "5/5 - 0s - loss: 14.0957 - mae: 87.0562 - val_loss: 15.5546 - val_mae: 92.9160 - 89ms/epoch - 18ms/step\n",
      "Epoch 296/300\n",
      "5/5 - 0s - loss: 14.0833 - mae: 86.9325 - val_loss: 15.5381 - val_mae: 94.2239 - 86ms/epoch - 17ms/step\n",
      "Epoch 297/300\n",
      "5/5 - 0s - loss: 14.0773 - mae: 86.2318 - val_loss: 15.5147 - val_mae: 93.6171 - 84ms/epoch - 17ms/step\n",
      "Epoch 298/300\n",
      "5/5 - 0s - loss: 14.0486 - mae: 86.2173 - val_loss: 15.5086 - val_mae: 93.0951 - 85ms/epoch - 17ms/step\n",
      "Epoch 299/300\n",
      "5/5 - 0s - loss: 14.0866 - mae: 87.0594 - val_loss: 15.4938 - val_mae: 94.4426 - 82ms/epoch - 16ms/step\n",
      "Epoch 300/300\n",
      "5/5 - 0s - loss: 14.1953 - mae: 87.1301 - val_loss: 15.4906 - val_mae: 94.1435 - 90ms/epoch - 18ms/step\n",
      "Epoch 1/300\n",
      "5/5 - 1s - loss: 1399.4729 - mae: 69.6950 - val_loss: 10434.7012 - val_mae: 215.7149 - 1s/epoch - 254ms/step\n",
      "Epoch 2/300\n",
      "5/5 - 0s - loss: 1192.5227 - mae: 69.6573 - val_loss: 7302.0010 - val_mae: 215.7446 - 93ms/epoch - 19ms/step\n",
      "Epoch 3/300\n",
      "5/5 - 0s - loss: 1033.3746 - mae: 69.6357 - val_loss: 5577.1274 - val_mae: 215.7289 - 94ms/epoch - 19ms/step\n",
      "Epoch 4/300\n",
      "5/5 - 0s - loss: 970.0309 - mae: 69.6547 - val_loss: 4579.0405 - val_mae: 215.6326 - 96ms/epoch - 19ms/step\n",
      "Epoch 5/300\n",
      "5/5 - 0s - loss: 885.9478 - mae: 69.6733 - val_loss: 3857.2087 - val_mae: 215.6538 - 106ms/epoch - 21ms/step\n",
      "Epoch 6/300\n",
      "5/5 - 0s - loss: 810.6846 - mae: 69.6289 - val_loss: 3304.0938 - val_mae: 215.6925 - 96ms/epoch - 19ms/step\n",
      "Epoch 7/300\n",
      "5/5 - 0s - loss: 766.0313 - mae: 69.6232 - val_loss: 2884.1577 - val_mae: 215.4798 - 92ms/epoch - 18ms/step\n",
      "Epoch 8/300\n",
      "5/5 - 0s - loss: 711.8895 - mae: 69.5865 - val_loss: 2565.6714 - val_mae: 215.5912 - 94ms/epoch - 19ms/step\n",
      "Epoch 9/300\n",
      "5/5 - 0s - loss: 672.0580 - mae: 69.5847 - val_loss: 2307.6841 - val_mae: 215.6241 - 90ms/epoch - 18ms/step\n",
      "Epoch 10/300\n",
      "5/5 - 0s - loss: 630.6417 - mae: 69.5735 - val_loss: 2089.8052 - val_mae: 215.5569 - 107ms/epoch - 21ms/step\n",
      "Epoch 11/300\n",
      "5/5 - 0s - loss: 596.6288 - mae: 69.5320 - val_loss: 1909.2594 - val_mae: 215.4921 - 99ms/epoch - 20ms/step\n",
      "Epoch 12/300\n",
      "5/5 - 0s - loss: 571.4349 - mae: 69.5090 - val_loss: 1748.3784 - val_mae: 215.4198 - 94ms/epoch - 19ms/step\n",
      "Epoch 13/300\n",
      "5/5 - 0s - loss: 555.0190 - mae: 69.5006 - val_loss: 1608.6448 - val_mae: 215.4501 - 95ms/epoch - 19ms/step\n",
      "Epoch 14/300\n",
      "5/5 - 0s - loss: 529.1571 - mae: 69.5140 - val_loss: 1490.7515 - val_mae: 215.4937 - 99ms/epoch - 20ms/step\n",
      "Epoch 15/300\n",
      "5/5 - 0s - loss: 506.5814 - mae: 69.4850 - val_loss: 1390.9669 - val_mae: 215.4896 - 101ms/epoch - 20ms/step\n",
      "Epoch 16/300\n",
      "5/5 - 0s - loss: 485.5065 - mae: 69.4763 - val_loss: 1299.0493 - val_mae: 215.3240 - 102ms/epoch - 20ms/step\n",
      "Epoch 17/300\n",
      "5/5 - 0s - loss: 466.1417 - mae: 69.4667 - val_loss: 1217.6360 - val_mae: 215.2960 - 95ms/epoch - 19ms/step\n",
      "Epoch 18/300\n",
      "5/5 - 0s - loss: 452.7349 - mae: 69.4237 - val_loss: 1145.5992 - val_mae: 215.3111 - 91ms/epoch - 18ms/step\n",
      "Epoch 19/300\n",
      "5/5 - 0s - loss: 436.2343 - mae: 69.4315 - val_loss: 1079.6399 - val_mae: 215.5707 - 92ms/epoch - 18ms/step\n",
      "Epoch 20/300\n",
      "5/5 - 0s - loss: 420.4953 - mae: 69.3970 - val_loss: 1018.8915 - val_mae: 215.3467 - 101ms/epoch - 20ms/step\n",
      "Epoch 21/300\n",
      "5/5 - 0s - loss: 406.4742 - mae: 69.3929 - val_loss: 964.5034 - val_mae: 215.2188 - 95ms/epoch - 19ms/step\n",
      "Epoch 22/300\n",
      "5/5 - 0s - loss: 397.0190 - mae: 69.3877 - val_loss: 913.0594 - val_mae: 215.3576 - 94ms/epoch - 19ms/step\n",
      "Epoch 23/300\n",
      "5/5 - 0s - loss: 380.1040 - mae: 69.3929 - val_loss: 867.2236 - val_mae: 215.1014 - 94ms/epoch - 19ms/step\n",
      "Epoch 24/300\n",
      "5/5 - 0s - loss: 375.4053 - mae: 69.3367 - val_loss: 827.7551 - val_mae: 215.2243 - 94ms/epoch - 19ms/step\n",
      "Epoch 25/300\n",
      "5/5 - 0s - loss: 357.6723 - mae: 69.3120 - val_loss: 789.7654 - val_mae: 214.9112 - 104ms/epoch - 21ms/step\n",
      "Epoch 26/300\n",
      "5/5 - 0s - loss: 351.7462 - mae: 69.2993 - val_loss: 753.5999 - val_mae: 215.2709 - 96ms/epoch - 19ms/step\n",
      "Epoch 27/300\n",
      "5/5 - 0s - loss: 339.5887 - mae: 69.3084 - val_loss: 721.8842 - val_mae: 214.9680 - 90ms/epoch - 18ms/step\n",
      "Epoch 28/300\n",
      "5/5 - 0s - loss: 330.9824 - mae: 69.3063 - val_loss: 693.2014 - val_mae: 215.0811 - 91ms/epoch - 18ms/step\n",
      "Epoch 29/300\n",
      "5/5 - 0s - loss: 323.6281 - mae: 69.2599 - val_loss: 664.4810 - val_mae: 214.9886 - 93ms/epoch - 19ms/step\n",
      "Epoch 30/300\n",
      "5/5 - 0s - loss: 313.3885 - mae: 69.2780 - val_loss: 639.8657 - val_mae: 214.8094 - 96ms/epoch - 19ms/step\n",
      "Epoch 31/300\n",
      "5/5 - 0s - loss: 309.3250 - mae: 69.2348 - val_loss: 616.2448 - val_mae: 214.7778 - 110ms/epoch - 22ms/step\n",
      "Epoch 32/300\n",
      "5/5 - 0s - loss: 296.9017 - mae: 69.2629 - val_loss: 595.3363 - val_mae: 214.9843 - 94ms/epoch - 19ms/step\n",
      "Epoch 33/300\n",
      "5/5 - 0s - loss: 290.6942 - mae: 69.2117 - val_loss: 574.7133 - val_mae: 214.9464 - 92ms/epoch - 18ms/step\n",
      "Epoch 34/300\n",
      "5/5 - 0s - loss: 287.4330 - mae: 69.1482 - val_loss: 555.7629 - val_mae: 214.8439 - 105ms/epoch - 21ms/step\n",
      "Epoch 35/300\n",
      "5/5 - 0s - loss: 280.7538 - mae: 69.1901 - val_loss: 538.0759 - val_mae: 215.0977 - 104ms/epoch - 21ms/step\n",
      "Epoch 36/300\n",
      "5/5 - 0s - loss: 273.0255 - mae: 69.1546 - val_loss: 520.6624 - val_mae: 214.6344 - 98ms/epoch - 20ms/step\n",
      "Epoch 37/300\n",
      "5/5 - 0s - loss: 267.0058 - mae: 69.1750 - val_loss: 503.7781 - val_mae: 215.0334 - 97ms/epoch - 19ms/step\n",
      "Epoch 38/300\n",
      "5/5 - 0s - loss: 260.2177 - mae: 69.1394 - val_loss: 489.0439 - val_mae: 214.5946 - 95ms/epoch - 19ms/step\n",
      "Epoch 39/300\n",
      "5/5 - 0s - loss: 255.3064 - mae: 69.1391 - val_loss: 473.7859 - val_mae: 214.7819 - 97ms/epoch - 19ms/step\n",
      "Epoch 40/300\n",
      "5/5 - 0s - loss: 248.0722 - mae: 69.1218 - val_loss: 459.3733 - val_mae: 214.6362 - 98ms/epoch - 20ms/step\n",
      "Epoch 41/300\n",
      "5/5 - 0s - loss: 244.8388 - mae: 69.0731 - val_loss: 445.8554 - val_mae: 214.7765 - 115ms/epoch - 23ms/step\n",
      "Epoch 42/300\n",
      "5/5 - 0s - loss: 242.3881 - mae: 69.0881 - val_loss: 433.2586 - val_mae: 214.8281 - 95ms/epoch - 19ms/step\n",
      "Epoch 43/300\n",
      "5/5 - 0s - loss: 234.8183 - mae: 69.0759 - val_loss: 421.2141 - val_mae: 214.6646 - 91ms/epoch - 18ms/step\n",
      "Epoch 44/300\n",
      "5/5 - 0s - loss: 234.3221 - mae: 69.0493 - val_loss: 409.6807 - val_mae: 214.7957 - 97ms/epoch - 19ms/step\n",
      "Epoch 45/300\n",
      "5/5 - 0s - loss: 226.3972 - mae: 69.0521 - val_loss: 398.9044 - val_mae: 214.6545 - 92ms/epoch - 18ms/step\n",
      "Epoch 46/300\n",
      "5/5 - 0s - loss: 222.1277 - mae: 69.0256 - val_loss: 388.0465 - val_mae: 214.7260 - 94ms/epoch - 19ms/step\n",
      "Epoch 47/300\n",
      "5/5 - 0s - loss: 217.2619 - mae: 69.0434 - val_loss: 378.0674 - val_mae: 214.8796 - 97ms/epoch - 19ms/step\n",
      "Epoch 48/300\n",
      "5/5 - 0s - loss: 211.0990 - mae: 69.0347 - val_loss: 368.8962 - val_mae: 214.6678 - 91ms/epoch - 18ms/step\n",
      "Epoch 49/300\n",
      "5/5 - 0s - loss: 208.5040 - mae: 68.9542 - val_loss: 359.7386 - val_mae: 214.6858 - 93ms/epoch - 19ms/step\n",
      "Epoch 50/300\n",
      "5/5 - 0s - loss: 206.3566 - mae: 69.0360 - val_loss: 350.6904 - val_mae: 214.3269 - 95ms/epoch - 19ms/step\n",
      "Epoch 51/300\n",
      "5/5 - 0s - loss: 200.1610 - mae: 68.9359 - val_loss: 342.3056 - val_mae: 214.7272 - 112ms/epoch - 22ms/step\n",
      "Epoch 52/300\n",
      "5/5 - 0s - loss: 198.0683 - mae: 68.8962 - val_loss: 333.8583 - val_mae: 214.4346 - 97ms/epoch - 19ms/step\n",
      "Epoch 53/300\n",
      "5/5 - 0s - loss: 196.1178 - mae: 68.9666 - val_loss: 326.1454 - val_mae: 214.6525 - 92ms/epoch - 18ms/step\n",
      "Epoch 54/300\n",
      "5/5 - 0s - loss: 190.3018 - mae: 68.9077 - val_loss: 318.6666 - val_mae: 214.6071 - 100ms/epoch - 20ms/step\n",
      "Epoch 55/300\n",
      "5/5 - 0s - loss: 187.5949 - mae: 68.9276 - val_loss: 311.2328 - val_mae: 214.3677 - 125ms/epoch - 25ms/step\n",
      "Epoch 56/300\n",
      "5/5 - 0s - loss: 183.7578 - mae: 68.8886 - val_loss: 304.4015 - val_mae: 214.2538 - 151ms/epoch - 30ms/step\n",
      "Epoch 57/300\n",
      "5/5 - 0s - loss: 182.2885 - mae: 68.8815 - val_loss: 296.9390 - val_mae: 214.4986 - 152ms/epoch - 30ms/step\n",
      "Epoch 58/300\n",
      "5/5 - 0s - loss: 177.8075 - mae: 68.8692 - val_loss: 290.3532 - val_mae: 214.1089 - 157ms/epoch - 31ms/step\n",
      "Epoch 59/300\n",
      "5/5 - 0s - loss: 172.9766 - mae: 68.8155 - val_loss: 284.6187 - val_mae: 213.8798 - 187ms/epoch - 37ms/step\n",
      "Epoch 60/300\n",
      "5/5 - 0s - loss: 171.8355 - mae: 68.8334 - val_loss: 278.4796 - val_mae: 214.5778 - 153ms/epoch - 31ms/step\n",
      "Epoch 61/300\n",
      "5/5 - 0s - loss: 168.6736 - mae: 68.8191 - val_loss: 272.6409 - val_mae: 214.0938 - 172ms/epoch - 34ms/step\n",
      "Epoch 62/300\n",
      "5/5 - 0s - loss: 166.1513 - mae: 68.8011 - val_loss: 266.8172 - val_mae: 214.2863 - 158ms/epoch - 32ms/step\n",
      "Epoch 63/300\n",
      "5/5 - 0s - loss: 162.5170 - mae: 68.8246 - val_loss: 261.5893 - val_mae: 214.0067 - 168ms/epoch - 34ms/step\n",
      "Epoch 64/300\n",
      "5/5 - 0s - loss: 160.6179 - mae: 68.8055 - val_loss: 256.6210 - val_mae: 213.8194 - 155ms/epoch - 31ms/step\n",
      "Epoch 65/300\n",
      "5/5 - 0s - loss: 157.9763 - mae: 68.8199 - val_loss: 251.4182 - val_mae: 213.9535 - 156ms/epoch - 31ms/step\n",
      "Epoch 66/300\n",
      "5/5 - 0s - loss: 156.7824 - mae: 68.7196 - val_loss: 246.1092 - val_mae: 214.0069 - 171ms/epoch - 34ms/step\n",
      "Epoch 67/300\n",
      "5/5 - 0s - loss: 152.6451 - mae: 68.6842 - val_loss: 241.2431 - val_mae: 214.2409 - 169ms/epoch - 34ms/step\n",
      "Epoch 68/300\n",
      "5/5 - 0s - loss: 150.5902 - mae: 68.7688 - val_loss: 236.9088 - val_mae: 214.1069 - 155ms/epoch - 31ms/step\n",
      "Epoch 69/300\n",
      "5/5 - 0s - loss: 147.8194 - mae: 68.7092 - val_loss: 232.2862 - val_mae: 214.0276 - 157ms/epoch - 31ms/step\n",
      "Epoch 70/300\n",
      "5/5 - 0s - loss: 146.1263 - mae: 68.7010 - val_loss: 228.1634 - val_mae: 213.9218 - 128ms/epoch - 26ms/step\n",
      "Epoch 71/300\n",
      "5/5 - 0s - loss: 144.5931 - mae: 68.6282 - val_loss: 223.7557 - val_mae: 214.0460 - 110ms/epoch - 22ms/step\n",
      "Epoch 72/300\n",
      "5/5 - 0s - loss: 141.5461 - mae: 68.6152 - val_loss: 219.4484 - val_mae: 214.2149 - 94ms/epoch - 19ms/step\n",
      "Epoch 73/300\n",
      "5/5 - 0s - loss: 140.1131 - mae: 68.6287 - val_loss: 215.7968 - val_mae: 213.7349 - 105ms/epoch - 21ms/step\n",
      "Epoch 74/300\n",
      "5/5 - 0s - loss: 137.3255 - mae: 68.6507 - val_loss: 211.7162 - val_mae: 213.6462 - 97ms/epoch - 19ms/step\n",
      "Epoch 75/300\n",
      "5/5 - 0s - loss: 135.8924 - mae: 68.6638 - val_loss: 207.8671 - val_mae: 213.9431 - 97ms/epoch - 19ms/step\n",
      "Epoch 76/300\n",
      "5/5 - 0s - loss: 134.4867 - mae: 68.6397 - val_loss: 204.1746 - val_mae: 213.4263 - 97ms/epoch - 19ms/step\n",
      "Epoch 77/300\n",
      "5/5 - 0s - loss: 130.3101 - mae: 68.5742 - val_loss: 200.8258 - val_mae: 213.2821 - 92ms/epoch - 18ms/step\n",
      "Epoch 78/300\n",
      "5/5 - 0s - loss: 129.4688 - mae: 68.5908 - val_loss: 197.6388 - val_mae: 213.2518 - 93ms/epoch - 19ms/step\n",
      "Epoch 79/300\n",
      "5/5 - 0s - loss: 129.4637 - mae: 68.6079 - val_loss: 194.3790 - val_mae: 213.6484 - 94ms/epoch - 19ms/step\n",
      "Epoch 80/300\n",
      "5/5 - 0s - loss: 128.0352 - mae: 68.5375 - val_loss: 190.8105 - val_mae: 213.0554 - 94ms/epoch - 19ms/step\n",
      "Epoch 81/300\n",
      "5/5 - 0s - loss: 124.8297 - mae: 68.5539 - val_loss: 187.7575 - val_mae: 213.7310 - 95ms/epoch - 19ms/step\n",
      "Epoch 82/300\n",
      "5/5 - 0s - loss: 123.0267 - mae: 68.4942 - val_loss: 184.8520 - val_mae: 213.2101 - 94ms/epoch - 19ms/step\n",
      "Epoch 83/300\n",
      "5/5 - 0s - loss: 120.7296 - mae: 68.5269 - val_loss: 181.7590 - val_mae: 213.1925 - 96ms/epoch - 19ms/step\n",
      "Epoch 84/300\n",
      "5/5 - 0s - loss: 120.2240 - mae: 68.4216 - val_loss: 178.7468 - val_mae: 213.6267 - 122ms/epoch - 24ms/step\n",
      "Epoch 85/300\n",
      "5/5 - 0s - loss: 116.5471 - mae: 68.4822 - val_loss: 175.9116 - val_mae: 213.9034 - 95ms/epoch - 19ms/step\n",
      "Epoch 86/300\n",
      "5/5 - 0s - loss: 116.2284 - mae: 68.4750 - val_loss: 173.3842 - val_mae: 213.3910 - 91ms/epoch - 18ms/step\n",
      "Epoch 87/300\n",
      "5/5 - 0s - loss: 115.7911 - mae: 68.4390 - val_loss: 170.8540 - val_mae: 213.4717 - 91ms/epoch - 18ms/step\n",
      "Epoch 88/300\n",
      "5/5 - 0s - loss: 113.2357 - mae: 68.4631 - val_loss: 168.0392 - val_mae: 213.2980 - 95ms/epoch - 19ms/step\n",
      "Epoch 89/300\n",
      "5/5 - 0s - loss: 111.2900 - mae: 68.4260 - val_loss: 165.6002 - val_mae: 213.2357 - 99ms/epoch - 20ms/step\n",
      "Epoch 90/300\n",
      "5/5 - 0s - loss: 110.4374 - mae: 68.3829 - val_loss: 163.1510 - val_mae: 213.2546 - 95ms/epoch - 19ms/step\n",
      "Epoch 91/300\n",
      "5/5 - 0s - loss: 107.7542 - mae: 68.3852 - val_loss: 160.6304 - val_mae: 212.9675 - 95ms/epoch - 19ms/step\n",
      "Epoch 92/300\n",
      "5/5 - 0s - loss: 108.8397 - mae: 68.4039 - val_loss: 158.4048 - val_mae: 213.5111 - 92ms/epoch - 18ms/step\n",
      "Epoch 93/300\n",
      "5/5 - 0s - loss: 105.6446 - mae: 68.3761 - val_loss: 156.2374 - val_mae: 212.8994 - 95ms/epoch - 19ms/step\n",
      "Epoch 94/300\n",
      "5/5 - 0s - loss: 104.9846 - mae: 68.3168 - val_loss: 153.9081 - val_mae: 212.6685 - 115ms/epoch - 23ms/step\n",
      "Epoch 95/300\n",
      "5/5 - 0s - loss: 102.6550 - mae: 68.2925 - val_loss: 151.6518 - val_mae: 213.1246 - 91ms/epoch - 18ms/step\n",
      "Epoch 96/300\n",
      "5/5 - 0s - loss: 102.4511 - mae: 68.2707 - val_loss: 149.6367 - val_mae: 213.1763 - 94ms/epoch - 19ms/step\n",
      "Epoch 97/300\n",
      "5/5 - 0s - loss: 101.4264 - mae: 68.3122 - val_loss: 147.7009 - val_mae: 213.0455 - 92ms/epoch - 18ms/step\n",
      "Epoch 98/300\n",
      "5/5 - 0s - loss: 100.0929 - mae: 68.2063 - val_loss: 145.6283 - val_mae: 212.9678 - 94ms/epoch - 19ms/step\n",
      "Epoch 99/300\n",
      "5/5 - 0s - loss: 98.8477 - mae: 68.2354 - val_loss: 143.5818 - val_mae: 213.1209 - 90ms/epoch - 18ms/step\n",
      "Epoch 100/300\n",
      "5/5 - 0s - loss: 97.6199 - mae: 68.2330 - val_loss: 141.4673 - val_mae: 212.8432 - 97ms/epoch - 19ms/step\n",
      "Epoch 101/300\n",
      "5/5 - 0s - loss: 95.8205 - mae: 68.2500 - val_loss: 139.6487 - val_mae: 213.1598 - 97ms/epoch - 19ms/step\n",
      "Epoch 102/300\n",
      "5/5 - 0s - loss: 95.2773 - mae: 68.2104 - val_loss: 138.0256 - val_mae: 212.6691 - 94ms/epoch - 19ms/step\n",
      "Epoch 103/300\n",
      "5/5 - 0s - loss: 94.1918 - mae: 68.1501 - val_loss: 136.2968 - val_mae: 212.7892 - 95ms/epoch - 19ms/step\n",
      "Epoch 104/300\n",
      "5/5 - 0s - loss: 92.5164 - mae: 68.1485 - val_loss: 134.5187 - val_mae: 212.9610 - 103ms/epoch - 21ms/step\n",
      "Epoch 105/300\n",
      "5/5 - 0s - loss: 93.0036 - mae: 68.1596 - val_loss: 132.7537 - val_mae: 212.4374 - 108ms/epoch - 22ms/step\n",
      "Epoch 106/300\n",
      "5/5 - 0s - loss: 91.2321 - mae: 68.1144 - val_loss: 131.1996 - val_mae: 213.2336 - 109ms/epoch - 22ms/step\n",
      "Epoch 107/300\n",
      "5/5 - 0s - loss: 88.5434 - mae: 68.2047 - val_loss: 129.5177 - val_mae: 213.3996 - 92ms/epoch - 18ms/step\n",
      "Epoch 108/300\n",
      "5/5 - 0s - loss: 88.2604 - mae: 68.1208 - val_loss: 127.9663 - val_mae: 212.8756 - 91ms/epoch - 18ms/step\n",
      "Epoch 109/300\n",
      "5/5 - 0s - loss: 87.2628 - mae: 68.0817 - val_loss: 126.5255 - val_mae: 213.0081 - 94ms/epoch - 19ms/step\n",
      "Epoch 110/300\n",
      "5/5 - 0s - loss: 87.4876 - mae: 68.1263 - val_loss: 124.9292 - val_mae: 212.7670 - 95ms/epoch - 19ms/step\n",
      "Epoch 111/300\n",
      "5/5 - 0s - loss: 86.3741 - mae: 68.1153 - val_loss: 123.4269 - val_mae: 212.7514 - 95ms/epoch - 19ms/step\n",
      "Epoch 112/300\n",
      "5/5 - 0s - loss: 85.1055 - mae: 68.0949 - val_loss: 122.0153 - val_mae: 212.6969 - 93ms/epoch - 19ms/step\n",
      "Epoch 113/300\n",
      "5/5 - 0s - loss: 84.6862 - mae: 68.1072 - val_loss: 120.6323 - val_mae: 212.4108 - 92ms/epoch - 18ms/step\n",
      "Epoch 114/300\n",
      "5/5 - 0s - loss: 82.3339 - mae: 68.0665 - val_loss: 119.3192 - val_mae: 212.1642 - 97ms/epoch - 19ms/step\n",
      "Epoch 115/300\n",
      "5/5 - 0s - loss: 81.8940 - mae: 67.9845 - val_loss: 117.8914 - val_mae: 212.5727 - 114ms/epoch - 23ms/step\n",
      "Epoch 116/300\n",
      "5/5 - 0s - loss: 81.6554 - mae: 67.9777 - val_loss: 116.6189 - val_mae: 212.3854 - 90ms/epoch - 18ms/step\n",
      "Epoch 117/300\n",
      "5/5 - 0s - loss: 79.4043 - mae: 67.9957 - val_loss: 115.2901 - val_mae: 212.4387 - 88ms/epoch - 18ms/step\n",
      "Epoch 118/300\n",
      "5/5 - 0s - loss: 81.1732 - mae: 67.8815 - val_loss: 113.9951 - val_mae: 212.4978 - 91ms/epoch - 18ms/step\n",
      "Epoch 119/300\n",
      "5/5 - 0s - loss: 78.4832 - mae: 67.8255 - val_loss: 112.8289 - val_mae: 212.5085 - 94ms/epoch - 19ms/step\n",
      "Epoch 120/300\n",
      "5/5 - 0s - loss: 77.5551 - mae: 67.8879 - val_loss: 111.6666 - val_mae: 212.7732 - 91ms/epoch - 18ms/step\n",
      "Epoch 121/300\n",
      "5/5 - 0s - loss: 76.8376 - mae: 67.8430 - val_loss: 110.4270 - val_mae: 212.4953 - 99ms/epoch - 20ms/step\n",
      "Epoch 122/300\n",
      "5/5 - 0s - loss: 77.4463 - mae: 67.9375 - val_loss: 109.3411 - val_mae: 211.9590 - 93ms/epoch - 19ms/step\n",
      "Epoch 123/300\n",
      "5/5 - 0s - loss: 75.2594 - mae: 67.8726 - val_loss: 108.2274 - val_mae: 212.1167 - 93ms/epoch - 19ms/step\n",
      "Epoch 124/300\n",
      "5/5 - 0s - loss: 75.0672 - mae: 67.8640 - val_loss: 107.0389 - val_mae: 211.9830 - 87ms/epoch - 17ms/step\n",
      "Epoch 125/300\n",
      "5/5 - 0s - loss: 73.6863 - mae: 67.9473 - val_loss: 105.9757 - val_mae: 212.5984 - 105ms/epoch - 21ms/step\n",
      "Epoch 126/300\n",
      "5/5 - 0s - loss: 73.0375 - mae: 67.7370 - val_loss: 104.8247 - val_mae: 211.8017 - 98ms/epoch - 20ms/step\n",
      "Epoch 127/300\n",
      "5/5 - 0s - loss: 72.2838 - mae: 67.8828 - val_loss: 103.8210 - val_mae: 212.3477 - 93ms/epoch - 19ms/step\n",
      "Epoch 128/300\n",
      "5/5 - 0s - loss: 71.3011 - mae: 67.7571 - val_loss: 102.9057 - val_mae: 212.0346 - 109ms/epoch - 22ms/step\n",
      "Epoch 129/300\n",
      "5/5 - 0s - loss: 71.7256 - mae: 67.8040 - val_loss: 101.8762 - val_mae: 211.6573 - 94ms/epoch - 19ms/step\n",
      "Epoch 130/300\n",
      "5/5 - 0s - loss: 70.3525 - mae: 67.7112 - val_loss: 100.8820 - val_mae: 211.8503 - 89ms/epoch - 18ms/step\n",
      "Epoch 131/300\n",
      "5/5 - 0s - loss: 69.5133 - mae: 67.6947 - val_loss: 99.8306 - val_mae: 211.6906 - 96ms/epoch - 19ms/step\n",
      "Epoch 132/300\n",
      "5/5 - 0s - loss: 68.8245 - mae: 67.7773 - val_loss: 98.8255 - val_mae: 211.9693 - 91ms/epoch - 18ms/step\n",
      "Epoch 133/300\n",
      "5/5 - 0s - loss: 68.7914 - mae: 67.7332 - val_loss: 97.8589 - val_mae: 211.1070 - 94ms/epoch - 19ms/step\n",
      "Epoch 134/300\n",
      "5/5 - 0s - loss: 66.8975 - mae: 67.8254 - val_loss: 97.0079 - val_mae: 211.8736 - 90ms/epoch - 18ms/step\n",
      "Epoch 135/300\n",
      "5/5 - 0s - loss: 67.1976 - mae: 67.6647 - val_loss: 96.0958 - val_mae: 212.0823 - 95ms/epoch - 19ms/step\n",
      "Epoch 136/300\n",
      "5/5 - 0s - loss: 66.5694 - mae: 67.6592 - val_loss: 95.1323 - val_mae: 212.3951 - 110ms/epoch - 22ms/step\n",
      "Epoch 137/300\n",
      "5/5 - 0s - loss: 65.6902 - mae: 67.5877 - val_loss: 94.2248 - val_mae: 212.4036 - 93ms/epoch - 19ms/step\n",
      "Epoch 138/300\n",
      "5/5 - 0s - loss: 66.1177 - mae: 67.6886 - val_loss: 93.2853 - val_mae: 212.0468 - 93ms/epoch - 19ms/step\n",
      "Epoch 139/300\n",
      "5/5 - 0s - loss: 65.8171 - mae: 67.5665 - val_loss: 92.5034 - val_mae: 212.4163 - 95ms/epoch - 19ms/step\n",
      "Epoch 140/300\n",
      "5/5 - 0s - loss: 63.7144 - mae: 67.6149 - val_loss: 91.7029 - val_mae: 211.1799 - 94ms/epoch - 19ms/step\n",
      "Epoch 141/300\n",
      "5/5 - 0s - loss: 64.2784 - mae: 67.5306 - val_loss: 90.7922 - val_mae: 211.1668 - 96ms/epoch - 19ms/step\n",
      "Epoch 142/300\n",
      "5/5 - 0s - loss: 62.7942 - mae: 67.5359 - val_loss: 90.0550 - val_mae: 212.2911 - 102ms/epoch - 20ms/step\n",
      "Epoch 143/300\n",
      "5/5 - 0s - loss: 62.8288 - mae: 67.5092 - val_loss: 89.2687 - val_mae: 212.0231 - 91ms/epoch - 18ms/step\n",
      "Epoch 144/300\n",
      "5/5 - 0s - loss: 62.2851 - mae: 67.5531 - val_loss: 88.4545 - val_mae: 211.8013 - 93ms/epoch - 19ms/step\n",
      "Epoch 145/300\n",
      "5/5 - 0s - loss: 62.0182 - mae: 67.5280 - val_loss: 87.6947 - val_mae: 211.4376 - 104ms/epoch - 21ms/step\n",
      "Epoch 146/300\n",
      "5/5 - 0s - loss: 61.1271 - mae: 67.5110 - val_loss: 86.9155 - val_mae: 211.8356 - 107ms/epoch - 21ms/step\n",
      "Epoch 147/300\n",
      "5/5 - 0s - loss: 60.9489 - mae: 67.5538 - val_loss: 86.1366 - val_mae: 212.2525 - 93ms/epoch - 19ms/step\n",
      "Epoch 148/300\n",
      "5/5 - 0s - loss: 60.3892 - mae: 67.4199 - val_loss: 85.4291 - val_mae: 211.6992 - 92ms/epoch - 18ms/step\n",
      "Epoch 149/300\n",
      "5/5 - 0s - loss: 59.4989 - mae: 67.4554 - val_loss: 84.7133 - val_mae: 211.9329 - 94ms/epoch - 19ms/step\n",
      "Epoch 150/300\n",
      "5/5 - 0s - loss: 59.8528 - mae: 67.4367 - val_loss: 84.0561 - val_mae: 211.2431 - 95ms/epoch - 19ms/step\n",
      "Epoch 151/300\n",
      "5/5 - 0s - loss: 59.0327 - mae: 67.4369 - val_loss: 83.2796 - val_mae: 211.8208 - 98ms/epoch - 20ms/step\n",
      "Epoch 152/300\n",
      "5/5 - 0s - loss: 58.2889 - mae: 67.4608 - val_loss: 82.6937 - val_mae: 211.1658 - 96ms/epoch - 19ms/step\n",
      "Epoch 153/300\n",
      "5/5 - 0s - loss: 58.1017 - mae: 67.3430 - val_loss: 82.0001 - val_mae: 210.9489 - 94ms/epoch - 19ms/step\n",
      "Epoch 154/300\n",
      "5/5 - 0s - loss: 57.5559 - mae: 67.4274 - val_loss: 81.3263 - val_mae: 211.0199 - 98ms/epoch - 20ms/step\n",
      "Epoch 155/300\n",
      "5/5 - 0s - loss: 56.9157 - mae: 67.3485 - val_loss: 80.8170 - val_mae: 211.3524 - 103ms/epoch - 21ms/step\n",
      "Epoch 156/300\n",
      "5/5 - 0s - loss: 56.5938 - mae: 67.3886 - val_loss: 80.0884 - val_mae: 210.6594 - 93ms/epoch - 19ms/step\n",
      "Epoch 157/300\n",
      "5/5 - 0s - loss: 56.2611 - mae: 67.3588 - val_loss: 79.4375 - val_mae: 210.8154 - 114ms/epoch - 23ms/step\n",
      "Epoch 158/300\n",
      "5/5 - 0s - loss: 55.0232 - mae: 67.2799 - val_loss: 78.7980 - val_mae: 211.0003 - 94ms/epoch - 19ms/step\n",
      "Epoch 159/300\n",
      "5/5 - 0s - loss: 54.7813 - mae: 67.2352 - val_loss: 78.2167 - val_mae: 211.4875 - 96ms/epoch - 19ms/step\n",
      "Epoch 160/300\n",
      "5/5 - 0s - loss: 54.6079 - mae: 67.2743 - val_loss: 77.7236 - val_mae: 211.0079 - 95ms/epoch - 19ms/step\n",
      "Epoch 161/300\n",
      "5/5 - 0s - loss: 54.6565 - mae: 67.2007 - val_loss: 77.0597 - val_mae: 211.5392 - 96ms/epoch - 19ms/step\n",
      "Epoch 162/300\n",
      "5/5 - 0s - loss: 53.7467 - mae: 67.3090 - val_loss: 76.5209 - val_mae: 211.3501 - 99ms/epoch - 20ms/step\n",
      "Epoch 163/300\n",
      "5/5 - 0s - loss: 53.5293 - mae: 67.2324 - val_loss: 75.8978 - val_mae: 210.3679 - 102ms/epoch - 20ms/step\n",
      "Epoch 164/300\n",
      "5/5 - 0s - loss: 53.7754 - mae: 67.1860 - val_loss: 75.3168 - val_mae: 211.2649 - 100ms/epoch - 20ms/step\n",
      "Epoch 165/300\n",
      "5/5 - 0s - loss: 53.1055 - mae: 67.2264 - val_loss: 74.7310 - val_mae: 210.9275 - 98ms/epoch - 20ms/step\n",
      "Epoch 166/300\n",
      "5/5 - 0s - loss: 52.3891 - mae: 67.1615 - val_loss: 74.2339 - val_mae: 210.2121 - 112ms/epoch - 22ms/step\n",
      "Epoch 167/300\n",
      "5/5 - 0s - loss: 51.8401 - mae: 67.1984 - val_loss: 73.7217 - val_mae: 210.3414 - 110ms/epoch - 22ms/step\n",
      "Epoch 168/300\n",
      "5/5 - 0s - loss: 52.1457 - mae: 67.1590 - val_loss: 73.2038 - val_mae: 210.4614 - 98ms/epoch - 20ms/step\n",
      "Epoch 169/300\n",
      "5/5 - 0s - loss: 51.0154 - mae: 67.1347 - val_loss: 72.7076 - val_mae: 211.0480 - 105ms/epoch - 21ms/step\n",
      "Epoch 170/300\n",
      "5/5 - 0s - loss: 51.0776 - mae: 67.2364 - val_loss: 72.1350 - val_mae: 210.8146 - 159ms/epoch - 32ms/step\n",
      "Epoch 171/300\n",
      "5/5 - 0s - loss: 50.9586 - mae: 67.1217 - val_loss: 71.6393 - val_mae: 210.8304 - 163ms/epoch - 33ms/step\n",
      "Epoch 172/300\n",
      "5/5 - 0s - loss: 50.2727 - mae: 67.0450 - val_loss: 71.2023 - val_mae: 211.1101 - 161ms/epoch - 32ms/step\n",
      "Epoch 173/300\n",
      "5/5 - 0s - loss: 50.0636 - mae: 67.0544 - val_loss: 70.6363 - val_mae: 211.1125 - 159ms/epoch - 32ms/step\n",
      "Epoch 174/300\n",
      "5/5 - 0s - loss: 49.4465 - mae: 67.1946 - val_loss: 70.1625 - val_mae: 210.3163 - 175ms/epoch - 35ms/step\n",
      "Epoch 175/300\n",
      "5/5 - 0s - loss: 49.0965 - mae: 66.9826 - val_loss: 69.6205 - val_mae: 210.0293 - 154ms/epoch - 31ms/step\n",
      "Epoch 176/300\n",
      "5/5 - 0s - loss: 48.9455 - mae: 66.9936 - val_loss: 69.1429 - val_mae: 209.9534 - 149ms/epoch - 30ms/step\n",
      "Epoch 177/300\n",
      "5/5 - 0s - loss: 48.3777 - mae: 67.0414 - val_loss: 68.6595 - val_mae: 210.5789 - 162ms/epoch - 32ms/step\n",
      "Epoch 178/300\n",
      "5/5 - 0s - loss: 48.4661 - mae: 66.9916 - val_loss: 68.2257 - val_mae: 210.6155 - 158ms/epoch - 32ms/step\n",
      "Epoch 179/300\n",
      "5/5 - 0s - loss: 47.7840 - mae: 66.9767 - val_loss: 67.6638 - val_mae: 210.5849 - 165ms/epoch - 33ms/step\n",
      "Epoch 180/300\n",
      "5/5 - 0s - loss: 47.4143 - mae: 66.8985 - val_loss: 67.2015 - val_mae: 210.6716 - 166ms/epoch - 33ms/step\n",
      "Epoch 181/300\n",
      "5/5 - 0s - loss: 47.2502 - mae: 66.9807 - val_loss: 66.7590 - val_mae: 210.5465 - 169ms/epoch - 34ms/step\n",
      "Epoch 182/300\n",
      "5/5 - 0s - loss: 46.9856 - mae: 66.8657 - val_loss: 66.3304 - val_mae: 210.2013 - 172ms/epoch - 34ms/step\n",
      "Epoch 183/300\n",
      "5/5 - 0s - loss: 46.6184 - mae: 66.9115 - val_loss: 65.9302 - val_mae: 210.4104 - 163ms/epoch - 33ms/step\n",
      "Epoch 184/300\n",
      "5/5 - 0s - loss: 46.4038 - mae: 66.9367 - val_loss: 65.5468 - val_mae: 210.4230 - 108ms/epoch - 22ms/step\n",
      "Epoch 185/300\n",
      "5/5 - 0s - loss: 45.4719 - mae: 66.8836 - val_loss: 65.1150 - val_mae: 211.2235 - 97ms/epoch - 19ms/step\n",
      "Epoch 186/300\n",
      "5/5 - 0s - loss: 46.1909 - mae: 66.8624 - val_loss: 64.7084 - val_mae: 210.7583 - 90ms/epoch - 18ms/step\n",
      "Epoch 187/300\n",
      "5/5 - 0s - loss: 45.2337 - mae: 66.8333 - val_loss: 64.3565 - val_mae: 210.1181 - 92ms/epoch - 18ms/step\n",
      "Epoch 188/300\n",
      "5/5 - 0s - loss: 45.4880 - mae: 66.8510 - val_loss: 63.9871 - val_mae: 210.1122 - 93ms/epoch - 19ms/step\n",
      "Epoch 189/300\n",
      "5/5 - 0s - loss: 45.1800 - mae: 66.7979 - val_loss: 63.6005 - val_mae: 210.1977 - 107ms/epoch - 21ms/step\n",
      "Epoch 190/300\n",
      "5/5 - 0s - loss: 45.3021 - mae: 66.7900 - val_loss: 63.1738 - val_mae: 210.8764 - 95ms/epoch - 19ms/step\n",
      "Epoch 191/300\n",
      "5/5 - 0s - loss: 44.1643 - mae: 66.7989 - val_loss: 62.7900 - val_mae: 209.9854 - 100ms/epoch - 20ms/step\n",
      "Epoch 192/300\n",
      "5/5 - 0s - loss: 44.4587 - mae: 66.7375 - val_loss: 62.4408 - val_mae: 210.4456 - 96ms/epoch - 19ms/step\n",
      "Epoch 193/300\n",
      "5/5 - 0s - loss: 44.3209 - mae: 66.8461 - val_loss: 62.0586 - val_mae: 210.1130 - 93ms/epoch - 19ms/step\n",
      "Epoch 194/300\n",
      "5/5 - 0s - loss: 44.2551 - mae: 66.7791 - val_loss: 61.7194 - val_mae: 210.0771 - 95ms/epoch - 19ms/step\n",
      "Epoch 195/300\n",
      "5/5 - 0s - loss: 43.0076 - mae: 66.7112 - val_loss: 61.3389 - val_mae: 210.2629 - 101ms/epoch - 20ms/step\n",
      "Epoch 196/300\n",
      "5/5 - 0s - loss: 42.9976 - mae: 66.6121 - val_loss: 61.0071 - val_mae: 209.7902 - 93ms/epoch - 19ms/step\n",
      "Epoch 197/300\n",
      "5/5 - 0s - loss: 43.4298 - mae: 66.6294 - val_loss: 60.6508 - val_mae: 209.3298 - 107ms/epoch - 21ms/step\n",
      "Epoch 198/300\n",
      "5/5 - 0s - loss: 42.7034 - mae: 66.7052 - val_loss: 60.3024 - val_mae: 210.2330 - 99ms/epoch - 20ms/step\n",
      "Epoch 199/300\n",
      "5/5 - 0s - loss: 42.2791 - mae: 66.7076 - val_loss: 59.8979 - val_mae: 209.6903 - 105ms/epoch - 21ms/step\n",
      "Epoch 200/300\n",
      "5/5 - 0s - loss: 42.4699 - mae: 66.7842 - val_loss: 59.5418 - val_mae: 210.1050 - 95ms/epoch - 19ms/step\n",
      "Epoch 201/300\n",
      "5/5 - 0s - loss: 41.9238 - mae: 66.5902 - val_loss: 59.2012 - val_mae: 210.4812 - 94ms/epoch - 19ms/step\n",
      "Epoch 202/300\n",
      "5/5 - 0s - loss: 41.6745 - mae: 66.6256 - val_loss: 58.9263 - val_mae: 209.8953 - 99ms/epoch - 20ms/step\n",
      "Epoch 203/300\n",
      "5/5 - 0s - loss: 42.1479 - mae: 66.7620 - val_loss: 58.5557 - val_mae: 209.2020 - 93ms/epoch - 19ms/step\n",
      "Epoch 204/300\n",
      "5/5 - 0s - loss: 41.6362 - mae: 66.5678 - val_loss: 58.2147 - val_mae: 209.3752 - 95ms/epoch - 19ms/step\n",
      "Epoch 205/300\n",
      "5/5 - 0s - loss: 41.5921 - mae: 66.6413 - val_loss: 57.8515 - val_mae: 210.3217 - 98ms/epoch - 20ms/step\n",
      "Epoch 206/300\n",
      "5/5 - 0s - loss: 40.8358 - mae: 66.5685 - val_loss: 57.5193 - val_mae: 209.4426 - 93ms/epoch - 19ms/step\n",
      "Epoch 207/300\n",
      "5/5 - 0s - loss: 40.8054 - mae: 66.5230 - val_loss: 57.2189 - val_mae: 209.7179 - 94ms/epoch - 19ms/step\n",
      "Epoch 208/300\n",
      "5/5 - 0s - loss: 40.6372 - mae: 66.5607 - val_loss: 56.9428 - val_mae: 209.5762 - 94ms/epoch - 19ms/step\n",
      "Epoch 209/300\n",
      "5/5 - 0s - loss: 39.9611 - mae: 66.4149 - val_loss: 56.6778 - val_mae: 210.0722 - 92ms/epoch - 18ms/step\n",
      "Epoch 210/300\n",
      "5/5 - 0s - loss: 39.5223 - mae: 66.4358 - val_loss: 56.4158 - val_mae: 209.9923 - 113ms/epoch - 23ms/step\n",
      "Epoch 211/300\n",
      "5/5 - 0s - loss: 39.8458 - mae: 66.5350 - val_loss: 56.0877 - val_mae: 210.2280 - 94ms/epoch - 19ms/step\n",
      "Epoch 212/300\n",
      "5/5 - 0s - loss: 39.2244 - mae: 66.3717 - val_loss: 55.8003 - val_mae: 209.2268 - 94ms/epoch - 19ms/step\n",
      "Epoch 213/300\n",
      "5/5 - 0s - loss: 38.6747 - mae: 66.3559 - val_loss: 55.5141 - val_mae: 208.8087 - 99ms/epoch - 20ms/step\n",
      "Epoch 214/300\n",
      "5/5 - 0s - loss: 39.3664 - mae: 66.4610 - val_loss: 55.2256 - val_mae: 209.8646 - 104ms/epoch - 21ms/step\n",
      "Epoch 215/300\n",
      "5/5 - 0s - loss: 38.7785 - mae: 66.4002 - val_loss: 54.9123 - val_mae: 209.5033 - 100ms/epoch - 20ms/step\n",
      "Epoch 216/300\n",
      "5/5 - 0s - loss: 38.3922 - mae: 66.4930 - val_loss: 54.6707 - val_mae: 209.2514 - 92ms/epoch - 18ms/step\n",
      "Epoch 217/300\n",
      "5/5 - 0s - loss: 37.9313 - mae: 66.3860 - val_loss: 54.3429 - val_mae: 209.9845 - 94ms/epoch - 19ms/step\n",
      "Epoch 218/300\n",
      "5/5 - 0s - loss: 38.0464 - mae: 66.3824 - val_loss: 54.0533 - val_mae: 209.0230 - 96ms/epoch - 19ms/step\n",
      "Epoch 219/300\n",
      "5/5 - 0s - loss: 37.7123 - mae: 66.3223 - val_loss: 53.7778 - val_mae: 208.4318 - 90ms/epoch - 18ms/step\n",
      "Epoch 220/300\n",
      "5/5 - 0s - loss: 37.8725 - mae: 66.3529 - val_loss: 53.4834 - val_mae: 209.1930 - 106ms/epoch - 21ms/step\n",
      "Epoch 221/300\n",
      "5/5 - 0s - loss: 37.4519 - mae: 66.2375 - val_loss: 53.1984 - val_mae: 209.3282 - 96ms/epoch - 19ms/step\n",
      "Epoch 222/300\n",
      "5/5 - 0s - loss: 38.0472 - mae: 66.3897 - val_loss: 52.9061 - val_mae: 209.0214 - 93ms/epoch - 19ms/step\n",
      "Epoch 223/300\n",
      "5/5 - 0s - loss: 37.2089 - mae: 66.1685 - val_loss: 52.6890 - val_mae: 209.4303 - 110ms/epoch - 22ms/step\n",
      "Epoch 224/300\n",
      "5/5 - 0s - loss: 36.5630 - mae: 66.1567 - val_loss: 52.4455 - val_mae: 209.3916 - 98ms/epoch - 20ms/step\n",
      "Epoch 225/300\n",
      "5/5 - 0s - loss: 36.3639 - mae: 66.1162 - val_loss: 52.1735 - val_mae: 208.5670 - 96ms/epoch - 19ms/step\n",
      "Epoch 226/300\n",
      "5/5 - 0s - loss: 37.0452 - mae: 66.1824 - val_loss: 51.8756 - val_mae: 210.0229 - 96ms/epoch - 19ms/step\n",
      "Epoch 227/300\n",
      "5/5 - 0s - loss: 36.2791 - mae: 66.1206 - val_loss: 51.6407 - val_mae: 208.8696 - 98ms/epoch - 20ms/step\n",
      "Epoch 228/300\n",
      "5/5 - 0s - loss: 36.6279 - mae: 66.1934 - val_loss: 51.3711 - val_mae: 208.9801 - 93ms/epoch - 19ms/step\n",
      "Epoch 229/300\n",
      "5/5 - 0s - loss: 36.6141 - mae: 66.1043 - val_loss: 51.1276 - val_mae: 208.8587 - 94ms/epoch - 19ms/step\n",
      "Epoch 230/300\n",
      "5/5 - 0s - loss: 36.3100 - mae: 66.1246 - val_loss: 50.8951 - val_mae: 208.6056 - 106ms/epoch - 21ms/step\n",
      "Epoch 231/300\n",
      "5/5 - 0s - loss: 36.1285 - mae: 66.1772 - val_loss: 50.6495 - val_mae: 209.9537 - 95ms/epoch - 19ms/step\n",
      "Epoch 232/300\n",
      "5/5 - 0s - loss: 35.5777 - mae: 66.1161 - val_loss: 50.4220 - val_mae: 208.7760 - 94ms/epoch - 19ms/step\n",
      "Epoch 233/300\n",
      "5/5 - 0s - loss: 35.6555 - mae: 66.1062 - val_loss: 50.1879 - val_mae: 209.4301 - 93ms/epoch - 19ms/step\n",
      "Epoch 234/300\n",
      "5/5 - 0s - loss: 35.8754 - mae: 66.1370 - val_loss: 49.9361 - val_mae: 208.6464 - 98ms/epoch - 20ms/step\n",
      "Epoch 235/300\n",
      "5/5 - 0s - loss: 35.1940 - mae: 65.9523 - val_loss: 49.7175 - val_mae: 208.9651 - 92ms/epoch - 18ms/step\n",
      "Epoch 236/300\n",
      "5/5 - 0s - loss: 35.2057 - mae: 66.0535 - val_loss: 49.4534 - val_mae: 208.2310 - 95ms/epoch - 19ms/step\n",
      "Epoch 237/300\n",
      "5/5 - 0s - loss: 35.3071 - mae: 66.0176 - val_loss: 49.2663 - val_mae: 208.8334 - 89ms/epoch - 18ms/step\n",
      "Epoch 238/300\n",
      "5/5 - 0s - loss: 35.0636 - mae: 66.0617 - val_loss: 49.0365 - val_mae: 208.4548 - 91ms/epoch - 18ms/step\n",
      "Epoch 239/300\n",
      "5/5 - 0s - loss: 34.8738 - mae: 66.1432 - val_loss: 48.8156 - val_mae: 208.7854 - 88ms/epoch - 18ms/step\n",
      "Epoch 240/300\n",
      "5/5 - 0s - loss: 34.5920 - mae: 66.0481 - val_loss: 48.5735 - val_mae: 208.6493 - 89ms/epoch - 18ms/step\n",
      "Epoch 241/300\n",
      "5/5 - 0s - loss: 35.0107 - mae: 66.0019 - val_loss: 48.3427 - val_mae: 209.2907 - 104ms/epoch - 21ms/step\n",
      "Epoch 242/300\n",
      "5/5 - 0s - loss: 34.2906 - mae: 65.9117 - val_loss: 48.1318 - val_mae: 208.3164 - 91ms/epoch - 18ms/step\n",
      "Epoch 243/300\n",
      "5/5 - 0s - loss: 34.0744 - mae: 66.1259 - val_loss: 47.9032 - val_mae: 208.0576 - 96ms/epoch - 19ms/step\n",
      "Epoch 244/300\n",
      "5/5 - 0s - loss: 33.7387 - mae: 65.9734 - val_loss: 47.6885 - val_mae: 208.0666 - 94ms/epoch - 19ms/step\n",
      "Epoch 245/300\n",
      "5/5 - 0s - loss: 33.4921 - mae: 65.9605 - val_loss: 47.4967 - val_mae: 208.1718 - 97ms/epoch - 19ms/step\n",
      "Epoch 246/300\n",
      "5/5 - 0s - loss: 34.1589 - mae: 65.9136 - val_loss: 47.3313 - val_mae: 208.4385 - 93ms/epoch - 19ms/step\n",
      "Epoch 247/300\n",
      "5/5 - 0s - loss: 33.7804 - mae: 65.9645 - val_loss: 47.1585 - val_mae: 208.8668 - 93ms/epoch - 19ms/step\n",
      "Epoch 248/300\n",
      "5/5 - 0s - loss: 32.9610 - mae: 65.8694 - val_loss: 46.9400 - val_mae: 208.2185 - 92ms/epoch - 18ms/step\n",
      "Epoch 249/300\n",
      "5/5 - 0s - loss: 33.1281 - mae: 65.8661 - val_loss: 46.7274 - val_mae: 208.3159 - 90ms/epoch - 18ms/step\n",
      "Epoch 250/300\n",
      "5/5 - 0s - loss: 32.6073 - mae: 66.0592 - val_loss: 46.5276 - val_mae: 208.4508 - 92ms/epoch - 18ms/step\n",
      "Epoch 251/300\n",
      "5/5 - 0s - loss: 32.8837 - mae: 65.8956 - val_loss: 46.3276 - val_mae: 207.7756 - 94ms/epoch - 19ms/step\n",
      "Epoch 252/300\n",
      "5/5 - 0s - loss: 32.4050 - mae: 65.8112 - val_loss: 46.1114 - val_mae: 208.1922 - 112ms/epoch - 22ms/step\n",
      "Epoch 253/300\n",
      "5/5 - 0s - loss: 32.8641 - mae: 65.7003 - val_loss: 45.9132 - val_mae: 208.2177 - 94ms/epoch - 19ms/step\n",
      "Epoch 254/300\n",
      "5/5 - 0s - loss: 32.5288 - mae: 65.9473 - val_loss: 45.6828 - val_mae: 207.6326 - 93ms/epoch - 19ms/step\n",
      "Epoch 255/300\n",
      "5/5 - 0s - loss: 32.2685 - mae: 65.7560 - val_loss: 45.4847 - val_mae: 208.5669 - 99ms/epoch - 20ms/step\n",
      "Epoch 256/300\n",
      "5/5 - 0s - loss: 32.4089 - mae: 65.7347 - val_loss: 45.3029 - val_mae: 207.6572 - 92ms/epoch - 18ms/step\n",
      "Epoch 257/300\n",
      "5/5 - 0s - loss: 32.1603 - mae: 65.7805 - val_loss: 45.1060 - val_mae: 207.6788 - 93ms/epoch - 19ms/step\n",
      "Epoch 258/300\n",
      "5/5 - 0s - loss: 31.6084 - mae: 65.7043 - val_loss: 44.9550 - val_mae: 207.5832 - 95ms/epoch - 19ms/step\n",
      "Epoch 259/300\n",
      "5/5 - 0s - loss: 31.2016 - mae: 65.6560 - val_loss: 44.8064 - val_mae: 208.4156 - 93ms/epoch - 19ms/step\n",
      "Epoch 260/300\n",
      "5/5 - 0s - loss: 31.5037 - mae: 65.6407 - val_loss: 44.6163 - val_mae: 208.6346 - 93ms/epoch - 19ms/step\n",
      "Epoch 261/300\n",
      "5/5 - 0s - loss: 31.4392 - mae: 65.7690 - val_loss: 44.4071 - val_mae: 207.5329 - 90ms/epoch - 18ms/step\n",
      "Epoch 262/300\n",
      "5/5 - 0s - loss: 31.3050 - mae: 65.6801 - val_loss: 44.2115 - val_mae: 208.2604 - 109ms/epoch - 22ms/step\n",
      "Epoch 263/300\n",
      "5/5 - 0s - loss: 31.0737 - mae: 65.7279 - val_loss: 44.0181 - val_mae: 208.6075 - 98ms/epoch - 20ms/step\n",
      "Epoch 264/300\n",
      "5/5 - 0s - loss: 30.9419 - mae: 65.6561 - val_loss: 43.8277 - val_mae: 207.4293 - 91ms/epoch - 18ms/step\n",
      "Epoch 265/300\n",
      "5/5 - 0s - loss: 31.3097 - mae: 65.6366 - val_loss: 43.6191 - val_mae: 207.1718 - 96ms/epoch - 19ms/step\n",
      "Epoch 266/300\n",
      "5/5 - 0s - loss: 30.4381 - mae: 65.5553 - val_loss: 43.4379 - val_mae: 207.0230 - 94ms/epoch - 19ms/step\n",
      "Epoch 267/300\n",
      "5/5 - 0s - loss: 31.0897 - mae: 65.6964 - val_loss: 43.2574 - val_mae: 206.8649 - 90ms/epoch - 18ms/step\n",
      "Epoch 268/300\n",
      "5/5 - 0s - loss: 30.9005 - mae: 65.5114 - val_loss: 43.0730 - val_mae: 208.1436 - 92ms/epoch - 18ms/step\n",
      "Epoch 269/300\n",
      "5/5 - 0s - loss: 30.4801 - mae: 65.6567 - val_loss: 42.9087 - val_mae: 206.3136 - 95ms/epoch - 19ms/step\n",
      "Epoch 270/300\n",
      "5/5 - 0s - loss: 30.2810 - mae: 65.5922 - val_loss: 42.7413 - val_mae: 206.9364 - 91ms/epoch - 18ms/step\n",
      "Epoch 271/300\n",
      "5/5 - 0s - loss: 30.1896 - mae: 65.4639 - val_loss: 42.5742 - val_mae: 207.9094 - 92ms/epoch - 18ms/step\n",
      "Epoch 272/300\n",
      "5/5 - 0s - loss: 29.9828 - mae: 65.5376 - val_loss: 42.4172 - val_mae: 208.0281 - 95ms/epoch - 19ms/step\n",
      "Epoch 273/300\n",
      "5/5 - 0s - loss: 30.6751 - mae: 65.6719 - val_loss: 42.2398 - val_mae: 206.9473 - 112ms/epoch - 22ms/step\n",
      "Epoch 274/300\n",
      "5/5 - 0s - loss: 29.8121 - mae: 65.5522 - val_loss: 42.0846 - val_mae: 207.4627 - 91ms/epoch - 18ms/step\n",
      "Epoch 275/300\n",
      "5/5 - 0s - loss: 29.6070 - mae: 65.6531 - val_loss: 41.8955 - val_mae: 207.4670 - 99ms/epoch - 20ms/step\n",
      "Epoch 276/300\n",
      "5/5 - 0s - loss: 29.5933 - mae: 65.4171 - val_loss: 41.7541 - val_mae: 207.6973 - 94ms/epoch - 19ms/step\n",
      "Epoch 277/300\n",
      "5/5 - 0s - loss: 29.3670 - mae: 65.6842 - val_loss: 41.6001 - val_mae: 207.6206 - 90ms/epoch - 18ms/step\n",
      "Epoch 278/300\n",
      "5/5 - 0s - loss: 29.6040 - mae: 65.4279 - val_loss: 41.4726 - val_mae: 207.5326 - 90ms/epoch - 18ms/step\n",
      "Epoch 279/300\n",
      "5/5 - 0s - loss: 29.3708 - mae: 65.3742 - val_loss: 41.2809 - val_mae: 206.5085 - 90ms/epoch - 18ms/step\n",
      "Epoch 280/300\n",
      "5/5 - 0s - loss: 29.3195 - mae: 65.3360 - val_loss: 41.1339 - val_mae: 207.2607 - 88ms/epoch - 18ms/step\n",
      "Epoch 281/300\n",
      "5/5 - 0s - loss: 29.2139 - mae: 65.4832 - val_loss: 40.9646 - val_mae: 207.6127 - 91ms/epoch - 18ms/step\n",
      "Epoch 282/300\n",
      "5/5 - 0s - loss: 28.5507 - mae: 65.3621 - val_loss: 40.8438 - val_mae: 206.5005 - 91ms/epoch - 18ms/step\n",
      "Epoch 283/300\n",
      "5/5 - 0s - loss: 29.0602 - mae: 65.3148 - val_loss: 40.6818 - val_mae: 207.3454 - 91ms/epoch - 18ms/step\n",
      "Epoch 284/300\n",
      "5/5 - 0s - loss: 28.6282 - mae: 65.3375 - val_loss: 40.5359 - val_mae: 208.1689 - 111ms/epoch - 22ms/step\n",
      "Epoch 285/300\n",
      "5/5 - 0s - loss: 28.7842 - mae: 65.3260 - val_loss: 40.3910 - val_mae: 207.3064 - 156ms/epoch - 31ms/step\n",
      "Epoch 286/300\n",
      "5/5 - 0s - loss: 29.2023 - mae: 65.1538 - val_loss: 40.2463 - val_mae: 206.0342 - 165ms/epoch - 33ms/step\n",
      "Epoch 287/300\n",
      "5/5 - 0s - loss: 28.2509 - mae: 65.1323 - val_loss: 40.1334 - val_mae: 206.6749 - 151ms/epoch - 30ms/step\n",
      "Epoch 288/300\n",
      "5/5 - 0s - loss: 28.8290 - mae: 65.3293 - val_loss: 39.9733 - val_mae: 207.0697 - 148ms/epoch - 30ms/step\n",
      "Epoch 289/300\n",
      "5/5 - 0s - loss: 28.4614 - mae: 65.2982 - val_loss: 39.8022 - val_mae: 207.0142 - 155ms/epoch - 31ms/step\n",
      "Epoch 290/300\n",
      "5/5 - 0s - loss: 28.5576 - mae: 65.2176 - val_loss: 39.7266 - val_mae: 206.6658 - 168ms/epoch - 34ms/step\n",
      "Epoch 291/300\n",
      "5/5 - 0s - loss: 28.3916 - mae: 65.1013 - val_loss: 39.5780 - val_mae: 205.9701 - 173ms/epoch - 35ms/step\n",
      "Epoch 292/300\n",
      "5/5 - 0s - loss: 28.0400 - mae: 65.2460 - val_loss: 39.4471 - val_mae: 206.3728 - 166ms/epoch - 33ms/step\n",
      "Epoch 293/300\n",
      "5/5 - 0s - loss: 28.2131 - mae: 65.0952 - val_loss: 39.3008 - val_mae: 206.2769 - 155ms/epoch - 31ms/step\n",
      "Epoch 294/300\n",
      "5/5 - 0s - loss: 28.0313 - mae: 65.0785 - val_loss: 39.1464 - val_mae: 206.5919 - 172ms/epoch - 34ms/step\n",
      "Epoch 295/300\n",
      "5/5 - 0s - loss: 27.9245 - mae: 65.0699 - val_loss: 39.0287 - val_mae: 207.2819 - 153ms/epoch - 31ms/step\n",
      "Epoch 296/300\n",
      "5/5 - 0s - loss: 27.8698 - mae: 65.1222 - val_loss: 38.9169 - val_mae: 206.0102 - 164ms/epoch - 33ms/step\n",
      "Epoch 297/300\n",
      "5/5 - 0s - loss: 27.8148 - mae: 65.1203 - val_loss: 38.7530 - val_mae: 206.8972 - 174ms/epoch - 35ms/step\n",
      "Epoch 298/300\n",
      "5/5 - 0s - loss: 27.7519 - mae: 64.9692 - val_loss: 38.6397 - val_mae: 207.2065 - 174ms/epoch - 35ms/step\n",
      "Epoch 299/300\n",
      "5/5 - 0s - loss: 27.4554 - mae: 65.0685 - val_loss: 38.5089 - val_mae: 205.5994 - 132ms/epoch - 26ms/step\n",
      "Epoch 300/300\n",
      "5/5 - 0s - loss: 27.2757 - mae: 65.0691 - val_loss: 38.3723 - val_mae: 205.7465 - 95ms/epoch - 19ms/step\n",
      "Epoch 1/300\n",
      "5/5 - 1s - loss: 2381.8562 - mae: 87.8452 - val_loss: 7388.8550 - val_mae: 146.4321 - 1s/epoch - 254ms/step\n",
      "Epoch 2/300\n",
      "5/5 - 0s - loss: 2019.0085 - mae: 87.8318 - val_loss: 5348.6816 - val_mae: 146.3449 - 112ms/epoch - 22ms/step\n",
      "Epoch 3/300\n",
      "5/5 - 0s - loss: 1778.2052 - mae: 87.8095 - val_loss: 4141.3223 - val_mae: 146.3307 - 94ms/epoch - 19ms/step\n",
      "Epoch 4/300\n",
      "5/5 - 0s - loss: 1574.8085 - mae: 87.7557 - val_loss: 3376.2864 - val_mae: 146.3111 - 92ms/epoch - 18ms/step\n",
      "Epoch 5/300\n",
      "5/5 - 0s - loss: 1410.8344 - mae: 87.7710 - val_loss: 2850.0989 - val_mae: 146.3119 - 95ms/epoch - 19ms/step\n",
      "Epoch 6/300\n",
      "5/5 - 0s - loss: 1284.7961 - mae: 87.7843 - val_loss: 2454.3401 - val_mae: 146.1451 - 92ms/epoch - 18ms/step\n",
      "Epoch 7/300\n",
      "5/5 - 0s - loss: 1198.6622 - mae: 87.7649 - val_loss: 2177.6538 - val_mae: 146.3112 - 91ms/epoch - 18ms/step\n",
      "Epoch 8/300\n",
      "5/5 - 0s - loss: 1115.6971 - mae: 87.7318 - val_loss: 1960.4363 - val_mae: 146.2421 - 97ms/epoch - 19ms/step\n",
      "Epoch 9/300\n",
      "5/5 - 0s - loss: 1031.4507 - mae: 87.6940 - val_loss: 1762.5010 - val_mae: 146.2990 - 92ms/epoch - 18ms/step\n",
      "Epoch 10/300\n",
      "5/5 - 0s - loss: 968.8371 - mae: 87.7002 - val_loss: 1619.2283 - val_mae: 146.2410 - 97ms/epoch - 19ms/step\n",
      "Epoch 11/300\n",
      "5/5 - 0s - loss: 922.8737 - mae: 87.6775 - val_loss: 1494.6531 - val_mae: 146.2438 - 98ms/epoch - 20ms/step\n",
      "Epoch 12/300\n",
      "5/5 - 0s - loss: 881.1722 - mae: 87.6730 - val_loss: 1394.5420 - val_mae: 146.0870 - 110ms/epoch - 22ms/step\n",
      "Epoch 13/300\n",
      "5/5 - 0s - loss: 835.0037 - mae: 87.6813 - val_loss: 1316.2314 - val_mae: 146.1817 - 122ms/epoch - 24ms/step\n",
      "Epoch 14/300\n",
      "5/5 - 0s - loss: 786.9062 - mae: 87.6261 - val_loss: 1233.6082 - val_mae: 145.9687 - 92ms/epoch - 18ms/step\n",
      "Epoch 15/300\n",
      "5/5 - 0s - loss: 755.8019 - mae: 87.6120 - val_loss: 1167.5093 - val_mae: 146.1205 - 88ms/epoch - 18ms/step\n",
      "Epoch 16/300\n",
      "5/5 - 0s - loss: 722.0251 - mae: 87.5989 - val_loss: 1098.2141 - val_mae: 146.0041 - 94ms/epoch - 19ms/step\n",
      "Epoch 17/300\n",
      "5/5 - 0s - loss: 692.3099 - mae: 87.6010 - val_loss: 1046.0157 - val_mae: 145.9310 - 96ms/epoch - 19ms/step\n",
      "Epoch 18/300\n",
      "5/5 - 0s - loss: 669.1259 - mae: 87.5905 - val_loss: 1004.1329 - val_mae: 146.0317 - 98ms/epoch - 20ms/step\n",
      "Epoch 19/300\n",
      "5/5 - 0s - loss: 659.5925 - mae: 87.6028 - val_loss: 961.2064 - val_mae: 145.8765 - 97ms/epoch - 19ms/step\n",
      "Epoch 20/300\n",
      "5/5 - 0s - loss: 619.5312 - mae: 87.5748 - val_loss: 922.8251 - val_mae: 145.9568 - 96ms/epoch - 19ms/step\n",
      "Epoch 21/300\n",
      "5/5 - 0s - loss: 595.0833 - mae: 87.5659 - val_loss: 888.9364 - val_mae: 145.9801 - 97ms/epoch - 19ms/step\n",
      "Epoch 22/300\n",
      "5/5 - 0s - loss: 579.0940 - mae: 87.5671 - val_loss: 856.4440 - val_mae: 145.8619 - 109ms/epoch - 22ms/step\n",
      "Epoch 23/300\n",
      "5/5 - 0s - loss: 562.1776 - mae: 87.4897 - val_loss: 826.3688 - val_mae: 145.8432 - 97ms/epoch - 19ms/step\n",
      "Epoch 24/300\n",
      "5/5 - 0s - loss: 543.4716 - mae: 87.4938 - val_loss: 799.0226 - val_mae: 145.7807 - 98ms/epoch - 20ms/step\n",
      "Epoch 25/300\n",
      "5/5 - 0s - loss: 521.6768 - mae: 87.4820 - val_loss: 773.0953 - val_mae: 145.8761 - 94ms/epoch - 19ms/step\n",
      "Epoch 26/300\n",
      "5/5 - 0s - loss: 510.4831 - mae: 87.4566 - val_loss: 749.2789 - val_mae: 145.7781 - 95ms/epoch - 19ms/step\n",
      "Epoch 27/300\n",
      "5/5 - 0s - loss: 496.7668 - mae: 87.4694 - val_loss: 727.1386 - val_mae: 145.7816 - 94ms/epoch - 19ms/step\n",
      "Epoch 28/300\n",
      "5/5 - 0s - loss: 484.5244 - mae: 87.4133 - val_loss: 705.1426 - val_mae: 145.7403 - 96ms/epoch - 19ms/step\n",
      "Epoch 29/300\n",
      "5/5 - 0s - loss: 467.1037 - mae: 87.4665 - val_loss: 681.3927 - val_mae: 145.8627 - 92ms/epoch - 18ms/step\n",
      "Epoch 30/300\n",
      "5/5 - 0s - loss: 464.8935 - mae: 87.3899 - val_loss: 662.8047 - val_mae: 145.7432 - 100ms/epoch - 20ms/step\n",
      "Epoch 31/300\n",
      "5/5 - 0s - loss: 448.0035 - mae: 87.4489 - val_loss: 645.7157 - val_mae: 145.7766 - 98ms/epoch - 20ms/step\n",
      "Epoch 32/300\n",
      "5/5 - 0s - loss: 437.1466 - mae: 87.3606 - val_loss: 630.0040 - val_mae: 145.6473 - 96ms/epoch - 19ms/step\n",
      "Epoch 33/300\n",
      "5/5 - 0s - loss: 428.8878 - mae: 87.4076 - val_loss: 616.0991 - val_mae: 145.5477 - 112ms/epoch - 22ms/step\n",
      "Epoch 34/300\n",
      "5/5 - 0s - loss: 410.9968 - mae: 87.3077 - val_loss: 598.6998 - val_mae: 145.4935 - 95ms/epoch - 19ms/step\n",
      "Epoch 35/300\n",
      "5/5 - 0s - loss: 405.5130 - mae: 87.3503 - val_loss: 582.1433 - val_mae: 145.5674 - 94ms/epoch - 19ms/step\n",
      "Epoch 36/300\n",
      "5/5 - 0s - loss: 399.1215 - mae: 87.3461 - val_loss: 566.4358 - val_mae: 145.6355 - 96ms/epoch - 19ms/step\n",
      "Epoch 37/300\n",
      "5/5 - 0s - loss: 383.9970 - mae: 87.3177 - val_loss: 550.1679 - val_mae: 145.7359 - 98ms/epoch - 20ms/step\n",
      "Epoch 38/300\n",
      "5/5 - 0s - loss: 380.9352 - mae: 87.3180 - val_loss: 538.2225 - val_mae: 145.6350 - 93ms/epoch - 19ms/step\n",
      "Epoch 39/300\n",
      "5/5 - 0s - loss: 372.1167 - mae: 87.2698 - val_loss: 525.4855 - val_mae: 145.6281 - 94ms/epoch - 19ms/step\n",
      "Epoch 40/300\n",
      "5/5 - 0s - loss: 362.4694 - mae: 87.2935 - val_loss: 513.8046 - val_mae: 145.5103 - 97ms/epoch - 19ms/step\n",
      "Epoch 41/300\n",
      "5/5 - 0s - loss: 356.4506 - mae: 87.2930 - val_loss: 502.6657 - val_mae: 145.4900 - 101ms/epoch - 20ms/step\n",
      "Epoch 42/300\n",
      "5/5 - 0s - loss: 346.0305 - mae: 87.2375 - val_loss: 491.7784 - val_mae: 145.4453 - 95ms/epoch - 19ms/step\n",
      "Epoch 43/300\n",
      "5/5 - 0s - loss: 342.6496 - mae: 87.2421 - val_loss: 481.6098 - val_mae: 145.5025 - 110ms/epoch - 22ms/step\n",
      "Epoch 44/300\n",
      "5/5 - 0s - loss: 332.0206 - mae: 87.2330 - val_loss: 471.6585 - val_mae: 145.4218 - 95ms/epoch - 19ms/step\n",
      "Epoch 45/300\n",
      "5/5 - 0s - loss: 328.6613 - mae: 87.2005 - val_loss: 461.1821 - val_mae: 145.3081 - 94ms/epoch - 19ms/step\n",
      "Epoch 46/300\n",
      "5/5 - 0s - loss: 318.6438 - mae: 87.1928 - val_loss: 451.2444 - val_mae: 145.3180 - 92ms/epoch - 18ms/step\n",
      "Epoch 47/300\n",
      "5/5 - 0s - loss: 315.2668 - mae: 87.1527 - val_loss: 441.8553 - val_mae: 145.3452 - 92ms/epoch - 18ms/step\n",
      "Epoch 48/300\n",
      "5/5 - 0s - loss: 311.2546 - mae: 87.1425 - val_loss: 432.9281 - val_mae: 145.2656 - 94ms/epoch - 19ms/step\n",
      "Epoch 49/300\n",
      "5/5 - 0s - loss: 304.5366 - mae: 87.1505 - val_loss: 423.2364 - val_mae: 145.4932 - 95ms/epoch - 19ms/step\n",
      "Epoch 50/300\n",
      "5/5 - 0s - loss: 298.2650 - mae: 87.1496 - val_loss: 415.1538 - val_mae: 145.3087 - 103ms/epoch - 21ms/step\n",
      "Epoch 51/300\n",
      "5/5 - 0s - loss: 295.4458 - mae: 87.1676 - val_loss: 406.3881 - val_mae: 145.1836 - 98ms/epoch - 20ms/step\n",
      "Epoch 52/300\n",
      "5/5 - 0s - loss: 285.8158 - mae: 87.1264 - val_loss: 398.7898 - val_mae: 145.4148 - 95ms/epoch - 19ms/step\n",
      "Epoch 53/300\n",
      "5/5 - 0s - loss: 283.2459 - mae: 87.1181 - val_loss: 392.1331 - val_mae: 145.1634 - 106ms/epoch - 21ms/step\n",
      "Epoch 54/300\n",
      "5/5 - 0s - loss: 275.9876 - mae: 87.0748 - val_loss: 385.2151 - val_mae: 145.2928 - 96ms/epoch - 19ms/step\n",
      "Epoch 55/300\n",
      "5/5 - 0s - loss: 270.7033 - mae: 87.0925 - val_loss: 377.1762 - val_mae: 145.1592 - 92ms/epoch - 18ms/step\n",
      "Epoch 56/300\n",
      "5/5 - 0s - loss: 268.9335 - mae: 87.0843 - val_loss: 370.2789 - val_mae: 145.0523 - 98ms/epoch - 20ms/step\n",
      "Epoch 57/300\n",
      "5/5 - 0s - loss: 264.7483 - mae: 87.0233 - val_loss: 363.5931 - val_mae: 144.9967 - 90ms/epoch - 18ms/step\n",
      "Epoch 58/300\n",
      "5/5 - 0s - loss: 257.6352 - mae: 86.9927 - val_loss: 357.3733 - val_mae: 145.2589 - 94ms/epoch - 19ms/step\n",
      "Epoch 59/300\n",
      "5/5 - 0s - loss: 257.2863 - mae: 87.0163 - val_loss: 350.7080 - val_mae: 145.1275 - 100ms/epoch - 20ms/step\n",
      "Epoch 60/300\n",
      "5/5 - 0s - loss: 251.1755 - mae: 87.0072 - val_loss: 345.4402 - val_mae: 145.1061 - 99ms/epoch - 20ms/step\n",
      "Epoch 61/300\n",
      "5/5 - 0s - loss: 245.4723 - mae: 86.9429 - val_loss: 339.8242 - val_mae: 145.0519 - 101ms/epoch - 20ms/step\n",
      "Epoch 62/300\n",
      "5/5 - 0s - loss: 245.5345 - mae: 86.9540 - val_loss: 334.3235 - val_mae: 144.7381 - 97ms/epoch - 19ms/step\n",
      "Epoch 63/300\n",
      "5/5 - 0s - loss: 241.4698 - mae: 86.9221 - val_loss: 328.1858 - val_mae: 145.2081 - 93ms/epoch - 19ms/step\n",
      "Epoch 64/300\n",
      "5/5 - 0s - loss: 236.3080 - mae: 86.9576 - val_loss: 321.9843 - val_mae: 145.1523 - 114ms/epoch - 23ms/step\n",
      "Epoch 65/300\n",
      "5/5 - 0s - loss: 232.1631 - mae: 86.9133 - val_loss: 317.2490 - val_mae: 144.8931 - 98ms/epoch - 20ms/step\n",
      "Epoch 66/300\n",
      "5/5 - 0s - loss: 226.6504 - mae: 86.9016 - val_loss: 312.4492 - val_mae: 145.0215 - 90ms/epoch - 18ms/step\n",
      "Epoch 67/300\n",
      "5/5 - 0s - loss: 223.6570 - mae: 86.8639 - val_loss: 306.7823 - val_mae: 144.7943 - 93ms/epoch - 19ms/step\n",
      "Epoch 68/300\n",
      "5/5 - 0s - loss: 224.6045 - mae: 86.8670 - val_loss: 301.4989 - val_mae: 144.7669 - 92ms/epoch - 18ms/step\n",
      "Epoch 69/300\n",
      "5/5 - 0s - loss: 217.9668 - mae: 86.8772 - val_loss: 296.7635 - val_mae: 144.9021 - 92ms/epoch - 18ms/step\n",
      "Epoch 70/300\n",
      "5/5 - 0s - loss: 212.4985 - mae: 86.8713 - val_loss: 292.0450 - val_mae: 144.9165 - 96ms/epoch - 19ms/step\n",
      "Epoch 71/300\n",
      "5/5 - 0s - loss: 211.2560 - mae: 86.8503 - val_loss: 286.2659 - val_mae: 144.7871 - 99ms/epoch - 20ms/step\n",
      "Epoch 72/300\n",
      "5/5 - 0s - loss: 208.4098 - mae: 86.7926 - val_loss: 282.2595 - val_mae: 144.8610 - 109ms/epoch - 22ms/step\n",
      "Epoch 73/300\n",
      "5/5 - 0s - loss: 204.0403 - mae: 86.8711 - val_loss: 278.4054 - val_mae: 144.8904 - 105ms/epoch - 21ms/step\n",
      "Epoch 74/300\n",
      "5/5 - 0s - loss: 202.0236 - mae: 86.7656 - val_loss: 273.7455 - val_mae: 144.6898 - 120ms/epoch - 24ms/step\n",
      "Epoch 75/300\n",
      "5/5 - 0s - loss: 200.4137 - mae: 86.8097 - val_loss: 269.5679 - val_mae: 144.6287 - 103ms/epoch - 21ms/step\n",
      "Epoch 76/300\n",
      "5/5 - 0s - loss: 198.6301 - mae: 86.7177 - val_loss: 265.6039 - val_mae: 144.9127 - 96ms/epoch - 19ms/step\n",
      "Epoch 77/300\n",
      "5/5 - 0s - loss: 193.7039 - mae: 86.6694 - val_loss: 261.5659 - val_mae: 144.7734 - 95ms/epoch - 19ms/step\n",
      "Epoch 78/300\n",
      "5/5 - 0s - loss: 191.4194 - mae: 86.7646 - val_loss: 257.7303 - val_mae: 144.5014 - 94ms/epoch - 19ms/step\n",
      "Epoch 79/300\n",
      "5/5 - 0s - loss: 189.4542 - mae: 86.6876 - val_loss: 253.9172 - val_mae: 145.0548 - 95ms/epoch - 19ms/step\n",
      "Epoch 80/300\n",
      "5/5 - 0s - loss: 184.0243 - mae: 86.6870 - val_loss: 250.4410 - val_mae: 144.8458 - 98ms/epoch - 20ms/step\n",
      "Epoch 81/300\n",
      "5/5 - 0s - loss: 183.3426 - mae: 86.6354 - val_loss: 247.2542 - val_mae: 144.6403 - 95ms/epoch - 19ms/step\n",
      "Epoch 82/300\n",
      "5/5 - 0s - loss: 181.2488 - mae: 86.6561 - val_loss: 243.8138 - val_mae: 144.5806 - 95ms/epoch - 19ms/step\n",
      "Epoch 83/300\n",
      "5/5 - 0s - loss: 178.4008 - mae: 86.6282 - val_loss: 240.6613 - val_mae: 144.6760 - 94ms/epoch - 19ms/step\n",
      "Epoch 84/300\n",
      "5/5 - 0s - loss: 176.2044 - mae: 86.6671 - val_loss: 237.2622 - val_mae: 144.4781 - 171ms/epoch - 34ms/step\n",
      "Epoch 85/300\n",
      "5/5 - 0s - loss: 172.1234 - mae: 86.6147 - val_loss: 234.1361 - val_mae: 144.5633 - 153ms/epoch - 31ms/step\n",
      "Epoch 86/300\n",
      "5/5 - 0s - loss: 173.2157 - mae: 86.5000 - val_loss: 230.4971 - val_mae: 144.6905 - 151ms/epoch - 30ms/step\n",
      "Epoch 87/300\n",
      "5/5 - 0s - loss: 169.1310 - mae: 86.5841 - val_loss: 227.2917 - val_mae: 144.3987 - 172ms/epoch - 34ms/step\n",
      "Epoch 88/300\n",
      "5/5 - 0s - loss: 167.0005 - mae: 86.5030 - val_loss: 224.2895 - val_mae: 144.6936 - 152ms/epoch - 30ms/step\n",
      "Epoch 89/300\n",
      "5/5 - 0s - loss: 165.6826 - mae: 86.5285 - val_loss: 220.9008 - val_mae: 144.4066 - 154ms/epoch - 31ms/step\n",
      "Epoch 90/300\n",
      "5/5 - 0s - loss: 164.1373 - mae: 86.5527 - val_loss: 218.0558 - val_mae: 144.1867 - 167ms/epoch - 33ms/step\n",
      "Epoch 91/300\n",
      "5/5 - 0s - loss: 161.7878 - mae: 86.4914 - val_loss: 215.2124 - val_mae: 144.7474 - 166ms/epoch - 33ms/step\n",
      "Epoch 92/300\n",
      "5/5 - 0s - loss: 158.9249 - mae: 86.4976 - val_loss: 212.8902 - val_mae: 144.2814 - 147ms/epoch - 29ms/step\n",
      "Epoch 93/300\n",
      "5/5 - 0s - loss: 156.6355 - mae: 86.4894 - val_loss: 209.6626 - val_mae: 144.4340 - 160ms/epoch - 32ms/step\n",
      "Epoch 94/300\n",
      "5/5 - 0s - loss: 153.9475 - mae: 86.4738 - val_loss: 206.5490 - val_mae: 144.4015 - 152ms/epoch - 30ms/step\n",
      "Epoch 95/300\n",
      "5/5 - 0s - loss: 152.5056 - mae: 86.4217 - val_loss: 203.9193 - val_mae: 144.3121 - 164ms/epoch - 33ms/step\n",
      "Epoch 96/300\n",
      "5/5 - 0s - loss: 151.4126 - mae: 86.3677 - val_loss: 201.7721 - val_mae: 144.4029 - 159ms/epoch - 32ms/step\n",
      "Epoch 97/300\n",
      "5/5 - 0s - loss: 148.3737 - mae: 86.3830 - val_loss: 198.8901 - val_mae: 144.3976 - 174ms/epoch - 35ms/step\n",
      "Epoch 98/300\n",
      "5/5 - 0s - loss: 147.5971 - mae: 86.3254 - val_loss: 196.5380 - val_mae: 144.2307 - 135ms/epoch - 27ms/step\n",
      "Epoch 99/300\n",
      "5/5 - 0s - loss: 144.4962 - mae: 86.3349 - val_loss: 193.9993 - val_mae: 144.2608 - 95ms/epoch - 19ms/step\n",
      "Epoch 100/300\n",
      "5/5 - 0s - loss: 143.9907 - mae: 86.3077 - val_loss: 191.6566 - val_mae: 144.5748 - 96ms/epoch - 19ms/step\n",
      "Epoch 101/300\n",
      "5/5 - 0s - loss: 141.2332 - mae: 86.2872 - val_loss: 188.7360 - val_mae: 144.3856 - 101ms/epoch - 20ms/step\n",
      "Epoch 102/300\n",
      "5/5 - 0s - loss: 140.4377 - mae: 86.2573 - val_loss: 186.4860 - val_mae: 144.1145 - 98ms/epoch - 20ms/step\n",
      "Epoch 103/300\n",
      "5/5 - 0s - loss: 138.6947 - mae: 86.2584 - val_loss: 184.1479 - val_mae: 144.1903 - 93ms/epoch - 19ms/step\n",
      "Epoch 104/300\n",
      "5/5 - 0s - loss: 136.8087 - mae: 86.2862 - val_loss: 181.8335 - val_mae: 144.3920 - 91ms/epoch - 18ms/step\n",
      "Epoch 105/300\n",
      "5/5 - 0s - loss: 136.1932 - mae: 86.2087 - val_loss: 179.6146 - val_mae: 144.2483 - 93ms/epoch - 19ms/step\n",
      "Epoch 106/300\n",
      "5/5 - 0s - loss: 135.3268 - mae: 86.2182 - val_loss: 177.2047 - val_mae: 144.3476 - 93ms/epoch - 19ms/step\n",
      "Epoch 107/300\n",
      "5/5 - 0s - loss: 131.7877 - mae: 86.2095 - val_loss: 174.2875 - val_mae: 144.0957 - 110ms/epoch - 22ms/step\n",
      "Epoch 108/300\n",
      "5/5 - 0s - loss: 132.3455 - mae: 86.2680 - val_loss: 172.1437 - val_mae: 143.9894 - 91ms/epoch - 18ms/step\n",
      "Epoch 109/300\n",
      "5/5 - 0s - loss: 128.8878 - mae: 86.0968 - val_loss: 170.1290 - val_mae: 144.2120 - 92ms/epoch - 18ms/step\n",
      "Epoch 110/300\n",
      "5/5 - 0s - loss: 128.8154 - mae: 86.1461 - val_loss: 167.9242 - val_mae: 144.0334 - 90ms/epoch - 18ms/step\n",
      "Epoch 111/300\n",
      "5/5 - 0s - loss: 126.1710 - mae: 86.0770 - val_loss: 165.7877 - val_mae: 144.5032 - 103ms/epoch - 21ms/step\n",
      "Epoch 112/300\n",
      "5/5 - 0s - loss: 124.1909 - mae: 86.1150 - val_loss: 163.8785 - val_mae: 144.2028 - 94ms/epoch - 19ms/step\n",
      "Epoch 113/300\n",
      "5/5 - 0s - loss: 124.7214 - mae: 86.1043 - val_loss: 161.6904 - val_mae: 144.3925 - 104ms/epoch - 21ms/step\n",
      "Epoch 114/300\n",
      "5/5 - 0s - loss: 120.8712 - mae: 86.1507 - val_loss: 160.3389 - val_mae: 144.2115 - 95ms/epoch - 19ms/step\n",
      "Epoch 115/300\n",
      "5/5 - 0s - loss: 121.6472 - mae: 86.0203 - val_loss: 158.6406 - val_mae: 144.0956 - 92ms/epoch - 18ms/step\n",
      "Epoch 116/300\n",
      "5/5 - 0s - loss: 119.5228 - mae: 85.9483 - val_loss: 156.5798 - val_mae: 144.1196 - 91ms/epoch - 18ms/step\n",
      "Epoch 117/300\n",
      "5/5 - 0s - loss: 117.9217 - mae: 85.9767 - val_loss: 155.1855 - val_mae: 143.8420 - 108ms/epoch - 22ms/step\n",
      "Epoch 118/300\n",
      "5/5 - 0s - loss: 117.9715 - mae: 85.9988 - val_loss: 153.1376 - val_mae: 143.9354 - 94ms/epoch - 19ms/step\n",
      "Epoch 119/300\n",
      "5/5 - 0s - loss: 114.9388 - mae: 85.9551 - val_loss: 151.0068 - val_mae: 143.9389 - 94ms/epoch - 19ms/step\n",
      "Epoch 120/300\n",
      "5/5 - 0s - loss: 114.0539 - mae: 85.9292 - val_loss: 149.4740 - val_mae: 144.0538 - 101ms/epoch - 20ms/step\n",
      "Epoch 121/300\n",
      "5/5 - 0s - loss: 113.9535 - mae: 85.8857 - val_loss: 148.1084 - val_mae: 143.7754 - 102ms/epoch - 20ms/step\n",
      "Epoch 122/300\n",
      "5/5 - 0s - loss: 112.5998 - mae: 85.9292 - val_loss: 146.7454 - val_mae: 143.9550 - 96ms/epoch - 19ms/step\n",
      "Epoch 123/300\n",
      "5/5 - 0s - loss: 112.4363 - mae: 85.9211 - val_loss: 145.1147 - val_mae: 143.8048 - 92ms/epoch - 18ms/step\n",
      "Epoch 124/300\n",
      "5/5 - 0s - loss: 110.2714 - mae: 85.8778 - val_loss: 143.8022 - val_mae: 143.5491 - 92ms/epoch - 18ms/step\n",
      "Epoch 125/300\n",
      "5/5 - 0s - loss: 110.3964 - mae: 85.9355 - val_loss: 142.3968 - val_mae: 143.7019 - 96ms/epoch - 19ms/step\n",
      "Epoch 126/300\n",
      "5/5 - 0s - loss: 108.7848 - mae: 85.7891 - val_loss: 140.9476 - val_mae: 143.5819 - 94ms/epoch - 19ms/step\n",
      "Epoch 127/300\n",
      "5/5 - 0s - loss: 108.6565 - mae: 85.8685 - val_loss: 139.7895 - val_mae: 143.8888 - 94ms/epoch - 19ms/step\n",
      "Epoch 128/300\n",
      "5/5 - 0s - loss: 107.0829 - mae: 85.8046 - val_loss: 138.7163 - val_mae: 143.7458 - 105ms/epoch - 21ms/step\n",
      "Epoch 129/300\n",
      "5/5 - 0s - loss: 105.4416 - mae: 85.7851 - val_loss: 137.3519 - val_mae: 143.7406 - 99ms/epoch - 20ms/step\n",
      "Epoch 130/300\n",
      "5/5 - 0s - loss: 103.0010 - mae: 85.7505 - val_loss: 136.2042 - val_mae: 143.7978 - 95ms/epoch - 19ms/step\n",
      "Epoch 131/300\n",
      "5/5 - 0s - loss: 103.3848 - mae: 85.7029 - val_loss: 134.8972 - val_mae: 143.6934 - 105ms/epoch - 21ms/step\n",
      "Epoch 132/300\n",
      "5/5 - 0s - loss: 103.2451 - mae: 85.7635 - val_loss: 133.5165 - val_mae: 143.5366 - 96ms/epoch - 19ms/step\n",
      "Epoch 133/300\n",
      "5/5 - 0s - loss: 100.7017 - mae: 85.6894 - val_loss: 131.9381 - val_mae: 143.6288 - 97ms/epoch - 19ms/step\n",
      "Epoch 134/300\n",
      "5/5 - 0s - loss: 99.9672 - mae: 85.6624 - val_loss: 130.8051 - val_mae: 143.4474 - 94ms/epoch - 19ms/step\n",
      "Epoch 135/300\n",
      "5/5 - 0s - loss: 99.4605 - mae: 85.6640 - val_loss: 129.5644 - val_mae: 143.5724 - 93ms/epoch - 19ms/step\n",
      "Epoch 136/300\n",
      "5/5 - 0s - loss: 98.7598 - mae: 85.5958 - val_loss: 128.6273 - val_mae: 143.7973 - 97ms/epoch - 19ms/step\n",
      "Epoch 137/300\n",
      "5/5 - 0s - loss: 98.6485 - mae: 85.6993 - val_loss: 127.3579 - val_mae: 143.5672 - 97ms/epoch - 19ms/step\n",
      "Epoch 138/300\n",
      "5/5 - 0s - loss: 95.4919 - mae: 85.6925 - val_loss: 126.1505 - val_mae: 143.5801 - 113ms/epoch - 23ms/step\n",
      "Epoch 139/300\n",
      "5/5 - 0s - loss: 93.5565 - mae: 85.5575 - val_loss: 125.0312 - val_mae: 143.5390 - 110ms/epoch - 22ms/step\n",
      "Epoch 140/300\n",
      "5/5 - 0s - loss: 93.6368 - mae: 85.5337 - val_loss: 124.0405 - val_mae: 143.3441 - 98ms/epoch - 20ms/step\n",
      "Epoch 141/300\n",
      "5/5 - 0s - loss: 95.5987 - mae: 85.6315 - val_loss: 123.0809 - val_mae: 143.5485 - 103ms/epoch - 21ms/step\n",
      "Epoch 142/300\n",
      "5/5 - 0s - loss: 93.6408 - mae: 85.4832 - val_loss: 121.8503 - val_mae: 143.5844 - 93ms/epoch - 19ms/step\n",
      "Epoch 143/300\n",
      "5/5 - 0s - loss: 92.2073 - mae: 85.5187 - val_loss: 120.6397 - val_mae: 143.8558 - 94ms/epoch - 19ms/step\n",
      "Epoch 144/300\n",
      "5/5 - 0s - loss: 92.5902 - mae: 85.6210 - val_loss: 119.7536 - val_mae: 143.3937 - 96ms/epoch - 19ms/step\n",
      "Epoch 145/300\n",
      "5/5 - 0s - loss: 90.5245 - mae: 85.4685 - val_loss: 118.6627 - val_mae: 143.6231 - 95ms/epoch - 19ms/step\n",
      "Epoch 146/300\n",
      "5/5 - 0s - loss: 91.8501 - mae: 85.4175 - val_loss: 117.6886 - val_mae: 143.2394 - 96ms/epoch - 19ms/step\n",
      "Epoch 147/300\n",
      "5/5 - 0s - loss: 89.7349 - mae: 85.4140 - val_loss: 116.7729 - val_mae: 143.1937 - 97ms/epoch - 19ms/step\n",
      "Epoch 148/300\n",
      "5/5 - 0s - loss: 89.6718 - mae: 85.5454 - val_loss: 115.4717 - val_mae: 143.4341 - 115ms/epoch - 23ms/step\n",
      "Epoch 149/300\n",
      "5/5 - 0s - loss: 86.3877 - mae: 85.3912 - val_loss: 114.5233 - val_mae: 143.5010 - 98ms/epoch - 20ms/step\n",
      "Epoch 150/300\n",
      "5/5 - 0s - loss: 86.3471 - mae: 85.4994 - val_loss: 113.5238 - val_mae: 143.3789 - 102ms/epoch - 20ms/step\n",
      "Epoch 151/300\n",
      "5/5 - 0s - loss: 85.7376 - mae: 85.4173 - val_loss: 112.7720 - val_mae: 143.1604 - 100ms/epoch - 20ms/step\n",
      "Epoch 152/300\n",
      "5/5 - 0s - loss: 84.9971 - mae: 85.3844 - val_loss: 111.7020 - val_mae: 143.2797 - 92ms/epoch - 18ms/step\n",
      "Epoch 153/300\n",
      "5/5 - 0s - loss: 84.2461 - mae: 85.4140 - val_loss: 110.5735 - val_mae: 143.5484 - 96ms/epoch - 19ms/step\n",
      "Epoch 154/300\n",
      "5/5 - 0s - loss: 83.0959 - mae: 85.2603 - val_loss: 109.3430 - val_mae: 143.6105 - 93ms/epoch - 19ms/step\n",
      "Epoch 155/300\n",
      "5/5 - 0s - loss: 84.6594 - mae: 85.4064 - val_loss: 108.5816 - val_mae: 143.2508 - 94ms/epoch - 19ms/step\n",
      "Epoch 156/300\n",
      "5/5 - 0s - loss: 82.9401 - mae: 85.2569 - val_loss: 107.7150 - val_mae: 143.0809 - 96ms/epoch - 19ms/step\n",
      "Epoch 157/300\n",
      "5/5 - 0s - loss: 82.0377 - mae: 85.2229 - val_loss: 106.9021 - val_mae: 142.8594 - 95ms/epoch - 19ms/step\n",
      "Epoch 158/300\n",
      "5/5 - 0s - loss: 81.4985 - mae: 85.1292 - val_loss: 105.7955 - val_mae: 143.0474 - 109ms/epoch - 22ms/step\n",
      "Epoch 159/300\n",
      "5/5 - 0s - loss: 81.2215 - mae: 85.2190 - val_loss: 104.9706 - val_mae: 143.3407 - 108ms/epoch - 22ms/step\n",
      "Epoch 160/300\n",
      "5/5 - 0s - loss: 81.3494 - mae: 85.2551 - val_loss: 104.0978 - val_mae: 143.2471 - 100ms/epoch - 20ms/step\n",
      "Epoch 161/300\n",
      "5/5 - 0s - loss: 79.1860 - mae: 85.1293 - val_loss: 103.3043 - val_mae: 142.9344 - 98ms/epoch - 20ms/step\n",
      "Epoch 162/300\n",
      "5/5 - 0s - loss: 79.4295 - mae: 85.1778 - val_loss: 102.5668 - val_mae: 143.3144 - 110ms/epoch - 22ms/step\n",
      "Epoch 163/300\n",
      "5/5 - 0s - loss: 79.0525 - mae: 85.0911 - val_loss: 101.8274 - val_mae: 143.2078 - 93ms/epoch - 19ms/step\n",
      "Epoch 164/300\n",
      "5/5 - 0s - loss: 77.3158 - mae: 85.1336 - val_loss: 100.7024 - val_mae: 143.0965 - 96ms/epoch - 19ms/step\n",
      "Epoch 165/300\n",
      "5/5 - 0s - loss: 77.1626 - mae: 85.0401 - val_loss: 99.8106 - val_mae: 142.9199 - 110ms/epoch - 22ms/step\n",
      "Epoch 166/300\n",
      "5/5 - 0s - loss: 77.6429 - mae: 85.1692 - val_loss: 98.8646 - val_mae: 142.6682 - 92ms/epoch - 18ms/step\n",
      "Epoch 167/300\n",
      "5/5 - 0s - loss: 75.4744 - mae: 85.0478 - val_loss: 98.1047 - val_mae: 143.0700 - 96ms/epoch - 19ms/step\n",
      "Epoch 168/300\n",
      "5/5 - 0s - loss: 76.1702 - mae: 85.1013 - val_loss: 97.1624 - val_mae: 142.9643 - 115ms/epoch - 23ms/step\n",
      "Epoch 169/300\n",
      "5/5 - 0s - loss: 76.2186 - mae: 85.1035 - val_loss: 96.3798 - val_mae: 143.2357 - 95ms/epoch - 19ms/step\n",
      "Epoch 170/300\n",
      "5/5 - 0s - loss: 74.8224 - mae: 84.9413 - val_loss: 95.6133 - val_mae: 142.7045 - 103ms/epoch - 21ms/step\n",
      "Epoch 171/300\n",
      "5/5 - 0s - loss: 73.7219 - mae: 85.0517 - val_loss: 94.7278 - val_mae: 143.4313 - 98ms/epoch - 20ms/step\n",
      "Epoch 172/300\n",
      "5/5 - 0s - loss: 74.3417 - mae: 85.0707 - val_loss: 94.0552 - val_mae: 143.2032 - 97ms/epoch - 19ms/step\n",
      "Epoch 173/300\n",
      "5/5 - 0s - loss: 74.7391 - mae: 85.0601 - val_loss: 93.5130 - val_mae: 143.2990 - 96ms/epoch - 19ms/step\n",
      "Epoch 174/300\n",
      "5/5 - 0s - loss: 73.2226 - mae: 84.9749 - val_loss: 92.9732 - val_mae: 143.0071 - 100ms/epoch - 20ms/step\n",
      "Epoch 175/300\n",
      "5/5 - 0s - loss: 73.5857 - mae: 84.8357 - val_loss: 92.1128 - val_mae: 142.8156 - 98ms/epoch - 20ms/step\n",
      "Epoch 176/300\n",
      "5/5 - 0s - loss: 72.3819 - mae: 84.9095 - val_loss: 91.5520 - val_mae: 142.8273 - 96ms/epoch - 19ms/step\n",
      "Epoch 177/300\n",
      "5/5 - 0s - loss: 71.9915 - mae: 84.8986 - val_loss: 90.9762 - val_mae: 142.6275 - 93ms/epoch - 19ms/step\n",
      "Epoch 178/300\n",
      "5/5 - 0s - loss: 71.9710 - mae: 84.8197 - val_loss: 90.1462 - val_mae: 142.8861 - 116ms/epoch - 23ms/step\n",
      "Epoch 179/300\n",
      "5/5 - 0s - loss: 70.2202 - mae: 84.7682 - val_loss: 89.5443 - val_mae: 142.8298 - 98ms/epoch - 20ms/step\n",
      "Epoch 180/300\n",
      "5/5 - 0s - loss: 71.1578 - mae: 84.8178 - val_loss: 89.1059 - val_mae: 142.8073 - 102ms/epoch - 20ms/step\n",
      "Epoch 181/300\n",
      "5/5 - 0s - loss: 69.5040 - mae: 84.7068 - val_loss: 88.5736 - val_mae: 142.6757 - 102ms/epoch - 20ms/step\n",
      "Epoch 182/300\n",
      "5/5 - 0s - loss: 69.3599 - mae: 84.7645 - val_loss: 87.9915 - val_mae: 142.9651 - 95ms/epoch - 19ms/step\n",
      "Epoch 183/300\n",
      "5/5 - 0s - loss: 69.4497 - mae: 84.6536 - val_loss: 87.3304 - val_mae: 142.6211 - 99ms/epoch - 20ms/step\n",
      "Epoch 184/300\n",
      "5/5 - 0s - loss: 67.6557 - mae: 84.8053 - val_loss: 86.8458 - val_mae: 142.6612 - 91ms/epoch - 18ms/step\n",
      "Epoch 185/300\n",
      "5/5 - 0s - loss: 67.1644 - mae: 84.6202 - val_loss: 86.2294 - val_mae: 142.5022 - 94ms/epoch - 19ms/step\n",
      "Epoch 186/300\n",
      "5/5 - 0s - loss: 67.8220 - mae: 84.6865 - val_loss: 85.7095 - val_mae: 142.1612 - 91ms/epoch - 18ms/step\n",
      "Epoch 187/300\n",
      "5/5 - 0s - loss: 68.3656 - mae: 84.7468 - val_loss: 85.0796 - val_mae: 142.7457 - 93ms/epoch - 19ms/step\n",
      "Epoch 188/300\n",
      "5/5 - 0s - loss: 66.7182 - mae: 84.6287 - val_loss: 84.5958 - val_mae: 142.2234 - 114ms/epoch - 23ms/step\n",
      "Epoch 189/300\n",
      "5/5 - 0s - loss: 66.5135 - mae: 84.6037 - val_loss: 84.1133 - val_mae: 142.4754 - 101ms/epoch - 20ms/step\n",
      "Epoch 190/300\n",
      "5/5 - 0s - loss: 67.1622 - mae: 84.6524 - val_loss: 83.5589 - val_mae: 142.5935 - 98ms/epoch - 20ms/step\n",
      "Epoch 191/300\n",
      "5/5 - 0s - loss: 65.9454 - mae: 84.6447 - val_loss: 83.0311 - val_mae: 142.6189 - 93ms/epoch - 19ms/step\n",
      "Epoch 192/300\n",
      "5/5 - 0s - loss: 65.3268 - mae: 84.5890 - val_loss: 82.3399 - val_mae: 142.4098 - 101ms/epoch - 20ms/step\n",
      "Epoch 193/300\n",
      "5/5 - 0s - loss: 64.0958 - mae: 84.5775 - val_loss: 81.8700 - val_mae: 142.1806 - 95ms/epoch - 19ms/step\n",
      "Epoch 194/300\n",
      "5/5 - 0s - loss: 64.7803 - mae: 84.6780 - val_loss: 81.3292 - val_mae: 142.1030 - 93ms/epoch - 19ms/step\n",
      "Epoch 195/300\n",
      "5/5 - 0s - loss: 64.0407 - mae: 84.5475 - val_loss: 80.6172 - val_mae: 141.8963 - 99ms/epoch - 20ms/step\n",
      "Epoch 196/300\n",
      "5/5 - 0s - loss: 64.0006 - mae: 84.5149 - val_loss: 80.0431 - val_mae: 142.6354 - 89ms/epoch - 18ms/step\n",
      "Epoch 197/300\n",
      "5/5 - 0s - loss: 62.9754 - mae: 84.5963 - val_loss: 79.5443 - val_mae: 142.4004 - 140ms/epoch - 28ms/step\n",
      "Epoch 198/300\n",
      "5/5 - 0s - loss: 62.4614 - mae: 84.5022 - val_loss: 79.0270 - val_mae: 142.5946 - 173ms/epoch - 35ms/step\n",
      "Epoch 199/300\n",
      "5/5 - 0s - loss: 60.6822 - mae: 84.5341 - val_loss: 78.6916 - val_mae: 142.5977 - 163ms/epoch - 33ms/step\n",
      "Epoch 200/300\n",
      "5/5 - 0s - loss: 61.9182 - mae: 84.5262 - val_loss: 78.2658 - val_mae: 142.5154 - 164ms/epoch - 33ms/step\n",
      "Epoch 201/300\n",
      "5/5 - 0s - loss: 61.0757 - mae: 84.5100 - val_loss: 77.8161 - val_mae: 142.1124 - 168ms/epoch - 34ms/step\n",
      "Epoch 202/300\n",
      "5/5 - 0s - loss: 61.3298 - mae: 84.2785 - val_loss: 77.2290 - val_mae: 142.1665 - 155ms/epoch - 31ms/step\n",
      "Epoch 203/300\n",
      "5/5 - 0s - loss: 60.1842 - mae: 84.3861 - val_loss: 76.5885 - val_mae: 142.2902 - 166ms/epoch - 33ms/step\n",
      "Epoch 204/300\n",
      "5/5 - 0s - loss: 62.5143 - mae: 84.2547 - val_loss: 76.2043 - val_mae: 142.3759 - 178ms/epoch - 36ms/step\n",
      "Epoch 205/300\n",
      "5/5 - 0s - loss: 59.5210 - mae: 84.3005 - val_loss: 75.5997 - val_mae: 142.2925 - 155ms/epoch - 31ms/step\n",
      "Epoch 206/300\n",
      "5/5 - 0s - loss: 59.3877 - mae: 84.4770 - val_loss: 75.0446 - val_mae: 142.2436 - 166ms/epoch - 33ms/step\n",
      "Epoch 207/300\n",
      "5/5 - 0s - loss: 58.2015 - mae: 84.3742 - val_loss: 74.5553 - val_mae: 142.4431 - 169ms/epoch - 34ms/step\n",
      "Epoch 208/300\n",
      "5/5 - 0s - loss: 59.9609 - mae: 84.1216 - val_loss: 74.0538 - val_mae: 142.1142 - 153ms/epoch - 31ms/step\n",
      "Epoch 209/300\n",
      "5/5 - 0s - loss: 59.4961 - mae: 84.3723 - val_loss: 73.6338 - val_mae: 142.2455 - 157ms/epoch - 31ms/step\n",
      "Epoch 210/300\n",
      "5/5 - 0s - loss: 59.2490 - mae: 84.1356 - val_loss: 73.2613 - val_mae: 142.4652 - 170ms/epoch - 34ms/step\n",
      "Epoch 211/300\n",
      "5/5 - 0s - loss: 57.4427 - mae: 84.2467 - val_loss: 72.6976 - val_mae: 142.3094 - 140ms/epoch - 28ms/step\n",
      "Epoch 212/300\n",
      "5/5 - 0s - loss: 58.4214 - mae: 84.2997 - val_loss: 72.3942 - val_mae: 142.0401 - 93ms/epoch - 19ms/step\n",
      "Epoch 213/300\n",
      "5/5 - 0s - loss: 58.2667 - mae: 84.1795 - val_loss: 72.0184 - val_mae: 142.5771 - 90ms/epoch - 18ms/step\n",
      "Epoch 214/300\n",
      "5/5 - 0s - loss: 57.4831 - mae: 84.2634 - val_loss: 71.5510 - val_mae: 141.8431 - 91ms/epoch - 18ms/step\n",
      "Epoch 215/300\n",
      "5/5 - 0s - loss: 56.8973 - mae: 84.2386 - val_loss: 71.2625 - val_mae: 141.7049 - 91ms/epoch - 18ms/step\n",
      "Epoch 216/300\n",
      "5/5 - 0s - loss: 57.1430 - mae: 84.1063 - val_loss: 70.8251 - val_mae: 142.0507 - 90ms/epoch - 18ms/step\n",
      "Epoch 217/300\n",
      "5/5 - 0s - loss: 55.8358 - mae: 84.3435 - val_loss: 70.4151 - val_mae: 142.1152 - 90ms/epoch - 18ms/step\n",
      "Epoch 218/300\n",
      "5/5 - 0s - loss: 56.0361 - mae: 84.1119 - val_loss: 70.0763 - val_mae: 142.3677 - 90ms/epoch - 18ms/step\n",
      "Epoch 219/300\n",
      "5/5 - 0s - loss: 55.6564 - mae: 84.0465 - val_loss: 69.6711 - val_mae: 141.9958 - 90ms/epoch - 18ms/step\n",
      "Epoch 220/300\n",
      "5/5 - 0s - loss: 55.4308 - mae: 84.0201 - val_loss: 69.1500 - val_mae: 142.1570 - 92ms/epoch - 18ms/step\n",
      "Epoch 221/300\n",
      "5/5 - 0s - loss: 55.3918 - mae: 83.9557 - val_loss: 68.8219 - val_mae: 142.5149 - 113ms/epoch - 23ms/step\n",
      "Epoch 222/300\n",
      "5/5 - 0s - loss: 55.9561 - mae: 84.0259 - val_loss: 68.3637 - val_mae: 141.9892 - 95ms/epoch - 19ms/step\n",
      "Epoch 223/300\n",
      "5/5 - 0s - loss: 54.4592 - mae: 84.0532 - val_loss: 68.0992 - val_mae: 142.1337 - 92ms/epoch - 18ms/step\n",
      "Epoch 224/300\n",
      "5/5 - 0s - loss: 53.6592 - mae: 84.1355 - val_loss: 67.8054 - val_mae: 141.6602 - 93ms/epoch - 19ms/step\n",
      "Epoch 225/300\n",
      "5/5 - 0s - loss: 53.8143 - mae: 83.9437 - val_loss: 67.5030 - val_mae: 141.1171 - 89ms/epoch - 18ms/step\n",
      "Epoch 226/300\n",
      "5/5 - 0s - loss: 54.1327 - mae: 83.8341 - val_loss: 67.1238 - val_mae: 141.7437 - 92ms/epoch - 18ms/step\n",
      "Epoch 227/300\n",
      "5/5 - 0s - loss: 55.4111 - mae: 83.9549 - val_loss: 66.7393 - val_mae: 142.0500 - 91ms/epoch - 18ms/step\n",
      "Epoch 228/300\n",
      "5/5 - 0s - loss: 52.8237 - mae: 84.0166 - val_loss: 66.2932 - val_mae: 141.6206 - 95ms/epoch - 19ms/step\n",
      "Epoch 229/300\n",
      "5/5 - 0s - loss: 53.8295 - mae: 83.9552 - val_loss: 65.9161 - val_mae: 141.7790 - 97ms/epoch - 19ms/step\n",
      "Epoch 230/300\n",
      "5/5 - 0s - loss: 52.3399 - mae: 83.9273 - val_loss: 65.4664 - val_mae: 141.8338 - 93ms/epoch - 19ms/step\n",
      "Epoch 231/300\n",
      "5/5 - 0s - loss: 53.0384 - mae: 84.0709 - val_loss: 65.1202 - val_mae: 141.1739 - 100ms/epoch - 20ms/step\n",
      "Epoch 232/300\n",
      "5/5 - 0s - loss: 52.4426 - mae: 83.7840 - val_loss: 64.7484 - val_mae: 142.0904 - 114ms/epoch - 23ms/step\n",
      "Epoch 233/300\n",
      "5/5 - 0s - loss: 52.9787 - mae: 83.8162 - val_loss: 64.4134 - val_mae: 141.2219 - 95ms/epoch - 19ms/step\n",
      "Epoch 234/300\n",
      "5/5 - 0s - loss: 52.6324 - mae: 83.8095 - val_loss: 63.9131 - val_mae: 142.2969 - 92ms/epoch - 18ms/step\n",
      "Epoch 235/300\n",
      "5/5 - 0s - loss: 51.7620 - mae: 83.8196 - val_loss: 63.5097 - val_mae: 141.6145 - 90ms/epoch - 18ms/step\n",
      "Epoch 236/300\n",
      "5/5 - 0s - loss: 52.1756 - mae: 83.7990 - val_loss: 63.1109 - val_mae: 141.9632 - 98ms/epoch - 20ms/step\n",
      "Epoch 237/300\n",
      "5/5 - 0s - loss: 51.5866 - mae: 83.8197 - val_loss: 62.8322 - val_mae: 141.7989 - 88ms/epoch - 18ms/step\n",
      "Epoch 238/300\n",
      "5/5 - 0s - loss: 51.8455 - mae: 83.7940 - val_loss: 62.4564 - val_mae: 141.6472 - 89ms/epoch - 18ms/step\n",
      "Epoch 239/300\n",
      "5/5 - 0s - loss: 49.8501 - mae: 83.7234 - val_loss: 62.2319 - val_mae: 141.7869 - 95ms/epoch - 19ms/step\n",
      "Epoch 240/300\n",
      "5/5 - 0s - loss: 50.5601 - mae: 83.7533 - val_loss: 61.7739 - val_mae: 141.8690 - 94ms/epoch - 19ms/step\n",
      "Epoch 241/300\n",
      "5/5 - 0s - loss: 50.6552 - mae: 83.6085 - val_loss: 61.4555 - val_mae: 141.3273 - 103ms/epoch - 21ms/step\n",
      "Epoch 242/300\n",
      "5/5 - 0s - loss: 49.6351 - mae: 83.6159 - val_loss: 61.2139 - val_mae: 141.6036 - 110ms/epoch - 22ms/step\n",
      "Epoch 243/300\n",
      "5/5 - 0s - loss: 50.3714 - mae: 83.8117 - val_loss: 60.6862 - val_mae: 141.2233 - 91ms/epoch - 18ms/step\n",
      "Epoch 244/300\n",
      "5/5 - 0s - loss: 49.2606 - mae: 83.7451 - val_loss: 60.3406 - val_mae: 141.8795 - 94ms/epoch - 19ms/step\n",
      "Epoch 245/300\n",
      "5/5 - 0s - loss: 49.4572 - mae: 83.8058 - val_loss: 60.0274 - val_mae: 141.0938 - 88ms/epoch - 18ms/step\n",
      "Epoch 246/300\n",
      "5/5 - 0s - loss: 48.6838 - mae: 83.4997 - val_loss: 59.7456 - val_mae: 141.5096 - 105ms/epoch - 21ms/step\n",
      "Epoch 247/300\n",
      "5/5 - 0s - loss: 48.6130 - mae: 83.5323 - val_loss: 59.4204 - val_mae: 141.8233 - 88ms/epoch - 18ms/step\n",
      "Epoch 248/300\n",
      "5/5 - 0s - loss: 50.4434 - mae: 83.6538 - val_loss: 59.1798 - val_mae: 141.6185 - 92ms/epoch - 18ms/step\n",
      "Epoch 249/300\n",
      "5/5 - 0s - loss: 49.3997 - mae: 83.4857 - val_loss: 58.8454 - val_mae: 141.3982 - 92ms/epoch - 18ms/step\n",
      "Epoch 250/300\n",
      "5/5 - 0s - loss: 48.7347 - mae: 83.5432 - val_loss: 58.5383 - val_mae: 141.3426 - 90ms/epoch - 18ms/step\n",
      "Epoch 251/300\n",
      "5/5 - 0s - loss: 47.4602 - mae: 83.4811 - val_loss: 58.2201 - val_mae: 141.3485 - 101ms/epoch - 20ms/step\n",
      "Epoch 252/300\n",
      "5/5 - 0s - loss: 48.2723 - mae: 83.5479 - val_loss: 58.0614 - val_mae: 141.0291 - 95ms/epoch - 19ms/step\n",
      "Epoch 253/300\n",
      "5/5 - 0s - loss: 47.7753 - mae: 83.5816 - val_loss: 57.7712 - val_mae: 141.0619 - 112ms/epoch - 22ms/step\n",
      "Epoch 254/300\n",
      "5/5 - 0s - loss: 47.0204 - mae: 83.4356 - val_loss: 57.5676 - val_mae: 141.2821 - 95ms/epoch - 19ms/step\n",
      "Epoch 255/300\n",
      "5/5 - 0s - loss: 47.7472 - mae: 83.3006 - val_loss: 57.3945 - val_mae: 141.0006 - 92ms/epoch - 18ms/step\n",
      "Epoch 256/300\n",
      "5/5 - 0s - loss: 47.6125 - mae: 83.5247 - val_loss: 57.1359 - val_mae: 141.3087 - 96ms/epoch - 19ms/step\n",
      "Epoch 257/300\n",
      "5/5 - 0s - loss: 47.5730 - mae: 83.4381 - val_loss: 56.8548 - val_mae: 141.0719 - 92ms/epoch - 18ms/step\n",
      "Epoch 258/300\n",
      "5/5 - 0s - loss: 46.6402 - mae: 83.4046 - val_loss: 56.6495 - val_mae: 141.7740 - 89ms/epoch - 18ms/step\n",
      "Epoch 259/300\n",
      "5/5 - 0s - loss: 46.2345 - mae: 83.4334 - val_loss: 56.4542 - val_mae: 141.3597 - 90ms/epoch - 18ms/step\n",
      "Epoch 260/300\n",
      "5/5 - 0s - loss: 45.5882 - mae: 83.1626 - val_loss: 56.1903 - val_mae: 141.2384 - 95ms/epoch - 19ms/step\n",
      "Epoch 261/300\n",
      "5/5 - 0s - loss: 46.3579 - mae: 83.3759 - val_loss: 55.7878 - val_mae: 140.9401 - 99ms/epoch - 20ms/step\n",
      "Epoch 262/300\n",
      "5/5 - 0s - loss: 45.5163 - mae: 83.3905 - val_loss: 55.5873 - val_mae: 140.8894 - 97ms/epoch - 19ms/step\n",
      "Epoch 263/300\n",
      "5/5 - 0s - loss: 46.0644 - mae: 83.1895 - val_loss: 55.3203 - val_mae: 141.7010 - 91ms/epoch - 18ms/step\n",
      "Epoch 264/300\n",
      "5/5 - 0s - loss: 46.4270 - mae: 83.2411 - val_loss: 55.0440 - val_mae: 141.4374 - 107ms/epoch - 21ms/step\n",
      "Epoch 265/300\n",
      "5/5 - 0s - loss: 45.0347 - mae: 83.2341 - val_loss: 54.7333 - val_mae: 140.5217 - 90ms/epoch - 18ms/step\n",
      "Epoch 266/300\n",
      "5/5 - 0s - loss: 45.2868 - mae: 83.3364 - val_loss: 54.4098 - val_mae: 141.0206 - 100ms/epoch - 20ms/step\n",
      "Epoch 267/300\n",
      "5/5 - 0s - loss: 45.2053 - mae: 83.3422 - val_loss: 54.1301 - val_mae: 140.9687 - 92ms/epoch - 18ms/step\n",
      "Epoch 268/300\n",
      "5/5 - 0s - loss: 44.2442 - mae: 83.2679 - val_loss: 53.9181 - val_mae: 141.5363 - 90ms/epoch - 18ms/step\n",
      "Epoch 269/300\n",
      "5/5 - 0s - loss: 44.5601 - mae: 83.2331 - val_loss: 53.7707 - val_mae: 141.1891 - 93ms/epoch - 19ms/step\n",
      "Epoch 270/300\n",
      "5/5 - 0s - loss: 44.9230 - mae: 83.0043 - val_loss: 53.4447 - val_mae: 140.8648 - 92ms/epoch - 18ms/step\n",
      "Epoch 271/300\n",
      "5/5 - 0s - loss: 44.6898 - mae: 83.0753 - val_loss: 53.1387 - val_mae: 140.8548 - 97ms/epoch - 19ms/step\n",
      "Epoch 272/300\n",
      "5/5 - 0s - loss: 44.5660 - mae: 83.0322 - val_loss: 52.9268 - val_mae: 140.6759 - 97ms/epoch - 19ms/step\n",
      "Epoch 273/300\n",
      "5/5 - 0s - loss: 44.2828 - mae: 83.1007 - val_loss: 52.7402 - val_mae: 140.8456 - 93ms/epoch - 19ms/step\n",
      "Epoch 274/300\n",
      "5/5 - 0s - loss: 43.7449 - mae: 83.1447 - val_loss: 52.4794 - val_mae: 140.6813 - 106ms/epoch - 21ms/step\n",
      "Epoch 275/300\n",
      "5/5 - 0s - loss: 43.4344 - mae: 82.9690 - val_loss: 52.1906 - val_mae: 141.0703 - 92ms/epoch - 18ms/step\n",
      "Epoch 276/300\n",
      "5/5 - 0s - loss: 43.2391 - mae: 83.2136 - val_loss: 51.9659 - val_mae: 140.7328 - 92ms/epoch - 18ms/step\n",
      "Epoch 277/300\n",
      "5/5 - 0s - loss: 43.4042 - mae: 83.1151 - val_loss: 51.6613 - val_mae: 140.8795 - 92ms/epoch - 18ms/step\n",
      "Epoch 278/300\n",
      "5/5 - 0s - loss: 42.3082 - mae: 83.1700 - val_loss: 51.4180 - val_mae: 140.7670 - 94ms/epoch - 19ms/step\n",
      "Epoch 279/300\n",
      "5/5 - 0s - loss: 42.5917 - mae: 82.9218 - val_loss: 51.1106 - val_mae: 140.6496 - 91ms/epoch - 18ms/step\n",
      "Epoch 280/300\n",
      "5/5 - 0s - loss: 42.0589 - mae: 83.0023 - val_loss: 50.9179 - val_mae: 141.1404 - 96ms/epoch - 19ms/step\n",
      "Epoch 281/300\n",
      "5/5 - 0s - loss: 43.1578 - mae: 83.0261 - val_loss: 50.7345 - val_mae: 140.4339 - 96ms/epoch - 19ms/step\n",
      "Epoch 282/300\n",
      "5/5 - 0s - loss: 41.2466 - mae: 83.1083 - val_loss: 50.5847 - val_mae: 140.9324 - 96ms/epoch - 19ms/step\n",
      "Epoch 283/300\n",
      "5/5 - 0s - loss: 41.8860 - mae: 83.1005 - val_loss: 50.4483 - val_mae: 140.9334 - 93ms/epoch - 19ms/step\n",
      "Epoch 284/300\n",
      "5/5 - 0s - loss: 41.6921 - mae: 83.0904 - val_loss: 50.2779 - val_mae: 140.5625 - 97ms/epoch - 19ms/step\n",
      "Epoch 285/300\n",
      "5/5 - 0s - loss: 41.9709 - mae: 82.9497 - val_loss: 50.0556 - val_mae: 140.4586 - 109ms/epoch - 22ms/step\n",
      "Epoch 286/300\n",
      "5/5 - 0s - loss: 42.1934 - mae: 82.8191 - val_loss: 49.7635 - val_mae: 141.0567 - 95ms/epoch - 19ms/step\n",
      "Epoch 287/300\n",
      "5/5 - 0s - loss: 42.3584 - mae: 82.8234 - val_loss: 49.5002 - val_mae: 140.6749 - 97ms/epoch - 19ms/step\n",
      "Epoch 288/300\n",
      "5/5 - 0s - loss: 41.5962 - mae: 82.8350 - val_loss: 49.3400 - val_mae: 140.9326 - 91ms/epoch - 18ms/step\n",
      "Epoch 289/300\n",
      "5/5 - 0s - loss: 41.7113 - mae: 82.7821 - val_loss: 49.0798 - val_mae: 140.4366 - 92ms/epoch - 18ms/step\n",
      "Epoch 290/300\n",
      "5/5 - 0s - loss: 41.3460 - mae: 82.8995 - val_loss: 48.7631 - val_mae: 140.5184 - 96ms/epoch - 19ms/step\n",
      "Epoch 291/300\n",
      "5/5 - 0s - loss: 40.3845 - mae: 82.9194 - val_loss: 48.6114 - val_mae: 140.2477 - 111ms/epoch - 22ms/step\n",
      "Epoch 292/300\n",
      "5/5 - 0s - loss: 40.6578 - mae: 82.7527 - val_loss: 48.5088 - val_mae: 140.1587 - 97ms/epoch - 19ms/step\n",
      "Epoch 293/300\n",
      "5/5 - 0s - loss: 41.0198 - mae: 82.7765 - val_loss: 48.3017 - val_mae: 140.7069 - 99ms/epoch - 20ms/step\n",
      "Epoch 294/300\n",
      "5/5 - 0s - loss: 40.7527 - mae: 82.4796 - val_loss: 48.0832 - val_mae: 140.2575 - 126ms/epoch - 25ms/step\n",
      "Epoch 295/300\n",
      "5/5 - 0s - loss: 40.8782 - mae: 82.6276 - val_loss: 47.8474 - val_mae: 139.9703 - 108ms/epoch - 22ms/step\n",
      "Epoch 296/300\n",
      "5/5 - 0s - loss: 40.0477 - mae: 82.6569 - val_loss: 47.6580 - val_mae: 139.7171 - 101ms/epoch - 20ms/step\n",
      "Epoch 297/300\n",
      "5/5 - 0s - loss: 40.5724 - mae: 82.6777 - val_loss: 47.4933 - val_mae: 140.1436 - 89ms/epoch - 18ms/step\n",
      "Epoch 298/300\n",
      "5/5 - 0s - loss: 39.2338 - mae: 82.5770 - val_loss: 47.3425 - val_mae: 140.0427 - 101ms/epoch - 20ms/step\n",
      "Epoch 299/300\n",
      "5/5 - 0s - loss: 40.2587 - mae: 82.7839 - val_loss: 47.1938 - val_mae: 140.3326 - 98ms/epoch - 20ms/step\n",
      "Epoch 300/300\n",
      "5/5 - 0s - loss: 39.5714 - mae: 82.7420 - val_loss: 47.0665 - val_mae: 140.2885 - 91ms/epoch - 18ms/step\n",
      "Epoch 1/300\n",
      "5/5 - 1s - loss: 3645.0759 - mae: 98.9892 - val_loss: 2645.4092 - val_mae: 105.7037 - 1s/epoch - 299ms/step\n",
      "Epoch 2/300\n",
      "5/5 - 0s - loss: 2911.2759 - mae: 98.9678 - val_loss: 2049.9497 - val_mae: 105.5883 - 156ms/epoch - 31ms/step\n",
      "Epoch 3/300\n",
      "5/5 - 0s - loss: 2527.1782 - mae: 98.9502 - val_loss: 1659.1410 - val_mae: 105.6765 - 163ms/epoch - 33ms/step\n",
      "Epoch 4/300\n",
      "5/5 - 0s - loss: 2275.2024 - mae: 98.9472 - val_loss: 1391.9991 - val_mae: 105.5575 - 169ms/epoch - 34ms/step\n",
      "Epoch 5/300\n",
      "5/5 - 0s - loss: 2046.0804 - mae: 98.9131 - val_loss: 1198.5046 - val_mae: 105.5584 - 155ms/epoch - 31ms/step\n",
      "Epoch 6/300\n",
      "5/5 - 0s - loss: 1884.9094 - mae: 98.9056 - val_loss: 1057.9840 - val_mae: 105.4456 - 174ms/epoch - 35ms/step\n",
      "Epoch 7/300\n",
      "5/5 - 0s - loss: 1749.1918 - mae: 98.8970 - val_loss: 945.1964 - val_mae: 105.4432 - 160ms/epoch - 32ms/step\n",
      "Epoch 8/300\n",
      "5/5 - 0s - loss: 1641.1306 - mae: 98.8671 - val_loss: 859.4547 - val_mae: 105.6252 - 156ms/epoch - 31ms/step\n",
      "Epoch 9/300\n",
      "5/5 - 0s - loss: 1510.9806 - mae: 98.8336 - val_loss: 791.5735 - val_mae: 105.4982 - 176ms/epoch - 35ms/step\n",
      "Epoch 10/300\n",
      "5/5 - 0s - loss: 1423.2166 - mae: 98.8231 - val_loss: 735.1003 - val_mae: 105.5149 - 162ms/epoch - 32ms/step\n",
      "Epoch 11/300\n",
      "5/5 - 0s - loss: 1338.9092 - mae: 98.8165 - val_loss: 688.7401 - val_mae: 105.4340 - 162ms/epoch - 32ms/step\n",
      "Epoch 12/300\n",
      "5/5 - 0s - loss: 1281.0444 - mae: 98.7899 - val_loss: 650.0713 - val_mae: 105.5135 - 97ms/epoch - 19ms/step\n",
      "Epoch 13/300\n",
      "5/5 - 0s - loss: 1216.9323 - mae: 98.8054 - val_loss: 616.7808 - val_mae: 105.4130 - 106ms/epoch - 21ms/step\n",
      "Epoch 14/300\n",
      "5/5 - 0s - loss: 1153.9912 - mae: 98.7707 - val_loss: 586.7899 - val_mae: 105.4412 - 91ms/epoch - 18ms/step\n",
      "Epoch 15/300\n",
      "5/5 - 0s - loss: 1123.2047 - mae: 98.7582 - val_loss: 561.3322 - val_mae: 105.4513 - 95ms/epoch - 19ms/step\n",
      "Epoch 16/300\n",
      "5/5 - 0s - loss: 1062.3185 - mae: 98.7621 - val_loss: 540.1505 - val_mae: 105.4348 - 98ms/epoch - 20ms/step\n",
      "Epoch 17/300\n",
      "5/5 - 0s - loss: 1006.8253 - mae: 98.7679 - val_loss: 521.9675 - val_mae: 105.4462 - 97ms/epoch - 19ms/step\n",
      "Epoch 18/300\n",
      "5/5 - 0s - loss: 966.3376 - mae: 98.7376 - val_loss: 506.0126 - val_mae: 105.3358 - 97ms/epoch - 19ms/step\n",
      "Epoch 19/300\n",
      "5/5 - 0s - loss: 938.7570 - mae: 98.6813 - val_loss: 491.4751 - val_mae: 105.3782 - 95ms/epoch - 19ms/step\n",
      "Epoch 20/300\n",
      "5/5 - 0s - loss: 906.6998 - mae: 98.6840 - val_loss: 478.2111 - val_mae: 105.4808 - 97ms/epoch - 19ms/step\n",
      "Epoch 21/300\n",
      "5/5 - 0s - loss: 877.0874 - mae: 98.6804 - val_loss: 466.4549 - val_mae: 105.2857 - 94ms/epoch - 19ms/step\n",
      "Epoch 22/300\n",
      "5/5 - 0s - loss: 837.3209 - mae: 98.6880 - val_loss: 454.5832 - val_mae: 105.3733 - 89ms/epoch - 18ms/step\n",
      "Epoch 23/300\n",
      "5/5 - 0s - loss: 813.8480 - mae: 98.6954 - val_loss: 443.9068 - val_mae: 105.2903 - 106ms/epoch - 21ms/step\n",
      "Epoch 24/300\n",
      "5/5 - 0s - loss: 792.2875 - mae: 98.6409 - val_loss: 434.1208 - val_mae: 105.3535 - 91ms/epoch - 18ms/step\n",
      "Epoch 25/300\n",
      "5/5 - 0s - loss: 753.9846 - mae: 98.6300 - val_loss: 425.6759 - val_mae: 105.2223 - 88ms/epoch - 18ms/step\n",
      "Epoch 26/300\n",
      "5/5 - 0s - loss: 735.1070 - mae: 98.6230 - val_loss: 417.4407 - val_mae: 105.2245 - 93ms/epoch - 19ms/step\n",
      "Epoch 27/300\n",
      "5/5 - 0s - loss: 714.6745 - mae: 98.5833 - val_loss: 410.0336 - val_mae: 105.2843 - 99ms/epoch - 20ms/step\n",
      "Epoch 28/300\n",
      "5/5 - 0s - loss: 696.7424 - mae: 98.6119 - val_loss: 403.3286 - val_mae: 105.2422 - 94ms/epoch - 19ms/step\n",
      "Epoch 29/300\n",
      "5/5 - 0s - loss: 672.0630 - mae: 98.5568 - val_loss: 396.0046 - val_mae: 105.2345 - 95ms/epoch - 19ms/step\n",
      "Epoch 30/300\n",
      "5/5 - 0s - loss: 653.1794 - mae: 98.5760 - val_loss: 390.3793 - val_mae: 105.1115 - 93ms/epoch - 19ms/step\n",
      "Epoch 31/300\n",
      "5/5 - 0s - loss: 639.7925 - mae: 98.5087 - val_loss: 385.0145 - val_mae: 105.1759 - 89ms/epoch - 18ms/step\n",
      "Epoch 32/300\n",
      "5/5 - 0s - loss: 618.9111 - mae: 98.5436 - val_loss: 379.0219 - val_mae: 105.0892 - 89ms/epoch - 18ms/step\n",
      "Epoch 33/300\n",
      "5/5 - 0s - loss: 598.6904 - mae: 98.5115 - val_loss: 372.5094 - val_mae: 105.0226 - 94ms/epoch - 19ms/step\n",
      "Epoch 34/300\n",
      "5/5 - 0s - loss: 580.5300 - mae: 98.5080 - val_loss: 366.4817 - val_mae: 105.2128 - 114ms/epoch - 23ms/step\n",
      "Epoch 35/300\n",
      "5/5 - 0s - loss: 565.9355 - mae: 98.4779 - val_loss: 361.8593 - val_mae: 105.1843 - 93ms/epoch - 19ms/step\n",
      "Epoch 36/300\n",
      "5/5 - 0s - loss: 550.3016 - mae: 98.4608 - val_loss: 356.3566 - val_mae: 105.2049 - 91ms/epoch - 18ms/step\n",
      "Epoch 37/300\n",
      "5/5 - 0s - loss: 533.5139 - mae: 98.4401 - val_loss: 351.2924 - val_mae: 105.1310 - 93ms/epoch - 19ms/step\n",
      "Epoch 38/300\n",
      "5/5 - 0s - loss: 520.2228 - mae: 98.4338 - val_loss: 347.1319 - val_mae: 105.0380 - 94ms/epoch - 19ms/step\n",
      "Epoch 39/300\n",
      "5/5 - 0s - loss: 512.1248 - mae: 98.4229 - val_loss: 341.4122 - val_mae: 104.9870 - 111ms/epoch - 22ms/step\n",
      "Epoch 40/300\n",
      "5/5 - 0s - loss: 496.8615 - mae: 98.3941 - val_loss: 337.1128 - val_mae: 105.0495 - 91ms/epoch - 18ms/step\n",
      "Epoch 41/300\n",
      "5/5 - 0s - loss: 484.3440 - mae: 98.4163 - val_loss: 333.8195 - val_mae: 104.8480 - 93ms/epoch - 19ms/step\n",
      "Epoch 42/300\n",
      "5/5 - 0s - loss: 474.7906 - mae: 98.4018 - val_loss: 329.1161 - val_mae: 105.0046 - 91ms/epoch - 18ms/step\n",
      "Epoch 43/300\n",
      "5/5 - 0s - loss: 464.0572 - mae: 98.3658 - val_loss: 324.4677 - val_mae: 104.9586 - 94ms/epoch - 19ms/step\n",
      "Epoch 44/300\n",
      "5/5 - 0s - loss: 454.8243 - mae: 98.3467 - val_loss: 320.1376 - val_mae: 104.9996 - 105ms/epoch - 21ms/step\n",
      "Epoch 45/300\n",
      "5/5 - 0s - loss: 442.7945 - mae: 98.3115 - val_loss: 315.9877 - val_mae: 104.9283 - 101ms/epoch - 20ms/step\n",
      "Epoch 46/300\n",
      "5/5 - 0s - loss: 434.9871 - mae: 98.3392 - val_loss: 312.1839 - val_mae: 104.9944 - 94ms/epoch - 19ms/step\n",
      "Epoch 47/300\n",
      "5/5 - 0s - loss: 425.1178 - mae: 98.2871 - val_loss: 308.2367 - val_mae: 104.9491 - 99ms/epoch - 20ms/step\n",
      "Epoch 48/300\n",
      "5/5 - 0s - loss: 416.3584 - mae: 98.2775 - val_loss: 304.1105 - val_mae: 104.9004 - 100ms/epoch - 20ms/step\n",
      "Epoch 49/300\n",
      "5/5 - 0s - loss: 410.1621 - mae: 98.2907 - val_loss: 300.6513 - val_mae: 104.8933 - 95ms/epoch - 19ms/step\n",
      "Epoch 50/300\n",
      "5/5 - 0s - loss: 398.1059 - mae: 98.2801 - val_loss: 296.6720 - val_mae: 104.8785 - 93ms/epoch - 19ms/step\n",
      "Epoch 51/300\n",
      "5/5 - 0s - loss: 392.0050 - mae: 98.2814 - val_loss: 293.8175 - val_mae: 104.7873 - 95ms/epoch - 19ms/step\n",
      "Epoch 52/300\n",
      "5/5 - 0s - loss: 389.5489 - mae: 98.2477 - val_loss: 290.8477 - val_mae: 104.9504 - 89ms/epoch - 18ms/step\n",
      "Epoch 53/300\n",
      "5/5 - 0s - loss: 378.6599 - mae: 98.2203 - val_loss: 286.9820 - val_mae: 104.9438 - 92ms/epoch - 18ms/step\n",
      "Epoch 54/300\n",
      "5/5 - 0s - loss: 366.7530 - mae: 98.2064 - val_loss: 283.1478 - val_mae: 104.7484 - 96ms/epoch - 19ms/step\n",
      "Epoch 55/300\n",
      "5/5 - 0s - loss: 355.8454 - mae: 98.1975 - val_loss: 279.5821 - val_mae: 104.9215 - 111ms/epoch - 22ms/step\n",
      "Epoch 56/300\n",
      "5/5 - 0s - loss: 351.9218 - mae: 98.1623 - val_loss: 275.9847 - val_mae: 104.5567 - 101ms/epoch - 20ms/step\n",
      "Epoch 57/300\n",
      "5/5 - 0s - loss: 344.6028 - mae: 98.1316 - val_loss: 271.8252 - val_mae: 104.8460 - 100ms/epoch - 20ms/step\n",
      "Epoch 58/300\n",
      "5/5 - 0s - loss: 339.0446 - mae: 98.1955 - val_loss: 268.1628 - val_mae: 104.9384 - 97ms/epoch - 19ms/step\n",
      "Epoch 59/300\n",
      "5/5 - 0s - loss: 327.0352 - mae: 98.1502 - val_loss: 265.1234 - val_mae: 104.8537 - 94ms/epoch - 19ms/step\n",
      "Epoch 60/300\n",
      "5/5 - 0s - loss: 322.9155 - mae: 98.1607 - val_loss: 262.2340 - val_mae: 104.7696 - 94ms/epoch - 19ms/step\n",
      "Epoch 61/300\n",
      "5/5 - 0s - loss: 323.5445 - mae: 98.1315 - val_loss: 258.9250 - val_mae: 104.7696 - 90ms/epoch - 18ms/step\n",
      "Epoch 62/300\n",
      "5/5 - 0s - loss: 312.9477 - mae: 98.0808 - val_loss: 255.9532 - val_mae: 104.6590 - 93ms/epoch - 19ms/step\n",
      "Epoch 63/300\n",
      "5/5 - 0s - loss: 310.8937 - mae: 98.1011 - val_loss: 253.1403 - val_mae: 104.7099 - 92ms/epoch - 18ms/step\n",
      "Epoch 64/300\n",
      "5/5 - 0s - loss: 304.3827 - mae: 98.0470 - val_loss: 249.6266 - val_mae: 104.7414 - 91ms/epoch - 18ms/step\n",
      "Epoch 65/300\n",
      "5/5 - 0s - loss: 298.7434 - mae: 98.0533 - val_loss: 246.2076 - val_mae: 104.7892 - 113ms/epoch - 23ms/step\n",
      "Epoch 66/300\n",
      "5/5 - 0s - loss: 291.5985 - mae: 98.0523 - val_loss: 243.6395 - val_mae: 104.5040 - 96ms/epoch - 19ms/step\n",
      "Epoch 67/300\n",
      "5/5 - 0s - loss: 287.5706 - mae: 97.9840 - val_loss: 241.3729 - val_mae: 104.6622 - 95ms/epoch - 19ms/step\n",
      "Epoch 68/300\n",
      "5/5 - 0s - loss: 282.7430 - mae: 97.9676 - val_loss: 238.8820 - val_mae: 104.5452 - 100ms/epoch - 20ms/step\n",
      "Epoch 69/300\n",
      "5/5 - 0s - loss: 282.7236 - mae: 97.9307 - val_loss: 236.1107 - val_mae: 104.7140 - 97ms/epoch - 19ms/step\n",
      "Epoch 70/300\n",
      "5/5 - 0s - loss: 272.8416 - mae: 98.0037 - val_loss: 233.6631 - val_mae: 104.6133 - 93ms/epoch - 19ms/step\n",
      "Epoch 71/300\n",
      "5/5 - 0s - loss: 270.7033 - mae: 97.9554 - val_loss: 231.2135 - val_mae: 104.5964 - 98ms/epoch - 20ms/step\n",
      "Epoch 72/300\n",
      "5/5 - 0s - loss: 265.3732 - mae: 97.9521 - val_loss: 227.8967 - val_mae: 104.6271 - 102ms/epoch - 20ms/step\n",
      "Epoch 73/300\n",
      "5/5 - 0s - loss: 258.6741 - mae: 97.9035 - val_loss: 224.9304 - val_mae: 104.6033 - 98ms/epoch - 20ms/step\n",
      "Epoch 74/300\n",
      "5/5 - 0s - loss: 255.2339 - mae: 97.9162 - val_loss: 222.1020 - val_mae: 104.6324 - 96ms/epoch - 19ms/step\n",
      "Epoch 75/300\n",
      "5/5 - 0s - loss: 252.9588 - mae: 97.9220 - val_loss: 219.6365 - val_mae: 104.3616 - 110ms/epoch - 22ms/step\n",
      "Epoch 76/300\n",
      "5/5 - 0s - loss: 250.2856 - mae: 97.8016 - val_loss: 217.0609 - val_mae: 104.5716 - 97ms/epoch - 19ms/step\n",
      "Epoch 77/300\n",
      "5/5 - 0s - loss: 243.2336 - mae: 97.8644 - val_loss: 215.0547 - val_mae: 104.5604 - 102ms/epoch - 20ms/step\n",
      "Epoch 78/300\n",
      "5/5 - 0s - loss: 241.6624 - mae: 97.7781 - val_loss: 212.8361 - val_mae: 104.5670 - 95ms/epoch - 19ms/step\n",
      "Epoch 79/300\n",
      "5/5 - 0s - loss: 235.6899 - mae: 97.8913 - val_loss: 209.8206 - val_mae: 104.4804 - 112ms/epoch - 22ms/step\n",
      "Epoch 80/300\n",
      "5/5 - 0s - loss: 233.4906 - mae: 97.8514 - val_loss: 207.0145 - val_mae: 104.5387 - 95ms/epoch - 19ms/step\n",
      "Epoch 81/300\n",
      "5/5 - 0s - loss: 232.8106 - mae: 97.7871 - val_loss: 204.4086 - val_mae: 104.3947 - 95ms/epoch - 19ms/step\n",
      "Epoch 82/300\n",
      "5/5 - 0s - loss: 226.3648 - mae: 97.7677 - val_loss: 202.5493 - val_mae: 104.3433 - 92ms/epoch - 18ms/step\n",
      "Epoch 83/300\n",
      "5/5 - 0s - loss: 220.7364 - mae: 97.7379 - val_loss: 200.6576 - val_mae: 104.4763 - 94ms/epoch - 19ms/step\n",
      "Epoch 84/300\n",
      "5/5 - 0s - loss: 221.7286 - mae: 97.7357 - val_loss: 198.3953 - val_mae: 104.5667 - 89ms/epoch - 18ms/step\n",
      "Epoch 85/300\n",
      "5/5 - 0s - loss: 218.4945 - mae: 97.6856 - val_loss: 196.2336 - val_mae: 104.2561 - 109ms/epoch - 22ms/step\n",
      "Epoch 86/300\n",
      "5/5 - 0s - loss: 213.7956 - mae: 97.7417 - val_loss: 194.1634 - val_mae: 104.3084 - 93ms/epoch - 19ms/step\n",
      "Epoch 87/300\n",
      "5/5 - 0s - loss: 210.2496 - mae: 97.7266 - val_loss: 192.2546 - val_mae: 104.3915 - 104ms/epoch - 21ms/step\n",
      "Epoch 88/300\n",
      "5/5 - 0s - loss: 206.4607 - mae: 97.7752 - val_loss: 190.6962 - val_mae: 104.5522 - 96ms/epoch - 19ms/step\n",
      "Epoch 89/300\n",
      "5/5 - 0s - loss: 205.3959 - mae: 97.6457 - val_loss: 188.6600 - val_mae: 104.5840 - 98ms/epoch - 20ms/step\n",
      "Epoch 90/300\n",
      "5/5 - 0s - loss: 199.9167 - mae: 97.6794 - val_loss: 186.6187 - val_mae: 104.2402 - 91ms/epoch - 18ms/step\n",
      "Epoch 91/300\n",
      "5/5 - 0s - loss: 199.3012 - mae: 97.5434 - val_loss: 185.0610 - val_mae: 104.3554 - 88ms/epoch - 18ms/step\n",
      "Epoch 92/300\n",
      "5/5 - 0s - loss: 197.9147 - mae: 97.6138 - val_loss: 183.2388 - val_mae: 104.2347 - 91ms/epoch - 18ms/step\n",
      "Epoch 93/300\n",
      "5/5 - 0s - loss: 195.0058 - mae: 97.6354 - val_loss: 181.6628 - val_mae: 104.3707 - 92ms/epoch - 18ms/step\n",
      "Epoch 94/300\n",
      "5/5 - 0s - loss: 190.7683 - mae: 97.5108 - val_loss: 180.0444 - val_mae: 104.1962 - 89ms/epoch - 18ms/step\n",
      "Epoch 95/300\n",
      "5/5 - 0s - loss: 191.0636 - mae: 97.5664 - val_loss: 177.7646 - val_mae: 104.3597 - 92ms/epoch - 18ms/step\n",
      "Epoch 96/300\n",
      "5/5 - 0s - loss: 183.5561 - mae: 97.4797 - val_loss: 176.3375 - val_mae: 104.3766 - 113ms/epoch - 23ms/step\n",
      "Epoch 97/300\n",
      "5/5 - 0s - loss: 184.5226 - mae: 97.4999 - val_loss: 174.5913 - val_mae: 104.2502 - 98ms/epoch - 20ms/step\n",
      "Epoch 98/300\n",
      "5/5 - 0s - loss: 179.2806 - mae: 97.5191 - val_loss: 173.1566 - val_mae: 104.1408 - 93ms/epoch - 19ms/step\n",
      "Epoch 99/300\n",
      "5/5 - 0s - loss: 180.3702 - mae: 97.4536 - val_loss: 171.4778 - val_mae: 104.2561 - 97ms/epoch - 19ms/step\n",
      "Epoch 100/300\n",
      "5/5 - 0s - loss: 178.9128 - mae: 97.4459 - val_loss: 169.8662 - val_mae: 104.2875 - 92ms/epoch - 18ms/step\n",
      "Epoch 101/300\n",
      "5/5 - 0s - loss: 173.6738 - mae: 97.3805 - val_loss: 168.7473 - val_mae: 104.1553 - 93ms/epoch - 19ms/step\n",
      "Epoch 102/300\n",
      "5/5 - 0s - loss: 171.9901 - mae: 97.4844 - val_loss: 166.9033 - val_mae: 104.1572 - 92ms/epoch - 18ms/step\n",
      "Epoch 103/300\n",
      "5/5 - 0s - loss: 172.4666 - mae: 97.3306 - val_loss: 165.2217 - val_mae: 104.2266 - 90ms/epoch - 18ms/step\n",
      "Epoch 104/300\n",
      "5/5 - 0s - loss: 168.1037 - mae: 97.3446 - val_loss: 163.5709 - val_mae: 103.9349 - 92ms/epoch - 18ms/step\n",
      "Epoch 105/300\n",
      "5/5 - 0s - loss: 167.3954 - mae: 97.4144 - val_loss: 162.0029 - val_mae: 104.1736 - 97ms/epoch - 19ms/step\n",
      "Epoch 106/300\n",
      "5/5 - 0s - loss: 163.6736 - mae: 97.2970 - val_loss: 160.8731 - val_mae: 104.2693 - 100ms/epoch - 20ms/step\n",
      "Epoch 107/300\n",
      "5/5 - 0s - loss: 161.7235 - mae: 97.2568 - val_loss: 159.2610 - val_mae: 104.1506 - 104ms/epoch - 21ms/step\n",
      "Epoch 108/300\n",
      "5/5 - 0s - loss: 159.6443 - mae: 97.3105 - val_loss: 158.0889 - val_mae: 103.9688 - 101ms/epoch - 20ms/step\n",
      "Epoch 109/300\n",
      "5/5 - 0s - loss: 157.6044 - mae: 97.3192 - val_loss: 156.6868 - val_mae: 104.0234 - 102ms/epoch - 20ms/step\n",
      "Epoch 110/300\n",
      "5/5 - 0s - loss: 156.3840 - mae: 97.2726 - val_loss: 155.5319 - val_mae: 103.8727 - 96ms/epoch - 19ms/step\n",
      "Epoch 111/300\n",
      "5/5 - 0s - loss: 153.6330 - mae: 97.3404 - val_loss: 153.8584 - val_mae: 104.0503 - 94ms/epoch - 19ms/step\n",
      "Epoch 112/300\n",
      "5/5 - 0s - loss: 152.7297 - mae: 97.2221 - val_loss: 152.6557 - val_mae: 104.1240 - 136ms/epoch - 27ms/step\n",
      "Epoch 113/300\n",
      "5/5 - 0s - loss: 150.5537 - mae: 97.1258 - val_loss: 151.1563 - val_mae: 103.9528 - 165ms/epoch - 33ms/step\n",
      "Epoch 114/300\n",
      "5/5 - 0s - loss: 149.9489 - mae: 97.2380 - val_loss: 149.3999 - val_mae: 103.7476 - 155ms/epoch - 31ms/step\n",
      "Epoch 115/300\n",
      "5/5 - 0s - loss: 148.2365 - mae: 97.1221 - val_loss: 148.6055 - val_mae: 103.9685 - 162ms/epoch - 32ms/step\n",
      "Epoch 116/300\n",
      "5/5 - 0s - loss: 146.8181 - mae: 97.2413 - val_loss: 147.4023 - val_mae: 103.8883 - 161ms/epoch - 32ms/step\n",
      "Epoch 117/300\n",
      "5/5 - 0s - loss: 145.0721 - mae: 97.1916 - val_loss: 146.3403 - val_mae: 103.7430 - 152ms/epoch - 30ms/step\n",
      "Epoch 118/300\n",
      "5/5 - 0s - loss: 142.4256 - mae: 97.1239 - val_loss: 145.4547 - val_mae: 103.8670 - 153ms/epoch - 31ms/step\n",
      "Epoch 119/300\n",
      "5/5 - 0s - loss: 142.5596 - mae: 97.0839 - val_loss: 144.1911 - val_mae: 104.0080 - 169ms/epoch - 34ms/step\n",
      "Epoch 120/300\n",
      "5/5 - 0s - loss: 138.8571 - mae: 97.1068 - val_loss: 143.5479 - val_mae: 104.0608 - 151ms/epoch - 30ms/step\n",
      "Epoch 121/300\n",
      "5/5 - 0s - loss: 136.3884 - mae: 97.0283 - val_loss: 142.4201 - val_mae: 103.6445 - 174ms/epoch - 35ms/step\n",
      "Epoch 122/300\n",
      "5/5 - 0s - loss: 136.6848 - mae: 96.9588 - val_loss: 141.4529 - val_mae: 103.7986 - 172ms/epoch - 34ms/step\n",
      "Epoch 123/300\n",
      "5/5 - 0s - loss: 134.4548 - mae: 97.0292 - val_loss: 140.2576 - val_mae: 104.2301 - 164ms/epoch - 33ms/step\n",
      "Epoch 124/300\n",
      "5/5 - 0s - loss: 133.0505 - mae: 97.0305 - val_loss: 139.0178 - val_mae: 103.5104 - 166ms/epoch - 33ms/step\n",
      "Epoch 125/300\n",
      "5/5 - 0s - loss: 131.6653 - mae: 96.9767 - val_loss: 137.8768 - val_mae: 103.9713 - 153ms/epoch - 31ms/step\n",
      "Epoch 126/300\n",
      "5/5 - 0s - loss: 132.2998 - mae: 97.0240 - val_loss: 136.5790 - val_mae: 103.6358 - 127ms/epoch - 25ms/step\n",
      "Epoch 127/300\n",
      "5/5 - 0s - loss: 128.5926 - mae: 97.0904 - val_loss: 135.4853 - val_mae: 104.0202 - 96ms/epoch - 19ms/step\n",
      "Epoch 128/300\n",
      "5/5 - 0s - loss: 128.4900 - mae: 96.9972 - val_loss: 134.5351 - val_mae: 104.0492 - 101ms/epoch - 20ms/step\n",
      "Epoch 129/300\n",
      "5/5 - 0s - loss: 127.7907 - mae: 96.9277 - val_loss: 133.5969 - val_mae: 103.7899 - 110ms/epoch - 22ms/step\n",
      "Epoch 130/300\n",
      "5/5 - 0s - loss: 125.4351 - mae: 96.9924 - val_loss: 132.4785 - val_mae: 103.8245 - 100ms/epoch - 20ms/step\n",
      "Epoch 131/300\n",
      "5/5 - 0s - loss: 124.5200 - mae: 96.9073 - val_loss: 131.3840 - val_mae: 103.6815 - 92ms/epoch - 18ms/step\n",
      "Epoch 132/300\n",
      "5/5 - 0s - loss: 123.3663 - mae: 96.8636 - val_loss: 130.5020 - val_mae: 103.9526 - 94ms/epoch - 19ms/step\n",
      "Epoch 133/300\n",
      "5/5 - 0s - loss: 121.8887 - mae: 96.9510 - val_loss: 129.5574 - val_mae: 103.7507 - 96ms/epoch - 19ms/step\n",
      "Epoch 134/300\n",
      "5/5 - 0s - loss: 122.7236 - mae: 96.8590 - val_loss: 128.8962 - val_mae: 103.6819 - 94ms/epoch - 19ms/step\n",
      "Epoch 135/300\n",
      "5/5 - 0s - loss: 118.9922 - mae: 96.8518 - val_loss: 128.2016 - val_mae: 103.5726 - 91ms/epoch - 18ms/step\n",
      "Epoch 136/300\n",
      "5/5 - 0s - loss: 117.7253 - mae: 96.8330 - val_loss: 127.0594 - val_mae: 103.7632 - 92ms/epoch - 18ms/step\n",
      "Epoch 137/300\n",
      "5/5 - 0s - loss: 115.8009 - mae: 96.8490 - val_loss: 126.4161 - val_mae: 103.0891 - 96ms/epoch - 19ms/step\n",
      "Epoch 138/300\n",
      "5/5 - 0s - loss: 116.6531 - mae: 96.6973 - val_loss: 125.1943 - val_mae: 103.7511 - 104ms/epoch - 21ms/step\n",
      "Epoch 139/300\n",
      "5/5 - 0s - loss: 116.2227 - mae: 96.7119 - val_loss: 124.3750 - val_mae: 103.4133 - 122ms/epoch - 24ms/step\n",
      "Epoch 140/300\n",
      "5/5 - 0s - loss: 113.0323 - mae: 96.7515 - val_loss: 123.4577 - val_mae: 103.5735 - 95ms/epoch - 19ms/step\n",
      "Epoch 141/300\n",
      "5/5 - 0s - loss: 114.0315 - mae: 96.6860 - val_loss: 122.4129 - val_mae: 103.6355 - 98ms/epoch - 20ms/step\n",
      "Epoch 142/300\n",
      "5/5 - 0s - loss: 112.2772 - mae: 96.7296 - val_loss: 121.4443 - val_mae: 103.4446 - 95ms/epoch - 19ms/step\n",
      "Epoch 143/300\n",
      "5/5 - 0s - loss: 112.4731 - mae: 96.6871 - val_loss: 120.7336 - val_mae: 103.6743 - 94ms/epoch - 19ms/step\n",
      "Epoch 144/300\n",
      "5/5 - 0s - loss: 110.8277 - mae: 96.5902 - val_loss: 120.0501 - val_mae: 103.5810 - 96ms/epoch - 19ms/step\n",
      "Epoch 145/300\n",
      "5/5 - 0s - loss: 108.8696 - mae: 96.6628 - val_loss: 119.0094 - val_mae: 103.2443 - 95ms/epoch - 19ms/step\n",
      "Epoch 146/300\n",
      "5/5 - 0s - loss: 109.1943 - mae: 96.6697 - val_loss: 118.3716 - val_mae: 103.5787 - 93ms/epoch - 19ms/step\n",
      "Epoch 147/300\n",
      "5/5 - 0s - loss: 107.3519 - mae: 96.5749 - val_loss: 117.7186 - val_mae: 103.4795 - 95ms/epoch - 19ms/step\n",
      "Epoch 148/300\n",
      "5/5 - 0s - loss: 106.0565 - mae: 96.6234 - val_loss: 117.0770 - val_mae: 103.3789 - 98ms/epoch - 20ms/step\n",
      "Epoch 149/300\n",
      "5/5 - 0s - loss: 107.4385 - mae: 96.6966 - val_loss: 116.1326 - val_mae: 103.4604 - 103ms/epoch - 21ms/step\n",
      "Epoch 150/300\n",
      "5/5 - 0s - loss: 105.1789 - mae: 96.5944 - val_loss: 115.4814 - val_mae: 103.4674 - 108ms/epoch - 22ms/step\n",
      "Epoch 151/300\n",
      "5/5 - 0s - loss: 103.7883 - mae: 96.4913 - val_loss: 114.5833 - val_mae: 103.4033 - 95ms/epoch - 19ms/step\n",
      "Epoch 152/300\n",
      "5/5 - 0s - loss: 102.0240 - mae: 96.5683 - val_loss: 113.7787 - val_mae: 103.5756 - 94ms/epoch - 19ms/step\n",
      "Epoch 153/300\n",
      "5/5 - 0s - loss: 101.7768 - mae: 96.3569 - val_loss: 113.2696 - val_mae: 103.6511 - 100ms/epoch - 20ms/step\n",
      "Epoch 154/300\n",
      "5/5 - 0s - loss: 100.5347 - mae: 96.3938 - val_loss: 112.4941 - val_mae: 103.3982 - 91ms/epoch - 18ms/step\n",
      "Epoch 155/300\n",
      "5/5 - 0s - loss: 100.5057 - mae: 96.4317 - val_loss: 111.9249 - val_mae: 103.3894 - 93ms/epoch - 19ms/step\n",
      "Epoch 156/300\n",
      "5/5 - 0s - loss: 97.8735 - mae: 96.5201 - val_loss: 111.2560 - val_mae: 103.1516 - 97ms/epoch - 19ms/step\n",
      "Epoch 157/300\n",
      "5/5 - 0s - loss: 98.2030 - mae: 96.4431 - val_loss: 110.5598 - val_mae: 103.0779 - 97ms/epoch - 19ms/step\n",
      "Epoch 158/300\n",
      "5/5 - 0s - loss: 97.1362 - mae: 96.4619 - val_loss: 109.9583 - val_mae: 103.2893 - 101ms/epoch - 20ms/step\n",
      "Epoch 159/300\n",
      "5/5 - 0s - loss: 95.2813 - mae: 96.3390 - val_loss: 108.9951 - val_mae: 103.2533 - 97ms/epoch - 19ms/step\n",
      "Epoch 160/300\n",
      "5/5 - 0s - loss: 97.3639 - mae: 96.4347 - val_loss: 108.5216 - val_mae: 103.4670 - 114ms/epoch - 23ms/step\n",
      "Epoch 161/300\n",
      "5/5 - 0s - loss: 95.6152 - mae: 96.2781 - val_loss: 107.7705 - val_mae: 103.1682 - 95ms/epoch - 19ms/step\n",
      "Epoch 162/300\n",
      "5/5 - 0s - loss: 93.9842 - mae: 96.2880 - val_loss: 107.0149 - val_mae: 103.5435 - 94ms/epoch - 19ms/step\n",
      "Epoch 163/300\n",
      "5/5 - 0s - loss: 93.1300 - mae: 96.2822 - val_loss: 106.4527 - val_mae: 103.1979 - 96ms/epoch - 19ms/step\n",
      "Epoch 164/300\n",
      "5/5 - 0s - loss: 92.7653 - mae: 96.3662 - val_loss: 106.2021 - val_mae: 103.1152 - 94ms/epoch - 19ms/step\n",
      "Epoch 165/300\n",
      "5/5 - 0s - loss: 92.7173 - mae: 96.1477 - val_loss: 105.5282 - val_mae: 103.2053 - 92ms/epoch - 18ms/step\n",
      "Epoch 166/300\n",
      "5/5 - 0s - loss: 91.6777 - mae: 96.2248 - val_loss: 104.8689 - val_mae: 103.2987 - 94ms/epoch - 19ms/step\n",
      "Epoch 167/300\n",
      "5/5 - 0s - loss: 88.7350 - mae: 96.3004 - val_loss: 104.3589 - val_mae: 103.1337 - 98ms/epoch - 20ms/step\n",
      "Epoch 168/300\n",
      "5/5 - 0s - loss: 89.8705 - mae: 96.1439 - val_loss: 103.6446 - val_mae: 103.0856 - 103ms/epoch - 21ms/step\n",
      "Epoch 169/300\n",
      "5/5 - 0s - loss: 89.2906 - mae: 96.2267 - val_loss: 102.7250 - val_mae: 102.9652 - 91ms/epoch - 18ms/step\n",
      "Epoch 170/300\n",
      "5/5 - 0s - loss: 88.8629 - mae: 96.2295 - val_loss: 102.2390 - val_mae: 103.4510 - 132ms/epoch - 26ms/step\n",
      "Epoch 171/300\n",
      "5/5 - 0s - loss: 88.2206 - mae: 96.0735 - val_loss: 101.6156 - val_mae: 103.2793 - 91ms/epoch - 18ms/step\n",
      "Epoch 172/300\n",
      "5/5 - 0s - loss: 86.2418 - mae: 96.1604 - val_loss: 101.0864 - val_mae: 103.3979 - 95ms/epoch - 19ms/step\n",
      "Epoch 173/300\n",
      "5/5 - 0s - loss: 87.6496 - mae: 96.1433 - val_loss: 100.4654 - val_mae: 102.9817 - 96ms/epoch - 19ms/step\n",
      "Epoch 174/300\n",
      "5/5 - 0s - loss: 84.4455 - mae: 96.1153 - val_loss: 100.2953 - val_mae: 103.1564 - 92ms/epoch - 18ms/step\n",
      "Epoch 175/300\n",
      "5/5 - 0s - loss: 84.7799 - mae: 96.1413 - val_loss: 99.8867 - val_mae: 103.6161 - 97ms/epoch - 19ms/step\n",
      "Epoch 176/300\n",
      "5/5 - 0s - loss: 83.9872 - mae: 96.1323 - val_loss: 99.4484 - val_mae: 102.9991 - 95ms/epoch - 19ms/step\n",
      "Epoch 177/300\n",
      "5/5 - 0s - loss: 85.4017 - mae: 96.0432 - val_loss: 98.7170 - val_mae: 102.9200 - 96ms/epoch - 19ms/step\n",
      "Epoch 178/300\n",
      "5/5 - 0s - loss: 83.4309 - mae: 96.1644 - val_loss: 98.1857 - val_mae: 103.0901 - 100ms/epoch - 20ms/step\n",
      "Epoch 179/300\n",
      "5/5 - 0s - loss: 81.9018 - mae: 96.1321 - val_loss: 97.8242 - val_mae: 102.8822 - 98ms/epoch - 20ms/step\n",
      "Epoch 180/300\n",
      "5/5 - 0s - loss: 83.2627 - mae: 96.0234 - val_loss: 97.4485 - val_mae: 103.0304 - 107ms/epoch - 21ms/step\n",
      "Epoch 181/300\n",
      "5/5 - 0s - loss: 81.8733 - mae: 95.9627 - val_loss: 97.2268 - val_mae: 102.6725 - 91ms/epoch - 18ms/step\n",
      "Epoch 182/300\n",
      "5/5 - 0s - loss: 81.1264 - mae: 95.8778 - val_loss: 96.6562 - val_mae: 103.4714 - 90ms/epoch - 18ms/step\n",
      "Epoch 183/300\n",
      "5/5 - 0s - loss: 81.1373 - mae: 95.8670 - val_loss: 95.8439 - val_mae: 103.1751 - 94ms/epoch - 19ms/step\n",
      "Epoch 184/300\n",
      "5/5 - 0s - loss: 80.7993 - mae: 95.9461 - val_loss: 95.3359 - val_mae: 103.0596 - 90ms/epoch - 18ms/step\n",
      "Epoch 185/300\n",
      "5/5 - 0s - loss: 79.4535 - mae: 95.8580 - val_loss: 94.9074 - val_mae: 102.7583 - 95ms/epoch - 19ms/step\n",
      "Epoch 186/300\n",
      "5/5 - 0s - loss: 79.2779 - mae: 95.8011 - val_loss: 94.4037 - val_mae: 103.0170 - 92ms/epoch - 18ms/step\n",
      "Epoch 187/300\n",
      "5/5 - 0s - loss: 78.5886 - mae: 95.9030 - val_loss: 93.9516 - val_mae: 103.0670 - 96ms/epoch - 19ms/step\n",
      "Epoch 188/300\n",
      "5/5 - 0s - loss: 77.6972 - mae: 95.8541 - val_loss: 93.4642 - val_mae: 102.8599 - 97ms/epoch - 19ms/step\n",
      "Epoch 189/300\n",
      "5/5 - 0s - loss: 77.8637 - mae: 95.8842 - val_loss: 92.9601 - val_mae: 102.8211 - 92ms/epoch - 18ms/step\n",
      "Epoch 190/300\n",
      "5/5 - 0s - loss: 77.6002 - mae: 95.8296 - val_loss: 92.6644 - val_mae: 102.7838 - 94ms/epoch - 19ms/step\n",
      "Epoch 191/300\n",
      "5/5 - 0s - loss: 77.2577 - mae: 95.9173 - val_loss: 92.2205 - val_mae: 102.9528 - 127ms/epoch - 25ms/step\n",
      "Epoch 192/300\n",
      "5/5 - 0s - loss: 77.3422 - mae: 95.8279 - val_loss: 91.7842 - val_mae: 102.7007 - 91ms/epoch - 18ms/step\n",
      "Epoch 193/300\n",
      "5/5 - 0s - loss: 76.0895 - mae: 95.7684 - val_loss: 91.7843 - val_mae: 102.9018 - 93ms/epoch - 19ms/step\n",
      "Epoch 194/300\n",
      "5/5 - 0s - loss: 74.4219 - mae: 95.7560 - val_loss: 91.4489 - val_mae: 103.0497 - 93ms/epoch - 19ms/step\n",
      "Epoch 195/300\n",
      "5/5 - 0s - loss: 73.7961 - mae: 95.7649 - val_loss: 91.2022 - val_mae: 103.0826 - 90ms/epoch - 18ms/step\n",
      "Epoch 196/300\n",
      "5/5 - 0s - loss: 76.8121 - mae: 95.8159 - val_loss: 90.9073 - val_mae: 103.0231 - 95ms/epoch - 19ms/step\n",
      "Epoch 197/300\n",
      "5/5 - 0s - loss: 73.4347 - mae: 95.6932 - val_loss: 90.5802 - val_mae: 102.7176 - 99ms/epoch - 20ms/step\n",
      "Epoch 198/300\n",
      "5/5 - 0s - loss: 73.0877 - mae: 95.7252 - val_loss: 90.0779 - val_mae: 102.9728 - 97ms/epoch - 19ms/step\n",
      "Epoch 199/300\n",
      "5/5 - 0s - loss: 71.8307 - mae: 95.7338 - val_loss: 89.8934 - val_mae: 102.7079 - 92ms/epoch - 18ms/step\n",
      "Epoch 200/300\n",
      "5/5 - 0s - loss: 72.4433 - mae: 95.8432 - val_loss: 89.5067 - val_mae: 102.7693 - 98ms/epoch - 20ms/step\n",
      "Epoch 201/300\n",
      "5/5 - 0s - loss: 70.9940 - mae: 95.5804 - val_loss: 89.1085 - val_mae: 102.7242 - 104ms/epoch - 21ms/step\n",
      "Epoch 202/300\n",
      "5/5 - 0s - loss: 71.1735 - mae: 95.5124 - val_loss: 88.6849 - val_mae: 102.6990 - 93ms/epoch - 19ms/step\n",
      "Epoch 203/300\n",
      "5/5 - 0s - loss: 70.3399 - mae: 95.5643 - val_loss: 88.3486 - val_mae: 102.3377 - 96ms/epoch - 19ms/step\n",
      "Epoch 204/300\n",
      "5/5 - 0s - loss: 71.0382 - mae: 95.5167 - val_loss: 88.1070 - val_mae: 102.4575 - 91ms/epoch - 18ms/step\n",
      "Epoch 205/300\n",
      "5/5 - 0s - loss: 70.9160 - mae: 95.6015 - val_loss: 87.9284 - val_mae: 102.3803 - 92ms/epoch - 18ms/step\n",
      "Epoch 206/300\n",
      "5/5 - 0s - loss: 70.0774 - mae: 95.4430 - val_loss: 87.5505 - val_mae: 102.8041 - 97ms/epoch - 19ms/step\n",
      "Epoch 207/300\n",
      "5/5 - 0s - loss: 68.0997 - mae: 95.4657 - val_loss: 87.3385 - val_mae: 102.5723 - 94ms/epoch - 19ms/step\n",
      "Epoch 208/300\n",
      "5/5 - 0s - loss: 68.3118 - mae: 95.5196 - val_loss: 86.9258 - val_mae: 102.7923 - 97ms/epoch - 19ms/step\n",
      "Epoch 209/300\n",
      "5/5 - 0s - loss: 68.8650 - mae: 95.4598 - val_loss: 86.6378 - val_mae: 102.8279 - 95ms/epoch - 19ms/step\n",
      "Epoch 210/300\n",
      "5/5 - 0s - loss: 69.1651 - mae: 95.5944 - val_loss: 86.3236 - val_mae: 102.6002 - 95ms/epoch - 19ms/step\n",
      "Epoch 211/300\n",
      "5/5 - 0s - loss: 66.1604 - mae: 95.4630 - val_loss: 86.1002 - val_mae: 102.6713 - 94ms/epoch - 19ms/step\n",
      "Epoch 212/300\n",
      "5/5 - 0s - loss: 67.8427 - mae: 95.4557 - val_loss: 85.9519 - val_mae: 102.6363 - 110ms/epoch - 22ms/step\n",
      "Epoch 213/300\n",
      "5/5 - 0s - loss: 66.5084 - mae: 95.3559 - val_loss: 85.6136 - val_mae: 102.0223 - 93ms/epoch - 19ms/step\n",
      "Epoch 214/300\n",
      "5/5 - 0s - loss: 66.3737 - mae: 95.3938 - val_loss: 85.3106 - val_mae: 102.1755 - 92ms/epoch - 18ms/step\n",
      "Epoch 215/300\n",
      "5/5 - 0s - loss: 66.6726 - mae: 95.3383 - val_loss: 84.9018 - val_mae: 102.5992 - 92ms/epoch - 18ms/step\n",
      "Epoch 216/300\n",
      "5/5 - 0s - loss: 66.3104 - mae: 95.3744 - val_loss: 84.7578 - val_mae: 102.7185 - 90ms/epoch - 18ms/step\n",
      "Epoch 217/300\n",
      "5/5 - 0s - loss: 64.6714 - mae: 95.3112 - val_loss: 84.6596 - val_mae: 102.1656 - 90ms/epoch - 18ms/step\n",
      "Epoch 218/300\n",
      "5/5 - 0s - loss: 64.4150 - mae: 95.4144 - val_loss: 84.3663 - val_mae: 102.1935 - 99ms/epoch - 20ms/step\n",
      "Epoch 219/300\n",
      "5/5 - 0s - loss: 65.1934 - mae: 95.3243 - val_loss: 84.0600 - val_mae: 102.2782 - 92ms/epoch - 18ms/step\n",
      "Epoch 220/300\n",
      "5/5 - 0s - loss: 63.4525 - mae: 95.2047 - val_loss: 83.8583 - val_mae: 102.1914 - 110ms/epoch - 22ms/step\n",
      "Epoch 221/300\n",
      "5/5 - 0s - loss: 63.4042 - mae: 95.2881 - val_loss: 83.5531 - val_mae: 102.6352 - 95ms/epoch - 19ms/step\n",
      "Epoch 222/300\n",
      "5/5 - 0s - loss: 62.5801 - mae: 95.2061 - val_loss: 83.2896 - val_mae: 102.3871 - 138ms/epoch - 28ms/step\n",
      "Epoch 223/300\n",
      "5/5 - 0s - loss: 61.6713 - mae: 95.2755 - val_loss: 82.8875 - val_mae: 102.3852 - 93ms/epoch - 19ms/step\n",
      "Epoch 224/300\n",
      "5/5 - 0s - loss: 61.4836 - mae: 95.2212 - val_loss: 82.7372 - val_mae: 102.4627 - 101ms/epoch - 20ms/step\n",
      "Epoch 225/300\n",
      "5/5 - 0s - loss: 64.1903 - mae: 95.4122 - val_loss: 82.4123 - val_mae: 102.3633 - 111ms/epoch - 22ms/step\n",
      "Epoch 226/300\n",
      "5/5 - 0s - loss: 62.7901 - mae: 95.1587 - val_loss: 82.3612 - val_mae: 102.1555 - 163ms/epoch - 33ms/step\n",
      "Epoch 227/300\n",
      "5/5 - 0s - loss: 60.8224 - mae: 95.1481 - val_loss: 82.1743 - val_mae: 102.2437 - 155ms/epoch - 31ms/step\n",
      "Epoch 228/300\n",
      "5/5 - 0s - loss: 61.3784 - mae: 95.1093 - val_loss: 81.8635 - val_mae: 102.3212 - 151ms/epoch - 30ms/step\n",
      "Epoch 229/300\n",
      "5/5 - 0s - loss: 59.8390 - mae: 95.1910 - val_loss: 81.5038 - val_mae: 102.3046 - 153ms/epoch - 31ms/step\n",
      "Epoch 230/300\n",
      "5/5 - 0s - loss: 60.5904 - mae: 95.0883 - val_loss: 81.0933 - val_mae: 102.2222 - 154ms/epoch - 31ms/step\n",
      "Epoch 231/300\n",
      "5/5 - 0s - loss: 59.3865 - mae: 95.1592 - val_loss: 80.8056 - val_mae: 102.8619 - 166ms/epoch - 33ms/step\n",
      "Epoch 232/300\n",
      "5/5 - 0s - loss: 61.3843 - mae: 95.0923 - val_loss: 80.4977 - val_mae: 102.3557 - 148ms/epoch - 30ms/step\n",
      "Epoch 233/300\n",
      "5/5 - 0s - loss: 61.4678 - mae: 95.0229 - val_loss: 80.3673 - val_mae: 102.4837 - 155ms/epoch - 31ms/step\n",
      "Epoch 234/300\n",
      "5/5 - 0s - loss: 59.6111 - mae: 95.0797 - val_loss: 79.9711 - val_mae: 102.1904 - 156ms/epoch - 31ms/step\n",
      "Epoch 235/300\n",
      "5/5 - 0s - loss: 58.6523 - mae: 94.9944 - val_loss: 79.7445 - val_mae: 102.0621 - 156ms/epoch - 31ms/step\n",
      "Epoch 236/300\n",
      "5/5 - 0s - loss: 58.0540 - mae: 94.9792 - val_loss: 79.6749 - val_mae: 102.5117 - 170ms/epoch - 34ms/step\n",
      "Epoch 237/300\n",
      "5/5 - 0s - loss: 59.4896 - mae: 95.0769 - val_loss: 79.2198 - val_mae: 101.9986 - 159ms/epoch - 32ms/step\n",
      "Epoch 238/300\n",
      "5/5 - 0s - loss: 59.2160 - mae: 94.9411 - val_loss: 78.9156 - val_mae: 101.8753 - 173ms/epoch - 35ms/step\n",
      "Epoch 239/300\n",
      "5/5 - 0s - loss: 57.7857 - mae: 94.9942 - val_loss: 78.6996 - val_mae: 102.2783 - 155ms/epoch - 31ms/step\n",
      "Epoch 240/300\n",
      "5/5 - 0s - loss: 58.1343 - mae: 94.8538 - val_loss: 78.6283 - val_mae: 102.0923 - 116ms/epoch - 23ms/step\n",
      "Epoch 241/300\n",
      "5/5 - 0s - loss: 57.6909 - mae: 94.8107 - val_loss: 78.1876 - val_mae: 102.4016 - 102ms/epoch - 20ms/step\n",
      "Epoch 242/300\n",
      "5/5 - 0s - loss: 56.1810 - mae: 94.8416 - val_loss: 77.7642 - val_mae: 101.9909 - 89ms/epoch - 18ms/step\n",
      "Epoch 243/300\n",
      "5/5 - 0s - loss: 57.0863 - mae: 94.8267 - val_loss: 77.4801 - val_mae: 102.3499 - 93ms/epoch - 19ms/step\n",
      "Epoch 244/300\n",
      "5/5 - 0s - loss: 57.5672 - mae: 94.7926 - val_loss: 77.3793 - val_mae: 102.1137 - 103ms/epoch - 21ms/step\n",
      "Epoch 245/300\n",
      "5/5 - 0s - loss: 55.3339 - mae: 94.8679 - val_loss: 77.0205 - val_mae: 102.0698 - 102ms/epoch - 20ms/step\n",
      "Epoch 246/300\n",
      "5/5 - 0s - loss: 55.8399 - mae: 94.7342 - val_loss: 76.7993 - val_mae: 101.4760 - 92ms/epoch - 18ms/step\n",
      "Epoch 247/300\n",
      "5/5 - 0s - loss: 55.6010 - mae: 94.7467 - val_loss: 76.5789 - val_mae: 102.0063 - 91ms/epoch - 18ms/step\n",
      "Epoch 248/300\n",
      "5/5 - 0s - loss: 55.1136 - mae: 94.7736 - val_loss: 76.3459 - val_mae: 101.9893 - 103ms/epoch - 21ms/step\n",
      "Epoch 249/300\n",
      "5/5 - 0s - loss: 54.6702 - mae: 94.8853 - val_loss: 76.1626 - val_mae: 101.8679 - 93ms/epoch - 19ms/step\n",
      "Epoch 250/300\n",
      "5/5 - 0s - loss: 55.2235 - mae: 94.6476 - val_loss: 75.8586 - val_mae: 101.9583 - 94ms/epoch - 19ms/step\n",
      "Epoch 251/300\n",
      "5/5 - 0s - loss: 54.1462 - mae: 94.6865 - val_loss: 75.5986 - val_mae: 101.7080 - 95ms/epoch - 19ms/step\n",
      "Epoch 252/300\n",
      "5/5 - 0s - loss: 54.0539 - mae: 94.6669 - val_loss: 75.2695 - val_mae: 102.2253 - 121ms/epoch - 24ms/step\n",
      "Epoch 253/300\n",
      "5/5 - 0s - loss: 53.3118 - mae: 94.5168 - val_loss: 75.0331 - val_mae: 101.7771 - 92ms/epoch - 18ms/step\n",
      "Epoch 254/300\n",
      "5/5 - 0s - loss: 54.1383 - mae: 94.7859 - val_loss: 74.7021 - val_mae: 102.3234 - 92ms/epoch - 18ms/step\n",
      "Epoch 255/300\n",
      "5/5 - 0s - loss: 54.0153 - mae: 94.7932 - val_loss: 74.6058 - val_mae: 102.1373 - 111ms/epoch - 22ms/step\n",
      "Epoch 256/300\n",
      "5/5 - 0s - loss: 53.1050 - mae: 94.4565 - val_loss: 74.3965 - val_mae: 101.8284 - 93ms/epoch - 19ms/step\n",
      "Epoch 257/300\n",
      "5/5 - 0s - loss: 53.1654 - mae: 94.8317 - val_loss: 74.2607 - val_mae: 101.7375 - 94ms/epoch - 19ms/step\n",
      "Epoch 258/300\n",
      "5/5 - 0s - loss: 52.8893 - mae: 94.5382 - val_loss: 74.1370 - val_mae: 102.2392 - 100ms/epoch - 20ms/step\n",
      "Epoch 259/300\n",
      "5/5 - 0s - loss: 51.9658 - mae: 94.4854 - val_loss: 73.9370 - val_mae: 101.7231 - 93ms/epoch - 19ms/step\n",
      "Epoch 260/300\n",
      "5/5 - 0s - loss: 51.3655 - mae: 94.6950 - val_loss: 73.6307 - val_mae: 101.1823 - 106ms/epoch - 21ms/step\n",
      "Epoch 261/300\n",
      "5/5 - 0s - loss: 52.7478 - mae: 94.5146 - val_loss: 73.3233 - val_mae: 101.6591 - 94ms/epoch - 19ms/step\n",
      "Epoch 262/300\n",
      "5/5 - 0s - loss: 51.6197 - mae: 94.4940 - val_loss: 73.2958 - val_mae: 101.5411 - 93ms/epoch - 19ms/step\n",
      "Epoch 263/300\n",
      "5/5 - 0s - loss: 50.9067 - mae: 94.5301 - val_loss: 73.1002 - val_mae: 101.2532 - 94ms/epoch - 19ms/step\n",
      "Epoch 264/300\n",
      "5/5 - 0s - loss: 50.6992 - mae: 94.3221 - val_loss: 72.9469 - val_mae: 101.4069 - 97ms/epoch - 19ms/step\n",
      "Epoch 265/300\n",
      "5/5 - 0s - loss: 51.1255 - mae: 94.4298 - val_loss: 72.7362 - val_mae: 101.8467 - 122ms/epoch - 24ms/step\n",
      "Epoch 266/300\n",
      "5/5 - 0s - loss: 50.5205 - mae: 94.4750 - val_loss: 72.5316 - val_mae: 102.0314 - 94ms/epoch - 19ms/step\n",
      "Epoch 267/300\n",
      "5/5 - 0s - loss: 50.7836 - mae: 94.4059 - val_loss: 72.2598 - val_mae: 101.4021 - 97ms/epoch - 19ms/step\n",
      "Epoch 268/300\n",
      "5/5 - 0s - loss: 49.2609 - mae: 94.5201 - val_loss: 71.8886 - val_mae: 101.5637 - 113ms/epoch - 23ms/step\n",
      "Epoch 269/300\n",
      "5/5 - 0s - loss: 51.3480 - mae: 94.5219 - val_loss: 71.9143 - val_mae: 102.0056 - 90ms/epoch - 18ms/step\n",
      "Epoch 270/300\n",
      "5/5 - 0s - loss: 50.1613 - mae: 94.4215 - val_loss: 71.7243 - val_mae: 101.7706 - 94ms/epoch - 19ms/step\n",
      "Epoch 271/300\n",
      "5/5 - 0s - loss: 48.6240 - mae: 94.3450 - val_loss: 71.6075 - val_mae: 101.6147 - 90ms/epoch - 18ms/step\n",
      "Epoch 272/300\n",
      "5/5 - 0s - loss: 48.7003 - mae: 94.2385 - val_loss: 71.4269 - val_mae: 101.2047 - 89ms/epoch - 18ms/step\n",
      "Epoch 273/300\n",
      "5/5 - 0s - loss: 47.9982 - mae: 94.3348 - val_loss: 71.3353 - val_mae: 101.4049 - 92ms/epoch - 18ms/step\n",
      "Epoch 274/300\n",
      "5/5 - 0s - loss: 48.6461 - mae: 94.4441 - val_loss: 71.1695 - val_mae: 101.6451 - 91ms/epoch - 18ms/step\n",
      "Epoch 275/300\n",
      "5/5 - 0s - loss: 48.9192 - mae: 94.2552 - val_loss: 70.8903 - val_mae: 101.8510 - 105ms/epoch - 21ms/step\n",
      "Epoch 276/300\n",
      "5/5 - 0s - loss: 49.6093 - mae: 94.4625 - val_loss: 70.6857 - val_mae: 101.8470 - 92ms/epoch - 18ms/step\n",
      "Epoch 277/300\n",
      "5/5 - 0s - loss: 47.8448 - mae: 94.2638 - val_loss: 70.5979 - val_mae: 101.1112 - 92ms/epoch - 18ms/step\n",
      "Epoch 278/300\n",
      "5/5 - 0s - loss: 47.9746 - mae: 94.2166 - val_loss: 70.3479 - val_mae: 101.0586 - 105ms/epoch - 21ms/step\n",
      "Epoch 279/300\n",
      "5/5 - 0s - loss: 46.0886 - mae: 94.1829 - val_loss: 70.0767 - val_mae: 101.3982 - 93ms/epoch - 19ms/step\n",
      "Epoch 280/300\n",
      "5/5 - 0s - loss: 47.2946 - mae: 94.0841 - val_loss: 69.9519 - val_mae: 101.0659 - 96ms/epoch - 19ms/step\n",
      "Epoch 281/300\n",
      "5/5 - 0s - loss: 47.5962 - mae: 94.1319 - val_loss: 69.7830 - val_mae: 101.4577 - 93ms/epoch - 19ms/step\n",
      "Epoch 282/300\n",
      "5/5 - 0s - loss: 46.9332 - mae: 94.2104 - val_loss: 69.6520 - val_mae: 101.6471 - 93ms/epoch - 19ms/step\n",
      "Epoch 283/300\n",
      "5/5 - 0s - loss: 46.3603 - mae: 94.2703 - val_loss: 69.3857 - val_mae: 101.5503 - 92ms/epoch - 18ms/step\n",
      "Epoch 284/300\n",
      "5/5 - 0s - loss: 46.0854 - mae: 94.2439 - val_loss: 69.1825 - val_mae: 101.3779 - 93ms/epoch - 19ms/step\n",
      "Epoch 285/300\n",
      "5/5 - 0s - loss: 46.2917 - mae: 94.2026 - val_loss: 69.0312 - val_mae: 101.5771 - 89ms/epoch - 18ms/step\n",
      "Epoch 286/300\n",
      "5/5 - 0s - loss: 46.1240 - mae: 94.0398 - val_loss: 68.9942 - val_mae: 101.3024 - 112ms/epoch - 22ms/step\n",
      "Epoch 287/300\n",
      "5/5 - 0s - loss: 46.1106 - mae: 94.0766 - val_loss: 68.8462 - val_mae: 101.3041 - 93ms/epoch - 19ms/step\n",
      "Epoch 288/300\n",
      "5/5 - 0s - loss: 46.4034 - mae: 94.0710 - val_loss: 68.6193 - val_mae: 101.2683 - 104ms/epoch - 21ms/step\n",
      "Epoch 289/300\n",
      "5/5 - 0s - loss: 46.3594 - mae: 93.9907 - val_loss: 68.5837 - val_mae: 101.5330 - 91ms/epoch - 18ms/step\n",
      "Epoch 290/300\n",
      "5/5 - 0s - loss: 45.6579 - mae: 94.0602 - val_loss: 68.3737 - val_mae: 101.4117 - 95ms/epoch - 19ms/step\n",
      "Epoch 291/300\n",
      "5/5 - 0s - loss: 44.9941 - mae: 94.0383 - val_loss: 68.3282 - val_mae: 101.4817 - 100ms/epoch - 20ms/step\n",
      "Epoch 292/300\n",
      "5/5 - 0s - loss: 45.1635 - mae: 94.0365 - val_loss: 68.2072 - val_mae: 101.6384 - 92ms/epoch - 18ms/step\n",
      "Epoch 293/300\n",
      "5/5 - 0s - loss: 44.1476 - mae: 94.0412 - val_loss: 68.0865 - val_mae: 101.6388 - 92ms/epoch - 18ms/step\n",
      "Epoch 294/300\n",
      "5/5 - 0s - loss: 44.8845 - mae: 93.9878 - val_loss: 68.0119 - val_mae: 101.3368 - 95ms/epoch - 19ms/step\n",
      "Epoch 295/300\n",
      "5/5 - 0s - loss: 45.5066 - mae: 94.1205 - val_loss: 67.8651 - val_mae: 101.3930 - 90ms/epoch - 18ms/step\n",
      "Epoch 296/300\n",
      "5/5 - 0s - loss: 44.7129 - mae: 93.7950 - val_loss: 67.7361 - val_mae: 100.8501 - 105ms/epoch - 21ms/step\n",
      "Epoch 297/300\n",
      "5/5 - 0s - loss: 45.0854 - mae: 93.8060 - val_loss: 67.5750 - val_mae: 101.2588 - 94ms/epoch - 19ms/step\n",
      "Epoch 298/300\n",
      "5/5 - 0s - loss: 44.4185 - mae: 93.9234 - val_loss: 67.4556 - val_mae: 101.1841 - 114ms/epoch - 23ms/step\n",
      "Epoch 299/300\n",
      "5/5 - 0s - loss: 44.7943 - mae: 93.9625 - val_loss: 67.3478 - val_mae: 101.5645 - 95ms/epoch - 19ms/step\n",
      "Epoch 300/300\n",
      "5/5 - 0s - loss: 43.3641 - mae: 93.9770 - val_loss: 67.2980 - val_mae: 101.3268 - 88ms/epoch - 18ms/step\n",
      "{'price_D-1': True, 'price_D-2': False, 'price_D-3': False, 'price_D-7': False, 'load_D': False, 'load_D-1': False, 'load_D-7': True, 'RES_D': True, 'RES_D-1': False, 'EUA': False, 'Coal': True, 'Gas': False, 'Oil': True, 'Dummy': True, 'dropout': True, 'dropout_rate': 0.23997247978992076, 'regularize_h1_activation': True, 'regularize_h1_kernel': False, 'h1_activation_rate_l1': 7.915919680298221e-05, 'neurons_1': 405, 'activation_1': 'tanh', 'regularize_h2_activation': True, 'regularize_h2_kernel': False, 'h2_activation_rate_l1': 1.2879367172215846e-05, 'neurons_2': 396, 'activation_2': 'relu', 'regularize_loc': False, 'regularize_scale': True, 'scale_rate_l1': 0.006225497041894772, 'learning_rate': 0.0021427587352087774}\n",
      "   number      value             datetime_start          datetime_complete  \\\n",
      "0       0  17.902987 2026-01-19 13:23:13.467814 2026-01-19 13:25:07.736920   \n",
      "1       1   8.372637 2026-01-19 13:25:07.753321 2026-01-19 13:26:43.051764   \n",
      "2       2  16.027928 2026-01-19 13:26:43.068741 2026-01-19 13:28:24.278762   \n",
      "3       3  50.912286 2026-01-19 13:28:24.296311 2026-01-19 13:30:14.447552   \n",
      "\n",
      "                duration  params_Coal  params_Dummy  params_EUA  params_Gas  \\\n",
      "0 0 days 00:01:54.269106         True         False        True        True   \n",
      "1 0 days 00:01:35.298443         True          True       False       False   \n",
      "2 0 days 00:01:41.210021         True         False        True        True   \n",
      "3 0 days 00:01:50.151241        False         False        True        True   \n",
      "\n",
      "   params_Oil  ...  params_price_D-3  params_price_D-7  \\\n",
      "0        True  ...              True              True   \n",
      "1        True  ...             False             False   \n",
      "2        True  ...             False              True   \n",
      "3       False  ...              True              True   \n",
      "\n",
      "  params_regularize_h1_activation params_regularize_h1_kernel  \\\n",
      "0                            True                        True   \n",
      "1                            True                       False   \n",
      "2                           False                        True   \n",
      "3                            True                        True   \n",
      "\n",
      "   params_regularize_h2_activation  params_regularize_h2_kernel  \\\n",
      "0                             True                        False   \n",
      "1                             True                        False   \n",
      "2                             True                        False   \n",
      "3                            False                         True   \n",
      "\n",
      "   params_regularize_loc  params_regularize_scale  params_scale_rate_l1  \\\n",
      "0                  False                    False                   NaN   \n",
      "1                  False                     True              0.006225   \n",
      "2                   True                     True              0.002084   \n",
      "3                   True                     True              0.005147   \n",
      "\n",
      "      state  \n",
      "0  COMPLETE  \n",
      "1  COMPLETE  \n",
      "2  COMPLETE  \n",
      "3  COMPLETE  \n",
      "\n",
      "[4 rows x 39 columns]\n",
      "==================== Training/Evaluation on rolling window ====================\n"
     ]
    }
   ],
   "source": [
    "%pip install optuna\n",
    "!git clone https://github.com/bekzod-amonov/ddnn-execute-once.git\n",
    "%cd ddnn-execute-once\n",
    "!ls\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.compat.v2 as tf\n",
    "tf.enable_v2_behavior()\n",
    "import tensorflow_probability as tfp  \n",
    "from tensorflow_probability import distributions as tfd\n",
    "import tf_keras as keras\n",
    "from multiprocessing import Pool\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "import logging\n",
    "import sys\n",
    "import os, getpass\n",
    "import glob\n",
    "import optuna\n",
    "from optuna.trial import TrialState\n",
    "import time\n",
    "import math\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "print(f\"==================== Obtaining Hyperparameters ====================\")\n",
    "\n",
    "distribution = 'Normal'\n",
    "paramcount = {'Normal': 2,\n",
    "              'StudentT': 3,\n",
    "              'JSU': 4,\n",
    "              'SinhArcsinh': 4,\n",
    "              'NormalInverseGaussian': 4,\n",
    "              'Point': None}\n",
    "val_multi = 3 # int for # of re-trains - 1 corresponds to old approach\n",
    "val_window = 364 // val_multi\n",
    "\n",
    "if not os.path.exists(f'../trialfiles'):\n",
    "    os.mkdir(f'../trialfiles')\n",
    "\n",
    "INP_SIZE = 221\n",
    "activations = ['sigmoid', 'relu', 'elu', 'tanh', 'softplus', 'softmax']\n",
    "\n",
    "binopt = [True, False]\n",
    "\n",
    "cty = 'ES'\n",
    "repo_root = Path.cwd()\n",
    "storeDBintmp = False\n",
    "\n",
    "print(cty, distribution)\n",
    "\n",
    "if cty != 'ES':\n",
    "    raise ValueError('Incorrect country')\n",
    "if distribution not in paramcount:\n",
    "    raise ValueError('Incorrect distribution')\n",
    "\n",
    "# read data file\n",
    "data       = pd.read_csv(repo_root / \"Datasets\" / f\"{cty}.csv\", index_col=0) \n",
    "data.index = [datetime.strptime(e, '%Y-%m-%d %H:%M:%S') for e in data.index]\n",
    "data = data.iloc[:4*364*24] # take the first 4 years - 1456 days\n",
    "\n",
    "def objective(trial):\n",
    "    \n",
    "    # prepare the input/output dataframes\n",
    "    Y = np.zeros((1456, 24))\n",
    "    Yf = np.zeros((364, 24))\n",
    "    for d in range(1456):\n",
    "        Y[d, :] = data.loc[data.index[d*24:(d+1)*24], 'Price'].to_numpy()\n",
    "    # Y = Y[7:, :] # skip first 7 days\n",
    "    for d in range(364):\n",
    "        Yf[d, :] = data.loc[data.index[(d+1092)*24:(d+1093)*24], 'Price'].to_numpy()\n",
    "    # \n",
    "    # build X \n",
    "    X = np.zeros((1092+364, INP_SIZE))\n",
    "\n",
    "    for d in range(7, 1092+364):\n",
    "      \n",
    "        X[d, :24] = data.loc[data.index[(d-1)*24:(d)*24], 'Price'].to_numpy() # D-1 price\n",
    "        X[d, 24:48] = data.loc[data.index[(d-2)*24:(d-1)*24], 'Price'].to_numpy() # D-2 price\n",
    "        X[d, 48:72] = data.loc[data.index[(d-3)*24:(d-2)*24], 'Price'].to_numpy() # D-3 price\n",
    "        X[d, 72:96] = data.loc[data.index[(d-7)*24:(d-6)*24], 'Price'].to_numpy() # D-7 price\n",
    "        X[d, 96:120] = data.loc[data.index[(d)*24:(d+1)*24], data.columns[1]].to_numpy() # D load forecast\n",
    "        X[d, 120:144] = data.loc[data.index[(d-1)*24:(d)*24], data.columns[1]].to_numpy() # D-1 load forecast\n",
    "        X[d, 144:168] = data.loc[data.index[(d-7)*24:(d-6)*24], data.columns[1]].to_numpy() # D-7 load forecast\n",
    "        X[d, 168:192] = data.loc[data.index[(d)*24:(d+1)*24], data.columns[2]].to_numpy() # D RES sum forecast\n",
    "        X[d, 192:216] = data.loc[data.index[(d-1)*24:(d)*24], data.columns[2]].to_numpy() # D-1 RES sum forecast\n",
    "        \n",
    "        # # original aouthors code\n",
    "        # X[d, 216] = data.loc[data.index[(d-2)*24:(d-1)*24:24], data.columns[3]].to_numpy() # D-2 EUA\n",
    "        # X[d, 217] = data.loc[data.index[(d-2)*24:(d-1)*24:24], data.columns[4]].to_numpy() # D-2 API2_Coal\n",
    "        # X[d, 218] = data.loc[data.index[(d-2)*24:(d-1)*24:24], data.columns[5]].to_numpy() # D-2 TTF_Gas\n",
    "        # X[d, 219] = data.loc[data.index[(d-2)*24:(d-1)*24:24], data.columns[6]].to_numpy() # D-2 Brent oil\n",
    "        \n",
    "        X[d, 216] = data.loc[data.index[(d-2)*24:(d-1)*24:24], data.columns[3]].to_numpy().item()\n",
    "        X[d, 217] = data.loc[data.index[(d-2)*24:(d-1)*24:24], data.columns[4]].to_numpy().item()\n",
    "        X[d, 218] = data.loc[data.index[(d-2)*24:(d-1)*24:24], data.columns[5]].to_numpy().item()\n",
    "        X[d, 219] = data.loc[data.index[(d-2)*24:(d-1)*24:24], data.columns[6]].to_numpy().item()\n",
    "        \n",
    "        # authors code\n",
    "        X[d, 220] = data.index[d].weekday()\n",
    "\n",
    "    # '''\n",
    "    # input feature selection\n",
    "    colmask = [False] * INP_SIZE\n",
    "    if trial.suggest_categorical('price_D-1', binopt):\n",
    "        colmask[:24] = [True] * 24\n",
    "    if trial.suggest_categorical('price_D-2', binopt):\n",
    "        colmask[24:48] = [True] * 24\n",
    "    if trial.suggest_categorical('price_D-3', binopt):\n",
    "        colmask[48:72] = [True] * 24\n",
    "    if trial.suggest_categorical('price_D-7', binopt):\n",
    "        colmask[72:96] = [True] * 24\n",
    "    if trial.suggest_categorical('load_D', binopt):\n",
    "        colmask[96:120] = [True] * 24\n",
    "    if trial.suggest_categorical('load_D-1', binopt):\n",
    "        colmask[120:144] = [True] * 24\n",
    "    if trial.suggest_categorical('load_D-7', binopt):\n",
    "        colmask[144:168] = [True] * 24\n",
    "    if trial.suggest_categorical('RES_D', binopt):\n",
    "        colmask[168:192] = [True] * 24\n",
    "    if trial.suggest_categorical('RES_D-1', binopt):\n",
    "        colmask[192:216] = [True] * 24\n",
    "    if trial.suggest_categorical('EUA', binopt):\n",
    "        colmask[216] = True\n",
    "    if trial.suggest_categorical('Coal', binopt):\n",
    "        colmask[217] = True\n",
    "    if trial.suggest_categorical('Gas', binopt):\n",
    "        colmask[218] = True\n",
    "    if trial.suggest_categorical('Oil', binopt):\n",
    "        colmask[219] = True\n",
    "    if trial.suggest_categorical('Dummy', binopt):\n",
    "        colmask[220] = True\n",
    "    X = X[:, colmask]\n",
    "    \n",
    "    # '''\n",
    "    Xwhole = X.copy()\n",
    "    Ywhole = Y.copy()\n",
    "    Yfwhole = Yf.copy()\n",
    "    metrics_sub = []\n",
    "    \n",
    "    for train_no in range(val_multi):\n",
    "        \n",
    "        start = val_window * train_no\n",
    "        X = Xwhole[start:1092+start, :]\n",
    "        Xf = Xwhole[1092+start:1092+start+val_window, :]\n",
    "        Y = Ywhole[start:1092+start, :]\n",
    "        Yf = Ywhole[1092+start:1092+start+val_window, :]\n",
    "        X = X[7:1092, :]\n",
    "        Y = Y[7:1092, :]\n",
    "        \n",
    "        # begin building a model\n",
    "        inputs = keras.Input(shape=(X.shape[1],)) # <= INP_SIZE as some columns might have been turned off\n",
    "        # batch normalization\n",
    "        # we decided to always normalize the inputs\n",
    "        batchnorm = True #trial.suggest_categorical('batch_normalization', [True, False])\n",
    "        if batchnorm:\n",
    "            norm = keras.layers.BatchNormalization()(inputs)\n",
    "            last_layer = norm\n",
    "        else:\n",
    "            last_layer = inputs\n",
    "        # dropout\n",
    "        dropout = trial.suggest_categorical('dropout', binopt)\n",
    "        if dropout:\n",
    "            rate = trial.suggest_float('dropout_rate', 0, 1)\n",
    "            drop = keras.layers.Dropout(rate)(last_layer)\n",
    "            last_layer = drop\n",
    "        # regularization of 1st hidden layer,\n",
    "        #activation - output, kernel - weights/parameters of input\n",
    "        regularize_h1_activation = trial.suggest_categorical('regularize_h1_activation', binopt)\n",
    "        regularize_h1_kernel = trial.suggest_categorical('regularize_h1_kernel', binopt)\n",
    "        h1_activation_rate = (0.0 if not regularize_h1_activation\n",
    "                              else trial.suggest_float('h1_activation_rate_l1', 1e-5, 1e-2, log=True))\n",
    "        h1_kernel_rate = (0.0 if not regularize_h1_kernel\n",
    "                          else trial.suggest_float('h1_kernel_rate_l1', 1e-5, 1e-2, log=True))\n",
    "        # define 1st hidden layer with regularization\n",
    "        hidden = keras.layers.Dense(trial.suggest_int('neurons_1', 256, 512, log=False),\n",
    "                                    activation=trial.suggest_categorical('activation_1', activations),\n",
    "                                    # kernel_initializer='ones',\n",
    "                                    kernel_regularizer=keras.regularizers.L1(h1_kernel_rate),\n",
    "                                    activity_regularizer=keras.regularizers.L1(h1_activation_rate))(last_layer)\n",
    "        # regularization of 2nd hidden layer,\n",
    "        #activation - output, kernel - weights/parameters of input\n",
    "        regularize_h2_activation = trial.suggest_categorical('regularize_h2_activation', binopt)\n",
    "        regularize_h2_kernel = trial.suggest_categorical('regularize_h2_kernel', binopt)\n",
    "        h2_activation_rate = (0.0 if not regularize_h2_activation\n",
    "                              else trial.suggest_float('h2_activation_rate_l1', 1e-5, 1e-2, log=True))\n",
    "        h2_kernel_rate = (0.0 if not regularize_h2_kernel\n",
    "                          else trial.suggest_float('h2_kernel_rate_l1', 1e-5, 1e-2, log=True))\n",
    "        # define 2nd hidden layer with regularization\n",
    "        hidden = keras.layers.Dense(trial.suggest_int('neurons_2', 256, 512, log=False),\n",
    "                                    activation=trial.suggest_categorical('activation_2', activations),\n",
    "                                    # kernel_initializer='ones',\n",
    "                                    kernel_regularizer=keras.regularizers.L1(h2_kernel_rate),\n",
    "                                    activity_regularizer=keras.regularizers.L1(h2_activation_rate))(hidden)\n",
    "        if paramcount[distribution] is None:\n",
    "            outputs = tfp.layers.DistributionLambda(lambda t: tfd.Normal(loc=t[..., :24],scale=1e-3 + 3.0 * tf.nn.softplus(t[..., 24:])))(linear)\n",
    "            # # authors one\n",
    "            # outputs = keras.layers.Dense(24, activation='linear')(hidden)\n",
    "            \n",
    "            model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "            model.compile(optimizer=keras.optimizers.legacy.Adam(trial.suggest_float('learning_rate', 1e-5, 1e-1, log=True)),\n",
    "                          # loss=lambda y, rv_y: -rv_y.log_prob(y),\n",
    "                          loss='mae',\n",
    "                          metrics='mae')\n",
    "        else:\n",
    "            # now define parameter layers with their regularization\n",
    "            param_layers = []\n",
    "            param_names = [\"loc\", \"scale\", \"tailweight\", \"skewness\"]\n",
    "            for p in range(paramcount[distribution]):\n",
    "                # regularize_param_kernel = True\n",
    "                # param_kernel_rate = 0.1\n",
    "                regularize_param_kernel = trial.suggest_categorical('regularize_'+param_names[p], binopt)\n",
    "                param_kernel_rate = (0.0 if not regularize_param_kernel\n",
    "                                     else trial.suggest_float(param_names[p]+'_rate_l1', 1e-5, 1e-2, log=True))\n",
    "                param_layers.append(keras.layers.Dense(\n",
    "                    24, activation='linear', # kernel_initializer='ones',\n",
    "                    kernel_regularizer=keras.regularizers.L1(param_kernel_rate))(hidden))\n",
    "            # concatenate the parameter layers to one\n",
    "            linear = tf.keras.layers.concatenate(param_layers)\n",
    "            # define outputs\n",
    "            if distribution == 'Normal':\n",
    "                outputs = tfp.layers.DistributionLambda(\n",
    "                        lambda t: tfd.Normal(\n",
    "                            loc=t[..., :24],\n",
    "                            scale = 1e-3 + 3 * tf.math.softplus(t[..., 24:])))(linear)\n",
    "            elif distribution == 'StudentT':\n",
    "                outputs = tfp.layers.DistributionLambda(\n",
    "                        lambda t: tfd.StudentT(\n",
    "                            loc=t[..., :24],\n",
    "                            scale=1e-3 + 3 * tf.math.softplus(t[..., 24:48]),\n",
    "                            df=1 + 3 * tf.math.softplus(t[..., 48:])))(linear)\n",
    "            elif distribution == 'JSU':\n",
    "                outputs = tfp.layers.DistributionLambda(\n",
    "                        lambda t: tfd.JohnsonSU(\n",
    "                            loc=t[..., :24],\n",
    "                            scale=1e-3 + 3 * tf.math.softplus(t[..., 24:48]),\n",
    "                            tailweight= 1 + 3 * tf.math.softplus(t[..., 48:72]),\n",
    "                            skewness=t[..., 72:]))(linear)\n",
    "            elif distribution == 'SinhArcsinh':\n",
    "                outputs = tfp.layers.DistributionLambda(\n",
    "                        lambda t: tfd.SinhArcsinh(\n",
    "                            loc=t[..., :24],\n",
    "                            scale=1e-3 + 3 * tf.math.softplus(t[..., 24:48]),\n",
    "                            tailweight=1e-3 + 3 * tf.math.softplus(t[..., 48:72]),\n",
    "                            skewness=t[..., 72:]))(linear)\n",
    "            elif distribution == 'NormalInverseGaussian':\n",
    "                outputs = tfp.layers.DistributionLambda(\n",
    "                        lambda t: tfd.NormalInverseGaussian(\n",
    "                            loc=t[..., :24],\n",
    "                            scale=1e-3 + 3 * tf.math.softplus(t[..., 24:48]),\n",
    "                            tailweight=1e-3 + 3 * tf.math.softplus(t[..., 48:72]),\n",
    "                            skewness=t[..., 72:]))(linear)\n",
    "            else:\n",
    "                raise ValueError(f'Incorrect distribution {distribution}')\n",
    "            model = keras.Model(inputs = inputs, outputs=outputs)\n",
    "            model.compile(optimizer=keras.optimizers.legacy.Adam(trial.suggest_float('learning_rate', 1e-5, 1e-2, log=True)),\n",
    "                          loss=lambda y, rv_y: -rv_y.log_prob(y),\n",
    "                          metrics='mae')\n",
    "        # '''\n",
    "\n",
    "        # define callbacks\n",
    "        callbacks = [keras.callbacks.EarlyStopping(patience=50, restore_best_weights=True)]    \n",
    "        model.fit(X, Y, epochs=300, validation_data=(Xf, Yf), callbacks=callbacks, batch_size=256, verbose=2)\n",
    "\n",
    "        metrics = model.evaluate(Xf, Yf, verbose=0) # for point its a list of one [loss, MAE] as \n",
    "        metrics_sub.append(metrics[0])\n",
    "        # we optimize the returned value, -1 will always take the model with best MAE\n",
    "    return np.mean(metrics_sub)\n",
    "\n",
    "#optuna.logging.get_logger('optuna').addHandler(logging.StreamHandler(sys.stdout))\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "study_name = f'FINAL_DE_selection_prob_{distribution.lower()}'\n",
    "if storeDBintmp:\n",
    "    storage_name = f'sqlite:////tmp/{study_name}'\n",
    "else:\n",
    "    storage_name = f'sqlite:///../trialfiles/{study_name}'\n",
    "# below calls to create either random sampler and default (tree parzen estimator)\n",
    "# study can be resumed using a different one\n",
    "# (or one process can sample randomly, the second one run the TPE sampler at the same time)\n",
    "# study = optuna.create_study(study_name=study_name, storage=storage_name, load_if_exists=True, sampler=optuna.samplers.RandomSampler())\n",
    "study = optuna.create_study(study_name=study_name, storage=storage_name, load_if_exists=True)\n",
    "study.optimize(objective, n_trials=4, show_progress_bar=False)\n",
    "best_params = study.best_params\n",
    "print(best_params)\n",
    "print(study.trials_dataframe())\n",
    "if storeDBintmp:\n",
    "    print('Trials DB stored in /tmp')\n",
    "    \n",
    "print(f\"==================== Training/Evaluation on rolling window ====================\")\n",
    "\n",
    "if not os.path.exists(f'../forecasts_probNN_{distribution.lower()}'):\n",
    "    os.mkdir(f'../forecasts_probNN_{distribution.lower()}')\n",
    "\n",
    "if not os.path.exists(f'../distparams_probNN_{distribution.lower()}'):\n",
    "    os.mkdir(f'../distparams_probNN_{distribution.lower()}')\n",
    "\n",
    "if not os.path.exists(f'../trialfiles'):\n",
    "    os.mkdir(f'../trialfiles')\n",
    "\n",
    "def runoneday(inp):\n",
    "    params, dayno = inp\n",
    "    df = data.iloc[dayno*24:dayno*24+1456*24+24]\n",
    "    # prepare the input/output dataframes\n",
    "    Y = np.zeros((1456, 24))\n",
    "    # Yf = np.zeros((1, 24)) # no Yf for rolling prediction\n",
    "    for d in range(1456):\n",
    "        Y[d, :] = df.loc[df.index[d*24:(d+1)*24], 'Price'].to_numpy()\n",
    "    Y = Y[7:, :] # skip first 7 days\n",
    "    # for d in range(1):\n",
    "    #     Yf[d, :] = df.loc[df.index[(d+1092)*24:(d+1093)*24], 'Price'].to_numpy()\n",
    "    X = np.zeros((1456+1, INP_SIZE))\n",
    "    for d in range(7, 1456+1):\n",
    "        X[d, :24] = df.loc[df.index[(d-1)*24:(d)*24], 'Price'].to_numpy() # D-1 price\n",
    "        X[d, 24:48] = df.loc[df.index[(d-2)*24:(d-1)*24], 'Price'].to_numpy() # D-2 price\n",
    "        X[d, 48:72] = df.loc[df.index[(d-3)*24:(d-2)*24], 'Price'].to_numpy() # D-3 price\n",
    "        X[d, 72:96] = df.loc[df.index[(d-7)*24:(d-6)*24], 'Price'].to_numpy() # D-7 price\n",
    "        X[d, 96:120] = df.loc[df.index[(d)*24:(d+1)*24], df.columns[1]].to_numpy() # D load forecast\n",
    "        X[d, 120:144] = df.loc[df.index[(d-1)*24:(d)*24], df.columns[1]].to_numpy() # D-1 load forecast\n",
    "        X[d, 144:168] = df.loc[df.index[(d-7)*24:(d-6)*24], df.columns[1]].to_numpy() # D-7 load forecast\n",
    "        X[d, 168:192] = df.loc[df.index[(d)*24:(d+1)*24], df.columns[2]].to_numpy() # D RES sum forecast\n",
    "        X[d, 192:216] = df.loc[df.index[(d-1)*24:(d)*24], df.columns[2]].to_numpy() # D-1 RES sum forecast\n",
    "        # #original author's code\n",
    "        # X[d, 216] = df.loc[df.index[(d-2)*24:(d-1)*24:24], df.columns[3]].to_numpy() # D-2 EUA\n",
    "        # X[d, 217] = df.loc[df.index[(d-2)*24:(d-1)*24:24], df.columns[4]].to_numpy() # D-2 API2_Coal\n",
    "        # X[d, 218] = df.loc[df.index[(d-2)*24:(d-1)*24:24], df.columns[5]].to_numpy() # D-2 TTF_Gas\n",
    "        # X[d, 219] = data.loc[data.index[(d-2)*24:(d-1)*24:24], data.columns[6]].to_numpy() # D-2 Brent oil\n",
    "        X[d, 216] = data.loc[data.index[(d-2)*24:(d-1)*24:24], data.columns[3]].to_numpy().item()\n",
    "        X[d, 217] = data.loc[data.index[(d-2)*24:(d-1)*24:24], data.columns[4]].to_numpy().item()\n",
    "        X[d, 218] = data.loc[data.index[(d-2)*24:(d-1)*24:24], data.columns[5]].to_numpy().item()\n",
    "        X[d, 219] = data.loc[data.index[(d-2)*24:(d-1)*24:24], data.columns[6]].to_numpy().item()\n",
    "        # original author's code\n",
    "        X[d, 220] = data.index[d].weekday()\n",
    "    \n",
    "    # '''\n",
    "    # input feature selection\n",
    "    colmask = [False] * INP_SIZE\n",
    "    if params['price_D-1']:\n",
    "        colmask[:24] = [True] * 24\n",
    "    if params['price_D-2']:\n",
    "        colmask[24:48] = [True] * 24\n",
    "    if params['price_D-3']:\n",
    "        colmask[48:72] = [True] * 24\n",
    "    if params['price_D-7']:\n",
    "        colmask[72:96] = [True] * 24\n",
    "    if params['load_D']:\n",
    "        colmask[96:120] = [True] * 24\n",
    "    if params['load_D-1']:\n",
    "        colmask[120:144] = [True] * 24\n",
    "    if params['load_D-7']:\n",
    "        colmask[144:168] = [True] * 24\n",
    "    if params['RES_D']:\n",
    "        colmask[168:192] = [True] * 24\n",
    "    if params['RES_D-1']:\n",
    "        colmask[192:216] = [True] * 24\n",
    "    if params['EUA']:\n",
    "        colmask[216] = True\n",
    "    if params['Coal']:\n",
    "        colmask[217] = True\n",
    "    if params['Gas']:\n",
    "        colmask[218] = True\n",
    "    if params['Oil']:\n",
    "        colmask[219] = True\n",
    "    if params['Dummy']:\n",
    "        colmask[220] = True\n",
    "    X = X[:, colmask]\n",
    "    # '''\n",
    "    Xf = X[-1:, :]\n",
    "    X = X[7:-1, :]\n",
    "    # begin building a model\n",
    "    inputs = keras.Input(X.shape[1]) # <= INP_SIZE as some columns might have been turned off\n",
    "    # batch normalization\n",
    "    batchnorm = True#params['batch_normalization'] # trial.suggest_categorical('batch_normalization', [True, False])\n",
    "    if batchnorm:\n",
    "        norm = keras.layers.BatchNormalization()(inputs)\n",
    "        last_layer = norm\n",
    "    else:\n",
    "        last_layer = inputs\n",
    "    # dropout\n",
    "    dropout = params['dropout'] # trial.suggest_categorical('dropout', [True, False])\n",
    "    if dropout:\n",
    "        rate = params['dropout_rate'] # trial.suggest_float('dropout_rate', 0, 1)\n",
    "        drop = keras.layers.Dropout(rate)(last_layer)\n",
    "        last_layer = drop\n",
    "    # regularization of 1st hidden layer, \n",
    "    #activation - output, kernel - weights/parameters of input\n",
    "    regularize_h1_activation = params['regularize_h1_activation']\n",
    "    regularize_h1_kernel = params['regularize_h1_kernel']\n",
    "    h1_activation_rate = (0.0 if not regularize_h1_activation \n",
    "                          else params['h1_activation_rate_l1'])\n",
    "    h1_kernel_rate = (0.0 if not regularize_h1_kernel \n",
    "                      else params['h1_kernel_rate_l1'])\n",
    "    # define 1st hidden layer with regularization\n",
    "    hidden = keras.layers.Dense(params['neurons_1'], \n",
    "                                activation=params['activation_1'],\n",
    "                                # kernel_initializer='ones',\n",
    "                                kernel_regularizer=keras.regularizers.L1(h1_kernel_rate),\n",
    "                                activity_regularizer=keras.regularizers.L1(h1_activation_rate))(last_layer)\n",
    "    # regularization of 2nd hidden layer, \n",
    "    #activation - output, kernel - weights/parameters of input\n",
    "    regularize_h2_activation = params['regularize_h2_activation']\n",
    "    regularize_h2_kernel = params['regularize_h2_kernel']\n",
    "    h2_activation_rate = (0.0 if not regularize_h2_activation \n",
    "                          else params['h2_activation_rate_l1'])\n",
    "    h2_kernel_rate = (0.0 if not regularize_h2_kernel \n",
    "                      else params['h2_kernel_rate_l1'])\n",
    "    # define 2nd hidden layer with regularization\n",
    "    hidden = keras.layers.Dense(params['neurons_2'], \n",
    "                                activation=params['activation_2'],\n",
    "                                # kernel_initializer='ones',\n",
    "                                kernel_regularizer=keras.regularizers.L1(h2_kernel_rate),\n",
    "                                activity_regularizer=keras.regularizers.L1(h2_activation_rate))(hidden)\n",
    "    if paramcount[distribution] is None:\n",
    "        outputs = keras.layers.Dense(24, activation='linear')(hidden)\n",
    "        model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "        model.compile(optimizer=keras.optimizers.Adam(params['learning_rate']),\n",
    "                      loss='mae',\n",
    "                      metrics='mae')\n",
    "    else:\n",
    "        # now define parameter layers with their regularization\n",
    "        param_layers = []\n",
    "        param_names = [\"loc\", \"scale\", \"tailweight\", \"skewness\"]\n",
    "        for p in range(paramcount[distribution]):\n",
    "            regularize_param_kernel = params['regularize_'+param_names[p]]\n",
    "            param_kernel_rate = (0.0 if not regularize_param_kernel \n",
    "                                 else params[str(param_names[p])+'_rate_l1'])\n",
    "            param_layers.append(keras.layers.Dense(\n",
    "                24, activation='linear', # kernel_initializer='ones',\n",
    "                kernel_regularizer=keras.regularizers.L1(param_kernel_rate))(hidden))\n",
    "        # concatenate the parameter layers to one\n",
    "        linear = tf.keras.layers.concatenate(param_layers)\n",
    "        # define outputs\n",
    "        if distribution == 'Normal':\n",
    "            outputs = tfp.layers.DistributionLambda(\n",
    "                    lambda t: tfd.Normal(\n",
    "                        loc=t[..., :24],\n",
    "                        scale = 1e-3 + 3 * tf.math.softplus(t[..., 24:])))(linear)\n",
    "        elif distribution == 'StudentT':\n",
    "            outputs = tfp.layers.DistributionLambda(\n",
    "                    lambda t: tfd.StudentT(\n",
    "                        loc=t[..., :24],\n",
    "                        scale=1e-3 + 3 * tf.math.softplus(t[..., 24:48]),\n",
    "                        df=1 + 3 * tf.math.softplus(t[..., 48:])))(linear)\n",
    "        elif distribution == 'JSU':\n",
    "            outputs = tfp.layers.DistributionLambda(\n",
    "                    lambda t: tfd.JohnsonSU(\n",
    "                        loc=t[..., :24],\n",
    "                        scale=1e-3 + 3 * tf.math.softplus(t[..., 24:48]),\n",
    "                        tailweight= 1 + 3 * tf.math.softplus(t[..., 48:72]),\n",
    "                        skewness=t[..., 72:]))(linear)\n",
    "        elif distribution == 'SinhArcsinh':\n",
    "            outputs = tfp.layers.DistributionLambda(\n",
    "                    lambda t: tfd.SinhArcsinh(\n",
    "                        loc=t[..., :24],\n",
    "                        scale=1e-3 + 3 * tf.math.softplus(t[..., 24:48]),\n",
    "                        tailweight=1e-3 + 3 * tf.math.softplus(t[..., 48:72]),\n",
    "                        skewness=t[..., 72:]))(linear)\n",
    "        elif distribution == 'NormalInverseGaussian':\n",
    "            outputs = tfp.layers.DistributionLambda(\n",
    "                    lambda t: tfd.NormalInverseGaussian(\n",
    "                        loc=t[..., :24],\n",
    "                        scale=1e-3 + 3 * tf.math.softplus(t[..., 24:48]),\n",
    "                        tailweight=1e-3 + 3 * tf.math.softplus(t[..., 48:72]),\n",
    "                        skewness=t[..., 72:]))(linear) \n",
    "        else:\n",
    "            raise ValueError(f'Incorrect distribution {distribution}')\n",
    "        model = keras.Model(inputs = inputs, outputs=outputs)\n",
    "        model.compile(optimizer=keras.optimizers.Adam(params['learning_rate']),\n",
    "                      loss=lambda y, rv_y: -rv_y.log_prob(y),\n",
    "                      metrics='mae')\n",
    "    # '''\n",
    "    # define callbacks\n",
    "    callbacks = [keras.callbacks.EarlyStopping(patience=50, restore_best_weights=True)]\n",
    "    perm = np.random.permutation(np.arange(X.shape[0]))\n",
    "    VAL_DATA = .2\n",
    "    trainsubset = perm[:int((1 - VAL_DATA)*len(perm))]\n",
    "    valsubset = perm[int((1 - VAL_DATA)*len(perm)):]\n",
    "    model.fit(X[trainsubset], Y[trainsubset], epochs=1500, validation_data=(X[valsubset], Y[valsubset]), callbacks=callbacks, batch_size=32, verbose=False)\n",
    "    \n",
    "    # metrics = model.evaluate(Xf, Yf) # for point its a list of one [loss, MAE]\n",
    "    # we optimize the returned value, -1 will always take the model with best MAE\n",
    "\n",
    "    # pred = model.predict(Xf)[0]\n",
    "    if paramcount[distribution] is not None:\n",
    "        dist = model(Xf)\n",
    "        if distribution == 'Normal':\n",
    "            getters = {'loc': dist.loc, 'scale': dist.scale}\n",
    "        elif distribution == 'StudentT':\n",
    "            getters = {'loc': dist.loc, 'scale': dist.scale, 'df': dist.df}\n",
    "        elif distribution in {'JSU', 'SinhArcsinh', 'NormalInverseGaussian'}:\n",
    "            getters = {'loc': dist.loc, 'scale': dist.scale, \n",
    "                       'tailweight': dist.tailweight, 'skewness': dist.skewness}\n",
    "        print(getters)\n",
    "        params = {k: [float(e) for e in v.numpy()[0]] for k, v in getters.items()}\n",
    "        print(params)\n",
    "        json.dump(params, open(os.path.join(f'../distparams_probNN_{distribution.lower()}', datetime.strftime(df.index[-24], '%Y-%m-%d')), 'w'))\n",
    "        pred = model.predict(np.tile(Xf, (10000, 1)))\n",
    "        predDF = pd.DataFrame(index=df.index[-24:])\n",
    "        predDF['real'] = df.loc[df.index[-24:], 'Price'].to_numpy()\n",
    "        predDF['forecast'] = pd.NA\n",
    "        predDF.loc[predDF.index[:], 'forecast'] = pred.mean(0)\n",
    "        # predDF.to_csv(os.path.join('../forecasts', datetime.strftime(df.index[-24], '%Y-%m-%d')))\n",
    "        np.savetxt(os.path.join(f'../forecasts_probNN_{distribution.lower()}', datetime.strftime(df.index[-24], '%Y-%m-%d')), pred, delimiter=',', fmt='%.3f')\n",
    "    else:\n",
    "        predDF = pd.DataFrame(index=df.index[-24:])\n",
    "        predDF['real'] = df.loc[df.index[-24:], 'Price'].to_numpy()\n",
    "        predDF['forecast'] = pd.NA\n",
    "        predDF.loc[predDF.index[:], 'forecast'] = model.predict(Xf)[0]\n",
    "        pred = model.predict(Xf)\n",
    "        np.savetxt(os.path.join(f'../forecasts_probNN_{distribution.lower()}', datetime.strftime(df.index[-24], '%Y-%m-%d')), pred, delimiter=',', fmt='%.3f')\n",
    "    print(predDF)\n",
    "    return predDF\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9002bd4f",
   "metadata": {},
   "source": [
    "### Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b305dcc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob\n",
    "\n",
    "base = \"/Users/bekzodamonov/Documents/GitHub/distributionalnn-execute-once/trialfiles\"\n",
    "\n",
    "print(\"BASE list:\")\n",
    "for name in sorted(os.listdir(base)):\n",
    "    path = os.path.join(base, name)\n",
    "    print(f\"{name:35s}  {'DIR' if os.path.isdir(path) else 'FILE'}\")\n",
    "\n",
    "def is_sqlite_file(path: str) -> bool:\n",
    "    if not os.path.isfile(path):\n",
    "        return False\n",
    "    try:\n",
    "        with open(path, \"rb\") as f:\n",
    "            header = f.read(16)\n",
    "        return header.startswith(b\"SQLite format 3\")\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "# 1) Find sqlite files directly under base (no extension needed)\n",
    "sqlite_like = []\n",
    "for name in os.listdir(base):\n",
    "    p = os.path.join(base, name)\n",
    "    if is_sqlite_file(p):\n",
    "        sqlite_like.append(p)\n",
    "\n",
    "print(\"\\nSQLite files directly under BASE:\")\n",
    "print(sqlite_like)\n",
    "\n",
    "# 2) Find sqlite files anywhere under base (recursive)\n",
    "sqlite_like_recursive = []\n",
    "for root, dirs, files in os.walk(base):\n",
    "    for fn in files:\n",
    "        p = os.path.join(root, fn)\n",
    "        if is_sqlite_file(p):\n",
    "            sqlite_like_recursive.append(p)\n",
    "\n",
    "print(\"\\nSQLite files under BASE (recursive):\")\n",
    "print(sqlite_like_recursive[:50], \" ... total:\", len(sqlite_like_recursive))\n",
    "\n",
    "# 3) Now ACTUALLY list inside jsu1\n",
    "trial_dir = os.path.join(base, \"FINAL_DE_selection_prob_jsu1\")\n",
    "print(\"\\nInside jsu1:\")\n",
    "print(sorted(os.listdir(trial_dir))[:100])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09cf0c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"TF:\", tf.__version__)\n",
    "print(\"Devices:\", tf.config.list_physical_devices())\n",
    "print(\"GPUs:\", tf.config.list_physical_devices(\"GPU\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21346bb4",
   "metadata": {},
   "source": [
    "## Rolling predictions & Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bbd0e63",
   "metadata": {},
   "source": [
    "### setup and diagnostics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3823232b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# upgrade optuna storage (sqllineDB)\n",
    "import optuna, os\n",
    "from optuna.trial import TrialState\n",
    "\n",
    "base = \"/Users/bekzodamonov/Documents/GitHub/distributionalnn-execute-once/trialfiles\"\n",
    "db_files = sorted([os.path.join(base, f) for f in os.listdir(base)])\n",
    "\n",
    "def summarize_db(db_path):\n",
    "    storage_url = f\"sqlite:///{db_path}\"\n",
    "    print(\"\\n---\", os.path.basename(db_path), \"---\")\n",
    "    try:\n",
    "        summaries = optuna.study.get_all_study_summaries(storage_url)\n",
    "    except RuntimeError as e:\n",
    "        print(\"CANNOT READ (schema mismatch). Fix with:\")\n",
    "        print(f\"  optuna storage upgrade --storage {storage_url}\")\n",
    "        print(\"Error:\", e)\n",
    "        return\n",
    "\n",
    "    if not summaries:\n",
    "        print(\"No studies found in this DB.\")\n",
    "        return\n",
    "\n",
    "    for s in summaries:\n",
    "        study = optuna.load_study(study_name=s.study_name, storage=storage_url)\n",
    "        n_complete = len(study.get_trials(states=(TrialState.COMPLETE,)))\n",
    "        n_fail = len(study.get_trials(states=(TrialState.FAIL,)))\n",
    "        n_running = len(study.get_trials(states=(TrialState.RUNNING,)))\n",
    "        print(f\"study_name={s.study_name} | trials={len(study.trials)} | COMPLETE={n_complete} FAIL={n_fail} RUNNING={n_running}\")\n",
    "        if n_complete:\n",
    "            print(\"  best_value:\", study.best_value)\n",
    "\n",
    "for db in db_files:\n",
    "    summarize_db(db)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8398e93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# author's original code\n",
    "# Accepts arguments:\n",
    "#     cty (currently only DE), default: DE\n",
    "#     distribution (Normal, StudentT, JSU, SinhArcsinh and NormalInverseGaussian), default: Normal\n",
    "\n",
    "distribution = 'Normal'\n",
    "paramcount = {'Normal': 2,\n",
    "              'StudentT': 3,\n",
    "              'JSU': 4,\n",
    "              'SinhArcsinh': 4,\n",
    "              'NormalInverseGaussian': 4,\n",
    "              'Point': None,\n",
    "}\n",
    "\n",
    "INP_SIZE = 221\n",
    "# activations, neurons and params read from the trials info\n",
    "\n",
    "cty = 'DE'\n",
    "\n",
    "if not os.path.exists(f'../forecasts_probNN_{distribution.lower()}'):\n",
    "    os.mkdir(f'../forecasts_probNN_{distribution.lower()}')\n",
    "\n",
    "if not os.path.exists(f'../distparams_probNN_{distribution.lower()}'):\n",
    "    os.mkdir(f'../distparams_probNN_{distribution.lower()}')\n",
    "\n",
    "if not os.path.exists(f'../trialfiles'):\n",
    "    os.mkdir(f'../trialfiles')\n",
    "\n",
    "print(cty, distribution)\n",
    "\n",
    "if cty != 'DE':\n",
    "    raise ValueError('Incorrect country')\n",
    "if distribution not in paramcount:\n",
    "    raise ValueError('Incorrect distribution')\n",
    "\n",
    "# read data file\n",
    "data = pd.read_csv(f'../Datasets/{cty}.csv', index_col=0)\n",
    "data.index = [datetime.strptime(e, '%Y-%m-%d %H:%M:%S') for e in data.index]\n",
    "# data = data.iloc[:4*364*24] # take the first 4 years - 1456 days\n",
    "\n",
    "def runoneday(inp):\n",
    "    params, dayno = inp\n",
    "    df = data.iloc[dayno*24:dayno*24+1456*24+24]\n",
    "    # prepare the input/output dataframes\n",
    "    Y = np.zeros((1456, 24))\n",
    "    # Yf = np.zeros((1, 24)) # no Yf for rolling prediction\n",
    "    for d in range(1456):\n",
    "        Y[d, :] = df.loc[df.index[d*24:(d+1)*24], 'Price'].to_numpy()\n",
    "    Y = Y[7:, :] # skip first 7 days\n",
    "    # for d in range(1):\n",
    "    #     Yf[d, :] = df.loc[df.index[(d+1092)*24:(d+1093)*24], 'Price'].to_numpy()\n",
    "    X = np.zeros((1456+1, INP_SIZE))\n",
    "    for d in range(7, 1456+1):\n",
    "        X[d, :24] = df.loc[df.index[(d-1)*24:(d)*24], 'Price'].to_numpy() # D-1 price\n",
    "        X[d, 24:48] = df.loc[df.index[(d-2)*24:(d-1)*24], 'Price'].to_numpy() # D-2 price\n",
    "        X[d, 48:72] = df.loc[df.index[(d-3)*24:(d-2)*24], 'Price'].to_numpy() # D-3 price\n",
    "        X[d, 72:96] = df.loc[df.index[(d-7)*24:(d-6)*24], 'Price'].to_numpy() # D-7 price\n",
    "        X[d, 96:120] = df.loc[df.index[(d)*24:(d+1)*24], df.columns[1]].to_numpy() # D load forecast\n",
    "        X[d, 120:144] = df.loc[df.index[(d-1)*24:(d)*24], df.columns[1]].to_numpy() # D-1 load forecast\n",
    "        X[d, 144:168] = df.loc[df.index[(d-7)*24:(d-6)*24], df.columns[1]].to_numpy() # D-7 load forecast\n",
    "        X[d, 168:192] = df.loc[df.index[(d)*24:(d+1)*24], df.columns[2]].to_numpy() # D RES sum forecast\n",
    "        X[d, 192:216] = df.loc[df.index[(d-1)*24:(d)*24], df.columns[2]].to_numpy() # D-1 RES sum forecast\n",
    "        # #original author's code\n",
    "        # X[d, 216] = df.loc[df.index[(d-2)*24:(d-1)*24:24], df.columns[3]].to_numpy() # D-2 EUA\n",
    "        # X[d, 217] = df.loc[df.index[(d-2)*24:(d-1)*24:24], df.columns[4]].to_numpy() # D-2 API2_Coal\n",
    "        # X[d, 218] = df.loc[df.index[(d-2)*24:(d-1)*24:24], df.columns[5]].to_numpy() # D-2 TTF_Gas\n",
    "        # X[d, 219] = data.loc[data.index[(d-2)*24:(d-1)*24:24], data.columns[6]].to_numpy() # D-2 Brent oil\n",
    "        X[d, 216] = data.loc[data.index[(d-2)*24:(d-1)*24:24], data.columns[3]].to_numpy().item()\n",
    "        X[d, 217] = data.loc[data.index[(d-2)*24:(d-1)*24:24], data.columns[4]].to_numpy().item()\n",
    "        X[d, 218] = data.loc[data.index[(d-2)*24:(d-1)*24:24], data.columns[5]].to_numpy().item()\n",
    "        X[d, 219] = data.loc[data.index[(d-2)*24:(d-1)*24:24], data.columns[6]].to_numpy().item()\n",
    "        # original author's code\n",
    "        X[d, 220] = data.index[d].weekday()\n",
    "    \n",
    "    # '''\n",
    "    # input feature selection\n",
    "    colmask = [False] * INP_SIZE\n",
    "    if params['price_D-1']:\n",
    "        colmask[:24] = [True] * 24\n",
    "    if params['price_D-2']:\n",
    "        colmask[24:48] = [True] * 24\n",
    "    if params['price_D-3']:\n",
    "        colmask[48:72] = [True] * 24\n",
    "    if params['price_D-7']:\n",
    "        colmask[72:96] = [True] * 24\n",
    "    if params['load_D']:\n",
    "        colmask[96:120] = [True] * 24\n",
    "    if params['load_D-1']:\n",
    "        colmask[120:144] = [True] * 24\n",
    "    if params['load_D-7']:\n",
    "        colmask[144:168] = [True] * 24\n",
    "    if params['RES_D']:\n",
    "        colmask[168:192] = [True] * 24\n",
    "    if params['RES_D-1']:\n",
    "        colmask[192:216] = [True] * 24\n",
    "    if params['EUA']:\n",
    "        colmask[216] = True\n",
    "    if params['Coal']:\n",
    "        colmask[217] = True\n",
    "    if params['Gas']:\n",
    "        colmask[218] = True\n",
    "    if params['Oil']:\n",
    "        colmask[219] = True\n",
    "    if params['Dummy']:\n",
    "        colmask[220] = True\n",
    "    X = X[:, colmask]\n",
    "    # '''\n",
    "    Xf = X[-1:, :]\n",
    "    X = X[7:-1, :]\n",
    "    # begin building a model\n",
    "    inputs = keras.Input(X.shape[1]) # <= INP_SIZE as some columns might have been turned off\n",
    "    # batch normalization\n",
    "    batchnorm = True#params['batch_normalization'] # trial.suggest_categorical('batch_normalization', [True, False])\n",
    "    if batchnorm:\n",
    "        norm = keras.layers.BatchNormalization()(inputs)\n",
    "        last_layer = norm\n",
    "    else:\n",
    "        last_layer = inputs\n",
    "    # dropout\n",
    "    dropout = params['dropout'] # trial.suggest_categorical('dropout', [True, False])\n",
    "    if dropout:\n",
    "        rate = params['dropout_rate'] # trial.suggest_float('dropout_rate', 0, 1)\n",
    "        drop = keras.layers.Dropout(rate)(last_layer)\n",
    "        last_layer = drop\n",
    "    # regularization of 1st hidden layer, \n",
    "    #activation - output, kernel - weights/parameters of input\n",
    "    regularize_h1_activation = params['regularize_h1_activation']\n",
    "    regularize_h1_kernel = params['regularize_h1_kernel']\n",
    "    h1_activation_rate = (0.0 if not regularize_h1_activation \n",
    "                          else params['h1_activation_rate_l1'])\n",
    "    h1_kernel_rate = (0.0 if not regularize_h1_kernel \n",
    "                      else params['h1_kernel_rate_l1'])\n",
    "    # define 1st hidden layer with regularization\n",
    "    hidden = keras.layers.Dense(params['neurons_1'], \n",
    "                                activation=params['activation_1'],\n",
    "                                # kernel_initializer='ones',\n",
    "                                kernel_regularizer=keras.regularizers.L1(h1_kernel_rate),\n",
    "                                activity_regularizer=keras.regularizers.L1(h1_activation_rate))(last_layer)\n",
    "    # regularization of 2nd hidden layer, \n",
    "    #activation - output, kernel - weights/parameters of input\n",
    "    regularize_h2_activation = params['regularize_h2_activation']\n",
    "    regularize_h2_kernel = params['regularize_h2_kernel']\n",
    "    h2_activation_rate = (0.0 if not regularize_h2_activation \n",
    "                          else params['h2_activation_rate_l1'])\n",
    "    h2_kernel_rate = (0.0 if not regularize_h2_kernel \n",
    "                      else params['h2_kernel_rate_l1'])\n",
    "    # define 2nd hidden layer with regularization\n",
    "    hidden = keras.layers.Dense(params['neurons_2'], \n",
    "                                activation=params['activation_2'],\n",
    "                                # kernel_initializer='ones',\n",
    "                                kernel_regularizer=keras.regularizers.L1(h2_kernel_rate),\n",
    "                                activity_regularizer=keras.regularizers.L1(h2_activation_rate))(hidden)\n",
    "    if paramcount[distribution] is None:\n",
    "        outputs = keras.layers.Dense(24, activation='linear')(hidden)\n",
    "        model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "        model.compile(optimizer=keras.optimizers.Adam(params['learning_rate']),\n",
    "                      loss='mae',\n",
    "                      metrics='mae')\n",
    "    else:\n",
    "        # now define parameter layers with their regularization\n",
    "        param_layers = []\n",
    "        param_names = [\"loc\", \"scale\", \"tailweight\", \"skewness\"]\n",
    "        for p in range(paramcount[distribution]):\n",
    "            regularize_param_kernel = params['regularize_'+param_names[p]]\n",
    "            param_kernel_rate = (0.0 if not regularize_param_kernel \n",
    "                                 else params[str(param_names[p])+'_rate_l1'])\n",
    "            param_layers.append(keras.layers.Dense(\n",
    "                24, activation='linear', # kernel_initializer='ones',\n",
    "                kernel_regularizer=keras.regularizers.L1(param_kernel_rate))(hidden))\n",
    "        # concatenate the parameter layers to one\n",
    "        linear = tf.keras.layers.concatenate(param_layers)\n",
    "        # define outputs\n",
    "        if distribution == 'Normal':\n",
    "            outputs = tfp.layers.DistributionLambda(\n",
    "                    lambda t: tfd.Normal(\n",
    "                        loc=t[..., :24],\n",
    "                        scale = 1e-3 + 3 * tf.math.softplus(t[..., 24:])))(linear)\n",
    "        elif distribution == 'StudentT':\n",
    "            outputs = tfp.layers.DistributionLambda(\n",
    "                    lambda t: tfd.StudentT(\n",
    "                        loc=t[..., :24],\n",
    "                        scale=1e-3 + 3 * tf.math.softplus(t[..., 24:48]),\n",
    "                        df=1 + 3 * tf.math.softplus(t[..., 48:])))(linear)\n",
    "        elif distribution == 'JSU':\n",
    "            outputs = tfp.layers.DistributionLambda(\n",
    "                    lambda t: tfd.JohnsonSU(\n",
    "                        loc=t[..., :24],\n",
    "                        scale=1e-3 + 3 * tf.math.softplus(t[..., 24:48]),\n",
    "                        tailweight= 1 + 3 * tf.math.softplus(t[..., 48:72]),\n",
    "                        skewness=t[..., 72:]))(linear)\n",
    "        elif distribution == 'SinhArcsinh':\n",
    "            outputs = tfp.layers.DistributionLambda(\n",
    "                    lambda t: tfd.SinhArcsinh(\n",
    "                        loc=t[..., :24],\n",
    "                        scale=1e-3 + 3 * tf.math.softplus(t[..., 24:48]),\n",
    "                        tailweight=1e-3 + 3 * tf.math.softplus(t[..., 48:72]),\n",
    "                        skewness=t[..., 72:]))(linear)\n",
    "        elif distribution == 'NormalInverseGaussian':\n",
    "            outputs = tfp.layers.DistributionLambda(\n",
    "                    lambda t: tfd.NormalInverseGaussian(\n",
    "                        loc=t[..., :24],\n",
    "                        scale=1e-3 + 3 * tf.math.softplus(t[..., 24:48]),\n",
    "                        tailweight=1e-3 + 3 * tf.math.softplus(t[..., 48:72]),\n",
    "                        skewness=t[..., 72:]))(linear) \n",
    "        else:\n",
    "            raise ValueError(f'Incorrect distribution {distribution}')\n",
    "        model = keras.Model(inputs = inputs, outputs=outputs)\n",
    "        model.compile(optimizer=keras.optimizers.Adam(params['learning_rate']),\n",
    "                      loss=lambda y, rv_y: -rv_y.log_prob(y),\n",
    "                      metrics='mae')\n",
    "    # '''\n",
    "    # define callbacks\n",
    "    callbacks = [keras.callbacks.EarlyStopping(patience=50, restore_best_weights=True)]\n",
    "    perm = np.random.permutation(np.arange(X.shape[0]))\n",
    "    VAL_DATA = .2\n",
    "    trainsubset = perm[:int((1 - VAL_DATA)*len(perm))]\n",
    "    valsubset = perm[int((1 - VAL_DATA)*len(perm)):]\n",
    "    model.fit(X[trainsubset], Y[trainsubset], epochs=1500, validation_data=(X[valsubset], Y[valsubset]), callbacks=callbacks, batch_size=32, verbose=False)\n",
    "    \n",
    "    # metrics = model.evaluate(Xf, Yf) # for point its a list of one [loss, MAE]\n",
    "    # we optimize the returned value, -1 will always take the model with best MAE\n",
    "\n",
    "    # pred = model.predict(Xf)[0]\n",
    "    if paramcount[distribution] is not None:\n",
    "        dist = model(Xf)\n",
    "        if distribution == 'Normal':\n",
    "            getters = {'loc': dist.loc, 'scale': dist.scale}\n",
    "        elif distribution == 'StudentT':\n",
    "            getters = {'loc': dist.loc, 'scale': dist.scale, 'df': dist.df}\n",
    "        elif distribution in {'JSU', 'SinhArcsinh', 'NormalInverseGaussian'}:\n",
    "            getters = {'loc': dist.loc, 'scale': dist.scale, \n",
    "                       'tailweight': dist.tailweight, 'skewness': dist.skewness}\n",
    "        print(getters)\n",
    "        params = {k: [float(e) for e in v.numpy()[0]] for k, v in getters.items()}\n",
    "        print(params)\n",
    "        json.dump(params, open(os.path.join(f'../distparams_probNN_{distribution.lower()}', datetime.strftime(df.index[-24], '%Y-%m-%d')), 'w'))\n",
    "        pred = model.predict(np.tile(Xf, (10000, 1)))\n",
    "        predDF = pd.DataFrame(index=df.index[-24:])\n",
    "        predDF['real'] = df.loc[df.index[-24:], 'Price'].to_numpy()\n",
    "        predDF['forecast'] = pd.NA\n",
    "        predDF.loc[predDF.index[:], 'forecast'] = pred.mean(0)\n",
    "        # predDF.to_csv(os.path.join('../forecasts', datetime.strftime(df.index[-24], '%Y-%m-%d')))\n",
    "        np.savetxt(os.path.join(f'../forecasts_probNN_{distribution.lower()}', datetime.strftime(df.index[-24], '%Y-%m-%d')), pred, delimiter=',', fmt='%.3f')\n",
    "    else:\n",
    "        predDF = pd.DataFrame(index=df.index[-24:])\n",
    "        predDF['real'] = df.loc[df.index[-24:], 'Price'].to_numpy()\n",
    "        predDF['forecast'] = pd.NA\n",
    "        predDF.loc[predDF.index[:], 'forecast'] = model.predict(Xf)[0]\n",
    "        pred = model.predict(Xf)\n",
    "        np.savetxt(os.path.join(f'../forecasts_probNN_{distribution.lower()}', datetime.strftime(df.index[-24], '%Y-%m-%d')), pred, delimiter=',', fmt='%.3f')\n",
    "    print(predDF)\n",
    "    return predDF\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5605e48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chatgpt code\n",
    "distribution = \"Normal\"  \n",
    "study_file = os.path.abspath(f\"../trialfiles/FINAL_DE_selection_prob_{distribution.lower()}\")  # e.g. .../FINAL_DE_selection_prob_normal\n",
    "storage_url = f\"sqlite:///{study_file}\"\n",
    "\n",
    "summaries = optuna.study.get_all_study_summaries(storage_url)\n",
    "if not summaries:\n",
    "    raise RuntimeError(f\"No Optuna studies found inside {study_file}\")\n",
    "\n",
    "study_name = summaries[0].study_name\n",
    "study = optuna.load_study(study_name=study_name, storage=storage_url)\n",
    "print(\"Loaded:\", study_name, \"| trials:\", len(study.trials))\n",
    "\n",
    "required = {\n",
    "    \"dropout\", \"learning_rate\", \"neurons_1\", \"neurons_2\", \"activation_1\", \"activation_2\",\n",
    "    \"price_D-1\",\"price_D-2\",\"price_D-3\",\"price_D-7\",\n",
    "    \"load_D\",\"load_D-1\",\"load_D-7\",\"RES_D\",\"RES_D-1\",\n",
    "    \"EUA\",\"Coal\",\"Gas\",\"Oil\",\"Dummy\",\n",
    "    \"regularize_h1_activation\",\"regularize_h1_kernel\",\"regularize_h2_activation\",\"regularize_h2_kernel\",\n",
    "    \"regularize_loc\",\"regularize_scale\",\n",
    "}\n",
    "\n",
    "def usable(t):\n",
    "    if t.state not in (TrialState.FAIL, TrialState.COMPLETE):\n",
    "        return False\n",
    "    if not t.params:\n",
    "        return False\n",
    "    return required.issubset(set(t.params.keys()))\n",
    "\n",
    "cands = [t for t in study.trials if usable(t)]\n",
    "print(\"Usable trials:\", [t.number for t in cands[:10]])\n",
    "\n",
    "if not cands:\n",
    "    richest = max(study.trials, key=lambda t: len(t.params))\n",
    "    missing = sorted(list(required - set(richest.params.keys())))\n",
    "    raise RuntimeError(f\"No usable trials found. Richest trial={richest.number} missing keys={missing[:20]}\")\n",
    "\n",
    "trial = cands[0]  \n",
    "params = trial.params\n",
    "print(\"Using trial:\", trial.number, \"state:\", trial.state, \"n_params:\", len(params))\n",
    "\n",
    "_ = runoneday((params, 0))\n",
    "\n",
    "# # author's code\n",
    "# optuna.logging.get_logger('optuna').addHandler(logging.StreamHandler(sys.stdout))\n",
    "# study_name = f'FINAL_DE_selection_prob_{distribution.lower()}' # 'on_new_data_no_feature_selection'\n",
    "# storage_name = f'sqlite:///../trialfiles/{study_name}'\n",
    "# study = optuna.create_study(study_name=study_name, storage=storage_name, load_if_exists=True)\n",
    "# print(study.trials_dataframe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687328c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# diagnostics cell\n",
    "print(\"Storage: \", storage_name)\n",
    "print(\"Study: \", study.study_name)\n",
    "print(\"n_trials: \", len(study.trials))\n",
    "completed = study.get_trials(states=(TrialState.COMPLETE,))\n",
    "print(\"n_completed: \", len(completed))\n",
    "print(study.trials_dataframe().head())\n",
    "print(study.trials_dataframe()[\"state\"].value_counts() if len(study.trials) else \"no trials\")\n",
    "\n",
    "best_params = study.best_params\n",
    "print(best_params)\n",
    "\n",
    "inputlist = [(best_params, day) for day in range(len(data) // 24 - 1456)]\n",
    "print(len(inputlist))\n",
    "\n",
    "# for e in inputlist:\n",
    "#     _ = runoneday(e)\n",
    "\n",
    "with Pool(max(os.cpu_count() // 4, 1)) as p:\n",
    "    _ = p.map(runoneday, inputlist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5656a164",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accepts arguments:\n",
    "#     cty (currently only DE), default: DE\n",
    "#     distribution (Normal, StudentT, JSU, SinhArcsinh and NormalInverseGaussian), default: Normal\n",
    "\n",
    "distribution = 'Normal'\n",
    "paramcount = {'Normal': 2,\n",
    "              'StudentT': 3,\n",
    "              'JSU': 4,\n",
    "              'SinhArcsinh': 4,\n",
    "              'NormalInverseGaussian': 4,\n",
    "              'Point': None\n",
    "}\n",
    "val_multi = 3 # int for # of re-trains - 1 corresponds to old approach\n",
    "val_window = 364 // val_multi\n",
    "\n",
    "if not os.path.exists(f'../trialfiles'):\n",
    "    os.mkdir(f'../trialfiles')\n",
    "\n",
    "INP_SIZE = 221\n",
    "activations = ['sigmoid', 'relu', 'elu', 'tanh', 'softplus', 'softmax']\n",
    "\n",
    "binopt = [True, False]\n",
    "\n",
    "cty = 'ES'\n",
    "repo_root = Path.cwd()\n",
    "storeDBintmp = False\n",
    "\n",
    "print(cty, distribution)\n",
    "\n",
    "if cty != 'ES':\n",
    "    raise ValueError('Incorrect country')\n",
    "if distribution not in paramcount:\n",
    "    raise ValueError('Incorrect distribution')\n",
    "\n",
    "# read data file\n",
    "data = pd.read_csv(f'../Datasets/{cty}.csv', index_col=0)\n",
    "data.index = [datetime.strptime(e, '%Y-%m-%d %H:%M:%S') for e in data.index]\n",
    "data = data.iloc[:4*364*24] # take the first 4 years - 1456 days\n",
    "\n",
    "def objective(trial):\n",
    "    \n",
    "    # prepare the input/output dataframes\n",
    "    Y = np.zeros((1456, 24))\n",
    "    Yf = np.zeros((364, 24))\n",
    "    for d in range(1456):\n",
    "        Y[d, :] = data.loc[data.index[d*24:(d+1)*24], 'Price'].to_numpy()\n",
    "    # Y = Y[7:, :] # skip first 7 days\n",
    "    for d in range(364):\n",
    "        Yf[d, :] = data.loc[data.index[(d+1092)*24:(d+1093)*24], 'Price'].to_numpy()\n",
    "    # \n",
    "    # build X \n",
    "    X = np.zeros((1092+364, INP_SIZE))\n",
    "\n",
    "    for d in range(7, 1092+364):\n",
    "      \n",
    "        X[d, :24] = data.loc[data.index[(d-1)*24:(d)*24], 'Price'].to_numpy() # D-1 price\n",
    "        X[d, 24:48] = data.loc[data.index[(d-2)*24:(d-1)*24], 'Price'].to_numpy() # D-2 price\n",
    "        X[d, 48:72] = data.loc[data.index[(d-3)*24:(d-2)*24], 'Price'].to_numpy() # D-3 price\n",
    "        X[d, 72:96] = data.loc[data.index[(d-7)*24:(d-6)*24], 'Price'].to_numpy() # D-7 price\n",
    "        X[d, 96:120] = data.loc[data.index[(d)*24:(d+1)*24], data.columns[1]].to_numpy() # D load forecast\n",
    "        X[d, 120:144] = data.loc[data.index[(d-1)*24:(d)*24], data.columns[1]].to_numpy() # D-1 load forecast\n",
    "        X[d, 144:168] = data.loc[data.index[(d-7)*24:(d-6)*24], data.columns[1]].to_numpy() # D-7 load forecast\n",
    "        X[d, 168:192] = data.loc[data.index[(d)*24:(d+1)*24], data.columns[2]].to_numpy() # D RES sum forecast\n",
    "        X[d, 192:216] = data.loc[data.index[(d-1)*24:(d)*24], data.columns[2]].to_numpy() # D-1 RES sum forecast\n",
    "        \n",
    "        # # original aouthors code\n",
    "        # X[d, 216] = data.loc[data.index[(d-2)*24:(d-1)*24:24], data.columns[3]].to_numpy() # D-2 EUA\n",
    "        # X[d, 217] = data.loc[data.index[(d-2)*24:(d-1)*24:24], data.columns[4]].to_numpy() # D-2 API2_Coal\n",
    "        # X[d, 218] = data.loc[data.index[(d-2)*24:(d-1)*24:24], data.columns[5]].to_numpy() # D-2 TTF_Gas\n",
    "        # X[d, 219] = data.loc[data.index[(d-2)*24:(d-1)*24:24], data.columns[6]].to_numpy() # D-2 Brent oil\n",
    "        \n",
    "        X[d, 216] = data.loc[data.index[(d-2)*24:(d-1)*24:24], data.columns[3]].to_numpy().item()\n",
    "        X[d, 217] = data.loc[data.index[(d-2)*24:(d-1)*24:24], data.columns[4]].to_numpy().item()\n",
    "        X[d, 218] = data.loc[data.index[(d-2)*24:(d-1)*24:24], data.columns[5]].to_numpy().item()\n",
    "        X[d, 219] = data.loc[data.index[(d-2)*24:(d-1)*24:24], data.columns[6]].to_numpy().item()\n",
    "        \n",
    "        # authors code\n",
    "        X[d, 220] = data.index[d].weekday()\n",
    "\n",
    "    # '''\n",
    "    # input feature selection\n",
    "    colmask = [False] * INP_SIZE\n",
    "    if trial.suggest_categorical('price_D-1', binopt):\n",
    "        colmask[:24] = [True] * 24\n",
    "    if trial.suggest_categorical('price_D-2', binopt):\n",
    "        colmask[24:48] = [True] * 24\n",
    "    if trial.suggest_categorical('price_D-3', binopt):\n",
    "        colmask[48:72] = [True] * 24\n",
    "    if trial.suggest_categorical('price_D-7', binopt):\n",
    "        colmask[72:96] = [True] * 24\n",
    "    if trial.suggest_categorical('load_D', binopt):\n",
    "        colmask[96:120] = [True] * 24\n",
    "    if trial.suggest_categorical('load_D-1', binopt):\n",
    "        colmask[120:144] = [True] * 24\n",
    "    if trial.suggest_categorical('load_D-7', binopt):\n",
    "        colmask[144:168] = [True] * 24\n",
    "    if trial.suggest_categorical('RES_D', binopt):\n",
    "        colmask[168:192] = [True] * 24\n",
    "    if trial.suggest_categorical('RES_D-1', binopt):\n",
    "        colmask[192:216] = [True] * 24\n",
    "    if trial.suggest_categorical('EUA', binopt):\n",
    "        colmask[216] = True\n",
    "    if trial.suggest_categorical('Coal', binopt):\n",
    "        colmask[217] = True\n",
    "    if trial.suggest_categorical('Gas', binopt):\n",
    "        colmask[218] = True\n",
    "    if trial.suggest_categorical('Oil', binopt):\n",
    "        colmask[219] = True\n",
    "    if trial.suggest_categorical('Dummy', binopt):\n",
    "        colmask[220] = True\n",
    "    X = X[:, colmask]\n",
    "    \n",
    "    # '''\n",
    "    Xwhole = X.copy()\n",
    "    Ywhole = Y.copy()\n",
    "    Yfwhole = Yf.copy()\n",
    "    metrics_sub = []\n",
    "    \n",
    "    for train_no in range(val_multi):\n",
    "        \n",
    "        start = val_window * train_no\n",
    "        X = Xwhole[start:1092+start, :]\n",
    "        Xf = Xwhole[1092+start:1092+start+val_window, :]\n",
    "        Y = Ywhole[start:1092+start, :]\n",
    "        Yf = Ywhole[1092+start:1092+start+val_window, :]\n",
    "        X = X[7:1092, :]\n",
    "        Y = Y[7:1092, :]\n",
    "        \n",
    "        # begin building a model\n",
    "        inputs = keras.Input(shape=(X.shape[1],)) # <= INP_SIZE as some columns might have been turned off\n",
    "        # batch normalization\n",
    "        # we decided to always normalize the inputs\n",
    "        batchnorm = True #trial.suggest_categorical('batch_normalization', [True, False])\n",
    "        if batchnorm:\n",
    "            norm = keras.layers.BatchNormalization()(inputs)\n",
    "            last_layer = norm\n",
    "        else:\n",
    "            last_layer = inputs\n",
    "        # dropout\n",
    "        dropout = trial.suggest_categorical('dropout', binopt)\n",
    "        if dropout:\n",
    "            rate = trial.suggest_float('dropout_rate', 0, 1)\n",
    "            drop = keras.layers.Dropout(rate)(last_layer)\n",
    "            last_layer = drop\n",
    "        # regularization of 1st hidden layer,\n",
    "        #activation - output, kernel - weights/parameters of input\n",
    "        regularize_h1_activation = trial.suggest_categorical('regularize_h1_activation', binopt)\n",
    "        regularize_h1_kernel = trial.suggest_categorical('regularize_h1_kernel', binopt)\n",
    "        h1_activation_rate = (0.0 if not regularize_h1_activation\n",
    "                              else trial.suggest_float('h1_activation_rate_l1', 1e-5, 1e-2, log=True))\n",
    "        h1_kernel_rate = (0.0 if not regularize_h1_kernel\n",
    "                          else trial.suggest_float('h1_kernel_rate_l1', 1e-5, 1e-2, log=True))\n",
    "        # define 1st hidden layer with regularization\n",
    "        hidden = keras.layers.Dense(trial.suggest_int('neurons_1', 256, 512, log=False),\n",
    "                                    activation=trial.suggest_categorical('activation_1', activations),\n",
    "                                    # kernel_initializer='ones',\n",
    "                                    kernel_regularizer=keras.regularizers.L1(h1_kernel_rate),\n",
    "                                    activity_regularizer=keras.regularizers.L1(h1_activation_rate))(last_layer)\n",
    "        # regularization of 2nd hidden layer,\n",
    "        #activation - output, kernel - weights/parameters of input\n",
    "        regularize_h2_activation = trial.suggest_categorical('regularize_h2_activation', binopt)\n",
    "        regularize_h2_kernel = trial.suggest_categorical('regularize_h2_kernel', binopt)\n",
    "        h2_activation_rate = (0.0 if not regularize_h2_activation\n",
    "                              else trial.suggest_float('h2_activation_rate_l1', 1e-5, 1e-2, log=True))\n",
    "        h2_kernel_rate = (0.0 if not regularize_h2_kernel\n",
    "                          else trial.suggest_float('h2_kernel_rate_l1', 1e-5, 1e-2, log=True))\n",
    "        # define 2nd hidden layer with regularization\n",
    "        hidden = keras.layers.Dense(trial.suggest_int('neurons_2', 256, 512, log=False),\n",
    "                                    activation=trial.suggest_categorical('activation_2', activations),\n",
    "                                    # kernel_initializer='ones',\n",
    "                                    kernel_regularizer=keras.regularizers.L1(h2_kernel_rate),\n",
    "                                    activity_regularizer=keras.regularizers.L1(h2_activation_rate))(hidden)\n",
    "        if paramcount[distribution] is None:\n",
    "            outputs = tfp.layers.DistributionLambda(lambda t: tfd.Normal(loc=t[..., :24],scale=1e-3 + 3.0 * tf.nn.softplus(t[..., 24:])))(linear)\n",
    "            # # authors one\n",
    "            # outputs = keras.layers.Dense(24, activation='linear')(hidden)\n",
    "            \n",
    "            model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "            model.compile(optimizer=keras.optimizers.legacy.Adam(trial.suggest_float('learning_rate', 1e-5, 1e-1, log=True)),\n",
    "                          # loss=lambda y, rv_y: -rv_y.log_prob(y),\n",
    "                          loss='mae',\n",
    "                          metrics='mae')\n",
    "        else:\n",
    "            # now define parameter layers with their regularization\n",
    "            param_layers = []\n",
    "            param_names = [\"loc\", \"scale\", \"tailweight\", \"skewness\"]\n",
    "            for p in range(paramcount[distribution]):\n",
    "                # regularize_param_kernel = True\n",
    "                # param_kernel_rate = 0.1\n",
    "                regularize_param_kernel = trial.suggest_categorical('regularize_'+param_names[p], binopt)\n",
    "                param_kernel_rate = (0.0 if not regularize_param_kernel\n",
    "                                     else trial.suggest_float(param_names[p]+'_rate_l1', 1e-5, 1e-2, log=True))\n",
    "                param_layers.append(keras.layers.Dense(\n",
    "                    24, activation='linear', # kernel_initializer='ones',\n",
    "                    kernel_regularizer=keras.regularizers.L1(param_kernel_rate))(hidden))\n",
    "            # concatenate the parameter layers to one\n",
    "            linear = tf.keras.layers.concatenate(param_layers)\n",
    "            # define outputs\n",
    "            if distribution == 'Normal':\n",
    "                outputs = tfp.layers.DistributionLambda(\n",
    "                        lambda t: tfd.Normal(\n",
    "                            loc=t[..., :24],\n",
    "                            scale = 1e-3 + 3 * tf.math.softplus(t[..., 24:])))(linear)\n",
    "            elif distribution == 'StudentT':\n",
    "                outputs = tfp.layers.DistributionLambda(\n",
    "                        lambda t: tfd.StudentT(\n",
    "                            loc=t[..., :24],\n",
    "                            scale=1e-3 + 3 * tf.math.softplus(t[..., 24:48]),\n",
    "                            df=1 + 3 * tf.math.softplus(t[..., 48:])))(linear)\n",
    "            elif distribution == 'JSU':\n",
    "                outputs = tfp.layers.DistributionLambda(\n",
    "                        lambda t: tfd.JohnsonSU(\n",
    "                            loc=t[..., :24],\n",
    "                            scale=1e-3 + 3 * tf.math.softplus(t[..., 24:48]),\n",
    "                            tailweight= 1 + 3 * tf.math.softplus(t[..., 48:72]),\n",
    "                            skewness=t[..., 72:]))(linear)\n",
    "            elif distribution == 'SinhArcsinh':\n",
    "                outputs = tfp.layers.DistributionLambda(\n",
    "                        lambda t: tfd.SinhArcsinh(\n",
    "                            loc=t[..., :24],\n",
    "                            scale=1e-3 + 3 * tf.math.softplus(t[..., 24:48]),\n",
    "                            tailweight=1e-3 + 3 * tf.math.softplus(t[..., 48:72]),\n",
    "                            skewness=t[..., 72:]))(linear)\n",
    "            elif distribution == 'NormalInverseGaussian':\n",
    "                outputs = tfp.layers.DistributionLambda(\n",
    "                        lambda t: tfd.NormalInverseGaussian(\n",
    "                            loc=t[..., :24],\n",
    "                            scale=1e-3 + 3 * tf.math.softplus(t[..., 24:48]),\n",
    "                            tailweight=1e-3 + 3 * tf.math.softplus(t[..., 48:72]),\n",
    "                            skewness=t[..., 72:]))(linear)\n",
    "            else:\n",
    "                raise ValueError(f'Incorrect distribution {distribution}')\n",
    "            model = keras.Model(inputs = inputs, outputs=outputs)\n",
    "            model.compile(optimizer=keras.optimizers.legacy.Adam(trial.suggest_float('learning_rate', 1e-5, 1e-2, log=True)),\n",
    "                          loss=lambda y, rv_y: -rv_y.log_prob(y),\n",
    "                          metrics='mae')\n",
    "        # '''\n",
    "\n",
    "        # define callbacks\n",
    "        callbacks = [keras.callbacks.EarlyStopping(patience=50, restore_best_weights=True)]    \n",
    "        model.fit(X, Y, epochs=300, validation_data=(Xf, Yf), callbacks=callbacks, batch_size=256, verbose=2)\n",
    "\n",
    "        metrics = model.evaluate(Xf, Yf, verbose=0) # for point its a list of one [loss, MAE] as \n",
    "        metrics_sub.append(metrics[0])\n",
    "        # we optimize the returned value, -1 will always take the model with best MAE\n",
    "    return np.mean(metrics_sub)\n",
    "\n",
    "#optuna.logging.get_logger('optuna').addHandler(logging.StreamHandler(sys.stdout))\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "study_name = f'FINAL_DE_selection_prob_{distribution.lower()}'\n",
    "if storeDBintmp:\n",
    "    storage_name = f'sqlite:////tmp/{study_name}'\n",
    "else:\n",
    "    storage_name = f'sqlite:///../trialfiles/{study_name}'\n",
    "# below calls to create either random sampler and default (tree parzen estimator)\n",
    "# study can be resumed using a different one\n",
    "# (or one process can sample randomly, the second one run the TPE sampler at the same time)\n",
    "# study = optuna.create_study(study_name=study_name, storage=storage_name, load_if_exists=True, sampler=optuna.samplers.RandomSampler())\n",
    "study = optuna.create_study(study_name=study_name, storage=storage_name, load_if_exists=True)\n",
    "study.optimize(objective, n_trials=4, show_progress_bar=True)\n",
    "best_params = study.best_params\n",
    "print(best_params)\n",
    "print(study.trials_dataframe())\n",
    "if storeDBintmp:\n",
    "    print('Trials DB stored in /tmp')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b28a71",
   "metadata": {},
   "source": [
    "### MIssing days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d70504db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rows: 96908\n",
      "range: 2014-12-09 23:00:00 -> 2026-01-01 00:00:00\n",
      "duplicates: False\n",
      "sorted: True\n",
      "\n",
      "=== Overall missing hours ===\n",
      "expected hours: 96962\n",
      "actual hours:   96908\n",
      "missing hours:  54\n",
      "\n",
      "=== Day-level ===\n",
      "days in range: 4042\n",
      "incomplete days: 8\n",
      "\n",
      "=== Missing days entirely (0 hours present) ===\n",
      "count: 0\n",
      "\n",
      "=== Top time differences in ACTUAL data ===\n",
      "time_utc\n",
      "0 days 01:00:00    96902\n",
      "1 days 01:00:00        2\n",
      "0 days 04:00:00        1\n",
      "0 days 03:00:00        1\n",
      "0 days 02:00:00        1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=== Year-level summary ===\n",
      "      days  incomplete_days  missing_hours_total  incomplete_days_share\n",
      "year                                                                   \n",
      "2014    23                0                    0               0.000000\n",
      "2015   365                6                   51               0.016438\n",
      "2016   366                0                    0               0.000000\n",
      "2017   365                0                    0               0.000000\n",
      "2018   365                2                    3               0.005479\n",
      "2019   365                0                    0               0.000000\n",
      "2020   366                0                    0               0.000000\n",
      "2021   365                0                    0               0.000000\n",
      "2022   365                0                    0               0.000000\n",
      "2023   365                0                    0               0.000000\n",
      "2024   366                0                    0               0.000000\n",
      "2025   365                0                    0               0.000000\n",
      "2026     1                0                    0               0.000000\n"
     ]
    }
   ],
   "source": [
    "df_at = pd.read_csv(\"/Users/bekzodamonov/Documents/GitHub/distributionalnn-execute-once/Datasets/AT.csv\",index_col=0)\n",
    "df_at.index = pd.to_datetime(df_at.index, format=\"%Y-%m-%d %H:%M:%S\", errors=\"raise\")\n",
    "df_at = df_at.sort_index()\n",
    "idx = pd.DatetimeIndex(df_at.index)\n",
    "\n",
    "print(\"rows:\", len(df_at))\n",
    "print(\"range:\", idx.min(), \"->\", idx.max())\n",
    "print(\"duplicates:\", idx.has_duplicates)\n",
    "print(\"sorted:\", idx.is_monotonic_increasing)\n",
    "\n",
    "# ---- expected full hourly timeline between min and max ----\n",
    "expected = pd.date_range(start=idx.min(), end=idx.max(), freq=\"h\")\n",
    "\n",
    "missing_ts = expected.difference(idx)\n",
    "print(\"\\n=== Overall missing hours ===\")\n",
    "print(\"expected hours:\", len(expected))\n",
    "print(\"actual hours:  \", len(idx))\n",
    "print(\"missing hours: \", len(missing_ts))\n",
    "\n",
    "# ---- day-level completeness (calendar days) ----\n",
    "actual_per_day = pd.Series(1, index=idx).groupby(idx.floor(\"D\")).sum()\n",
    "expected_per_day = pd.Series(1, index=expected).groupby(expected.floor(\"D\")).sum()\n",
    "\n",
    "day_stats = pd.DataFrame({\n",
    "    \"actual_hours\": actual_per_day,\n",
    "    \"expected_hours\": expected_per_day\n",
    "}).fillna(0).astype(int)\n",
    "\n",
    "day_stats[\"missing_hours\"] = day_stats[\"expected_hours\"] - day_stats[\"actual_hours\"]\n",
    "incomplete_days = day_stats[day_stats[\"missing_hours\"] != 0].sort_values(\"missing_hours\", ascending=False)\n",
    "\n",
    "print(\"\\n=== Day-level ===\")\n",
    "print(\"days in range:\", len(day_stats))\n",
    "print(\"incomplete days:\", len(incomplete_days))\n",
    "\n",
    "missing_days = day_stats[day_stats[\"actual_hours\"] == 0]\n",
    "print(\"\\n=== Missing days entirely (0 hours present) ===\")\n",
    "print(\"count:\", len(missing_days))\n",
    "\n",
    "# ---- frequency sanity (what time jumps exist) ----\n",
    "diff_counts = pd.Series(idx).diff().value_counts().head(15)\n",
    "print(\"\\n=== Top time differences in ACTUAL data ===\")\n",
    "print(diff_counts)\n",
    "\n",
    "day_stats[\"year\"] = day_stats.index.year\n",
    "year_summary = (\n",
    "    day_stats.groupby(\"year\").agg(\n",
    "        days=(\"missing_hours\", \"size\"),\n",
    "        incomplete_days=(\"missing_hours\", lambda s: (s != 0).sum()),\n",
    "        missing_hours_total=(\"missing_hours\", \"sum\")))\n",
    "\n",
    "year_summary[\"incomplete_days_share\"] = year_summary[\"incomplete_days\"] / year_summary[\"days\"]\n",
    "\n",
    "print(\"\\n=== Year-level summary ===\")\n",
    "print(year_summary)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca193d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_multi = 13 # int for # of re-trains - 1 corresponds to old approach\n",
    "val_window = 364 // val_multi\n",
    "\n",
    "if not os.path.exists(f'../trialfiles'):\n",
    "    os.mkdir(f'../trialfiles')\n",
    "\n",
    "INP_SIZE = 221\n",
    "activations = ['sigmoid', 'relu', 'elu', 'tanh', 'softplus', 'softmax']\n",
    "\n",
    "binopt = [True, False]\n",
    "\n",
    "cty = 'ES'\n",
    "\n",
    "# read data file\n",
    "repo_root = Path.cwd()\n",
    "data = pd.read_csv( f\"../Datasets/AT.csv\", index_col=0)\n",
    "data.index = [datetime.strptime(e, '%Y-%m-%d %H:%M:%S') for e in data.index]\n",
    "data = data.iloc[:4*364*24] # take the first 4 years - 1456 days\n",
    "\n",
    "\n",
    "# prepare the input/output dataframes\n",
    "Y = np.zeros((1456, 24))\n",
    "Yf = np.zeros((364, 24))\n",
    "for d in range(1456):\n",
    "    Y[d, :] = data.loc[data.index[d*24:(d+1)*24], 'Price'].to_numpy()\n",
    "# Y = Y[7:, :] # skip first 7 days\n",
    "for d in range(364):\n",
    "    Yf[d, :] = data.loc[data.index[(d+1092)*24:(d+1093)*24], 'Price'].to_numpy()\n",
    "# \n",
    "X = np.zeros((1092+364, INP_SIZE))\n",
    "for d in range(7, 1092+364):\n",
    "    X[d, :24] = data.loc[data.index[(d-1)*24:(d)*24], 'Price'].to_numpy() # D-1 price\n",
    "    X[d, 24:48] = data.loc[data.index[(d-2)*24:(d-1)*24], 'Price'].to_numpy() # D-2 price\n",
    "    X[d, 48:72] = data.loc[data.index[(d-3)*24:(d-2)*24], 'Price'].to_numpy() # D-3 price\n",
    "    X[d, 72:96] = data.loc[data.index[(d-7)*24:(d-6)*24], 'Price'].to_numpy() # D-7 price\n",
    "    X[d, 96:120] = data.loc[data.index[(d)*24:(d+1)*24], data.columns[1]].to_numpy() # D load forecast\n",
    "    X[d, 120:144] = data.loc[data.index[(d-1)*24:(d)*24], data.columns[1]].to_numpy() # D-1 load forecast\n",
    "    X[d, 144:168] = data.loc[data.index[(d-7)*24:(d-6)*24], data.columns[1]].to_numpy() # D-7 load forecast\n",
    "    X[d, 168:192] = data.loc[data.index[(d)*24:(d+1)*24], data.columns[2]].to_numpy() # D RES sum forecast\n",
    "    X[d, 192:216] = data.loc[data.index[(d-1)*24:(d)*24], data.columns[2]].to_numpy()[0] # D-1 RES sum forecast\n",
    "    X[d, 216] = data.loc[data.index[(d-2)*24:(d-1)*24:24], data.columns[3]].to_numpy()[0] # D-2 EUA\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "29c67e43",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '__file__' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[105]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m repo_root = Path(\u001b[34;43m__file__\u001b[39;49m).resolve().parent.parent\n",
      "\u001b[31mNameError\u001b[39m: name '__file__' is not defined"
     ]
    }
   ],
   "source": [
    "repo_root = Path(__file__).resolve().parent.parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "074bc867",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rows: 92303\n",
      "range: 2014-12-10 23:00:00 -> 2026-01-01 00:00:00\n",
      "duplicates: False\n",
      "sorted: True\n",
      "\n",
      "=== Overall missing hours ===\n",
      "expected hours: 96938\n",
      "actual hours:   92303\n",
      "missing hours:  4635\n",
      "\n",
      "=== Day-level ===\n",
      "days in range: 4041\n",
      "incomplete days: 2285\n",
      "\n",
      "=== Missing days entirely (0 hours present) ===\n",
      "count: 0\n",
      "\n",
      "=== Top time differences in ACTUAL data ===\n",
      "time_utc\n",
      "0 days 01:00:00    88865\n",
      "0 days 02:00:00     2781\n",
      "0 days 03:00:00      419\n",
      "0 days 04:00:00      108\n",
      "0 days 05:00:00       53\n",
      "0 days 06:00:00       42\n",
      "0 days 07:00:00       15\n",
      "0 days 08:00:00        8\n",
      "0 days 09:00:00        3\n",
      "0 days 10:00:00        2\n",
      "0 days 11:00:00        2\n",
      "0 days 18:00:00        1\n",
      "0 days 13:00:00        1\n",
      "0 days 16:00:00        1\n",
      "0 days 19:00:00        1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=== Year-level summary ===\n",
      "      days  incomplete_days  missing_hours_total  incomplete_days_share\n",
      "year                                                                   \n",
      "2014    22               16                   30               0.727273\n",
      "2015   365              224                  388               0.613699\n",
      "2016   366              226                  417               0.617486\n",
      "2017   365              243                  408               0.665753\n",
      "2018   365              122                  210               0.334247\n",
      "2019   365              182                  318               0.498630\n",
      "2020   366              194                  332               0.530055\n",
      "2021   365              198                  375               0.542466\n",
      "2022   365              204                  330               0.558904\n",
      "2023   365              224                  535               0.613699\n",
      "2024   366              260                  856               0.710383\n",
      "2025   365              192                  436               0.526027\n",
      "2026     1                0                    0               0.000000\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"/Users/bekzodamonov/Documents/GitHub/distributionalnn-execute-once/Datasets/ES.csv\",index_col=0)\n",
    "df.index = pd.to_datetime(df.index, format=\"%Y-%m-%d %H:%M:%S\", errors=\"raise\")\n",
    "df = df.sort_index()\n",
    "idx = pd.DatetimeIndex(df.index)\n",
    "\n",
    "print(\"rows:\", len(df))\n",
    "print(\"range:\", idx.min(), \"->\", idx.max())\n",
    "print(\"duplicates:\", idx.has_duplicates)\n",
    "print(\"sorted:\", idx.is_monotonic_increasing)\n",
    "\n",
    "# ---- expected full hourly timeline between min and max ----\n",
    "expected = pd.date_range(start=idx.min(), end=idx.max(), freq=\"h\")\n",
    "\n",
    "missing_ts = expected.difference(idx)\n",
    "print(\"\\n=== Overall missing hours ===\")\n",
    "print(\"expected hours:\", len(expected))\n",
    "print(\"actual hours:  \", len(idx))\n",
    "print(\"missing hours: \", len(missing_ts))\n",
    "\n",
    "# ---- day-level completeness (calendar days) ----\n",
    "actual_per_day = pd.Series(1, index=idx).groupby(idx.floor(\"D\")).sum()\n",
    "expected_per_day = pd.Series(1, index=expected).groupby(expected.floor(\"D\")).sum()\n",
    "\n",
    "day_stats = pd.DataFrame({\n",
    "    \"actual_hours\": actual_per_day,\n",
    "    \"expected_hours\": expected_per_day\n",
    "}).fillna(0).astype(int)\n",
    "\n",
    "day_stats[\"missing_hours\"] = day_stats[\"expected_hours\"] - day_stats[\"actual_hours\"]\n",
    "incomplete_days = day_stats[day_stats[\"missing_hours\"] != 0].sort_values(\"missing_hours\", ascending=False)\n",
    "\n",
    "print(\"\\n=== Day-level ===\")\n",
    "print(\"days in range:\", len(day_stats))\n",
    "print(\"incomplete days:\", len(incomplete_days))\n",
    "\n",
    "missing_days = day_stats[day_stats[\"actual_hours\"] == 0]\n",
    "print(\"\\n=== Missing days entirely (0 hours present) ===\")\n",
    "print(\"count:\", len(missing_days))\n",
    "\n",
    "# ---- frequency sanity (what time jumps exist) ----\n",
    "diff_counts = pd.Series(idx).diff().value_counts().head(15)\n",
    "print(\"\\n=== Top time differences in ACTUAL data ===\")\n",
    "print(diff_counts)\n",
    "\n",
    "day_stats[\"year\"] = day_stats.index.year\n",
    "year_summary = (\n",
    "    day_stats.groupby(\"year\").agg(\n",
    "        days=(\"missing_hours\", \"size\"),\n",
    "        incomplete_days=(\"missing_hours\", lambda s: (s != 0).sum()),\n",
    "        missing_hours_total=(\"missing_hours\", \"sum\")))\n",
    "\n",
    "year_summary[\"incomplete_days_share\"] = year_summary[\"incomplete_days\"] / year_summary[\"days\"]\n",
    "\n",
    "print(\"\\n=== Year-level summary ===\")\n",
    "print(year_summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d8b14965",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Year-level summary ===\n",
      "      days  incomplete_days  missing_hours_total  incomplete_days_share\n",
      "year                                                                   \n",
      "2014    22               16                   30               0.727273\n",
      "2015   365              224                  388               0.613699\n",
      "2016   366              226                  417               0.617486\n",
      "2017   365              243                  408               0.665753\n",
      "2018   365              122                  210               0.334247\n",
      "2019   365              182                  318               0.498630\n",
      "2020   366              194                  332               0.530055\n",
      "2021   365              198                  375               0.542466\n",
      "2022   365              204                  330               0.558904\n",
      "2023   365              224                  535               0.613699\n",
      "2024   366              260                  856               0.710383\n",
      "2025   365              192                  436               0.526027\n",
      "2026     1                0                    0               0.000000\n",
      "\n",
      "=== Top 15 most incomplete days PER YEAR ===\n",
      "\n",
      "--- 2014 ---\n",
      "            actual_hours  expected_hours  missing_hours\n",
      "2014-12-12            21              24              3\n",
      "2014-12-18            21              24              3\n",
      "2014-12-19            21              24              3\n",
      "2014-12-23            21              24              3\n",
      "2014-12-29            21              24              3\n",
      "2014-12-16            22              24              2\n",
      "2014-12-22            22              24              2\n",
      "2014-12-26            22              24              2\n",
      "2014-12-28            22              24              2\n",
      "2014-12-13            23              24              1\n",
      "2014-12-15            23              24              1\n",
      "2014-12-17            23              24              1\n",
      "2014-12-20            23              24              1\n",
      "2014-12-21            23              24              1\n",
      "2014-12-25            23              24              1\n",
      "\n",
      "--- 2015 ---\n",
      "            actual_hours  expected_hours  missing_hours\n",
      "2015-08-10            18              24              6\n",
      "2015-01-31            19              24              5\n",
      "2015-02-27            19              24              5\n",
      "2015-08-16            19              24              5\n",
      "2015-08-17            19              24              5\n",
      "2015-10-08            19              24              5\n",
      "2015-04-06            20              24              4\n",
      "2015-05-01            20              24              4\n",
      "2015-05-06            20              24              4\n",
      "2015-05-26            20              24              4\n",
      "2015-06-19            20              24              4\n",
      "2015-08-03            20              24              4\n",
      "2015-08-22            20              24              4\n",
      "2015-08-28            20              24              4\n",
      "2015-12-25            20              24              4\n",
      "\n",
      "--- 2016 ---\n",
      "            actual_hours  expected_hours  missing_hours\n",
      "2016-02-14            15              24              9\n",
      "2016-01-23            18              24              6\n",
      "2016-02-27            18              24              6\n",
      "2016-03-20            18              24              6\n",
      "2016-07-31            18              24              6\n",
      "2016-02-28            19              24              5\n",
      "2016-05-01            19              24              5\n",
      "2016-07-16            19              24              5\n",
      "2016-08-02            19              24              5\n",
      "2016-10-02            19              24              5\n",
      "2016-01-24            20              24              4\n",
      "2016-02-02            20              24              4\n",
      "2016-02-03            20              24              4\n",
      "2016-02-15            20              24              4\n",
      "2016-05-31            20              24              4\n",
      "\n",
      "--- 2017 ---\n",
      "            actual_hours  expected_hours  missing_hours\n",
      "2017-07-02            18              24              6\n",
      "2017-09-05            18              24              6\n",
      "2017-06-07            19              24              5\n",
      "2017-07-04            19              24              5\n",
      "2017-04-16            20              24              4\n",
      "2017-04-23            20              24              4\n",
      "2017-04-27            20              24              4\n",
      "2017-05-08            20              24              4\n",
      "2017-05-14            20              24              4\n",
      "2017-07-25            20              24              4\n",
      "2017-12-05            20              24              4\n",
      "2017-03-09            21              24              3\n",
      "2017-03-11            21              24              3\n",
      "2017-03-16            21              24              3\n",
      "2017-03-18            21              24              3\n",
      "\n",
      "--- 2018 ---\n",
      "            actual_hours  expected_hours  missing_hours\n",
      "2018-01-01            14              24             10\n",
      "2018-03-31            19              24              5\n",
      "2018-06-02            19              24              5\n",
      "2018-05-11            20              24              4\n",
      "2018-05-13            20              24              4\n",
      "2018-06-18            20              24              4\n",
      "2018-06-27            20              24              4\n",
      "2018-01-17            21              24              3\n",
      "2018-03-02            21              24              3\n",
      "2018-03-21            21              24              3\n",
      "2018-04-02            21              24              3\n",
      "2018-04-09            21              24              3\n",
      "2018-04-26            21              24              3\n",
      "2018-05-10            21              24              3\n",
      "2018-05-19            21              24              3\n",
      "\n",
      "--- 2019 ---\n",
      "            actual_hours  expected_hours  missing_hours\n",
      "2019-12-21             6              24             18\n",
      "2019-12-22            18              24              6\n",
      "2019-06-28            19              24              5\n",
      "2019-03-08            20              24              4\n",
      "2019-04-01            20              24              4\n",
      "2019-05-01            20              24              4\n",
      "2019-05-23            20              24              4\n",
      "2019-06-24            20              24              4\n",
      "2019-07-31            20              24              4\n",
      "2019-08-25            20              24              4\n",
      "2019-01-13            21              24              3\n",
      "2019-01-15            21              24              3\n",
      "2019-02-25            21              24              3\n",
      "2019-05-21            21              24              3\n",
      "2019-05-29            21              24              3\n",
      "\n",
      "--- 2020 ---\n",
      "            actual_hours  expected_hours  missing_hours\n",
      "2020-03-08            19              24              5\n",
      "2020-04-18            19              24              5\n",
      "2020-06-21            19              24              5\n",
      "2020-10-25            19              24              5\n",
      "2020-02-09            20              24              4\n",
      "2020-02-15            20              24              4\n",
      "2020-03-12            20              24              4\n",
      "2020-03-18            20              24              4\n",
      "2020-04-06            20              24              4\n",
      "2020-04-08            20              24              4\n",
      "2020-04-12            20              24              4\n",
      "2020-05-23            20              24              4\n",
      "2020-07-08            20              24              4\n",
      "2020-12-28            20              24              4\n",
      "2020-03-15            21              24              3\n",
      "\n",
      "--- 2021 ---\n",
      "            actual_hours  expected_hours  missing_hours\n",
      "2021-01-31            11              24             13\n",
      "2021-01-30            13              24             11\n",
      "2021-02-21            15              24              9\n",
      "2021-05-09            16              24              8\n",
      "2021-10-07            16              24              8\n",
      "2021-02-10            18              24              6\n",
      "2021-02-20            18              24              6\n",
      "2021-01-01            19              24              5\n",
      "2021-02-08            19              24              5\n",
      "2021-04-25            19              24              5\n",
      "2021-11-13            19              24              5\n",
      "2021-01-07            20              24              4\n",
      "2021-09-15            20              24              4\n",
      "2021-12-23            20              24              4\n",
      "2021-01-23            21              24              3\n",
      "\n",
      "--- 2022 ---\n",
      "            actual_hours  expected_hours  missing_hours\n",
      "2022-12-25            17              24              7\n",
      "2022-04-10            19              24              5\n",
      "2022-06-11            19              24              5\n",
      "2022-12-13            19              24              5\n",
      "2022-12-30            19              24              5\n",
      "2022-03-15            20              24              4\n",
      "2022-04-23            20              24              4\n",
      "2022-06-17            20              24              4\n",
      "2022-08-04            20              24              4\n",
      "2022-08-28            20              24              4\n",
      "2022-11-30            20              24              4\n",
      "2022-12-14            20              24              4\n",
      "2022-12-31            20              24              4\n",
      "2022-01-01            21              24              3\n",
      "2022-06-16            21              24              3\n",
      "\n",
      "--- 2023 ---\n",
      "            actual_hours  expected_hours  missing_hours\n",
      "2023-11-05             9              24             15\n",
      "2023-01-01            10              24             14\n",
      "2023-01-17            15              24              9\n",
      "2023-05-14            15              24              9\n",
      "2023-07-02            15              24              9\n",
      "2023-11-01            15              24              9\n",
      "2023-10-27            16              24              8\n",
      "2023-10-28            16              24              8\n",
      "2023-04-02            17              24              7\n",
      "2023-10-19            17              24              7\n",
      "2023-11-02            17              24              7\n",
      "2023-12-08            17              24              7\n",
      "2023-01-08            18              24              6\n",
      "2023-01-16            18              24              6\n",
      "2023-01-18            18              24              6\n",
      "\n",
      "--- 2024 ---\n",
      "            actual_hours  expected_hours  missing_hours\n",
      "2024-03-10             4              24             20\n",
      "2024-03-24             9              24             15\n",
      "2024-04-08             9              24             15\n",
      "2024-03-28            10              24             14\n",
      "2024-04-07            10              24             14\n",
      "2024-04-09            10              24             14\n",
      "2024-04-06            11              24             13\n",
      "2024-03-03            12              24             12\n",
      "2024-03-09            12              24             12\n",
      "2024-02-10            13              24             11\n",
      "2024-02-28            13              24             11\n",
      "2024-03-11            13              24             11\n",
      "2024-03-31            13              24             11\n",
      "2024-04-05            13              24             11\n",
      "2024-02-25            14              24             10\n",
      "\n",
      "--- 2025 ---\n",
      "            actual_hours  expected_hours  missing_hours\n",
      "2025-03-22            17              24              7\n",
      "2025-03-29            18              24              6\n",
      "2025-04-17            18              24              6\n",
      "2025-04-19            18              24              6\n",
      "2025-05-22            18              24              6\n",
      "2025-05-27            18              24              6\n",
      "2025-06-03            18              24              6\n",
      "2025-06-05            18              24              6\n",
      "2025-08-02            18              24              6\n",
      "2025-09-01            18              24              6\n",
      "2025-09-11            18              24              6\n",
      "2025-03-15            19              24              5\n",
      "2025-03-27            19              24              5\n",
      "2025-04-24            19              24              5\n",
      "2025-07-20            19              24              5\n"
     ]
    }
   ],
   "source": [
    "day_stats[\"year\"] = day_stats.index.year\n",
    "year_summary = (\n",
    "    day_stats.groupby(\"year\").agg(\n",
    "        days=(\"missing_hours\", \"size\"),\n",
    "        incomplete_days=(\"missing_hours\", lambda s: (s != 0).sum()),\n",
    "        missing_hours_total=(\"missing_hours\", \"sum\")))\n",
    "\n",
    "year_summary[\"incomplete_days_share\"] = year_summary[\"incomplete_days\"] / year_summary[\"days\"]\n",
    "\n",
    "print(\"\\n=== Year-level summary ===\")\n",
    "print(year_summary)\n",
    "\n",
    "# show the most incomplete days within each year\n",
    "TOP_K = 15\n",
    "top_days_each_year = (\n",
    "    day_stats[day_stats[\"missing_hours\"] > 0]\n",
    "    .sort_values([\"year\", \"missing_hours\"], ascending=[True, False])\n",
    "    .groupby(\"year\")\n",
    "    .head(TOP_K)\n",
    "    .drop(columns=[\"year\"])\n",
    ")\n",
    "\n",
    "print(f\"\\n=== Top {TOP_K} most incomplete days PER YEAR ===\")\n",
    "for y, block in top_days_each_year.groupby(top_days_each_year.index.year):\n",
    "    print(f\"\\n--- {y} ---\")\n",
    "    print(block)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c7ceb4da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spec columns:\n",
      " ['Currency', 'FileName', 'InAreaCode', 'InMapCode', 'InMapTypeCode', 'Name', 'OutAreaCode', 'OutMapCode', 'OutMapTypeCode', 'ProductionType', 'ResolutionCode', 'Specification', 'TimeSeriesID', 'Type', 'Unit', 'UnitID', 'UnitName', 'spec_hash']\n",
      "\n",
      "Market divisions (OutMapTypeCode preferred): ['BZA, BZN, CTA, CTY, LFA, MBA, SCA', 'BZA, CTA, LFA, SCA', 'BZN', 'BZN, CTA, CTY', 'BZN, CTA, CTY, IBA, IPA, MBA, SCA', 'BZN, CTA, CTY, IPA, LFA, LFB, MBA, SCA', 'BZN, CTA, CTY, LFA, LFB, MBA', 'BZN, CTA, CTY, LFA, LFB, MBA, SCA', 'BZN, CTA, CTY, LFA, MBA, SCA', 'BZN, CTA, CTY, MBA, SCA', 'BZN, CTA, LFA, LFB, MBA, SCA', 'BZN, CTA, LFA, LFB, MBA, SCA, SNA', 'BZN, CTA, LFA, MBA, SCA', 'BZN, CTA, MBA, SCA', 'BZN, CTA, SCA', 'BZN, CTY, LFB, MBA, SCA', 'BZN, IBA, IPA, LFA, MBA, SCA', 'BZN, IBA, IPA, MBA, SCA', 'BZN, IPA, MBA, SCA', 'BZN, LFB, MBA, SCA, SNA', 'BZN, MBA, SCA', 'BZN, SCA', 'CTA', 'CTA, CTY', 'CTA, CTY, LFA, LFB, MBA, SCA', 'CTA, CTY, MBA, SCA', 'CTA, LFA, SCA', 'CTA, MBA, SCA', 'CTY', 'CTY, IPA']\n",
      "Resolution codes: ['P1Y', 'P7D', 'PT15M', 'PT30M', 'PT60M']\n",
      "\n",
      "Total OutMapCodes: 94\n",
      "First 50 OutMapCodes: ['AL', 'AM', 'AT', 'AZ', 'BA', 'BE', 'BG', 'BY', 'Belarus (BY)', 'CH', 'CY', 'CZ', 'DE', 'DE(50Hertz)', 'DE(Amprion)', 'DE(TenneT GER)', 'DE(TransnetBW)', 'DE-AT-LU', 'DE-LU', 'DK', 'DK1', 'DK2', 'Denmark (DK)', 'EE', 'ES', 'FI', 'FR', 'GB', 'GB(ElecLink)', 'GB(IFA)', 'GB(IFA2)', 'GB, National Grid', 'GE', 'GR', 'HR', 'HU', 'IE', 'IE(SEM)', 'IT', 'IT-Brindisi', 'IT-Calabria', 'IT-Centre-North', 'IT-Centre-South', 'IT-Foggia', 'IT-GR', 'IT-North', 'IT-North-AT', 'IT-North-CH', 'IT-North-FR', 'IT-North-SI']\n",
      "\n",
      "Candidates (OutMapCode) containing any of ['DE']:\n",
      "['DE', 'DE(50Hertz)', 'DE(Amprion)', 'DE(TenneT GER)', 'DE(TransnetBW)', 'DE-AT-LU', 'DE-LU', 'Denmark (DK)']\n",
      "\n",
      "[!] These MAPCODES are not present in OutMapCode: ['DE_LU']\n",
      "Try: search_mapcodes(spec, contains='DE') or search_mapcodes(spec, prefix='10Y')\n",
      "\n",
      "Preview of matching series (first 50 rows):\n",
      "Empty DataFrame\n",
      "Columns: [Name, Type, OutMapCode, OutMapTypeCode, ResolutionCode, TimeSeriesID]\n",
      "Index: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l1/26hv4ds50v70g2zr2xbmd0bm0000gn/T/ipykernel_54789/495539176.py:58: FutureWarning: unique with argument that is not not a Series, Index, ExtensionArray, or np.ndarray is deprecated and will raise in a future version.\n",
      "  return sorted(pd.unique(codes))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import inspect\n",
    "\n",
    "# ---------- Helper functions (robust) ----------\n",
    "def get_spec(engine) -> pd.DataFrame:\n",
    "    return pd.read_sql_query(\"SELECT * FROM spec\", engine)\n",
    "\n",
    "def _pick_first_existing_col(df: pd.DataFrame, candidates: list[str]) -> str:\n",
    "    cols = set(df.columns)\n",
    "    for c in candidates:\n",
    "        if c in cols:\n",
    "            return c\n",
    "    raise KeyError(f\"None of these columns exist in spec: {candidates}\\nAvailable columns: {sorted(df.columns)}\")\n",
    "\n",
    "def get_market_divisions(spec_df: pd.DataFrame, which: str = \"out\"):\n",
    "    \"\"\"\n",
    "    Return unique market division codes.\n",
    "    Tries the common ENTSOE schema columns and picks what exists.\n",
    "    \"\"\"\n",
    "    if which.lower() == \"out\":\n",
    "        col = _pick_first_existing_col(spec_df, [\"OutMapTypeCode\", \"MapTypeCode\", \"out_map_type_code\"])\n",
    "    elif which.lower() == \"in\":\n",
    "        col = _pick_first_existing_col(spec_df, [\"InMapTypeCode\", \"MapTypeCode\", \"in_map_type_code\"])\n",
    "    else:\n",
    "        col = _pick_first_existing_col(spec_df, [\"OutMapTypeCode\", \"InMapTypeCode\", \"MapTypeCode\"])\n",
    "    return spec_df[col].dropna().unique()\n",
    "\n",
    "def get_map_codes(spec_df: pd.DataFrame, which: str = \"out\"):\n",
    "    \"\"\"\n",
    "    Return unique map codes.\n",
    "    In your pipeline you filter on OutMapCode, so default is 'out'.\n",
    "    \"\"\"\n",
    "    if which.lower() == \"out\":\n",
    "        col = _pick_first_existing_col(spec_df, [\"OutMapCode\", \"MapCode\", \"out_map_code\"])\n",
    "    elif which.lower() == \"in\":\n",
    "        col = _pick_first_existing_col(spec_df, [\"InMapCode\", \"MapCode\", \"in_map_code\"])\n",
    "    else:\n",
    "        col = _pick_first_existing_col(spec_df, [\"OutMapCode\", \"InMapCode\", \"MapCode\"])\n",
    "    return spec_df[col].dropna().unique()\n",
    "\n",
    "def get_map_codes_starting_with(spec_df: pd.DataFrame, prefix: str, which: str = \"out\"):\n",
    "    col = _pick_first_existing_col(spec_df, [\"OutMapCode\", \"MapCode\", \"InMapCode\"])\n",
    "    s = spec_df[col].fillna(\"\").astype(str)\n",
    "    return spec_df.loc[s.str.startswith(prefix), col].dropna().unique()\n",
    "\n",
    "def get_resolution_codes(spec_df: pd.DataFrame):\n",
    "    col = _pick_first_existing_col(spec_df, [\"ResolutionCode\", \"resolution\", \"resolution_code\"])\n",
    "    return spec_df[col].dropna().unique()\n",
    "\n",
    "def search_mapcodes(spec: pd.DataFrame, prefix: str | None = None, contains: str | None = None, which: str = \"out\") -> list[str]:\n",
    "    if prefix:\n",
    "        codes = list(get_map_codes_starting_with(spec, prefix, which=which))\n",
    "    else:\n",
    "        codes = list(get_map_codes(spec, which=which))\n",
    "    if contains:\n",
    "        contains_u = contains.upper()\n",
    "        codes = [c for c in codes if contains_u in str(c).upper()]\n",
    "    return sorted(pd.unique(codes))\n",
    "\n",
    "# ---------- Usage ----------\n",
    "engine = create_entsoe_engine()\n",
    "spec = get_spec(engine)\n",
    "\n",
    "print(\"Spec columns:\\n\", sorted(spec.columns))\n",
    "\n",
    "print(\"\\nMarket divisions (OutMapTypeCode preferred):\", sorted(get_market_divisions(spec, which=\"out\")))\n",
    "print(\"Resolution codes:\", sorted(get_resolution_codes(spec)))\n",
    "\n",
    "all_mapcodes = sorted(get_map_codes(spec, which=\"out\"))\n",
    "print(f\"\\nTotal OutMapCodes: {len(all_mapcodes)}\")\n",
    "print(\"First 50 OutMapCodes:\", all_mapcodes[:50])\n",
    "\n",
    "# \"Upload\" your desired codes here (edit these lists)\n",
    "COUNTRY_CODES = [\"DE\"]     # used only to search candidates\n",
    "MAPCODES      = [\"DE_LU\"]  # set to whatever you decide (OutMapCode)\n",
    "\n",
    "candidates = sorted(set().union(*[set(search_mapcodes(spec, contains=cc, which=\"out\")) for cc in COUNTRY_CODES]))\n",
    "print(f\"\\nCandidates (OutMapCode) containing any of {COUNTRY_CODES}:\")\n",
    "print(candidates[:200])\n",
    "\n",
    "missing = [c for c in MAPCODES if c not in all_mapcodes]\n",
    "if missing:\n",
    "    print(\"\\n[!] These MAPCODES are not present in OutMapCode:\", missing)\n",
    "    print(\"Try: search_mapcodes(spec, contains='DE') or search_mapcodes(spec, prefix='10Y')\")\n",
    "else:\n",
    "    print(\"\\n[OK] All MAPCODES exist in OutMapCode:\", MAPCODES)\n",
    "\n",
    "# Preview relevant series for those codes\n",
    "preview_cols = [c for c in [\"Name\",\"Type\",\"OutMapCode\",\"OutMapTypeCode\",\"ResolutionCode\",\"TimeSeriesID\"] if c in spec.columns]\n",
    "\n",
    "preview = spec[\n",
    "    spec[_pick_first_existing_col(spec, [\"OutMapCode\",\"MapCode\"])].isin(MAPCODES) &\n",
    "    spec[_pick_first_existing_col(spec, [\"OutMapTypeCode\",\"MapTypeCode\"])].astype(str).str.contains(r\"\\bBZN\\b\", na=False) &\n",
    "    spec[_pick_first_existing_col(spec, [\"Name\"])].isin([\"Prices\",\"Load\",\"Generation\"]) &\n",
    "    spec[_pick_first_existing_col(spec, [\"Type\"])].isin([\"DayAhead\",\"Actual\"])\n",
    "][preview_cols].drop_duplicates()\n",
    "\n",
    "print(\"\\nPreview of matching series (first 50 rows):\")\n",
    "print(preview.head(50))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "11a5ad72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n price series: 2 first IDs: [566, 3411]\n",
      "   TimeSeriesID            DateTime  Value\n",
      "0           566 2023-11-05 19:00:00   24.8\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import create_engine\n",
    "import urllib.parse\n",
    "\n",
    "ts = \"2023-11-05 19:00:00\" \n",
    "\n",
    "def create_entsoe_engine(config=None):\n",
    "    cfg = config or ENTSOE_DB\n",
    "    url = (\n",
    "        \"mysql+pymysql://\"\n",
    "        f\"{urllib.parse.quote_plus(cfg['user'])}:\"\n",
    "        f\"{urllib.parse.quote_plus(cfg['password'])}@\"\n",
    "        f\"{cfg['host']}:{cfg['port']}/{cfg['dbname']}\"\n",
    "    )\n",
    "\n",
    "    return create_engine(\n",
    "        url,\n",
    "        pool_pre_ping=True,      \n",
    "        pool_recycle=1800,       \n",
    "        pool_size=5,\n",
    "        max_overflow=10,\n",
    "        connect_args={\n",
    "            \"connect_timeout\": 10,\n",
    "            \"read_timeout\": 60,\n",
    "            \"write_timeout\": 60,},)\n",
    "\n",
    "engine.dispose()\n",
    "engine = create_entsoe_engine()\n",
    "targets_price = spec[\n",
    "    (spec[\"Name\"] == \"Prices\") &\n",
    "    (spec[\"Type\"].isin([\"DayAhead\", \"Actual\"])) &\n",
    "    (spec[\"OutMapCode\"].isin([\"ES\"]))   \n",
    "    # & (spec[\"OutMapTypeCode\"].astype(str).str.contains(r\"\\bBZN\\b\", na=False))\n",
    "]\n",
    "ids_list = targets_price[\"TimeSeriesID\"].dropna().astype(int).unique().tolist()\n",
    "print(\"n price series:\", len(ids_list), \"first IDs:\", ids_list[:10])\n",
    "ids = \", \".join(map(str, ids_list))\n",
    "q = f\"\"\"\n",
    "SELECT TimeSeriesID, DateTime, Value\n",
    "FROM vals\n",
    "WHERE TimeSeriesID IN ({ids})\n",
    "  AND DateTime = '{ts}'\n",
    "ORDER BY TimeSeriesID\n",
    "\"\"\"\n",
    "print(pd.read_sql_query(q, engine))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1fc38ebd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Name      Type OutMapCode    n\n",
      "0  Generation    Actual         ES  194\n",
      "1  Generation  DayAhead         ES    4\n",
      "2  Generation   Current         ES    2\n",
      "3  Generation  Intraday         ES    2\n",
      "4        Load  DayAhead         ES    1\n",
      "5        Load    Actual         ES    1\n"
     ]
    }
   ],
   "source": [
    "ts = \"2023-11-05 08:00:00\"\n",
    "\n",
    "q_any = f\"\"\"\n",
    "SELECT Name, Type, OutMapCode, COUNT(*) AS n\n",
    "FROM vals v\n",
    "JOIN spec s ON v.TimeSeriesID = s.TimeSeriesID\n",
    "WHERE s.OutMapCode = 'ES'\n",
    "  AND v.DateTime = '{ts}'\n",
    "GROUP BY Name, Type, OutMapCode\n",
    "ORDER BY n DESC;\n",
    "\"\"\"\n",
    "print(pd.read_sql_query(q_any, engine).head(30))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "ae74dc02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1456"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "START_YEAR      = 2020   \n",
    "VAL_START_YEAR  = 2022   \n",
    "TRAIN_END_YEAR  = 2023   \n",
    "FINAL_END_YEAR  = 2025   \n",
    "\n",
    "INIT_DATE_EXP   = pd.Timestamp(f'{START_YEAR}-01-01 00:00:00')     # hyper-parameter tuning: training start date\n",
    "VAL_INIT_DATE   = pd.Timestamp(f'{VAL_START_YEAR}-12-28 00:00:00') # hyper-parameter tuning: training end date\n",
    "TRAIN_END_DATE  = pd.Timestamp(f'{TRAIN_END_YEAR}-12-27 00:00:00') # hyper-parameter tuning: validation end date\n",
    "FINAL_DATE_EXP  = pd.Timestamp(f\"{FINAL_END_YEAR}-12-31 00:00:00\") # rolling window: evaluation end date\n",
    "\n",
    "train_val_days = (TRAIN_END_DATE - INIT_DATE_EXP).days\n",
    "train_days  = (VAL_INIT_DATE - INIT_DATE_EXP).days\n",
    "val_days   = (TRAIN_END_DATE - VAL_INIT_DATE).days\n",
    "train_val_days\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94ce7a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ddnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
